'''Name:''' Adithya Gurunathan

'''Email:''' agurunathan6@gatech.edu

'''Cell Phone:''' 470-641-5177

'''Interests:''' Machine Learning, Soccer, Poker, Coffee, Entrepreneurship

= Fall 2021 =


== Week 14: Nov 22, 2021 ==

===Overview:===

* Subteams updated on their weekly progress
* Peer evals open up on 29th November
* Dr. Zutty will let us know when the notebooks are due




== Week 13: Nov 15, 2021 ==

===Overview:===
* Subteams updated their progress during weekly meeting
* Worked on fixing the emade-viz repo along with Aditya Kumaran and Angela Young

===Lecture Notes:===

* Image Processing
  * Worked on testing X-ray dataset, where they will try to improve performance by implementing multiple changes including testing ROC and F1 score
* NLP
  * Identified output layer problem, and need to predict both start and end index. Return probability of word being start or end index.
  * Decided to reduce scope to regression for this semester
* Neural Architecture Search
  * Working on final presentation, discussed the set up of emade and the differences between their version of EMADE and bootcamp EMADE
* Modularity
  * Doing runs and debugged ARL selection methods
  * Fixed Cloudcopy.sh script for Google Collab runs
  * Established tasks for upcoming week: Working on EMADE-viz repo, fixing ARL selection, Improving Cloudcopy.sh script

===Sub-team Meeting Notes, November 18: ===
* Vincent will be continuing work on documentation, not sure if he will be able to work on unit tests as well
* Bernadette, Xufei, Tian, and Diptendu continue work on merging Cache V2 changes on modularity's fork of EMADE
* I will work with Angela and Aditya to work on graph visualizations
* Leul is working on the CloudCopy.sh script, might work on unit testing as well
* Gabe and Vincent discussed bugs on graph visualizations

=== Individual Notes: ===
* Working on cloning EMADE Viz fork, and the set up
* Cloned the fork and switched to branch 'ADFonlyAUC' branch
* Followed the instructions on ReadMe and created the virtual environment as following:
  * conda env create -f environment.yml
* Activated the environment:
  * conda activate emade-viz
* Installed packages in pip with the command:
  * pip install -r requirements.txt
* Ran the flask command:
  * flask run

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Weekly Notebook
|Complete
|November 15, 2021
|November 22, 2021
|November 19, 2021
|}


== Week 12: Nov 8, 2021 ==

===Overview:===

*Subteams shared their weekly progress during class
* Worked on joining as a worker process for EMADE extended-arl run on Google Colab

===Lecture Notes:===

* Subteam sharing of weekly progress
* Image Processing
  * Reprocessing data to work for 14 different classes of data.
  * Package conflicts with Windows 10 - possibly problem with PACE-ICE
  * Advised to set up a new environment with Python 3.8
* Modularity
  * Discussed bug with ARL algorithm, where when a child ARL was already used, causing matching to fail
  * Working on unit tests to prevent bugs like this in future
  * Planning for 2 runs a week for final presentation
* NLP
  * Introduced new members to team, had them to start working on PACE
  * Implementing primitives (first layer, modellling, outputs)
  * Exploring new ways to run with different word embeddings
  * Issues with output layer - probability layers output into words
* NAS
  * Want to set up an experimental loop to get data for final presentation
  * Changes to some individuals with ADFs
  * Might modify different usages with ARLs

===Sub-team Meeting Notes, Novemeber 11: ===
* Discussed and finalized plans to split up tasks for the rest of semester
* Task 1: Fixes for graph visualizations
  * Reoccuring bug where there were spikes in data, and best performing indiv not displayed
* Task 2: Find new ARL selection process
* Task 3: Improve CloudCopy.sh script to prevent recursive copying
* Task 4: Merge in Cache V2

=== Individual Notes: ===
* Error when trying to run Collab notebook - 'No Module found; GPFramework'
  * Fix involved getting 'bash reinstall.sh' command run properly
  * Changed command to: !python3 setup.py sdist; !python3 setup.py install
* Troubleshooted other errors to join the run as a worker process

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Weekly Notebook
|Complete
|November 8, 2021
|November 15, 2021
|November 8, 2021
|}

== Week 11: Nov 1, 2021 ==

===Overview:===
* Assigned to Modularity subteam - met with Angela, Vincent, Youssef
* Other members joining are Aditya, Leul, Nikihl
* Subteams updated on their progress for the week

===Lecture Notes:===

* Subteams updating on their weekly process:
* Image Processing:
  * Switching from detecting pneumonia to any kind of disease
* NLP:
  * Main team was split into subteams to test various combinations of their layers
* Neural Architecture Search:
  * Fixed time stopping callback glitches
* Modularity:
  * Migrating branch to CacheV2 to ensure compatability with Stocks team work
  * ARL sub-team will continue running emade
  * New members will assist with help running emade

===Individual Notes:===

* Cloned the Modularity branch of EMADE (https://github.gatech.edu/vhuang31/emade)
* Meetings will be held virtually on Thursdays, 11am (https://gatech.bluejeans.com/2224273722)
* Make a copy of Google Collab Notebook in Google Drive (https://colab.research.google.com/drive/1tUqnDzLHNg7RoYc4sarB3e2k3BvR_7D7?usp=sharing)
*  Notebook:
  * Edit the second step to rename personal directory: %cd /content/gdrive/MyDrive/INSERT-DIRECTORY-NAME-HERE/
  * Run the commands in the notebook except for !python src/GPFramework/seeding_from_file.py [input xml template] [seeding file] command (only for master process)
  * Ensure that the !python src/GPFramework/launchEMADE.py -w templates/INSERT-TEMPLATE-FILE-NAME command has the -w flag, to join as worker process, not master

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Clone Modularity Repo, setup other essentials
|Complete
|November 1, 2021
|November 8, 2021
|November 1, 2021
|-
|Update Weekly Notebook
|Complete
|November 1, 2021
|November 8, 2021
|November 1, 2021
|}

== Week 10: Oct 25, 2021 ==

===Overview:===
* Presentation Day - presented our EMADE findings, and compared with ML/ MOGP findings earlier this semester
* Presentation Link: https://docs.google.com/presentation/d/1ShDz-7hPoor3ExWA9BKqiSzqn-G4ufgBYWor-mtlzdU/edit?usp=sharing
* Watched presentations fron the different subteams in AAD

===Lecture Notes:===

* Team presented our work and findings on ML, MOGP, and EMADE models in the Titanic Dataset
  * Talked about the Pareto frontiers, AUC, and how we chose certain parameters
  * Highlighted the difficulties and mistakes we made to improve them in future
  * Explained the shortcomings of our model for EMADE, and why we were only able to run in for 10 gens
* Understood the work done in other subteams at AAD, such as NLP, Image Processing, NAS, Stocks, Modularity

===Individual Notes:===

* Presented on ML and MOGP models we used in our semester so far, and why explained why we chose certain parameters and arrived at certain results
* Took notes on other sub-team presentations to find out which team I would like to work with

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Weekly Notebook
|Complete
|October 25, 2021
|November 1, 2021
|October 28, 2021
|-
|Predicting Titanic Survivors with ML, MOGP, and Emade
|Complete
|October 25, 2021
|November 1, 2021
|October 28, 2021
|-
|Choose Subteam
|Complete
|October 25, 2021
|November 1, 2021
|October 28, 2021
|}


== Week 9: Oct 20, 2021 ==

===Overview:===
* Working session with VIP AAD alumni to use EMADE on Titanic Dataset
* Alumni guided us on how to resolve certain issues, and helped with troubleshooting joining as a worker process with my team

===Lecture Notes:===

* Configuration and discussion on how to run all processes to use EMADE
* Team learnt how to resolve our issues with EMADE running locally, and guided rest of the team in joining the EMADE worker processes

===Sub-team Meeting Notes:===

* Team was able to ensure that host process was working smoothly, and spent the rest of time troubleshooting the other worker processes
* Encountered difficulty with slow running time for EMADE across master processes and worker processes
  * Team was barely at 11th generation after over 3 days of runtime on EMADE, much slower than the usual expected speed
* Worked on the final presentation on 10/25, discussed content and delegated work

===Individual Notes:===

* Worked on setting up worker process and running EMADE
  * Due to hardware limitations on laptop, setup involved several backtracks and work arounds to ensure MySQL was running correctly
* Helped with others setting up EMADE and connecting their worker processes
* Worked on mid-term presentation slides for 10/25

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook
|Completed
|October 13th, 2021
|October 21th, 2021
|October 21th, 2021
|-
|Sub-team Meeting
|Completed
|October 13th, 2021
|October 16th, 2021
|October 16th, 2021
|-
|Running EMADE on Titanic Dataset
|In Progress
|October 13th, 2021
|October 20th, 2021
|N/A
|-
|}


== Week 8: Oct 13, 2021 ==

===Overview:===
* Class was spent working on Emade master process to run & joining worker processes
* Sub-team meetings were spent troubleshooting, and ensuring MySQL server was running smoothly

===Lecture Notes:===

* Workday: Learn about setting up and troubleshotting a MySQL server.
  * Server host command: mysql -h hostname -u username -d database_name -p
* Clarified doubts on process with Dr.Zutty, and resolved difficulties running EMADE

===Sub-team Meeting Notes:===

* Team managed to set up EMADE to recognize & write to our MySQL database
* Worked on steps to set up the generation process for EMADE
* Resolved Python version error, where Python 3.8.8 was incompatible with multiprocess package
* Errors we encountered:
  * Issue where fitness values for individuals were (inf, inf, inf)
  * EMADE error stated that "Tree missing valid primitve for data type"
* Solution:
  * We investigated and decided problem might have to do with false positive and false negative evaluation functions in evalFunctions.py

===Individual Notes:===

* Did research to investigate why the fitness values for individuals were returning as infinity
* Helped with creating our custom evaluation functions for FNR and FPR
* Cross-checked preprocessed data we had, to ensure that the columns were shuffled whilst being converted from pandas data to numpy arrays
* Worked on the process of joining the MySQL server for worker processes. Troubleshooted multiple issues with setup, such as version conflict and unexpected crashing

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update lecture notes
|Completed
|October 13th, 2021
|October 20th, 2021
|October 17th, 2021
|-
|Review lecture notes
|Completed
|October 13th, 2021
|October 20th, 2021
|October 14th, 2021
|-
|Worked on multiple issues
|Completed
|October 13th, 2021
|October 20th, 2021
|October 20th, 2021
|-
|Tried setting up worker process for MySQL
|In progress
|October 13th, 2021
|October 20th, 2021
|October 20th, 2021
|-
|Sub-Team Meetings
|Completed
|October 13th, 2021
|October 20th, 2021
|October 16th - 19th, 2021
|}

== Week 7: Oct 6, 2021 ==

===Overview:===
* Worked on Notebook for Midterm Evaluation
* Attended lecture on Introduction to emade
* Received instructions for next assignment

===Lecture Notes:===
* What is EMADE
  * EMADE is Evolutionary Multi-Objective Algorithm Design Engine
  * Combines a multi-objective evolutionary search with high-level primitves to automate process of designing ML algorithms

* Setup Instructions
  * Configure a mysql 5.x server on machine
  * Download and install git-lfs
  * Clone EMADE repository
  * Run setup module to install the package
    Commands: conda env create -f emade.yml
    python setup.py install

* Running EMADE
  * Navigate to top level directory and run
    python src/GPFramework/launchGTMOEP.py templates/input_titanic.xml

* Input File
  * input file is an xml document configuring all moving parts in EMADE
  * Configure python to run where all EMADE python dependencies are installed

* Databse Configuration:
  * Configure MySQL connection
    If running locally, server can be localhost or 127.0.0.1
  * Username and password are for MySQL & user should have full permissions to database

* Datasets
  * EMADE runs across multiple datasets - preprocessed into gzipped csv files
  * Each train and test file create a DataPair object in EMADE
  * Can decompress them or use an editor such as gvim to view while zipped
  * Each row corresponds to an instance, each column is a feature, final column is truth
  * EMADE reserves last column for fitting models (train data) and scoring (test data)

* Input File, continued:
  * Objectives are described next
  * Weight specifies if it should be minimized (-1.0) or maximized (1.0)
  * <evaluationFunction> specifies name of a method in src/GPFrameowrk/evalFunctions.py
  * Achievable and goal are used for steering optimization, lower and upper used for bounding

* Parameters
  * Evaluation specifies where eval func specified in objectives section live, how much memory allowed to use
  * <workersPerHost> specifies how many evaluations to run in parallel
  * Evolution parameters: hyperparameters that affect evolutionary process

* Connect Worker Process to a Peer
  * Use -w flag along with peer's server info in dbconfig to allow computer act as a worker process for peer's master process
    python src/GPFramework/launchGTMOEP.py templates/input_titanic.xml -w
  * dbconfig in input file specifies IP address and not localhost
  
* EMADE Structure
  * src/GPFramework is mainbody of code
  * datasets/ is where test datasets live
  * templates/ is where input files live

===Assignment===
* Run EMADE as a group - 1 person have SQL server set up and act as master process, rest connect workers
* Run for substantial generations
* Learn SQL
* Make plot of non-dominated frontier, compare with ML & MOGP
* Presentation of Monday the 25th

===Sub-team Meeting Notes:===
* Team members successfuly installed EMADE and MySQL on their laptops
* Configured input XML file to run Titanic Dataset, after meeting with Dr.Zutty
* Modified data splitter script to one-hot encode "Embarked" feature to improve algorithm. Reflected changes in our MOGP model as well.
* Debugging error where EMADE is unable to evaluate individuals in queue. Plan to fix the issue in the next sub-team meeting.

===Individual Notes:===
* Installed Anaconda and installed necessary dependencies for EMADE
* Cloned and installed EMADE from GitHub
* Set up Git and MySQL on computer
* Researched how MySQL worked, and the specific commands for various functions
* Resolved issues faced during sub-team meeting, such as debugging the algorithm for Titanic dataset

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Weekly Notebook
|Complete
|October 6, 2021
|October 13, 2021
|October 8, 2021
|-
|Run EMADE
|
|October 6, 2021
|October 13, 2021
|October 9, 2021
|}


== Week 6: Sep 29, 2021 ==

===Overview:===
* Presentation Day
* Took notes from other group's presentation on how we could improve our model
* Submitted CSV file for our lab containing best MOGP algorithms

===Lecture Notes:===
* Link to Group 2 Presentation: https://docs.google.com/presentation/d/1E5DIPJOt7uBeqUeYklg6TE7X7PTdOsaFdUjTDCrttkU/edit?usp=sharing
* Discussed one-hot encoding for columns like Embarked to prevent ML models from creating causal link between non-binary integer values

===Individual Notes:===
* Presented and explained about ML vs MOGP AUC, and the primitives used in our lab
* Wrote code with teammate for generating a csv file containing best MOGP algorithms
  Link: https://drive.google.com/file/d/1U3DTjQCR9zZx5LvaO1SqspM6T-hH7Dig/view?usp=sharing
* Completed Mid-term Peer Evaluation for teammamtes

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Weekly Notebook
|Complete
|September 29, 2021
|October 6, 2021
|September 29, 2021
|-
|VIP Peer Evaluation Survey
|Complete
|September 29, 2021
|October 6, 2021
|September 29, 2021
|}

== Week 5: Sep 22, 2021 ==

===Overview:===
* Discussed last week's project
* Attended presentation on guidelines to effectively present
* Introduction to this week's assignment

===Lecture Notes:===
* Week 5 Assignment
  * Utilize MOGP to find a set of pareto optimal algorithms for the titanic dataset
  * Tree will take in same inputs as the ML model
  * Both strongly/ loosely typed GP allowed
  * Use selection, crossover, mutator, to write genetic loop
  * Write evaluation function, with False Negative and False Positive Rate as criteria
  * Comparison of Pareto Front of MOGP and GP
  * Submit .csv files with columns of passengerID, each representing pareto optimal algorithms
  * Create a presentation for Week 6, to share and present findings

* Effective Presentation Guidelines
  * Ensure to introduce team on first slide
  * Include title, date on first slide
  * Page numbers are essential for audience to reference material afterwards
  * Write text in slides, but do not present by reading off it

===Titanic Dataset (MOGP) Project===
====Sub Team Meeting Notes====
* Discussed steps required to attain desired output for the experiment
* Chose same relevant columns as previous week's assignment (Pclass, Sex, SAge, SibSp, Parch & Embarked)
* Pre-processed data, and used NaN_ maps for encoding of string values
* Used primitives (arithmetic & logical) from Lab 2 to fulfil requirements of this Lab

* Functions used for our lab
  * Selection: SPEA2
  * Evaluate: EvalSymbReg
  * Mate: cxOnePoint
  * Mutate: mutUniform

* Wrote an evaluation function evalSymbReg()
  * Using activation function arctan() to map values from function to values between 0 & 1.
  * Activation function threshold was set to 0.5: Lower values were treated as zero, higher values treated as 1
  * Computed False Negatives, False Positives, True Negatives, True Positives
  * When TP OR TN = 0, function will set FNR/FPR to 1

* Designed and wrote our genetic loop
  * Population: 100, with 30 Generations
  * In each subloop, select next generation individuals and clone them. Apply crossover & mutation
  * Mating probability set to 0.4
  * Indiviuals with invalid fintesses were evaluated
  * HallOfFame (hOF) was updated with best individuals across generations in population

* Key Findings:
  * Best Individual: multiply(cos(add(subtract(Sex, Age), add(add(Sex, Sex), Parch))), Sex)
  * Fitness: (0.0, 0.37966101694915255)
  * MOGP AUC: 0.1256530649754448
  * ML AUC: 0.18129

* Conclusion
  * To improve accuracy of genetic programming models, we experimented with mate, mutate, selection methods
  * Tried different primitves used in Lab 2 to optain optimal solutions for our program
  * Area under curve is lower for MOGP than ML models
  * MOGP is more dominant than ML models

* Worked on presentation content to include findings and takeaway
  Link: https://docs.google.com/presentation/d/1E5DIPJOt7uBeqUeYklg6TE7X7PTdOsaFdUjTDCrttkU/edit?usp=sharing

====Individual Notes====
  * Read up on different symbolic regression evaluation functions and how they work
  * Researched the differences between NSGA II and SPEA2 selection algorithms
  * Contributed to group discussions and code development for genetic loop
  * Worked on presentation material

'''<i>Action Items</i>'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update lecture notes
|Completed
|September 22nd, 2021
|September 29th, 2021
|September 28th, 2021
|-
|Review lecture slides
|Completed
|September 22nd, 2021
|September 29th, 2021
|September 28th, 2021
|-
|Held team meeting #1
|Completed
|September 22nd, 2021
|September 29th, 2021
|September 26th, 2021
|- 
|Held team meeting #2
|Completed
|September 22nd, 2021
|September 29th, 2021
|September 28th, 2021
|- 
|Completed Python notebook
|Completed
|September 22nd, 2021
|September 29th, 2021
|September 29th, 2021
|- 
|Made Presentation
|Completed
|September 22nd, 2021
|September 29th, 2021
|September 28th, 2021
|}

== Week 4: Sep 15, 2021 ==

===Overview:===
* Assigned to Sub-teams for Project
* Obtained overview of Sci-kit learn and other ML-related libraries
* Discussed about Titanic dataset

===Lecture Notes:===
*Received sub-team assignment based on GA (ML & Python Proficiency)
*Assigned to sub-team #2
  *Members: 
    Adithya Gurunathan
    Aditya Kumaran
    Manas Harbola
    Rohan Batra
    Yisu
*Introduced to Titanic Dataset on Kaggle
    Problem: Implement a model predicting if a passenger on the Titanic either survived or died. Create and document 5 separate co-dominant models in your subteam and generate a prediction csv file for each model.
* Codominance: Two algorithms are said to be codominance when neither dominates the other on every objective.
* Objectives for Titanic Dataset: False Positive Rate (FPR) and False Negative Rate (FNR)
* Reviewed preprocessing data notebook in Jupyter and learned how to adapt it for our training models
* Breakout into sub-teams for introductions and setting up team meetings.

===Titanic Dataset (ML) Project===
====Sub Team Meeting Notes====
* Created a Discord chat to discuss the assignment, share ideas and schedule meetings
* Had a scheduled meeting at 2:45 PM on 18th September on a virtual call
* Set up a Python notebook, opening it via Jupyter through Anaconda
* Cleaned the dataset by removing following parameters, after discussing they do not affect passenger survival significantly:
  * Name
  * PassengerID
  * Ticket Number
  * Fare
* Kept 'Embarked' & 'Sex', mapped them to numerical values for easier comprehension when using a dictionary
* Other parameters that impacted survival rate could be reasons such as not willing to separate from their family, class, age, gender etc.
* Created a NaN_ map to fill in missing Age and Embarked values
* Ran different models using Sci Kit documentation
  * Used RandomForestClassifier and MLP classifier - were co-dominant algorithms
  * Found 3 other algorithms: AdaBoostClassifier, SVM, DecisionTreeClassifier. Changed parameters around in order to ensure algorithms were co-dominant. Led to a change in algorithmic accuracy, but not significant wnough to impact objective of confusion matrix
* Wrote functions to plot scatter graphs and save 5 different csv files for each model
* Pareto Optimal Frontier:
  **  Rohan = DecisionTreeClassifier (min_samples_leaf=30). False Positive = 9, False Negative = 45
  **  Manas = RandomForestClassifier (n_estimators = 100, max_depth = 5, min_samples_leaf = 5, criterion = entropy, random_state = 2). False Positive = 18, False Negative = 29. 
  **  Aditya = AdaBoostClassifier. False Positive = 32, False Negative = 21. 
  **  Adithya =  MLP Classifier. False Positive = 26, False Negative = 26.
  **  Yisu = SVM (used svm.SVC, sigmoid = kernel). False Positive = 0, False Negative = 104. 

====Individual Notes====
* Researched common models for classification, using MLP classifier
* Researched on SciKit Learn, StackOverflow, Medium to understand how to select appropriate parameter values
* Added code to generate prediction CSV
* Added cells for plotting performance on FPR/FNR axis to demonstrate co-dominance with other algorithms

'''<i>Action Items</i>'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update lecture notes
|Completed
|September 22nd, 2021
|September 29th, 2021
|September 26th, 2021
|-
|Review lecture slides
|Completed
|September 22nd, 2021
|September 29th, 2021
|September 25th, 2021
|-
|Held team meeting #1
|Completed
|September 22nd, 2021
|September 29th, 2021
|September 26th, 2021
|- 
|Held team meeting #2
|Completed
|September 22nd, 2021
|September 29th, 2021
|September 28th, 2021
|- 
|Completed Python notebook
|Completed
|September 22nd, 2021
|September 29th, 2021
|September 29th, 2021
|- 
|Made Presentation
|Completed
|September 22nd, 2021
|September 29th, 2021
|September 28th, 2021
|}



== Week 3: Sep 8, 2021 ==

===Self Evaluation Form===
https://drive.google.com/file/d/1wtvbb6bHFMIa8Im8UXZG4dJM4Is9ZHKi/view?usp=sharing

===Overview:===
* Reviewed multiple objectives in MOGA & MOGP
* Overview of Pareto Optimality
Rated Python & ML skills

===Lecture Notes:===
* Gene Pool is the set of genome to be evaluated during the current generation
  *Genome
    Genotypic description of an individals
    DNA
    GA = set of values
    GP = tree structure, string
  *Search Space
    Set of all possible genomes
    For AAD - all possible algorithms
    How big is search space
    Why is this important for algorithm design?

* Evaluation of a Genome associates a genome with a set of scores

* Objectives

* Objective Space

* Evaluation

* Classification Measures
  * Data Set - Positive Samples (P), Negative Samples (N)
  * Classifier
  * Confusion Matrix 
    (Actual Positive, Actual Negative, Predicted Positve, Predicted Negative)
    (True Positive, False Negative, False Positive, True Negative)

* Maximization Measures
  * Sensitivity of True Positive Rate (TPR)
    TPR = TP/P = TP/(TP+FN)
  * Specificity (SPC) Or True Negative Value (TNR)
    TNR = TN/N = TN/(TN+FP)
  * Want to achieve 1 for both metrics

* Minimization Measures
  * False Negative Rate (FNR)
    FNR = FN/P = FN/(TP+FN)
    FNR = 1 - TPR
  * Fallout or False Postive Rate (FPR)
    FPR = FP/N = TN/(FP+TN)
    FPR = 1 - SPC

* Other Measures
  * Precision or Postive Predictive Value (PPV) - Bigger is better
    PPV = TP/(TP+FP)
  * False Discoevery Rate (FDR) - Smaller is better
    FDR = FP/(TP+FP)
    FDR = 1 -PPV

   * Negative Predictive Value (NPV) - Bigger is better
     NPV = TN/(TN+FN)

   * Accuracy (ACC)
     ACC = (TP+TN)/PN
     ACC = (TP+TN)/(TP+FP+TN+FN)

* Objective Space

* Pareto Optimality
  * Individual is Pareto Optimal if there is no other individal in population that outperforms individual on all objectives
  * Set of all Pareto Individals is known as Pareto Frontier - represent unique contributions
  * Want to drive slection by favoring Pareto individuals
    But also maintain diversity by giving all individuals some probability of mating

* Nondominated Sorting Genetic Algorithm II (NSGA II)
  * Population is separated into nondomination ranks
  * Individuals selected using binary tournament
  * Lower Pareto ranks beat higher Pareto ranks
  * Ties on same front are broken by crowding distance
    Summation of normalized Euclidian distances to all points within the front
    Highest crowding distance wins

* Strength Pareto Evolutionary Algorithm 2 (SPEA2)
  * Each individual is given a strength S
    S is how many others in the population it dominates (draw horizontal and vertical lines, see how many points enclosed)
  * Each individual recieves a rank R
    R is sum of S's of the individuals that dominate it
    Paretio individuals are nondominated and recieve an R of 0
  * Distance to k^th nearest negither is calculated (sigma^k) and a fitness of R+1/(sigma^k + 2)

===Lab 2: Multi Objective Genetic Programming (Part 2)===

* Followed instructions in notebook and plotted the Pareto frontier
* Goal is to minimize the AUC, because we want to minize the tree size of Pareto individuals & mean squared error

* Area Under Curve with original configuration: 2.423721990054
* Best Individual is: negative(cos(multiply(add(cos(sin(cos(sin(cos(tan(x)))))), cos(x)), tan(x)))), fitness is (0.289613390243, 15.0)

* To reduce AUC by at least 25% by parameter tuning:
  * Removed sin and cos primitives:
    * AUC: 1.0688239759291 , approx 56% reduction
    * Best Individual: subtract(multiply(x, tan(multiply(x, x))), x), fitness of (0.6669255057183378, 8.0)
  * Removed all three trigonometric primitive:
    * AUC: 0.6912744703006891, approx 72% reduction
    * Best individual: subtract(x,x), fitness of (0.7223441838209306, 3.0)

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook
|Completed
|September 8th, 2021
|September 15th, 2021
|September 12th, 2021
|- 
|Complete Self-Evaluation rubric
|Completed
|September 8th, 2021
|September 15th, 2021
|September 13th, 2021
|-
|Review lecture slides
|Completed
|September 8th, 2021
|September 15th, 2021
|September 12th, 2021
|-
|Finish Lab 2, Part 2
|Completed
|September 8th, 2021
|September 15th, 2021
|September 14th, 2021
|}


== Week 2: Sep 1, 2021 ==

===Overview:===
* Attended lecture on Genetic Programming, learnt about Tree Representation, discussed Crossover, Mutation and Symbolic Regression in GP Algorithms
* Completed Lab 2: Symbolic Regression

===Lecture Notes:===
* Genetic Algorithms are population-based solution, drawing concepts from natural selection, properties of DNA to modify and exchange information between individuals
* Instead of taking an individual and having a function evaluator to obtain objective scores, the individual is the function itself
  * Individual: [0,1,0,1,0,1] -> Evaluator -> Objective Score: 3
    Input Data: [0,1,2,3,4,5] -> Individual (y = x^2) -> [0,1,4,916,25] -> Evaluator
* Tree Representation: Representing program as a tree structure
  * Nodes are called primitives - represent functions
  * Leaves are called terminals - represent parameters
* Trees are converted to Lisp preordered parse trees
  * Operators are followed by inputs
  * Tree for f(x) - 3*4 + 1 is expressed as [+,*,3,4,1]
  * Parse tree of f(x) = 2-(0+1) is [-,2,+,0,1]
* Crossovers are handled by exchanging subtrees in GP
  * Start by randomly picking a point in each tree
  * These points and everything below create subtrees
  * Subtrees are exchanged to produce children
* Mutation in GP involves:
  * Inserting a node or subtree
  * Deleting a node or subtree
  * Changing a node
* Example: Symbolic regression
  * Using simple primitves, we can use GP to evolve a solution to y = sinx
  * Primitves include: +,*,-,/
  * Terminals include integers and variable input X
  * Calculus utilizes Taylor series to approach this problem
* Evaluating a tree
  * Feed a number of input points into function to get outputs
  * Run f(x) to get results, and measure error between output of f(x) & expected output (e.g. sum square error)
* Primitives that make evolution easier:
  * Power(), Factorial(), Sin(), Cos(), Tan()
 
===Lab 2: Symbolic Regression (Part 1)===

This lab explores the evolutionary algorithm by running it several times to observe the improve in best fit individuals. Attempted to reduce error to almost zero, by tring different mutation and primitives.

* Tried deriving/inhering individuals from DEAP's PrimitiveTree instead of lists
* Added primitves to primitve set and chose mutation for most optimized solution
* Compiled primitve codde to generate evaluation function. Optimizing to find min values that approach zero faster
* Modified lab code in 4 ways

*Running algorithm with no modifications
  * Original Lab 2
  * Best individual: add(add(add(multiply(add(multiply(multiply(x, x), x), multiply(x, x)), x), multiply(x, x)), x), subtract(x, x)), (8.59033944318508e-17)
  * Depicts requirement for a more optimized and consistent solution to obtain minimum efficiently
  
* Program with added mutation
  * Best individual: add(x, multiply(x, add(multiply(x, x), add(multiply(multiply(x, x), x), x)))), (1.1608501979530989e-16)
  * Mutation added was mutShrink

* Program with Primitives
  * Added primitives were np.square and np.absolute
  * Best individual was add(add(multiply(x, x), multiply(multiply(add(square(x), x), x), x)), x), (1.0172711918255375e-16,)

* Program with Primitives and Added Mutation
  * Using mutInsert fir mutation
  * First pair of primitives: (sin and square)
  * Second pair of primitives: (absolute, cos)
  * Best individual: add(add(multiply(add(x, multiply(x, x)), x), multiply(x, multiply(multiply(x, x), x))), x), (9.846703645016068e-17,)





===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Join Slack
|Completed
|August 25, 2021
|September 1, 2021
|August 26, 2021
|-
|Set up Notebook
|Completed
|August 25, 2021
|September 1, 2021
|August 26, 2021
|-
|Install and set up DEAP library for Python
|Completed
|August 25, 2021
|September 1, 2021
|August 28, 2021
|-
|Lab 1
|Completed
|August 25, 2021
|September 1, 2021
|August 30, 2021
|-
|}



== Week 1: Aug 25, 2021 == 

===Overview:===

* Discussed course format and expectations, location of the course GitHub (https://github.gatech.edu/emade/emade/), Individual Notebooks, Assignment 1. 
* Attended lecture on Introduction to Genetic Algorithms.
* Completed Lab 1: Genetic Algorithms with DEAP 

===Lecture Notes:===

* Introduced to concept of Genetic Algorithms that mimic nature's evolutionary processes (mating, selection, mutation, reproduction, etc.) in order to maximize the fitness of individuals in a population of data
* Keywords/ Concepts
  *Individual: One specific candidate in population
  *Population: Group of individuals whose properties will be altered
  *Objective: A value used to characterize individuals that you are trying to maximize/minimize
  *Fitness: Relative comparison to other individuals, e.g relative task performance
  *Evaluation: Function that computes the objective of an individual
  *Selection: Represents 'survivial of fittest', where better individual are preferred, allowing them to pass on their genes
    - Fitness Proportionate: Greater the fitness value, higher the probability of being selected for mating
    - Tournament: Competition among individuals, where winners are selected for mating
  *Mating/Crossover: Represents mating between individuals
  *Mutate: Introducing random modifications, to maintain diversity
  *Algorithms: Various set of steps to create a solution or best individuals

* Steps behind Genetic Algorithm:
  1) Randomly initialize population
  2) Determine fitness of population
  3) Repeat following steps until best individual is good enough
     a) Select parents from population
     b) Perform crossover on parents creating population
     c) Perform mutation of population
     d) Determine fitness of population

===Lab 1: Genetic Algorithms with DEAP===

This lab explores One Max Problem & N-Queens Problem, and we will be defining genetic algorithms to solve them both.


'''Setup:'''

* Downloaded & installed Anaconda for Windows 10
* Launched JupyterLab using Anaconda Navigator
* Retrieved DEAP Problem from Calendar/Assignment 1st Semester /Week 1; saved file as .ipynb extension and imported it into JupyterLab
* Installed DEAP using pip under new Terminal window in JupyterLab

'''One Max Problem'''
One Max Problem is a problem that only performs the calculation of the maximum value from number of binary strings. The goal is to produce an individual whose list sums up to max value, which is all 1s. I followed the following steps for this lab:

* Import base, creator, * tools from Python random module and DEAP module
* Define fitness objective and individual classes using DEAP's creator
* Define tool functions for evaluation - evalOneMax(), mating, mutation and selection
* Define individuals in population defined as 1s and 0s, population of 300
* Define evaluation function (evalOneMax()) for fitness ibjective as sum of all 1s in a string
* Define evolutionary loop of 40 generations, and performed tournament selection on population to clone selected offspring for creating instances from previous iteration
* Ran mating function with 50% probability, Mutated individuals with 20% probability
* Observations: After 40 gnerations, max fitness score (100.0) was almost always achieved, but not guaranteed.


'''N Queens Problem'''
The objective of N Queens Problem is to determine a configuration of n queens on a n x n chessboard such that no queen can be taken by another. For this version, each queen was only assigned to one column, with only one queen able to be on each line. I followed the following steps for the lab:

* Import necessary DEAP modules, and define fitness objectives & evaluation function
* Fitness Objective: Minimize number of conflicts between two queens on nxn chessboard. Fitness weighted negatively
* Evaluation Function: Returns number of conflicts between queens along diagonal of chessboard
* Individual: Defined as list of n numbers that denote the column location of n queens in a nxn chessboard
* Define partially matched crossover function and mutation function to shuffle indices
* Run main evolutionary loop for 100 generations
* Findings: Algorithm often gets to a minimum of 1.0 quickly, but does not consistently achieve minimum of 0.0


===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Join Slack
|Completed
|August 25, 2021
|September 1, 2021
|August 26, 2021
|-
|Set up Notebook
|Completed
|August 25, 2021
|September 1, 2021
|August 26, 2021
|-
|Install and set up DEAP library for Python
|Completed
|August 25, 2021
|September 1, 2021
|August 28, 2021
|-
|Lab 1
|Completed
|August 25, 2021
|September 1, 2021
|August 30, 2021
|-
|}