== Team Member ==
[[files/PD4nb-66 400x400.jpg|thumb|80x80px]]
'''<big>Team Member: Anika B. Islam</big>'''

'''<big>Email: aislam43@gatech.edu</big>'''

'''<big>Cell Phone: 571-477-7866</big>'''

== '''Week 16(December 2nd)''' ==
Created a presentation and presented it.

'''''Link to presentation:'''''

https://gtvault-my.sharepoint.com/:p:/g/personal/aislam43_gatech_edu/EfmFjGoUxphKqxWjFTBFg1IBojcx4rxZhS832dz8jtJTEw?e=Xrf6wG

== '''Week 15 (November 27th)''' ==
-I ran 4 trail of APE over break, APE was running with the un-preprocessed titanic datasets, Oscar ran regular EMADE

-Each trail was approximately 10 hours

-Marc, Oscar, and I came up with code to get all the code from the SQL database and graph the area under Pareto front

'''''Results of APE:'''''

[[files/Ape3.png|frameless|300x300px]][[files/Ape 4.png|frameless|300x300px]]
[[files/APE 1.png|left|frameless|300x300px]]
[[files/Figure 2.png|frameless|300x300px]]

== '''Week 14 (November 20th)''' ==
-The team decided that we also wanted to implement a step before the image preprocessing ran that basically expanded the dataset, this would be done before EMADE ran so our truth data length and the data length remained the same

-During this week we were all still kind of confused as to how image stores image data and how to work with it

- We also downloaded the cancer dataset to run image data with EMADE on it

https://www.kaggle.com/c/histopathologic-cancer-detection/data

This dataset was composed of a large number of small pathology images to classify

== '''Week 13 (November 14th)''' ==
-Looked at the Keras documentation and there is already a function in there that does basically everything we wanted in to do 

https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/apply_affine_transform

It basically had a bunch of parameter for all the augmentations we wanted to do with the data  so used the keras function to make 3 separate primitives

'''def keras_rotate(  data, theta=0)'''

theta=(theta%360)+1

data=f.keras.preprocessing.image.apply_affine_transform(

data,

theta,

)

return data

'''def keras_shift(  data,tx=0,ty=0,fill_mode=0)'''

if fill_mode%4==0:

fill_mode='constant'

elif fill_mode%4==1:

fill_mode='nearest'

elif fill_mode%4==2:

fill_mode='reflect'

else:

fill_mode='wrap'

data=tf.keras.preprocessing.image.apply_affine_transform(data,tx,ty,fill_mode)

return data

'''def keras_shear(  data, shear=0)'''

data=tf.keras.preprocessing.image.apply_affine_transform(

data,shear)

return data

These were added into spatial_methods.py

== '''Week 12 (November 7th)''' ==
Talked to Austin about how to implement the image preprocessing primitives

-Originally, our idea was to create primitives that augmented the dataset and then was added to the dataset so it was expanded. This issue with that was that the truth data would no longer line up with our dataset. 

-We figured a solution to solve that is to only expand our dataset by a multiple of an integer instead of decimals and then expand our dataset by the same multiple

-Another solution we looked at was making our own evaluation method

- We also talked to Austin and he mentioned that spatial_method does not have any shifting or rotating primitives yet

Notes from Austin:
[[files/20191118 170620.jpg|left|frameless|200x200px]]

[[files/20191118 170622.jpg|frameless|200x200px]]

== '''Week 11 (October 31st)''' ==
I was sick with the Flu, so I missed all my classes that week

== '''Week 10 (October 24th)''' ==
'''Updates:'''

So we had two new members Marc and Ford. After talking to them about their preference on whether or not they wanted to do stream or Image data we came to the conclusion that we were going to stick with Image data preprocessing.We also showed Marc and Ford our code and how it was implemented in EMADE.

We also decided that our official meeting time will be 4:30 at Friday

'''Goals:'''

We will be meeting with Austin on November 8th, to discuss what to do with image data.

== '''Week 9 (October 17th)''' ==
Finished presentation and presented it

Link to presentation:https://gtvault-my.sharepoint.com/:p:/g/personal/aislam43_gatech_edu/EfmFjGoUxphKqxWjFTBFg1IBpF4xsuALQyl_F7SOoXfYjQ?e=vkgNAJ

== '''Week 7 to Week 8(October 7-October 14th)''' ==

=== '''Updates:''' ===
Designed an experiment to compare the accuracy of Emade vs. APE

Worked on our midterm presentation 

=== Experiment: ===
Control: Emade 

Independent variable: APE

Trials: 3 trials

We were trying to see if there was a noticeable difference in either accuracy or efficiency

However, although APE ran all three trials and produced FPs and FNs, however we were unable to get EMADE to run despite trying for over 6 hours.
  
Trails:

[[files/T1.png|thumb|none|381x381px]] 

[[files/T2Ape.png|thumb|none|387x387px]]  

[[files/T3.png|thumb|none|392x392px]]



  
{| class="wikitable"
!Tasks
!Current status
!Date Assigned 
!Date resolved
|-
|Finish Presenation
|Complete
|Oct 14th 
|Oct 17th
|-
|Decide between Image and Stream data 
|Complete
|Oct 14th
|Oct 17th
|-
|Figure our roles for new members
|Complete
|Oct 14th 
|Oct 17th
|}

== '''Week 6(September 30th)''' ==

=== Updates: ===
* EMADE is finally spitting out false positives and false negatives with the unpreprocessed titanic data
* I am looking into ways to implement Image Preprocessing
{| class="wikitable"
!Task 
!Current status
!Date Assigned
!Date resolved
|-
|Run the following Kaggle Datasets on APE EMADE
|In Progress
|Sep 30th, 2019
|N/A
|-
|Manually preprocess image data and run it 
|In progress 
|Sep 30th, 2019
|N/A
|-
|Meet with Austin to better understanding image preprocessing
|In progess
|Sep 30th, 2019
|N/A
|}

=== Resources for preprocessing Image data: ===
* I still haven't fully read through them, only did a quick skim 
# https://datasciencebowl.com/image-preprocessing-the-challenges-and-approach/
# https://datascience.stackexchange.com/questions/41984/cleaning-data-automatically
# https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html

=== Kaggle datasets to run/ already running: ===
* Still running these
# https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data (price should prolly babe the truth data, regression)
# https://www.kaggle.com/russellyates88/suicide-rates-overview-1985-to-2016 (lot's of potential truth data, but making this a classification problem could be interesting )
# https://www.kaggle.com/cities/titanic123 (already running*)

=== '''*''' ===
[[files/Emade_titanic.png|border|frameless|988x988px]]

== '''Week 5 (September 22nd)''' ==
{| class="wikitable"
!Task
!Current Status 
!Date assigned 
!Date resolved 
|-
|Fix Seeding file
|Complete
|Sep 18, 2019
|Sep 27,2019
|-
|Run EMADE using unprocessed Titanic 
|Complete 
|Sep 8th, 2019
|Sep 30th, 2019
|-
|Look at ways to implement Imagepreprocessing prmitives
|In progess
|Sep 15th, 2019
|N/A
|}
I met with James on Thursday the 26th and finalll fixed my EMADE installation problem.

=== '''<u>Problem:</u>''' ===
* Code that worked at GTRI no longer worked on my computer which I found really puzzling 

=== <u>Solution:</u> ===
* Turns out the issue in not with the code but the paraemters
* I had the preprocessing primitive set to false which meant that all seed parameter would get over written because preprocessing was not happening
* I then changed the parameter default so that anyone who wanted to auto-preprocess the data didn't have to alter any parameters
* Finally, I altered the seeding file code so it's more understandable to other people

=== <u>'''Current Errors:'''</u> ===
Okay so the main issue now is with data_splitter.py, when we gzip a file it often contain nothing even if the csv files that was gzipped was not empty 

=== Preprocessing documentation: ===

==== Parameters: ====
{| class="wikitable"
!Name in cmd
!Default
!Datatype
!Requred/Optional
!Usage
|-
|'path_of_data'
|None
|str
|REQUIRED
|his is the ABSOLUTE  (starting from C:...)  path of the Kaggle data set (this should be big enough to create both train and test datasets) in csv format
|-
|'name_of_folder'
|None
|str
|REQUIRED
|name of the schema, xml file, csv files folder, csv.gz files folder, and seeding files (all have the same name)
|-
|'tdi','--truth_data_index'
| -1
|int 
|HIGHLY RECCOMENDED but NOT required
|index of the column of truth data (starts counting how Pythonic way from 0', default=-1) and moves it to the last column because that's where the truth data of EMADE is stored
|-
|'-num','--number_of_splits'
|5
|int
|Optional
|number of times the test and train data needs to split, can not be zero, so if it was set to 2, then there would be 2 test and 2 train datasets
|-
|'-rp','--ratio_percent'
|100
|int
|Optional
|This will allow you to adjust the ratio between the test and train dataset, the smaller your ratio is the smaller your test dataset becomes. A ratio of 100 means the dataset is split half and half into test and train.
|-
|'-pass','--password'
|'SQLPASSWORD'
|str
|HIGHLY RECCOMENDED but NOT required
|password for SQL Workbench, WILL NOT CREATE A SQL SCHEMA OR SEED THE PRIMITIVES IN  without the correct password.
|-
|'-w', '--worker
|False
|bool
|Optional
|IF TRUE, Only run workers
|-
|'-head','--header'
|True
|bool
|Optional
|whether the data contains headers, if True it contains headers, this is because all headers must be removed in order for APE to work.
|-
|'-db','--create_database'
|True
|bool 
|Optional
|Create an sql database, if you put -db in the cmd it NO LONGER CREATES a schema, it by default creates a schema
|-
|'-dtype','--datatype'
|'featuredata'
|str
|Optional
|choices=['featuredata','streamdata','textdata','imagedata'], type of data
|-
|'-re','--reuse'
|1
|int
|Optional
|Whether or not to reuse data, must be 1 if you want to use seeds
|-
|'-p','--prep'
|True
|bool
|HIGHLY RECCOMENDED but NOT required
|whether or not to preprocess EMADE, THIS MUST BE TRUE IF ANY PREPROCESSING NEEDS TO BE DONE, also Seeds will only be prodeuced and seeded in the schema if this is TRUE
|-
|'-seed','--number_of_seeds'
|15
|int
|HIGHLY RECCOMENDED but NOT required
|number of seeds, only seeds in if preprocessing is True: IF you don't want any seeds set equal to 0
|-
|'-c','--cache'
|False
|bool
|Optional
|whether or not to cache data in EMADE
|-
|'-env','--environment'
|'ENVIRO_NAME'
|str
|Optional
|name of virtual environment
|-
|'-u','--user'
|root
|str
|Optional
|SQL username
|-
|'-hst','--host'
|'localhost'
|str
|Optional
|name of host 
|-
|'-lu','--local_username'
|'User'
|str
|Optional
|username for computer(the username that you cd in after cd in users)
|}

== '''Week4 (September 15th)''' ==
{| class="wikitable"
!Task 
!Current Status
!Date Assigned
!Date resolved
|-
|Research what preprocessing means in terms of image data
|In progess
|Sep 15th, 2019
|N/A
|-
|Use GCP to make EMADE installation easier 
|In progess
|Sep 15th, 2019 
|N/A
|-
|
|
|
|
|}

=== How to preprocess IMAGE data: ===
* Read image
** put path to image dataset into a list
* Resize image
** Make it a size that the algorithms can use 
* Remove noise(Denoise)
** I am still no fully sure what this means or how to implement this within EMADE
* Segmentation
* Morphology(smoothing edges)
[https://towardsdatascience.com/image-pre-processing-c1aec0be3edf Source] (will do more research this week)

== '''Week 3 (September 8th)''' ==
{| class="wikitable"
!Task 
!Current Stutus
!Date assigned
!Date resolved
|-
|Install EMADE
|Complete
|Sep 8th, 2019 
|Sep 28th, 2019
|-
|Run EMADE using Kaggle DATASETS
|Complete
|Sep 8th, 2019
|Sep 30th, 2019
|}
'''Errors while trying to install EMADE:'''
# Okay, first I deleted my old EMADE and tried to clone the preprocessing branch (This took a few tries but it eventually worked)
# After I realized many things are still not working, I deleted SQL and python and tried to reinstall them, but that didn't seem to help to many things
# My main issue is with just getting the modules installed
# I am almost out of storage as well
[[files/Hmmlearn.png|left|thumb|500x500px|Hmmlearn will not install (even with virtual environment)]]







































== '''Week 2  (September 1st)''' ==
{| class="wikitable"
!Task 
!Current Status
!Date assigned 
!Date Resolved 
|-
|On GIT HUB change instructions for installing the preprocessing Brach of EMADE 
|Complete
|Sep 1,2019
|Sep 13, 2019
|-
|Look at code and decide which files have to be altered 
|Complete 
|Sep 1, 2019
|Sep 5, 2019
|-
|Explain to Oscar what each file does and which ones were mostly changed for EMADE
|Complete
|Sep 1, 2019
|Sep 5, 2019
|}

=== Python files that need to be altered: ===
* data_spliiter.py
* launchEMADE_prep.py
* prep_seed_generator
* data.py

=== Python files that had major alteration or new  files in the preprocessing branch: ===
* data_spliiter.py
* launchEMADE_prep.py
* prep_seed_generator
* data.py
* preprocessing_methods.py
* seed_files_from_prep.py

== '''Week 1 (fall 2019)''' ==

==== Goals for the week: ====
* Clean up code and run EMADE with Automated preprocessing within my PC
* Expand seed generator to include all learner types 
* Change variables names within code to make code more clear
* Identify ways we can make EMADE inclusive to a wider set of data.
'''SEMESTER GOAL:'''

Ideally, all datatype preprocessing will be automated within EMADE. Our next goal after finishing feature data preprocessing is to look into how IMAGE data may be implemented into EMADE. I really have never done any Image preprocessing so I have kind of outline the following 'milestones' for image preprocessing
# Understand how Image Data is used within the learned types
# Understand what preprocessing means in terms of image data 
# Manually preprocess Image data
# Create some primitives to preprocess image Data

== '''Week 1: January 7th, 2019''' ==
Using DEAP we will use sample populations to find the fitness of a population.
* In this VIP we will be using a heuristic approach to genetics.

=== '''Action Items:''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
! colspan="2" |Date Resolved
|-
|Create a slack account
|Completed
|January 7,2019
|January 8, 2019
|
|-
|Learn more about DEAP and how to use it
|Complete
|January 7,2019
| colspan="2" |January 13,2019
|-
|Do the lab in Jupyter notebook
|Complete
|January 7, 2019
| colspan="2" |January 13,2019
|}DEAP understanding:
* Fitness: weights attributes to either minimize (-) or maximize (+) the population.

* DEAP is a type of algorithm
* Individual class is individuals in our population (list of booleans:1s (true) and 0s(false))
* We use a random generator to produce 0s or 1s
* We can see how fit a population is by summing them up

When our generation is 40: Best individual is [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], (99.0,)[https://deap.readthedocs.io/en/master/tutorials/basic/part1.html]


== <big><b>Week 2: January 14th 2019</b></big> ==




=== A genome is a list of genes. Our genome will be represented using a tree. ===

Mutations: modifying the structure of the program.

Used for diversity. If we change the tree we also end up changing the function.
[[files/(5*4)+(3-1)-1.jpg|left|thumb|A tree structure I made.]]

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Resolved
|-
|Symbolic regression lab
|Complete
|1/28/2019
|-
|Understand tree structure
|Complete
|1/25/2019
|-
|Ask about Office Hours
|Complete<!-- I was told that since my schedule does not work for office hours, I can email to get extra help. -->
|1/28/2019
|}
Lab 2 notes:
* We want to minimize mean square error between function we generated and the function we want to generate.
* Used same evolutionary loop as lab 1
* We then found g_max and g_min
* We plotted our results















== '''Week 4: January 28th, 2019''' ==

Action Items
{| class="wikitable"
!Task
!Current Status
!Date Resolved
|-
|Complete Lab 2 pt.2
|Working
|N/A
|-
|Improve Notebook
|Working
|N/A
|}
=== What we want in our algorithms:                                                                                                          Lab part 2: ===
-Efficient 
[[files/Screenshot 2019-02.png|thumb]]
-Accuracy

-Validation

-*-Hardware requirements
* GPU
* Memory
* TPU
* Size
* Power

=== Notes ===
[[files/Screenshot 2019-02-04 01.56.01.png|thumb|Fitness vs. Generation]]
False positive-Identifying something undesirable as desirable

Video I used to further my understanding:  [https://www.youtube.com/watch?v=M8xlOm2wP]






== '''Weak 5: February 9th, 2019''' ==
==== Recap: ====
This Monday we broke into groups of four people. I was placed in a team with Anish Thite, Mohan Dodda, and Shelby Robinson.

Our first assignment was to go through the Titanic CSV. My task was to parse the data.

'''Thought process:'''

The number of family members and spouses were added to become one piece of data.

Males were given the assignment value of 1 and females were given the value of 0.

I made a float of the average age rounded to one decimal place and replaced with all the None values for the ages.

Finally, I cleaned up and properly formatted the other pieces.

'''My Code Progress:'''

[[files/Screenshot 2019-02-09 15.09.10.png|thumb|250x250px|Intermediate code|none]]
[[files/Screenshot 2019-02-09 17.27.56.png|thumb|545x545px|Final code part 1|none]]

[[files/Screenshot 2019-02-09 17.28.00.png|thumb|507x507px|Final code part 2|none]]
.
{| class="wikitable sortable"
!Task 
!Current status
!Date resolved
|-
|Parce CSV
|Completed
|2/9/2019
|}

== February 17th, 2019 ==






{| class="wikitable sortable"
!Task 
!Current status
!Date resolved
|-
|Learn ML
|In progress
|2/18/2019<!-- I am not really much of a help right due to my inexperience in machine learning. -->
|-
|Complete Peer Eval
|Complete
|Not sure (but I finished it before the due date)
|}
Resourses I used and am continuing to use:

https://www.youtube.com/watch?v=h0e2HAPTGF4

https://www.youtube.com/watch?v=D_2LkhMJcfY

https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome







== February 24th, 2019 ==

{| class="wikitable"
!Task 
!Current Status
!Date resolved
|-
|Get Emade installed
|In progress
|N/A
|-
|Continue with coursera
|In progress
|N/A
|}<!-- I spent a few hours on Feb 24th trying to install Emad but when tried this "git clone https://github.gatech.edu/emade/emade" it took a few hours then just stopped working all together.  -->

The resource I used:https://github.gatech.edu/emade/emade

== March 2nd, 2019 ==
{| class="wikitable"
!Task 
!Current Progress
!Date resolved
|-
|Fix issues with emade installation
|In progress
|N/A
|-
|Continue understanding ML
|In progress
|N/A
|-
|Meet up with subteam
|Complete
|2/28/19-3/02/19
|}

== March 10th, 2019 ==
{| class="wikitable"
!Task 
!Current Progress
!Date resolved
|-
|Run data visulaization app
|Complete
|03/09/2019
|-
|Meet up with subteam
|Complete
|3/09/2019-3/10/2019
|}
I also calculated the area under the curve for EMADE using Reimann's sum:

-Fn: False negative (height)

-Fp: False positive (width)

- Reinmann's sum was used since the Pareto front was already in the shape of rectangles.

[[files/Auc.png|thumb|none]]

== March 25th, 2019 ==
{| class="wikitable"
!Task 
!Current progress
!Date resolved
|-
|Join subteam
|Complete 
|3/25/2019
|-
|Join Slack for subteam
|Complete 
|3/25/2019
|-
|Discuss meeting times
|Complete
|3/25/2019
|}
I joined the Stock subteam and met all new and returning members. 

==== Notes from meeting: ====
-Last semester the team was 13% more successful than random chance on deciding whether or not the price of the stock would go up or down.

-The teams usually either meet on Friday or Saturday

== April 1st, 2019 ==
{| class="wikitable"
!Task
!Current Progress
!Date resolved
|-
|Meeting
|Incomplete
|4/08/2019
|-
|Watched ML video
|Complete
|3/29/2019
|}
Summary of the video:

Basically, when you use neural networks, different layers of the filter light up when you are recognizing new things, next I learned why overfitting is bad and that you want your machine to work for all data not only your data. 

https://www.youtube.com/watch?v=aircAruvnKk&t=1024s

Other video:

Just explained what ML is used for and the basic concept of it.

https://www.youtube.com/watch?v=ukzFI9rgwfU

== April 8th, 2019 ==
{| class="wikitable"
!Task
!Current Progress
!Date Resolved
|-
|Subteam meeting (Friday:4-6:30)
|Complete
|4/05/2019
|}

== April 15th, 2019 ==
{| class="wikitable"
!Task
!Current Progress
!Date Resolved 
|-
|Subteam meeting (Saturday: 4- 5:30 pm)
|Complete
|4/15/2019
|}

Also, looked at the box-cox and tried to understand how to implement it to our data. 

I used this link to understand it, but I was still a little confused:

https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.boxcox.html.

== April 22nd, 2019 (Last Entry) ==
{| class="wikitable"
!Task
!Current Progress
!Date Resolved
|-
|*Presentation
|Complete
|4/22/2019
|}
<nowiki>*</nowiki> We all split up the presentation, Shark and I took the slides on Parsing the Data. 

=== Summary of the semester: ===

==== Biggest obstacle: ====
I felt that my gap in knowledge in knowing Machine Learning was by far the biggest obstacle, and was very difficult to understand most of the things. I felt that this gap in knowledge made understanding and utilizing Emade even more difficult and prevented me from really contributing to the degree I would like to. I didn't even realize how behind I was in the understanding of ML  until I had to literally look up things like "MLP" and "preprocessing". This definitely was on me because I knew what I was getting into when I joined the VIP. In the end, I felt that even my knowledge in Python didn't really make up for my lack of knowledge in Machine Learning. I also felt that just the installation of Emade was very difficult since I felt like I got some type of error in every step of the way. I do have to be honest, both Anish Thite and Mohan Dodda were incredibly helpful in explaining things to me and never made me feel stupid for asking rather dumb questions. 

==== Most Helpful Resource: ====
https://www.coursera.org/learn/neural-networks-deep-learning

I didn't finish this course yet, but so far I liked this the best compared to all the Youtube Videos since it was the most structured and still felt like a real class even though it was free. Most of the youtube videos I used were either too basic or really in depth and hard to follow. I really liked how they actually explained what Neural Networks are and why they are used, rather than just explained how they work. 

==== Response to feedback: ====
* Weekly Entries: I have definitely tried to get better at this, if I didn't do it on Sunday, I always make sure to do it on Monday especially if something happened in class that I would like to note.
* More specific and detailed to-do lists and meeting notes: I tried to improve on this but I usually spent more time trying to understand what was going in the team meetings rather than just contributing. Often I felt that I truly didn't understand what was going on with my stock group so I just spend a lot of time just trying to understand the terminology. I did try to document more the passages and videos I was reading. I felt like when I got to my stock group, I was really lost and it was really hard to keep up.

==== Grade deserved: ====
Honestly, if it's based on pure contribution to my group, I am not sure. But with the knowledge I had, I tried my best to understand the material and contribute to the group, so if it is based on that may be an A-?