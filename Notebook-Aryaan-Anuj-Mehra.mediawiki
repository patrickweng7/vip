=== Aryaan Mehra ===
* Email: aryaan@gatech.edu
* Phone: 678-979-6968
* Interests: Machine Learning, finance, swimming
* Teammates: Harris, Maxim, Dhruv, Heidi, Temi, Monil, Elan, Rohan, Austin, Eashan
= Fall 2021 = 
== November 29th - December 4th, 2021 == 
'''Subteam & Team Meeting Notes:''' 
* Code freeze 
* Testing
{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Make PR Multi-class Dataset 
|Completed
|November 1st, 2021
|November 9th, 2021
|November 9th, 2021
|-
|Add in new mating/mutation operators
|Completed
|November 1st, 2021
|November 15th, 2021
|November 15th, 2021
|-
|Test new operators on PACE
|Completed
|November 1st, 2021
|November 17th, 2021
|November 17th, 2021
|}
== November 22nd - 28th, 2021 == 
'''General Notes (no meetings due to thanksgiving):''' 
* Due to Thanksgiving break I did not work on too much code related work but the team coordinated on deadlines we needed to accomplish tasks by. We agreed that we needed to code-freeze irrespective of our results by December 3rd and begin to work on the final presentation. I will be handling the slides related to the dataset preparation, building a conda environment, fixing errors and the new mating methods. We knew that the memory errors we were getting leading to the '(inf, inf)' were due to the tensors being too large for 16GB GPU on PACE to handle. We discussed a solution which would be to reduce the batch size since it may have something to do with how the individuals and data are stored in memory.
* After adjusting the batch sizes the latest run seemed to adjust for these errors and we started obtaining desired results with lower AUC.

== November 15th - 21st, 2021 == 
'''Subteam & Team Meeting Notes:''' 
* I began testing the new mating mutations methods on my local conda environment which I had just made. I saw several errors associated with the runs I was doing. 
* There were errors with the following:
** Deap not being able to call the methods I was trying to use. Here the issue was that I was unable to call the methods like cxOnePoint (which we have been using for a while) by simply calling it as gp.cxOnePoint. We need to call it as gp.tools.whicheverMethod(). 
** I also had an error which stated that the PrimitiveSetType did not have an attribute 'len()' which I knew to be wrong since many of the functions that we use from deap and the custom operators call the 'len()' method on the individuals as they evolve. I surprisingly had to make the methods I was using the first methods to overcome this by hard-coding them.
** For most of the individuals that I evolved, they returned '(inf, inf)' as the result. This was due to the large batch-size that was hard-coded in the neural_network_methods.py file causing disk memory to exceed the limit. This was a change that we later took a look at to fix. 
* Finally, I was able to finish the code changes before the code-freeze which we have tentatively set as Friday December 3rd since we would have a week to continuously do runs and get testable results. 
* Here is the PR with the necessary code changes: ()
{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Make a PR for the new mating methods
|Completed
|November 1st, 2021
|December 3rd, 2021
|December 3rd, 2021
|-
|Fix bugs related to the mating methods
|Completed
|November 1st, 2021
|November 29th, 2021
|November 29th, 2021
|}
== November 8th - 14th, 2021 == 
'''Subteam & Team Meeting Notes:''' 
* At the beginning of this week I had implemented the 3 new mating methods (cxPartialyMatched(), cxUniformPartialyMatched(), cxOrdered()) and began testing them.
* I was having errors because of our implementation of NSGA-3 which was implemented in the GPFramework egg file on our team's shared conda environment. After speaking with Max we decided that rather than us all using the same conda environment, we should instead have our own environments on PACE for testing purposes so that we do not limit individual testing.
* The following were the steps I followed to create a new conda environment myself for testing:
1. Use the following lines to create a new environment on terminal:
<pre lang="bash">[amehra37@login-pace-ice-1 ~]$ module load anaconda3/2020.02
[amehra37@login-pace-ice-1 ~]$ module load gcc
[amehra37@login-pace-ice-1 ~]$ conda create -n env_name python=3.6</pre>
2. Before you begin installing packages, run this quick command to make sure they all compile the right way as this is a Linux installation:
<pre lang="bash">export CC=gcc</pre>
3. Install all of the necessary packages:
<pre lang="bash">conda install numpy pandas tensorflow keras scipy psutil lxml matplotlib PyWavelets sqlalchemy networkx cython scikit-image pymysql scikit-learn </pre> and subsequently <pre lang="bash"> pip install xgboost lmfit multiprocess hmmlearn deap opencv-python</pre>
4. Install mysqlclient separately using pip install since it does not work well with conda (it was giving me errors)
* I had several issues while setting up the new conda environment related to version differences between the code and the installed versions for tensorflow and deap. I had to be using deap 1.3.1 and tensorflow 2.2 so that the current build of GPPFramework would work.
* Heidi and I also finished working on the new dataset and made a pull request for that (https://github.gatech.edu/amehra37/emade/pull/8)
* We have made it such that all of the code necessary to download the images and format them so that they can be used for this image processing problem can be done by running just one python file enabling ease of use for future semesters.
{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Add in new mating/mutation operators
|Completed
|November 1st, 2021
|November 15th, 2021
|November 15th, 2021
|-
|Fix bugs related to new conda environment
|Completed
|November 1st, 2021
|November 19th, 2021
|November 19th, 2021
|}

== November 8th - 14th, 2021 == 
'''Subteam & Team Meeting Notes:''' 
* This week during the subteam meeting Heidi and I had a work session where we corrected the dataset that we had made the previous week. We had initially spent time making the dataset binary and not multi-class since we thought it would solve the issue we were having with the evaluation function i.e. we believed that the error with the Precision-Recall curve was due to the multi-label nature of the dataset itself and we have worked on making it multi-class rather than binary or multi-label to solve this issue. The code we wrote to solve this issue can be found here: https://github.gatech.edu/athite3/chestxray
* We have also been working to emulate the Neural Network team for dataset creation so that future teams that work with the Chest X-ray dataset can easily download it. We have compressed all of our work into two python scripts; https://github.gatech.edu/athite3/chestxray/blob/master/Preprocessing_Consolidated.py and https://github.gatech.edu/athite3/chestxray/blob/master/download_dataset.py which we will merge into the dataset folder of our forked repo (Image-Processing (nn-vip)).
* I have also begun working on adjusting our pull request for the geometric operators that Eashan and I will be working on. That PR and all the changes we are making can be found here: https://github.gatech.edu/amehra37/emade/pull/4/files
* We are looking into the different crossover operators in DEAP that could work with a strongly-typed GP which is what EMADE is built on. Some of the mating/mutation operators that we are going to work on implementing are (they can also be found in the DEAP documentation here: https://deap.readthedocs.io/en/master/api/tools.html): 
** cxPartialyMatched()
** cxUniformPartialyMatched()
** cxOrdered()
* We will be looking at the code-base (https://github.com/DEAP/deap/blob/master/deap/tools/crossover.py) closely to make sure that the changes we are making are in adherence to EMADE and strongly-typed GP to prevent any other type errors similar to the ones we've made before.
{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Make new Multi-class Dataset 
|Completed
|November 1st, 2021
|November 9th, 2021
|November 9th, 2021
|-
|Compete a literature review of DEAP's existing mating/mutation operators
|Completed
|November 1st, 2021
|November 9th, 2021
|November 9th, 2021
|-
|Add in new mating/mutation operators
|Completed
|November 1st, 2021
|November 15th, 2021
|November 15th, 2021
|-
|Test new operators on PACE
|Completed
|November 1st, 2021
|November 17th, 2021
|November 17th, 2021
|}

== November 1st, 2021 == 
'''Team Meeting Notes:''' 
* Consideration from Jason: reprocess data to just have single label for train/test (if there are not too too many multi-label cases)
** This is something that we will be switching since we want to work on a different type of problem. Since we want to not just work on basic image classification and we want to see how EMADE performs on multi-class images we will be editing the dataset to have multiple classes just not multiple labels. I will be working with Heidi on this project to make sure that everyone on the team has this new dataset to test on for future EMADE runs.
* To get vector out for checking the results of the objective function: dump out the numpy array inside the evaluation method, reinstall GPFramework, and then run individual with database or standalone tree evaluator script
* We also determined that Temi and I will be working with Eashan (bootcamp student) for the rest of the work we do on the mating and mutations methods that we decide to implement in the future.
* Food for thought for next semester: what about where in the image a disease is present, not just whether it exists or not (room for future work here with a bounding box for object detection!)
{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Make new Binary Dataset (Disease/No disease)
|Completed
|October 29th, 2021
|October 29th, 2021
|November 1st, 2021
|-
|Figure out the Geometric Primitives and/or search for new ones
|Completed
|October 29th, 2021
|October 29th, 2021
|November 1st, 2021
|-
|}
== October 29th, 2021 == 
'''Subteam Meeting Notes:''' 
* Met with the team after the midterm presentation and debriefed after the presentation to determine what next steps were.
* The following is work for the team for next week:
** Refactor geometric crossover and mutation to receive expected data type and add in further methods for testing
** Help Heidi make the new dataset which will only be binary in nature i.e. disease or no disease (edit here - we later decided to not have a binary problem or a multi-label problem but rather we went with a multi-class problem where every image has only one type of disease but there could be multiple diseases rather than disease/no disease)
* The following was the issue with the datatype mismatch while testing the geometric crossover methods on PACE:
'''
Traceback (most recent call last):
  File "src/GPFramework/didLaunch.py", line 122, in <module>
    main(evolutionParametersDict, objectivesDict, datasetDict, stats_dict, misc_dict, reuse, database_str, num_workers, debug=True)
  File "src/GPFramework/didLaunch.py", line 112, in main
    database_str=database_str, reuse=reuse, debug=True)
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/GPFramework-1.0-py3.6.egg/GPFramework/EMADE.py", line 805, in master_algorithm
    count = mate(offspring, _inst.toolbox.mateSimBinary, sim_binary_xover, OUTP)
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/GPFramework-1.0-py3.6.egg/GPFramework/EMADE.py", line 556, in mate
    mating_function(tree1, tree2)
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/GPFramework-1.0-py3.6.egg/GPFramework/emade_operators.py", line 628, in sim_binary_xover
    ind1[i] = 0.5 * (((1 + beta) * x1) + ((1 - beta) * x2))
TypeError: unsupported operand type(s) for *: 'float' and 'Primitive'
'''
* Will be working to either find a work-around to this issue or will move on with testing other types of geometric primitives which work with strongly typed GP. Clarification here - strongly typed means that primitive types are enforced i.e it is not loosely typed. We need to find a way to maintain the types of the trees that are being evolved while working on these types of crossover methods.
* Help all the new bootcamp students set up PACE, get up to speed with where we are with changes to EMADE for image processing.
{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Help complete Data Preprocessing
|Completed
|October 29th, 2021
|October 29th, 2021
|November 1st, 2021
|-
|Figure out the Geometric Primitives
|In Progress
|October 29th, 2021
|October 29th, 2021
|November 1st, 2021
|-
|}
== October 25th, 2021 == 
'''Midterm Presentation Notes:''' 
*NLP Team
**Trying to simulate the Bi-DAF model by first creating a word embedding and obtaining an output based on the context of the word
**Using the SQUAD dataset from Stanford with 100,000 answered and 50,000 unanswered questions.
**Trying to get close to the SOTA which is an F1 of 93.214
**They are also trying to get new evaluation metrics. For example, F1(new type), EM, MAP and MRR
**Haven’t completed all the primitives yet such as the output layer which is why they do not have any results yet.
**They are planning on using Facebook’s dataset. Dynamic/Episodic memory is the best as of now. 

*NAS:
**Hard for emade to outpace the seeded runs
**Long training times due to nesting
**Overall goal is to make EMADE competitive with VGG16 and other large structure architectures
**Objectives: 
***minimize accuracy errors and number of parameters
***Used time stopping of 600 vs 2500 seconds, latter ended in 1500 but generated less valid individuals and slightly better accuracy error (-0.05)
**Higher number of layers → higher num of error individuals (though 2-5 was less than baseline)
**Used only dense layers and convoluted layers
**Tracking layer frequencies across generations
**Created NNLearner table to track NNLearner individuals’ statistics

*Stocks (market and time series analysis):
**Objectives: use EMADE for regression on time series data and optimize market trading algorithm ; beat SOTA using EMADE
**They are trying to model papers and use technical indicators to predict price change points
**What are the best primitives to use: modelled TI’s versus the different regression techniques that are implemented
**Maximize profit percentage and average profit per transaction, minimize CDF of profit and variance of profit per transaction (four obj functions total)
**Best performance was with the least complex tree (only one TI)
**They are using minimization rather than maximization functions since they work better on EMADE.
**Having struggles with replicating the paper, primarily the fuzzy logic
**Hope to end the semester with a research paper

*Modularity:
**ARL: adaptive representation through learning
**ARL’s are implemented between the genetic operations and the evaluation phase
**Must be a complete tree
**It basically abstracts away complexity
**ARL’s should allow the population to converge faster
**Goal: allow search function to consider larger subtrees depth. Improve ARL candidate selection through a new weighting function (occurrences* ARL size / fitness of individual)
**Runs with both the old ARL’s and newer ARL’S are worse than with no ARL’s
**More data is needed to see effects of ARL complexity on performance
**Size != usefulness
**Using ARLs with Stocks
**Used various technical indicators
**Problems with Google Colab’s limited computing power and merging stocks’ codebase into the ARL codebase
**Individuals not evaluating because of cachev2 updates
**Study if selection during runs is biased
**Look into ARL construction (changes to hyperparameters, amount, etc.)
**More TI from stocks subteam

{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish Midterm Presentation
|Completed
|October 18th, 2021
|October 25th, 2021
|October 24th, 2021
|-
|}
== October 20th, 2021 == 
'''Subteam Meeting Notes:''' 
* We met on Wednesday to determine whether or not we could get pace to work on an EMADE run.
* Found out that many of the individuals with interesting primitives like the convolutional operator and LSTM were failing due to a mismatched data types i.e., changes have to be made to the primitives for working with image data. 
* Max showed us how to get the pace run done and make sure we're running on the shared conda environment.
* We also ended up meeting up on Sunday in order to get some more runs done. Me and Dhruv still struggled since the master worker was failing in a few minutes making the worker which was working till the walltime useless.
* In the end even the individuals which were evaluated through the valid pace run were limited due to primitives failing due to mismatched datatypes.
{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish Midterm Presentation
|Completed
|October 20th, 2021
|October 25th, 2021
|October 24th, 2021
|-
|}
== October 18th, 2021 == 
'''Team Meeting Notes:''' 
* Led the scrum session for our team this week since Max couldn't make it.
* Jason told us that it was the highest priority to get at least one emade run done to make sure that we had results to compare the CheXnet paper to and also make sure that we can test our new primitives because we can't showcase any results otherwise.
{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish Midterm Presentation
|Completed
|October 18th, 2021
|October 25th, 2021
|October 24th, 2021
|-
|Complete PACE Run
|Completed
|October 18th, 2021
|October 25th, 2021
|October 24th, 2021
|-
|}
== October 13th, 2021 == 
'''Subteam Meeting Notes:''' 
* General Notes:
** Start making presentation early next week 10/19 and reminder: mid-sem presentation is on 10/25
** Do comparison run after merging our changes such as the crossover methods, hyper feature packages and selection methods in
** Be prepared to talk about what we worked on individually/in your pairings (will need to put it on the slides)
* Goals for Monday:
** Complete testing changes
** Commit changes
** Pull Request
** Merge your changes!
{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Test the crossover functions using unit tests
|Completed
|October 18th, 2021
|October 20th, 2021
|October 23rd, 2021
|-
|Complete PACE Run
|Completed
|October 18th, 2021
|October 25th, 2021
|October 24th, 2021
|-
|}
== October 6th, 2021 == 
'''Subteam Meeting Notes:''' 
* Just completed my peer evaluations.
* Our objectives moving forward (for after fall break and before the presentations are due:
** Maxim gonna send his PACE setup so we can run EMADE on our pace-ice
** Aiming for end of fall break, getting runs working
** Monil working on testing some hyper features in EMADE, works locally and working with Heidi
** Dhruv/Harris are going to test NSGA3 (don’t need EMADE to make sure it works and will just use the StandAloneTree Evaluator)
** Will need actual EMADE run before mid-sem presentation to check improvement from baseline or not
** Aryaan/Temi looking at mating and crossover methods which will also need to be tested through multiple EMADE runs to check for improvement in individuals.
* I have not added a table here because the assignments are the same as the team meeting notes as October 4th.
== October 4th, 2021 == 
'''Team Meeting Notes:''' 
* I spoke to Temi separately since we are working together on the crossover functions. We will be implementing some of these crossover functions over the next week. These include different types of semantic and geometric crossover operators.
* I will also finish the peer evaluations before Friday this week.
{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Code some of the crossover functions out
|Completed
|October 4th, 2021
|October 13th, 2021
|October 13th, 2021
|-
|Set Up PACE
|Completed
|October 4th, 2021
|October 13th, 2021
|October 13th, 2021
|-
|Complete Peer Evaluations
|Completed
|October 4th, 2021
|October 7th, 2021
|October 7th, 2021
|}
== September 27th, 2021 == 
'''Team Meeting Notes:''' 
* I completed the image preprocessing work and created a dataset of 5000 images from which 1000 were augmented appropriately.
* Here is the link to the python file with the code: https://github.gatech.edu/athite3/chestxray/blob/master/Preprocessing_Consolidated.py
* The preprocessing including the resize, augmentation and data prep for emade are all in this one file now and there's no need to be running multiple files to work with the data.

{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Look for exact Crossover and Mutation functions
|Completed
|September 27th, 2021
|October 4th, 2021
|October 4th, 2021
|-
|Set Up PACE
|Completed
|September 27th, 2021
|October 13th, 2021
|October 13th, 2021
|}
== September 22nd, 2021 == 
'''Subteam Meeting Notes:''' 
* Each of us discussed the progress that we had made till now. I had started the preprocessing work, gotten a dataset ready and also discussed some of the strategies for new crossover and mutation methods. 
* Max and I discussed image augmentation for data preprocessing at length and decided to use the Keras API i.e. image data generator for the purpose of augmenting the images. 
* Here are the augmentations that we will be implementing:
** Image resize and normalization
** Horizontal flipping, shear transforms
** Cropping, translations and rotations
* Here is Anish's existing repo of code which I will be building upon: https://github.gatech.edu/athite3/chestxray
{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Pre-processing data
|Completed
|September 22nd, 2021
|September 27th, 2021
|September 25th, 2021
|-
|Research Crossover and mutation Strategies
|Completed
|September 22nd, 2021
|September 27th, 2021
|September 25th, 2021
|}
== September 20th, 2021 == 
'''Team Meeting Notes:''' 
* We discussed the goal of the team and what we had achieved thus far. 
* Discussed the difficulty in finding information for hyper-feature packaging in the literature.
* I will be creating a branch for the Image Processing team from the nn-vip repo and add the chest x-ray dataset into it so that we can use it effectively. 
{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Speak with Anish
|Completed
|September 15th, 2021
|September 22nd, 2021
|September 17th, 2021
|-
|Begin Pre-processing data
|Completed
|September 15th, 2021
|September 22nd, 2021
|September 22nd, 2021
|-
|Research Crossover and mutation Strategies
|Completed
|September 15th, 2021
|September 22nd, 2021
|September 22nd, 2021
|}
== September 15th, 2021 == 
'''Subteam Meeting Notes:''' 
* We discussed next steps for the image processing subteam and Jason also joined the meeting to discuss potential areas for improvement and next steps for the team as a whole. 
* We each had found one research paper do discuss and I found a couple which dealt with Autonomous Vehicles and image classification. In the end we agreed on working with the Chest X-ray dataset and improve upon a previous subteams work.
* Here are the overarching tasks for next week:
** Data preparation
*** Downsample (greyscale, lower resolution, balancing)
*** Talk to Anish
*** Try it out with EMADE as is
** Selection methods
*** NSGA3, Lexicase, etc.
*** Hypervolume indicator
*** Hyper-feature packaging
** Clever mating and mutation
*** Improve existing primitives
*** Semantic crossover
* I will be working with Maxim on the data pre-processing and also researching some interesting crossover and mutation strategies. 
* Max and I also spoke with Anish and here are the notes from our conversation: https://docs.google.com/document/d/1755uB7JKe1NMVQIE-bMr6wpuaCp3niDnOX3k5_0ghMg/edit?usp=sharing
{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Speak with Anish
|Completed
|September 15th, 2021
|September 22nd, 2021
|September 17th, 2021
|-
|Begin Pre-processing data
|Completed
|September 15th, 2021
|September 22nd, 2021
|September 22nd, 2021
|-
|Research Crossover and mutation Strategies
|Completed
|September 15th, 2021
|September 22nd, 2021
|September 22nd, 2021
|}
== September 13th, 2021 == 
'''Team Meeting Notes:'''
* Here is my self evaluation: https://docs.google.com/document/d/18q67t96hbUZOVGvsN2GpRRFAtC0Dzzj-XTIpCtf2VqQ/edit?usp=sharing
* Listened to all of the different subteams and their progress over the last 3 weeks. 
* We discussed next steps for the image processing subteam with Jason and he told us to make a decision regarding whether we are focussing on a classification or detection problem. 
* We each had found one research paper do discuss and I found one which was focused on object detection through masks.
* We decided that for Wednesday all of us should find one paper and dataset related to image classification to discuss during the Wednesday meeting so we can begin to work on replicating the results. 
* Jason will be joining our subteam meeting on Wednesday to assist us as well. 
{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Find a research paper to discuss for Wednesday
|In Progress
|September 13th, 2021
|September 15th, 2021
|September 14th, 2021
|}
== September 9th, 2021 == 
'''Subteam Meeting Notes:'''
* We have decided on a team meeting every Wednesday at 5:45pm. I made the Google drive and took notes here: https://drive.google.com/drive/folders/1IRk4E5YBhr0adXikULUOvEEea6jgxWMw
* We discussed our goals as a team and after thinking of some ideas, we decided on the following action items:
** We will be each familiarizing ourselves with the EMADE codebase, how to start EMADE runs, different primitives, etc. 
** We will each read at least 1 research paper of interest related to an image processing problem to decide how we can begin this semesters research.
* We will be trying to find interesting papers which apply either GP approaches or traditional ML approaches to an image processing problem and recreate it in EMADE. We will be implementing new primitives and going off of the work that the NAS team did in their research paper last semester. 
* The research paper that I found was https://www.sciencedirect.com/science/article/pii/S1568494604000316.
** The paper goes through a genetic approach to multi-object detection in an image
** In our subteam meeting I had mentioned image captioning but something we can try doing before that would be object detection. Single object or multi-object detection. Good datasets (possibly): MS COCO, with a variety of different objects
{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read paper published by VIP subteam
|Complete
|September 6th, 2021
|September 13th, 2021
|September 11th, 2021
|- 
|Go through EMADE Codebase
|Complete
|September 6th, 2021
|September 13th, 2021
|September 11th, 2021
|-
|Find potential dataset/paper to work with
|In progress
|September 6th, 2021
|September 13th, 2021
|September 12th, 2021
|}
== August 30th, 2021 == 
''' Team Meeting Notes: '''
* Maxim, Harris, and I met to discuss possible directions for the new image processing subteam and we discussed some of the research papers that Maxim had found. We thought that image registration might be an interesting direction and if not we could also look at some more basic image classification problems and think through the creation of better primitives. 
* Jason thought that image registration might not be the best strategy because of the lack of available data but we will be discussing more application for image processing later. 
''' Action Items: '''
{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
| Agree on Date for Subteam Meetings
| Completed
| August 30th, 2021
| September 6th, 2021
| September 1st, 2021
|}
== August 23rd, 2021 ==
''' Team Meeting Notes: '''
* I initially attended this team meeting remotely since I wasn't yet on campus. I thought that both NAS and image processing with Auto ML were great subteams to join since I had significant past experiences with deep nets, especially with computer vision.
* Through the image processing slack I was able to meet up with Maxim and Harris to discuss some of the potential ways in which the new image processing subteam might work this semester.
* I initially thought that there could be many applications like image denoising, image enhancement, image registration and many of these kinds of processing fields within AutoML.
''' Action Items:'''
{| class="wikitable"
!Assignment 
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
| Submit Subteam Rankings
| Completed
| August 23rd, 2021
| August 29th, 2021
| August 29th, 2021
|}
=== My notebook was deleted entirely in that I cannot find any of my previous work that was on the Wiki from the prior semesters so here's the link to the Wikipedia Wiki: https://wiki.vip.gatech.edu/mediawiki/index.php/Notebook_Aryaan_Anuj_Mehra ===