'''Name:''' Austin T. Peng

'''Email:''' [mailto:apeng39@gatech.edu apeng39@gatech.edu]

'''Cell Phone:''' 510-364-3210

'''Interests:''' Machine Learning, [https://sites.google.com/view/gtclubtennis Tennis], Traveling, Cooking

= Fall 2021 =
== Week 16: December 6, 2021 ==
=== 12/10/2021 Final Presentations ===
* Image Processing (thoughts for the future)
** consider presenting questions you don't know the answer to as well
** consider not averaging the ROC AUC (unpack the results for each multiclass classification)
*** after seeing all the results of selection methods, an averaged ROC AUC for all 14 classes doesn't unpack the results well
*** for example, 0.5 averaged ROC AUC could mean some classes (of lung diseases) were classified very well while other classes did not work as well
** in addition to unpacking results for each class, consider looking into creating confusion matrix (14 by 14) and analyze results
** why lexicase over NSGA2 and NSGA3?
*** lexicase does better when looking into individuals/instances (being classified against the 14 different CheXNet classes)

=== 12/8/2021 Subteam Meeting Notes ===
* FOLLOW UP: on why many single individual from my EMADE runs have an error string of <code>Objective Precision AUC failed to be evaluated, returning the exception multiclass format is not supported</code>
** The issue was fixed after Max merged NAS changes into our new branch <code>img-proc</code> which changed the evaluation method to use ROC AUC and the multilabel parameter in the XML to be 1.
** Max also created new <code>input_chest.xml</code> and <code>launchEMADE.py</code> scripts for our final runs before the final presentation.

==== Using MySQLWorkbench To Access Databases ====
* Note: remember to start the mysql service.
** ssh into PACE-ICE
** run <code>qsub pbsmysql.pbs</code>
* To use MySQLWorkbench, first download and install it.
* Then configure the settings for one MySQL connection with the following:
** <code>SSH Username</code> should be your GT username that you use to login to PACE
** <code>SSH Password</code> should be your GT password that you use to login in PACE
** <code>MySQL Hostname</code> should be the name of your mysqldb job running (use qsub pbsmysql.pbs to start it)
** <code>MySQL Server Port</code> should be the port number your specified in your <code>.my.cnf</code> file
** <code>Username</code> should be your mysql username
** <code>Password</code> should be your mysql password

[[files/apeng39/w16-ss3-mysqlworkbench-setup.png]]

==== Selection Method Results (NSGA3 and Lexicase) ====
* I helped Dhruv complete a run testing <code>sel_nsga3</code>.
** The job ran for 7:30 hours and 190 generations.
** The following is the tree of the best performing individual (based on the ROC AUC metric).
*** ROC AUC: 0.491509
*** numParams: 1215
<pre>
NNLearner(ARG0, GlobalMaxPoolingLayer2D(Conv2DLayer(Conv2DFilterUnit48, reluActivation, Conv2DKernelSize3, MaxPoolingLayer2D(Conv2DKernelSize5, Conv2DLayer(Conv2DFilterUnit16, softmaxActivation, Conv2DKernelSize1, DenseLayer4dim(DenseLayerUnit256, tanhActivation, MaxPoolingLayer2D(Conv2DKernelSize3, MaxPoolingLayer2D(Conv2DKernelSize5, Conv2DLayer(Conv2DFilterUnit48, softmaxActivation, Conv2DKernelSize5, MaxPoolingLayer2D(Conv2DKernelSize3, DenseLayer4dim(DenseLayerUnit32, defaultActivation, DenseLayer4dim(DenseLayerUnit256, seluActivation, MaxPoolingLayer2D(Conv2DKernelSize3, DenseLayer4dim(DenseLayerUnit32, seluActivation, Conv2DLayer(Conv2DFilterUnit16, softmaxActivation, Conv2DKernelSize1, DenseLayer4dim(DenseLayerUnit32, sigmoidActivation, Conv2DLayer(Conv2DFilterUnit16, softmaxActivation, Conv2DKernelSize3, Conv2DLayer(Conv2DFilterUnit16, defaultActivation, Conv2DKernelSize3, DenseLayer4dim(DenseLayerUnit32, eluActivation, DenseLayer4dim(DenseLayerUnit32, reluActivation, DenseLayer4dim(DenseLayerUnit256, sigmoidActivation, Conv2DLayer(Conv2DFilterUnit16, eluActivation, Conv2DKernelSize5, DenseLayer4dim(DenseLayerUnit256, tanhActivation, MaxPoolingLayer2D(Conv2DKernelSize1, DenseLayer4dim(DenseLayerUnit256, eluActivation, Conv2DLayer(Conv2DFilterUnit16, seluActivation, Conv2DKernelSize1, Conv2DLayer(Conv2DFilterUnit16, softmaxActivation, Conv2DKernelSize1, DenseLayer4dim(DenseLayerUnit256, tanhActivation, DenseLayer4dim(DenseLayerUnit256, sigmoidActivation, MaxPoolingLayer2D(Conv2DKernelSize3, ARG0))))))))))))))))))))))))))))), trueBool, FtrlOptimizer)
</pre>

[[files/apeng39/w16-ss1-sel-nsga3-best-ind.png]]

* For lexicase, Harris and I also completed a few runs using the <code>sel_lexicase</code>.
** The following is tree of an interesting individual (only 30 parameters).
*** ROC AUC: 0.5
*** numParams: 30
<pre>
NNLearner(ARG0, GlobalAveragePoolingLayer2D(MaxPoolingLayer2D(Conv2DKernelSize1, MaxPoolingLayer2D(Conv2DKernelSize1, DenseLayer4dim(DenseLayerUnit32, defaultActivation, MaxPoolingLayer2D(Conv2DKernelSize3, MaxPoolingLayer2D(Conv2DKernelSize1, DenseLayer4dim(DenseLayerUnit32, defaultActivation, MaxPoolingLayer2D(Conv2DKernelSize3, MaxPoolingLayer2D(Conv2DKernelSize3, MaxPoolingLayer2D(Conv2DKernelSize3, MaxPoolingLayer2D(Conv2DKernelSize1, DenseLayer4dim(DenseLayerUnit32, defaultActivation, MaxPoolingLayer2D(Conv2DKernelSize3, InputLayer))))))))))))), Conv2DFilterUnit48, NadamOptimizer)
</pre>

[[files/apeng39/w16-ss2-sel-lexicase-best-ind.png]]

=== 12/6/2021 Main Meeting Notes ===
* I encountered an error with editing and saving changes on <code>templates/input_chestxray.xml</code>. 
<pre>
E667: Fsync failed
</pre>

* EDIT (12/8/2021) FIXED:
** I removed the extremely large <code>.git</code> folder from my PACE account.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Find why many single individual from my EMADE runs have an error string of <code>Objective Precision AUC failed to be evaluated, returning the exception multiclass format is not supported</code>
|Completed
|November 29, 2021
|December 6, 2021
|December 8, 2021
|-
|Solve error with <code>OSError: [Errno 122] Disk quota exceeded</code>
|Completed
|November 29, 2021
|December 6, 2021
|December 8, 2021
|-
|Perform 1 trial of EMADE on <code>sel_nsga3</code>.
|Completed
|December 6, 2021
|December 8, 2021
|December 7, 2021
|-
|Perform 1 trial of EMADE on <code>sel_lexicase</code>.
|Completed
|December 6, 2021
|December 8, 2021
|December 8, 2021
|-
|Run EMADE with new selection method (selEpsilonLexicase from DEAP) on different epsilon values
|Blocked
|November 22, 2021
|December 6, 2021
|
|}

== Week 15: November 29, 2021 ==
=== 12/1/2021 Subteam Meeting Notes ===
* I completed a run with the input_chestxray.xml, however many individuals generated have an error string.

<pre>
Objective Precision AUC failed to be evaluated, returning the exception multiclass format is not supported

Traceback (most recent call last):
File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/GPFramework-1.0-py3.6.egg/GPFramework/EMADE.py", line 1800, in evaluate_individual     objectives[objective] = _inst.objectivesDict[objective]['evaluationFunction'](*args, **kwargs)   

File "/storage/home/hpaceice1/apeng39/emade/src/GPFramework/eval_methods.py", line 421, in precision_auc     return average_precision_score(truth_data, test_data)   File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sklearn/utils/validation.py", line 63, in inner_f     return f(*args, **kwargs)

File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sklearn/metrics/_ranking.py", line 225, in average_precision_score     average, sample_weight=sample_weight)

File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sklearn/metrics/_base.py", line 74, in _average_binary_score     raise ValueError("{0} format is not supported".format(y_type)) ValueError: multiclass format is not supported  It was detected that the individual performed perfectly. At least one objective returned inf. 
</pre>

* The error log in EMADE_master.eXXXXX file says
<pre>
/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/GPFramework-1.0-py3.6.egg/GPFramework/sql_connection_orm_master.py:293: SAWarning: Coercing Subquery object into a select() for use in IN(); please pass a select() construct explicitly
  .filter(self.Individual.hash.in_(ParetoFrontLatestGen))]
/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/deap/tools/emo.py:571: RuntimeWarning: invalid value encountered in subtract
  ft = fitnesses - best_point
/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/deap/tools/emo.py:588: RuntimeWarning: invalid value encountered in subtract
  A = extreme_points - best_point
/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/deap/tools/emo.py:608: RuntimeWarning: invalid value encountered in subtract
  fn = (fitnesses - best_point) / (intercepts - best_point)
Traceback (most recent call last):
  File "src/GPFramework/didLaunch.py", line 119, in <module>
    main(evolutionParametersDict, objectivesDict, datasetDict, stats_dict, misc_dict, reuse, database_str, num_workers, debug=True)
  File "src/GPFramework/didLaunch.py", line 109, in main
    database_str=database_str, reuse=reuse, debug=True)
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/GPFramework-1.0-py3.6.egg/GPFramework/EMADE.py", line 1268, in master_algorithm
    pickle.dump(pareto_front, f, -1)
OSError: [Errno 122] Disk quota exceeded
</pre>

* EDIT (12/8/2021) FIXED:
** I solved the problem with <code>OSError: [Errno 122] Disk quota exceeded</code> by removing the <code>.git</code> folder from my EMADE repository on PACE.

=== 11/29/2021 Main Meeting Notes ===
* I discovered that my error from last week was due to seeding with the incorrect seed file.
** Last week, I used <code>summary_seed</code> but my subteam uses <code>seeding_test_cv_all_empty</code>.
** Today, I ran the command <code>python src/GPFramework/seeding_from_file.py templates/input_chestxray.xml seeding_test_cv_all_empty</code> to seed my database but received the following error.
<pre>
"src/GPFramework/seeding_from_file.py" 334L, 15018C
    '''
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 3216, in _wrap_pool_connect
    e, dialect, self
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2070, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 3212, in _wrap_pool_connect
    return fn()
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 307, in connect
    return _ConnectionFairy._checkout(self)
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 767, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 425, in checkout
    rec = pool._do_get()
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 253, in _create_connection
    return _ConnectionRecord(self)
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 368, in __init__
    self.__connect()
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 611, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    connection = pool._invoke_creator(self)
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/MySQLdb/__init__.py", line 130, in Connect
    return Connection(*args, **kwargs)
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/MySQLdb/connections.py", line 185, in __init__
    super().__init__(*args, **kwargs2)
sqlalchemy.exc.OperationalError: (MySQLdb._exceptions.OperationalError) (2003, "Can't connect to MySQL server on 'atl1-1-02-012-7-l' (111)")
(Background on this error at: https://sqlalche.me/e/14/e3q8)
</pre>

* EDIT (12/3/2021) FIXED:
** I fixed the following error by directly editing the server_ip (which was originally <code>atl1-1-02-012-5-l:3304</code>) in the <code>src/GPFramework/seeding_from_file.py</code> to be <code>atl1-1-02-012-7-l:3304</code>
** With setting up PACE, MYSQL, running EMADE on PACE, and seeding all completed, I am now able to help the image processing subteam with their runs (specifically testing of lexicase selection methods with Harris).

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Seed EMADE runs with seeding_test_cv_all_empty file from /SeedingFiles
|Completed
|November 22, 2021
|December 6, 2021
|November 29, 2021
|-
|Find why many single individual from my EMADE runs have an error string of <code>Objective Precision AUC failed to be evaluated, returning the exception multiclass format is not supported</code>
|In Progress
|November 29, 2021
|December 6, 2021
|
|-
|Solve error with <code>OSError: [Errno 122] Disk quota exceeded</code>
|In Progress
|November 29, 2021
|December 6, 2021
|
|-
|Run EMADE with new selection method (selEpsilonLexicase from DEAP) on different epsilon values
|In Progress
|November 22, 2021
|December 6, 2021
|
|}

== Week 14: November 22, 2021 ==
=== 11/24/2021 Subteam Meeting Notes ===
* THANKSGIVING BREAK! NO MEETING!

=== 11/22/2021 Main Meeting Notes ===
* I attempted to seed my database using the summary_seed file.
** I first ran <code>qsub pbsmysql.pbs</code>
** Then ssh-ed into the node and ran <code>python src/GPFramework/seeding_from_file.py templates/input_chestxray.xml summary_seed</code> which produced the following error message.
<pre>
(/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs) -bash-4.2$ python src/GPFramework/seeding_from_file.py templates/input_chestxray.xml summary_seed
Using TensorFlow backend.
[nltk_data] Downloading package punkt to
[nltk_data]     /storage/home/hpaceice1/apeng39/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /storage/home/hpaceice1/apeng39/nltk_data...
[nltk_data]   Package averaged_perceptron_tagger is already up-to-
[nltk_data]       date!
[nltk_data] Downloading package wordnet to
[nltk_data]     /storage/home/hpaceice1/apeng39/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.
  RuntimeWarning)
/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.
  RuntimeWarning)
(224, 224, 1)
(224, 224, 1)
Performing connection setup for PID: 397839
Open Database Connection UUID: 88574626-dcaa-4f0a-8c86-24e404dc1261 PID: 397839 Ind Hash: None TimeStamp: 2021-11-29 15:59:45.433183
connected to database
Traceback (most recent call last):
  File "src/GPFramework/seeding_from_file.py", line 311, in <module>
    my_func, i = parse_tree(line, pset_info)
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/GPFramework-1.0-py3.6.egg/GPFramework/general_methods.py", line 109, in parse_tree
    node = ast.literal_eval(node)
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/ast.py", line 85, in literal_eval
    return _convert(node_or_string)
  File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/ast.py", line 84, in _convert
    raise ValueError('malformed node or string: ' + repr(node))
</pre>

* EDIT (12/1/2021): FIXED
** I used <code>summary_seed</code> file but my subteam uses <code>seeding_test_cv_all_empty</code> file for seeding.
** This change I made allowed me to seed my <code>chestxray</code> database correctly and provided the following completion message.
<pre>
Using TensorFlow backend.
[nltk_data] Downloading package punkt to
[nltk_data]     /storage/home/hpaceice1/apeng39/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /storage/home/hpaceice1/apeng39/nltk_data...
[nltk_data]   Package averaged_perceptron_tagger is already up-to-
[nltk_data]       date!
[nltk_data] Downloading package wordnet to
[nltk_data]     /storage/home/hpaceice1/apeng39/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
%s %s %s %s apeng39 apeng39 atl1-1-02-012-5-l:3304 chestxray
mysql://apeng39:apeng39@atl1-1-02-012-7-l:3304/chestxray
/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.
  RuntimeWarning)
/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.
  RuntimeWarning)
(224, 224, 1)
(224, 224, 1)
Performing connection setup for PID: 64813
Open Database Connection UUID: 93103eca-9e9d-4d4e-8ddd-184c0d4e94b9 PID: 64813 Ind Hash: None TimeStamp: 2021-11-29 20:14:02.910904
connected to database
NNLearner(ARG0, OutputLayer(InputLayer()), 100, AdamOptimizer)
NNLearner(ARG0, OutputLayer(InputLayer()), 99, AdamOptimizer)
NNLearner(ARG0, OutputLayer(InputLayer()), 98, AdamOptimizer)
NNLearner(ARG0, OutputLayer(InputLayer()), 97, AdamOptimizer)
NNLearner(ARG0, OutputLayer(InputLayer()), 96, AdamOptimizer)
NNLearner(ARG0, OutputLayer(InputLayer()), 95, AdamOptimizer)
NNLearner(ARG0, OutputLayer(InputLayer()), 94, AdamOptimizer)
NNLearner(ARG0, OutputLayer(InputLayer()), 93, AdamOptimizer)
NNLearner(ARG0, OutputLayer(InputLayer()), 92, AdamOptimizer)
NNLearner(ARG0, OutputLayer(InputLayer()), 91, AdamOptimizer)
NNLearner(ARG0, OutputLayer(InputLayer()), 90, AdamOptimizer)
NNLearner(ARG0, OutputLayer(InputLayer()), 89, AdamOptimizer)
NNLearner(ARG0, OutputLayer(InputLayer()), 88, AdamOptimizer)
NNLearner(ARG0, OutputLayer(InputLayer()), 87, AdamOptimizer)
NNLearner(ARG0, OutputLayer(InputLayer()), 86, AdamOptimizer)
NNLearner(ARG0, OutputLayer(InputLayer()), 85, AdamOptimizer)
NNLearner(ARG0, OutputLayer(InputLayer()), 84, AdamOptimizer)
NNLearner(ARG0, OutputLayer(InputLayer()), 83, AdamOptimizer)
</pre>


'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Seed EMADE runs with summary_seed file from /SeedingFiles
|Task Reassigned
|November 22, 2021
|December 6, 2021
|November 29, 2021
|-
|Implement sel_epsilon_lexicase using DEAP in <code>selection_methods.py</code>
|Completed
|November 22, 2021
|December 6, 2021
|November 29, 2021
|-
|Run EMADE with new selection method (selEpsilonLexicase from DEAP) on different epsilon values
|Blocked
|November 22, 2021
|December 6, 2021
|
|}

== Week 13: November 15, 2021 ==
=== 11/21/2021 Hackathon ===
* I successfully ran EMADE on PACE, but with some issues [https://github.gatech.edu/emade/emade/wiki/Notebook-Austin-Tinghao-Peng#Running_EMADE_On_Pace_Error_Fix documented here]
* I implemented <code>sel_epsilon_lexicase</code> in the selection_methods.py file in EMADE.
<pre>
def sel_epsilon_lexicase(individuals, k, epsilon=0.01):
    return tools.selEpsilonLexicase(individuals, k, epsilon)
</pre>
* Harris and I are currently working on running <code>sel_epsilon_lexicase</code> with epsilon values of 0.01, 0.05, 0.1, 0.5, 1, 5, 10.
** These epsilon values were chosen after reading this paper written about [https://dl.acm.org/doi/pdf/10.1145/2908812.2908898 Epsilon-Lexicase Selection for Regression]
* I had some difficulty navigating mysql so I am providing some common mysql commands (specifically to access a table in a database).
<pre>
SHOW databases; # shows all databases
USE <databaseName>; # selects databaseName for usage
SHOW tables; # shows all tables in the selected database
SELECT * FROM <tableName>; # shows all values from tableName
</pre>

=== 11/17/2021 Subteam Meeting Notes===
* I could not find a fix for my issue with mysql so I am deleting my <code>scratch/</code> folder and setting up PACE again.
* see [https://github.gatech.edu/emade/emade/wiki/Notebook-Austin-Tinghao-Peng#Setting_Up_PACE_Notes_And_Running_EMADE_on_PACE here] for updated setup procedures
* Because my team members deleted the original multilabel dataset from PACE, I am currently waiting for them to upload the new dataset to test run EMADE.

=== 11/15/2021 Main Meeting Notes ===
* I am having an issue running <code>mysql -u apeng39 -p</code> and getting the error <code>ERROR 2002 (HY000): Can't connect to local MySQL server through socket 'scratch/db/mysqldb.sock' (2)</code>.
* I checked that I have started the node with <code>pbsmysql.pbs</code> and ssh-ed into the correct node, but the error message was the same as above.
* I am currently asking Maxim about the error message and will include the solution I find [https://github.gatech.edu/emade/emade/wiki/Notebook-Austin-Tinghao-Peng#Setting_Up_PACE_Notes_And_Running_EMADE_on_PACE here]

=== Running EMADE On Pace [Error Fix] ===
* The error message was <code>ImportError: cannot import name 'stop_words' from 'sklearn.feature_extraction'</code> in the file <code>src/GPFramework/text_processing_methods.py</code>
** My solution was to replace <code>stop_words</code> in the file with <code>_stop_words</code>.
* link to solution: https://stackoverflow.com/questions/68620436/cannot-import-name-stop-words-from-sklearn-feature-extraction

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run EMADE On PACE-ICE
|Completed
|November 1, 2021
|November 22, 2021
|November 21, 2021
|-
|Run the current implementation of lexicase on chest data
|Completed
|November 8, 2021
|November 22, 2021
|November 21, 2021
|-
|Read literature about new implementations of lexicase
|NO LONGER NEEDED! (Harris said we won't be implementing those methods)
|November 8, 2021
|November 22, 2021
|November 21, 2021
|-
|Setup rsync on local devices to automatically since new EMADE pushes to PACE-ICE
|NO LONGER NEEDED! (Maxim is making the repo able to be git cloned rather than scp-ed)
|November 8, 2021
|November 22, 2021
|November 21, 2021
|}

== Week 12: November 8, 2021 ==
=== 11/10/2021 Subteam Meeting Notes ===
* I set up mysql on PACE-ICE (EDIT: I actually did not set it up correctly as later weeks I will have issues accessing mysql).

=== 11/8/2021 Main Meeting Notes ===
* The team reviewed the tasks assigned to each new member.
** I was assigned the task of implementing and running another implementation of lexicase.
* I continued to setup PACE-ICE on my laptop.

=== Setting Up PACE Notes And Running EMADE on PACE ===
* I transferred my local EMADE fork onto the remote server using the following command
** <code>scp -r <relative-path-to-local-EMADE-folder> <USERNAME>@pace-ice.pace.gatech.edu:~/</code>
* When creating your <code>.my.cnf</code> file, make sure it is in the home directory of your remote account (use vim to open file) and add the following contents to the file.
<pre>
[mysqld]
datadir=scratch/db
socket=mysqldb.sock
user=USERNAME # replace USERNAME with your GT username (ex. apeng39)
symbolic-links=0
# uncomment the following line if you use a port and change the port number to the one you use
# port=3304 

[mysqld_safe]
log-error=mysqldb.log
pid-file=mysqldb.pid

[mysql]
socket=scratch/db/mysqldb.sock
</pre>

* I then ran the following lines in the command prompt (making sure to replace USERNAME with your GT username)
** <code>mysql_install_db --datadir=$HOME/scratch/db</code>
** <code>/usr/bin/mysqld_safe --datadir='/storage/home/hpaceice1/USERNAME/scratch/db'</code>

* ssh into the node with `ssh USERNAME@atl1-1-02-012-5-l` and login
** Note: replace USERNAME with your GT username
* Inside the node I setup, I ran <code>mysql -u root</code>
** Within the mysql prompt, run the following code replacing USERNAME and PASSWORD with your desired USERNAME and PASSWORD for your mysql account.

<pre>
DELETE FROM mysql.user WHERE user='';
GRANT ALL PRIVILEGES ON *.* TO 'USERNAME'@'%' IDENTIFIED BY 'PASSWORD' WITH GRANT OPTION;
FLUSH PRIVILEGES;
</pre>

* Double check that now you should be able to log in to mysql shell with <code>mysql -u <USERNAME> -p</code> and typing your password when prompted.
* Within the mysql shell run the following lines to setup a database.
<pre>
CREATE DATABASE chestxray;
</pre>

* setting up PACE Anaconda (navigate to my EMADE folder)
** run <code>module load anaconda3/2020.02</code>
** run <code>conda activate /storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/</code>
** run <code>./reinstall.sh</code>
** run <code>python setup.py install</code>
** run <code>python src/GPFramework/seeding_from_file.py templates/input_chestxray.xml seeding_test_cv_all_empty</code> to seed my database.

* Finally, create a file called <code>launchEMADEchest.pbs</code> with the contents below.
<pre>
#PBS -N emade-chest
#PBS -l nodes=1:ppn=4
#PBS -l pmem=4gb
#PBS -l walltime=8:00:00
#PBS -q pace-ice-gpu
#PBS -o emade-chest.out

cd ~/emade
echo "Started on `/bin/hostname`"  # prints the name of the node job started on
export CC=gcc
module load anaconda3/2020.02
conda activate /storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs
echo "STARTING EMADE"
# The next line seeds the run if you're starting from scratch. if you're resuming a run then comment it out.
# python src/GPFramework/seeding_from_file.py templates/input_chestxray.xml seeding_test_cv_all_empty
# This line launches EMADE
python src/GPFramework/launchEMADE.py templates/input_chestxray.xml
</pre>

* run <code>qsub launchEMADEchest.pbs</code>
** The script will create EMADE_master.eXXXXX files after running for a while and check it for any errors.
** The script will create EMADE_master.oXXXXX files after running for a while and check it for any outputs.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run EMADE On PACE-ICE
|In Progress
|November 1, 2021
|November 22, 2021
|
|-
|Run the current implementation of lexicase on chest data
|
|November 8, 2021
|November 22, 2021
|
|-
|Read literature about new implementations of lexicase
|
|November 8, 2021
|November 22, 2021
|
|-
|Setup rsync on local devices to automatically since new EMADE pushes to PACE-ICE
|
|November 8, 2021
|November 22, 2021
|
|}

== Week 11: November 1, 2021 ==
=== 11/3/2021 Subteam Meeting Notes ===
* EMADE branches overview

master -> cacheV2 -> nn-vip & other-subteam-branches -> Image-Processing(nn-vip) -> group-member-branches

* *_methods.py (files contain primitives)
* launchEMADE.py (launches EMADE.py)
* PACE-ICE is currently under maintenance until Friday, November 1
** try to login and complete PACE-ICE setup then
* assigned to selection methods tasks team

=== 11/1/2021 Main Meeting Notes ===
* assigned to Image Processing subteam
* the goal of this subteam is to help improve EMADE's image processing algorithms
** we will use ChexNet dataset to perform multiclass classification
* binary vs. muticlass vs. multilabel classification
** binary classification
*** classifies an instance into 1 of 2 classes
*** in terms of image processing -> disease or not (given a chest xray scan)
** multiclass classification
*** classifies an instance into 1 of 3 or more classes
*** in terms of image processing -> classifying a xray scan to have 1 of 14 diseases
** multilabel classification
*** classifies an instance into 0 or more classes
*** in terms of image processing -> classifying an xray scan to have 0, 1, 2, ..., 14 diseases (any combination of diseases as well)
* consider which part of the team you want to be on
** hyperfeatures
** selection methods
** mating/mutation methods
** data preprocessing

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Checkout And Setup PACE-ICE
|In Progress
|November 1, 2021
|November 8, 2021
|November 8, 2021
|-
|Clone Aryaan's EMADE fork (Image-Processing(nn-vip))
|Complete
|November 1, 2021
|November 8, 2021
|November 3, 2021
|-
|Run EMADE On PACE-ICE
|In Progress
|November 1, 2021
|November 8, 2021
|
|-
|Read CheXNet
|Complete
|November 1, 2021
|November 15, 2021
|November 3, 2021
|-
|Read "Concurrent Neural Tree and Data Preprocessing AutoML for Image Classification"
|Complete
|November 1, 2021
|November 15, 2021
|November 3, 2021
|}

== Week 10: October 25, 2021 ==
=== EMADE Presentations & Subteam Recruitment ===
* ML vs MOGP vs EMADE presentation slides: https://github.gatech.edu/emade/emade/wiki/files/apeng39/presentations/titanic-ml-vs-gp-vs-emade.pdf

* Natural Language Processing
** meeting time: Wednesday 2pm
** BiDAF (bidirectional attention flow)
*** uses NNLearnner (a kind of learner in EMADE)
**** layers of neural networks are primitives in EMADE
* Neural Architecture Search
** meeting time: Friday 2pm
** future work
*** adding more testing/analysis methods
*** creating resources/documentation for setting up EMADE locally
*** restructuring EMADE primitives to enforce valid connections
*** speeding up training time for neural nets
*** integrating weight sharing
*** improving EMADE ability to recognize bad individuals
*** implement speciation for ADF's and individuals separately
* Image Processing
** data preprocessing
*** used image data generator to resize, normalize, and horizontally flip
*** other image augmentations include rotation, shearing, and translations
* Stocks Portfolio Optimization
** used EMADE for regression time series and optimization of market trading
** objective functions
*** (maximization) profit percentage, average profit per transaction
*** (minimization) cdf of profit, variance of profit per transaction
* Bootcamp Presentation Notes
** consider not dropping the "cabin" feature because the location of the cabin in the ship probably has an effect on survival
** an activation function can be used to force a boolean output in genetic programming
** squaring FP and FN don't actually change the order of our pareto front individual
** connecting worker nodes to the master is crucial to speeding up the process of EMADE

=== Takeaways From EMADE ===
* important to use trial and error when using new programs
** setting up EMADE was difficult for our team because we had Windows, Mac, and Mac M1 laptops
** we had to look around the internet and use trial and error to get EMADE set up
* if the evaluation function is updated, make sure to create a new database as the pareto front of the previous individuals will not be measured by the same metrics
* use <code>grep -rl "error string"</code> to trace the root cause of the error and reduce the amount of individuals with error strings

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run <code>mysql -h hostname -u username -D database -p</code>
|Completed
|October 13, 2021
|October 25, 2021
|October 23, 2021
|}

== Week 9: October 20, 2021 ==
=== Lecture Notes ===
* student run lecture and work day to get EMADE running
* helped us figure out how to graph multiple lines on the same graph with matplotlib
** allowed us to graph ML, MOGP, and EMADE pareto fronts all on the same graph

=== Bootcamp Team Meeting ===
* got EMADE master running
* my computer would run EMADE without errors but did not produce any evaluated values (TP, FP, TN, FN) in the database

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run <code>mysql -h hostname -u username -D database -p</code>
|In Progress
|October 13, 2021
|October 25, 2021
|
|-
|Run EMADE As A Group (1 person setup SQL and act as master)
|Completed
|October 6, 2021
|October 25, 2021
|October 23, 2021
|-
|EMADE Titanic Assignment Presentation
|Completed
|October 6, 2021
|October 25, 2021
|October 24, 2021
|}


== Week 8: October 13, 2021 ==
=== Bootcamp Team Meeting ===
* work session during class
* goal is to be able to run <code>mysql -h hostname -u username -D database -p</code> and connect master and worker programs
* Errors
** I had an error where my csv files were not downloaded and unzipped properly (because it was a gzip file).
** I solved the problem by installing git-lfs and the cloning the EMADE repository again.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run <code>mysql -h hostname -u username -D database -p</code>
|In Progress
|October 13, 2021
|October 20, 2021
|
|-
|Run EMADE As A Group (1 person setup SQL and act as master)
|In Progress
|October 6, 2021
|October 25, 2021
|
|-
|EMADE Titanic Assignment Presentation
|In Progress
|October 6, 2021
|October 25, 2021
|
|}

== Week 7: October 6, 2021 ==
=== Lecture Notes ===
* What Is EMADE?
** EMADE = Evolutionary Multi-objective Algorithm Design Engine
** combines a multi-objective evolutionary search with high-level primitives to automate the process of designing machine learning algorithms
* Install EMADE
** download git-lfs
** clone git repo
* connecting as a worker
** add -w flag (signals that this is not a master process)
** make sure mysql accepts remote connections
** to connect use mysql -h hostname -u username -p
** set the reuse flag to 1 if need to pickup on last state
* assignment
** run emade as a group (1 person setup SQL and act as master)
** run emade with a reasonable number of generations
** make a plot of non-dominated frontier at the end of the run (compare ML, MOGP, and EMADE)
** make plots to show analysis of EMADE running and show some successful trees

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review MOGP Code (then add code to notebook)
|Completed
|September 29, 2021
|October 13, 2021
|October 13, 2021
|-
|Update Notebook
|Completed
|October 6, 2021
|October 13, 2021
|October 13, 2021
|-
|Clone EMADE
|Completed
|October 6, 2021
|October 13, 2021
|October 13, 2021
|-
|Install mysql
|Completed
|October 6, 2021
|October 13, 2021
|October 13, 2021
|}

== Week 6: September 29, 2021 ==
* ML vs MOGP presentation slides: https://github.gatech.edu/emade/emade/wiki/files/apeng39/presentations/titanic-ml-vs-gp.pdf
=== Presentation Notes ===
* selection functions used by the groups
** NSGA II
** SPEA2
** custom selTournament
** NSGA II and selTournamentDCD
* selecting from hall of fame may preserve more pareto individuals
* adding terminals to GP can help improve performance (instead of just comparing)

=== Suggestions For Our MOGP ===
* try using one hot encoding for Mr, Miss, Mrs, Master, Rare
** one hot encoding is useful in any case where there is more than 2 options to select from
** one hot encoding is better since without it Master might be seen as more similar to Rare than Mr
* fix the MOGP Pareto front graph (the axes are incorrectly scaled)
* label each of the points in the ML graph and MOGP graph
* add a third objective for a constant in the MOGP algorithm to add a constant to the fitness value for each individuals rather than manually adding it in the evaluation function
* choose to keep either fare or ticket class, not both because they are related traits
* create a graph with both ML and MOGP results on it for better comparison
* pair NSGA-II with a selTournamentDCD for a better minimization of the AUC
* try toolbox.decorate() for mate and mutation (refer to lab 2) to restrict mate and mutation tree lengths
* have the evaluation function return FPR and FNR instead of FP and FN

=== Questions ===
* What is SPEA2 vs. NSGA-II?
* What is a hall of fame?
* How do I one hot encode something?

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook
|Completed
|September 29, 2021
|October 6, 2021
|October 6, 2021
|-
|Review MOGP Code (then add code to notebook)
|Completed
|September 29, 2021
|October 13, 2021
|October 13, 2021
|}

== Week 5: September 22, 2021 ==
=== Lecture Notes ===
* for next week:
** use same preprocessing, folds in data
** but use GP instead of ML on the Titanic dataset
** not allowed to use preprogrammed algorithms in DEAP (ex. mu+lambda)
** allowed to use selection and mutation algorithms
** create Pareto front for GP algorithm
** compare ML and GP algorithms using AUC
** submit a csv file for predictions with columns (PassengerID, Survived_1, ... Survived_n)

=== Bootcamp Team Meeting ===
* attempted to share code for evaluation function on Google Colab
* made little progress as we did not know which evaluation function to use and how to force a boolean output

=== Titantic Dataset MOGP ===
* Additional Problems With GP
** bloated tree size (size > 90)
*** set a max tree size for selection and mutation
*** add a penalizing factor into the evaluation function for large trees
*** the speed of the GP was faster when tree size was maximized
** forcing boolean output
*** we used strongly typed GP but could use loosely typed GP to force a boolean output
** unable to add terminals
*** being able to add terminals could allow for improvement of our GP result
*** our code currently only compares floats between columns rather than comparing them to a predetermined value
** ensuring that the solutions were not all FP or all FN
*** add squared penalizing factor for having high value of either FP or FN
*** the added penalizing factor encouraged a more equal distribution of FP and FN
* Evaluation Function
    def evaluation_func_multi(individual, x_train, y_train, pset):
        func = gp.compile(expr=individual, pset=pset)
        predictions = func(x_train[cols[0]],x_train[cols[1]],x_train[cols[2]],x_train[cols[3]],x_train[cols[4]],x_train[cols[5]],x_train[cols[6]],x_train[cols[7]],x_train[cols[8]],x_train[cols[9]])
        confusion = confusion_matrix(y_train, predictions)
        FN = confusion[1,0]
        FP = confusion[0,1]
        positives = np.sum(confusion, axis=1)[0]
        negatives = np.sum(confusion, axis=1)[1]
        if FN >= positives or FP > negatives:
            return (1000000, 1000000)
        e1 = FN**2 + len(individual) * 20
        e2 = FP**2 + len(individual) * 20
        return (e1, e2)

* Takeaways
** there are situations when our evaluation function would result in an increase in fitness over time (when our problem is a minimization problem)
*** could be the result of poor crossover or mutation methods
** compared to our ML algorithms, GP had a larger variation of results (most likely because of crossover and mutations)

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook
|Completed
|September 22, 2021
|September 29, 2021
|September 29, 2021
|-
|Meet With Group For Titanic Dataset Predictions
|Completed
|September 22, 2021
|September 29, 2021
|September 25, 2021
|-
|Titanic Dataset MOGP Predictions (submit to Canvas)
|Completed
|September 22, 2021
|September 29, 2021
|September 29, 2021
|-
|Titanic Dataset MOGP Predictions Presentation
|Completed
|September 22, 2021
|September 29, 2021
|September 29, 2021
|}

== Week 4: September 15, 2021 ==
=== Lecture Notes ===
* This week's goal is to download the Titanic dataset (from Kaggle competition), preprocess the data for machine learning, use scikit-learn, and evaluate objectives in a false positive and false negative space.
* introduction to sci-kit, pandas, 
* assigned to bootcamp groups with
** David Zhang
** Nikhil Vangala
** Jordan Stampfli
* within the subteam: preprocess data together, train data, try to get codominant models within your subteam
* decisions to make: how to encode data, how to fold data (train and test percentage), how to balance data (false positives, false negatives)

=== Bootcamp Team Meeting ===
* share code for preprocessing data on Google Colab
* split train.csv data to 67% training, 33% testing
* chose 4 codominant models
** multi-layer perceptron classifier
** random forest classifier
** gaussian naive bayes classifier
** logistic regression classifier
* found and made predictions using the above 4 models and saved as 4 seperate csv files

{| class="wikitable"
!Model
!False Negative
!False Positive
|-
|multi-layer perceptron
|30
|27
|-
|random forest
|30
|30
|-
|gaussian naive bayes
|40
|21
|-
|logistic regression
|31
|25
|}

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook (format, images, etc.)
|Completed
|September 15, 2021
|September 22, 2021
|September 22, 2021
|-
|Meet With Group For Titanic Dataset Predictions
|Completed
|September 15, 2021
|September 22, 2021
|September 18, 2021
|-
|Titanic Dataset ML Predictions (submit to Canvas)
|Completed
|September 15, 2021
|September 22, 2021
|September 18, 2021
|}

== Week 3: September 8, 2021 ==
=== Lecture Notes ===
* algorithms look for accuracy, efficiency, reliability, scalability, consistency
* the evaluation of a genome associates an individual with a set of scores (true positive, false positive, etc.)
* objectives are a set of measurements each individual is scored against
* data set (positive and negative samples) feed into a classifier which results in a confusion matrix

{| class="wikitable"
|+confusion matrix
|-
|
|predicted positive
|predicted negative
|-
|actual positive
|true positive (TP)
|false negative (FN), type II error
|-
|actual negative
|false positive (FP), type I error
|true negative (TN)
|}

* Maximization Measures
** sensitivity or true positive rate (TPR)
*** aka hit rate or recall
*** TPR = TP/P = TP/(TP+FN)
** specificity (SPC) or true negative rate (TNR)
*** TNR = TN/N = TN/(TN+FP)

* Minimization Measures
** false negative rate (FNR)
*** FNR = FN/P = FN/(TP+FN)
*** FNR = 1-TPR
** fallout or false positive rate (FPR)
*** FPR = FP/N = FP/(FP+TN)
*** FPR = 1-TNR = 1-SPC

* Other Measures
** precision or positive predictive value (PPV) - maximization
*** PPV = TP/(TP+FP)
** false discovery rate - minimization
*** FDR = FP/(TP+FP)
*** FDR = 1-PPV
*** negative predictive value (NPV) - maximization
*** NPV = TN/(TN+FN)
** accuracy (ACC) - maximization
*** ACC = (TP+TN)/(P+N)

* Objective Space
** each individual is evaluated using objective functions
*** ex. mean squared error, cost, complexity, TPR, FPR, etc.
** objective scores give each individual a point in objective space

* Pareto Optimality
** '''Pareto optimal''': if there is no other individual in the population that outperforms the individual on all objectives
** '''Pareto frontier''': the set of all Pareto individuals
** we want to drive selection by favoring Pareto individuals, but maintain diversity by giving all individuals some probability of mating

[[files/apeng39/w3-ss1-pareto-optimality.png]]

* Nondominated Sorting Genetic Algorithm II (NSGA II)
** separate population into nondomination ranks
** select individuals using a binary tournament
** lower Pareto ranks beat higher Pareto ranks (in minimizing problems)
** ties on the same front are broken by crowding distance
*** summation of normalized Euclidean distances to all points within the front
*** higher crowding distance wins

* Strength Pareto Evolutionary Algorithm 2 (SPEA2)
** each individual is given a strength S, where S is the number of other individuals it dominates
** each individual receives a rank R, where R is the sum of all S's of the individuals that dominate it
** Pareto individuals are nondominated and receive an R of 0
** a distance to the kth nearest neighbor (\sigma^k) is calculated and fitness of R + 1/(\sigma^k+2)

=== Lab 2: Part 2 ===
* In this lab, there were two objectives to be minimized: mean squared error and the size of the tree.
* In addition, three new primitives sin, cos, tan were added.
* The rest of the program was initialized similarly to Lab 2: Part 1.
* Using the fitness levels of the individuals, the Pareto front was determined with a key.
** blue = the given individual
** green = dominated by the given individual
** red = dominates the given individual
** black = uncomparable
* The initial run of my code returned the approximated function negative(cos(add(x, sin(subtract(add(x, sin(sin(sin(cos(x))))), cos(x)))))) with fitness: (0.18701281145428028, 15.0) for the given function np.negative(points) + np.sin(points**2) + np.tan(points**3) - np.cos(points). The area under the curve (AUC) was 3.578671731976013.
* I implemented several versions of the program to produce at least a 25% decrease in AUC. Every time I run the program, I get a different value for the AUC so I will simply list the general way I altered each factor to cause at least a 25% decrease in AUC.
** decreased NGEN -> decreased AUC, increased NGEN -> increased AUC
*** makes sense since increasing the number of generations should give the algorithm more opportunities to find the individual with the highest fitness
** decreased MU -> decreased AUC, increased MU -> increased AUC
*** makes sense since increasing the number of individuals to select for the next generation allows the algorithm to have a higher chance of picking an individual with the highest fitness
** decreased LAMBDA -> decreased AUC, increased LAMBDA -> increased AUC
*** makes sense since increasing the number of children allows for a higher probability of the children containing parts of their parent with higher fitness
** altering CXPB and MUTPB didn't seem to have an obvious effect on the AUC, however, I did observe that the spread of values for AUC became wider


=== Notebook Self-Evaluation ===
[[files/apeng39/notebook-evals/w3-notebook-eval.jpg]]

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Notebook Self Assessment
|Completed
|September 8, 2021
|September 15, 2021
|September 15, 2021
|-
|Update Notebook (format, images, etc.)
|Completed
|September 8, 2021
|September 15, 2021
|September 15, 2021
|-
|Lab 2: Part 2
|Completed
|September 8, 2021
|September 15, 2021
|September 15, 2021
|}

== Week 2: September 1, 2021 ==
=== Lecture Notes ===
* Tree Representation
** nodes are called primitives and represent functions
** leaves are called terminals and represent parameters
** the output is produced at the root of the tree
** the tree is converted to a lisp preordered parse tree (think preorder traversal)

[[files/apeng39/w2-ss1-lisp-preordered-parse-tree.png]]

* Crossover In Genetic Programming (GP)
** crossover in tree-based GP is simply exchanging subtrees

[[files/apeng39/w2-ss2-crossover-gp.png]]

* Mutation In GP
** Inserting a node or subtree
** Deleting a node or subtree
** Changing a node

* Evaluating A Tree
** we feed several input points to get outputs
** the error between the function's outputs and truth can be measured through a sum square error

* What Can Make Evolution Easier?
** if we had better primitives, it would be easier to evolve algorithms
** ex. if we wanted to approximate sin(x), we could use +,-,*,/, but we could also use factorial, exponent, summation, etc.

=== Lab 2: Part 1 ===
* For my two primitives, I added the sine and absolute value methods.
* I decided to use mutNodeReplacement() method from the DEAP package for my second mutation method. Based on the line graphs created using matplotlib, I saw that both mutUniform() and mutNodeReplacement() resulted in similar graphs. The mutNodeReplacement() method, however, resulted in a lower maximum fitness than mutUniform().
* I altered the function being approximated within the evaluation method found that almost all the time, the genetic algorithm was able to find a near-perfect approximation for the given function.
* I also noticed that the more complicated I made the function being approximated in the evaluation method, I would need to increase the minimum and maximum heights of the tree being generated to achieve a better approximation.

{| class="wikitable"
|+'''comparing mutation methods'''
|-
|mutNodeReplacement
|mutUniform
|-
|[[files/apeng39/w2-ss3-mutNodeReplacement-lineGraph.png]]
|[[files/apeng39/w2-ss4-mutUniform-lineGraph.png]]
|}

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Format Notebook (code, images)
|Completed
|September 1, 2021
|September 8, 2021
|September 3, 2021
|-
|Lab 2: Part 1
|Completed
|September 1, 2021
|September 8, 2021
|September 8, 2021
|}


== Week 1: August 25, 2021 ==
=== Lecture Notes ===
* The concept of genetic algorithms is that each new generation of algorithms is created through the mating or mutation of individuals in the previous population. Through many iterations of this process, it produces the best individual.
* Mating or crossover is the creation of a new algorithm using a specified number of parts of the previous algorithm depending on the number of split points.
* A mutation introduces random modifications to the algorithm to help maintain diversity.
* A simple genetic algorithm problem is the One Max problem which essentially wants to produce a list of all 1's given a list of binary numbers.
* keywords
** '''individual''': one specific candidate in the population (with properties like DNA)
** '''population''': a group of individuals whose properties will be altered
** '''objective''': a value used to characterize individuals that you are trying to maximize or minimize (goal is to increase objective through an evolutionary algorithm)
** '''fitness''': relative comparison to other individuals; how well does the individual accomplish the task relative to the rest of the population?
** '''evaluation''': a function that computes the objective of an individual
** '''selection''': represents 'survival of the fittest'; gives preference to better individuals, allowing them to pass on their genes
*** '''fitness proportionate''': the greater the fitness value, the higher the probability of being selected for mating
*** '''tournament''': several tournaments among individuals (number of individuals in each tournament is dependent on the tournament size); winners are selected for mating
** '''mate/crossover''': represents mating between individuals
*** anything up to n-point crossover is possible
[[files/apeng39/w1-ss1-crossover1.png]]
[[files/apeng39/w1-ss2-crossover2.png]]
** '''mutate''': introduces random modifications; purpose is to maintain diversity
[[files/apeng39/w1-ss3-mutate.png]]
** '''algorithms''': various evolutionary algorithms to create a solution or best individual

=== Lab 1 ===
* Part 1: One Max Problem ====
** The objective of this problem is to create a genetic algorithm that returns the maximum amount of 1s in a binary list of size n.
*** When I ran the algorithm with a much larger population (n=10000) it seemed like it took fewer generations for an individual in the population to reach maximum fitness.

* Part 2: N Queens Problem ====
** Learning Points
*** Python map(function, iterable) takes a function and maps an iterable (tuple, list, etc.) to it
*** Python zip() takes in iterables and returns an iterator of tuples with each tuple having elements from all the iterables
*** Python slicing arr[start:stop:step] (start through not past stop, by step)
*** arr[:] makes a shallow copy of the array
*** you can resize an array to the desired length using [0] * size

* My Mutation Methods
 <nowiki>def mutOppositeHalves(individual, indpb):
    """ Randomly picks two indexes from each half of the individual and swaps them with a probability of indpb.
    :param individual: Individual to be mutated.
    :param indpb: Independent probability for each attribute to be exchanged to another position.
    :returns: A tuple of one individual.
    """"
    size = len(individual)
    front_half = random.randint(0, size/2)
    back_half = random.randint(size/2, size-1)
    individual[front_half], individual[back_half] = individual[back_half], individual[front_half]
    return individual,
<nowiki></nowiki>

 <nowiki>def mutRandomHalves(individual, indpb):
    """ Randomly picks a "midpoint" from the individual and picks two indexes from each half of midpoint,
     swapping them with a probability of indpb.
    :param individual: Individual to be mutated.
    :param indpb: Independent probability for each attribute to be exchanged to another position.
    :returns: A tuple of one individual.
    """
    size = len(individual)
    midpoint = random.randint(0, size-2)
    front_half = random.randint(0, size/2)
    back_half = random.randint(size/2, size-1)
    individual[front_half], individual[back_half] = individual[back_half], individual[front_half]
    return individual,
<nowiki></nowiki>

* Observations & Reflection
** To test the effectiveness of my mutation methods, I ran each evolution (100 generations) 100 times and plotted the fitness values.
** I saw that my mutOppositeHalves() method performed the best, finding the global minimum of 0, 60 out of 100 evolutions. My mutRandomHalves() and the provided mutShuffleIndexes performed slightly worse producing the global minimum approximately 55 times out of 100 evolutions.
** However, for the methods I wrote, the maximum shown on the line graphs for each generation ended to be lower than the method provided.
** I struggled a bit with writing the code to make a bar graph using matplotlib mainly because of the data types that the toolbox returned. I kept feeding matplotlib a list of tuples when it wanted a list of ints.

{| class="wikitable"
|+'''mutOppositeHalves'''
|-
|[[files/apeng39/w1-ss4-mutOppositeHalves-barGraph.png]]
|[[files/apeng39/w1-ss5-mutOppositeHalves-lineGraphComparison.png]]
|}

{| class="wikitable"
|+'''mutRandomHalves'''
|-
|[[files/apeng39/w1-ss6-mutRandomHalves-barGraph.png]]
|[[files/apeng39/w1-ss7-mutRandomHalves-lineGraphComparison.png]]
|}

{| class="wikitable"
|+'''mutShuffleIndexes'''
|-
|[[files/apeng39/w1-ss8-mutShuffleIndexes-barGraph.png]]
|[[files/apeng39/w1-ss9-mutShuffleIndexes-lineGraphComparison.png]]
|}

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install DEAP
|Completed
|August 25, 2021
|September 1, 2021
|August 26, 2021
|-
|Lab 1
|Completed
|August 25, 2021
|September 1, 2021
|September 1, 2021
|-
|Update Notebook
|Completed
|August 25, 2021
|September 1, 2021
|September 1, 2021
|}

