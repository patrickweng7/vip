== August 21, 2019 ==

=== Class Notes: ===
* Genetic Algorithms
** Fitness for evaluation then select, exchange DNA between parents for offspring in Crossover, can mutate DNA in offspring
** Represent Individual as DNA
** Objective- something you are trying to maximize/ minimize
** Multiple objectives can feed into a single fitness ex. Grades in classes are objective but fitness is class rank
** Fitness- returns a set of objectives from an individual
** Selection- want best fitness but also randomness
** Fitness proportionate- the greater the fitness, the higher the probability for mating
** Tournament- several tournaments among individuals, winners selected for mating
** Single Point crossover- one half of parent 1 with one half of parent 2 and vice versa
** Double point crossover- 3 sections, can take 2 from one parent and 1 from the second parent
** Mutation is changing a random gene
** Algorithm - procedure, randomly init population, determine fitness of pop, select parents from pop, perform crossover on parents creating pop, perform mutation of pop, evaluate fitness

=== Lab 1 - Genetic Algorithms with DEAP: ===
[[files/Lab1 Code.png|thumb|This is the function I wrote to mutate a population during evolution. The function splits the attributes of the individual in half and switches the position of the halves for mutation.|334x334px|none]]

=== Sub-Team Notes: ===
* N/A: No team assigned

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class lecture slides with notes
|Completed
|August 21, 2019
|August 28, 2019
|August 24, 2019
|-
|Individual: Finish Lab 1 - Genetic Algorithms with DEAP
|Completed
|August 21, 2019
|August 28, 2019
|August 24, 2019
|}

== August 28, 2019 ==

=== '''Class Notes:''' ===
* Genetic Programming
** Using operations to create new populations
** Learned how to make a tree of operations using an array
** Learned how to interpret a tree of operations from an array and from an equation
** Mutation can involve inserting a node or subtree, deleting a node or subtree, changing a node
** Crossover in GP by taking one part of a tree under one node and substituting it at another node of another tree
** Taylor series to evolve a solution for a sin function
** More complicated functions would make evolution easier

=== Lab 2: Genetic Programming and Multi-Objective Optimization: ===

==== Part 1: Symbolic Regression ====
[[files/Lab 2 Part 1.png|none|thumb|I added two new primitives with the divide and exponent functionalities.]]
[[files/MutNodeReplacement.png|none|thumb|I added one mutation that randomizes through Node Replacement.]]
[[files/Evolutionary Graph.png|none|thumb|I changed the mutation method of the genetic programming to node replacement and increased the frequency of crossover in order to improve fitness of the population. ]]

=== Sub-Team Notes: ===
* N/A: No team assigned

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class lecture slides with notes
|Completed
|August 28, 2019
|September 4, 2019
|August 31, 2019
|-
|Individual: Finish the first part of Lab 2 - Genetic Programming and Multi-Objective Optimization
|Completed
|August 28, 2019
|September 4, 2019
|August 31, 2019
|}

== September 4, 2019 ==

=== Class Notes: ===
* Genetic Programming (Multiple Objectives)
** Algorithm is trying to optimize memory usage, minimize errors/ misclassifications (true positive, minimize false positives), time efficiency, security, usability, cost efficiency
** HCI- Human Computer Interface
** We are focusing on things dealing with performance today
** Genome- DNA, GA, GP
** Confusion Matrix for Classification Measures
** Type 2 Error: False Negative
** Type 1 Error: False Positive
** We want True Positive Rate (TPR to be as close to 1) over 
** TPR comes about expense of SPC rate
** False Negative Rate = -> NPR equals False Native/ Positives
** Accuracy to 1 means perfect
** Optimize phenotypes
** Pareto dominance 

=== Lab 2: Genetic Programming and Multi-Objective Optimization: ===
==== Part 2: Multi-Objective Genetic Programming ====
[[files/InitialAUC.png|none|thumb|The initial genetic programming had an initial Area Under the Curve of 2.463792426733847, which measures performance of the pareto front.]]
[[files/Lab2part2.png|none|thumb|In my version of the genetic programming, I decreased the field for NGEN and MUTPB (the number of generations and mutation probability) in order to decrease AUC.]]
[[files/ResultAUC.png|none|thumb|My resulting AUC of 1.0245630989777628 was more than 25% less, achieving the goal of the lab.]]

I noticed that the version of the genetic programming provided by the lab was changing too much between each generations as well as over time. Therefore, 

I reduced the amount of change and the time the population was able to change in order to decrease the means squared error.

=== Sub-Team Notes: ===
* N/A: No team assigned

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class lecture slides with notes
|Completed
|September 4, 2019
|September 11, 2019
|September 8, 2019
|-
|Individual: Finish the second part of Lab 2 - Genetic Algorithms with DEAP
|Completed
|September 4, 2019
|September 11, 2019
|September 8, 2019
|}

== September 11, 2019 ==

=== Class Notes: ===
*We need to find 5 co-dominant algorithms for predicting survivors 
* Use scikit learn and train test split function to predict 
* We will not have the results for test.csv because that is what are being tested on 
* Find False Positive and False Negatives, divide by number of Positives/ Negatives respectively  

=== Sub-Team Notes: ===
Team Meeting- 9/12
* Team Assigned: Nesha, Sanket, Tusheet, Tushna 
* https://www.washingtonpost.com/opinions/women-and-children-did-go-first-on-titanic/2012/04/19/gIQAgSaugT_story.html?noredirect=on
* “Heroism was exhibited by the men on board across all classes and crew.”

* “First-class men survived at a higher rate than the third-class children”

* “Men in first class survived at a lower rate, 32 percent, than did third-class women and children (42 percent)”
* “The Titanic sank at night, and most third-class passengers were far below in the ship, making such access difficult”
* “Altogether, survival percentage for all women and children on board was 70 percent, for men it was 19 percent”
* <nowiki>https://www.anesi.com/titanic.htm</nowiki>
* “third class women were 41% more likely to survive than first class men.”

=== Titanic ML Assignment: ===
https://github.gatech.edu/bsu32/emadeGroup[[files/Demographic.png|none|thumb|I added a new feature set by changing the Pclass to give class 1 a higher number and class 3 a lower one. I combined this edited Pclass with the Sex class, giving women a higher numeric value then men. This way, I accounted for the fact that women were put on lifeboats before men and higher class people had a higher chance of surviving.]]
* There happened to be a very large discrepancy between the men who survived the titanic vs women
* 340/470 (73.2%) of the females on the titanic survived while 367/1731 (21.2%) survived
* These discrepancies can be attributed to the fact that women were evacuated before men, along with men displaying heroism to help women and children evacuate first
* Class also made a difference in survival rates on the titanic as higher class passengers had a higher survival rate
* 62% of first class passengers survived vs. 43% of second class passengers vs 25% of third class passengers
* Third class passengers were often kept within their own area and not allowed to mingle with second and first class passengers
This factor could have decreased the accessibility of third class passengers in attempts to save them
[[files/Feature Set.png|none|thumb|I manipulated the features given by combining SibSp and Parch because both fields were describing how many people each passenger was related to. Also, I added a new feature by checking to see if the passenger was a child because children tending to be sent to lifeboats first.]]
[[files/Dropped Features.png|none|thumb|I dropped the features for Embarked and Fare because those did not signify how likely a passenger was to survive. Also, the Fare was too dependent on where the passenger got on the Titanic and his or her destination.]]
[[files/Additional Models.png|none|thumb|I added 3 additional models to try to improve our prediction score. The linear model was not accurate in any way. However, the Random Forest and the Gaussian model were similar to the models that were given in the notebook.]]
* We are looking for codominance
* Our highest score was .840
[[files/Screen Shot 2019-09-17 at 2.45.09 PM.png|none|thumb|This is my co-dominant pareto front made from the results of 5 different models.]]

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class lecture slides with notes
|Completed
|September 11, 2019
|September 18, 2019
|September 15, 2019
|-
|Group: Meet with team to do ML Assignment
|Completed
|September 11, 2019
|September 18, 2019
|September 12, 2019
|-
|Group: Finish Titanic ML Assignment
|Completed
|September 11, 2019
|September 18, 2019
|September 15, 2019
|}

== September 18, 2019 ==

=== Class Notes ===
*Presentations of Titanic ML project
**Feedback on our presentation:
***We shouldn't do research on our topic because that is cheating in a way
***By researching, we are finding out information about the test set
***We should only look at the training set and use that to generalize for our test set
***Play with weighting of the features
***Whitening- normalizing all data to be on same scale
***Vectorization- for tri-state problems, ex. embarked; separate each possibility to be a different feature
**Use a seed for models with randomness so that it won't change between tests
**Make sure you use post-increment in a minimizing situation
**We will eliminate this tedious process
=== Sub-Team Notes ===
* Team Assigned: Nesha, Sanket, Tusheet, Tushna

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class notes
|Completed
|September 18, 2019
|September 25, 2019
|September 21, 2019
|-
|
|
|
|
|
|}

== September 25, 2019 ==

=== Class Notes ===
* Find genetic 
* Evolving decision trees
* Multiple objective
* Use primitives (and, or, not, +, -, x, /)
* Return non-dominated frontier
* Submit all pareto individuals
* Measure AUC with Riemann sum at each individual
* Bound frontier with 1,0 and 0,1
* Don't use tournament as selection

* Tournament: Select the best individual among ''tournsize'' randomly chosen individuals, ''k'' times. The list returned contains references to the input ''individuals''.
* deap.tools.selBest(individuals, k, fit_attr='fitness') - Select the k best individuals among the input individuals. The list returned contains references to the input individuals.

=== Sub-Team Notes ===
* Team Assigned: Nesha, Sanket, Tusheet, Tushna
* Team Meeting- 9/30
* Sanket is working on redoing our feature set with vectorization
* Tusheet and I are working on GP
* Nesha/ Tushna are working on AUC and Riemann sums

=== Titanic GP Project ===
https://github.gatech.edu/bsu32/emadeGroup[[files/Primitive Set1.png|none|thumb|I chose the weights of -1.0 because we are minimizing the false negative and positive rates. I also added in the required primitives.]]
[[files/EvalFunc.png|none|thumb|I changed the evaluation function to calculate false negative, and false positive rates. I also changed the selection method to Select Best.]]
[[files/Best Individual1.png|none|thumb|This is our resulting Best Individual over 50 generations.]]
[[files/Pareto Front GP.png|none|thumb|This is our resulting Pareto Front showing codominance.]]

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class notes
|Completed
|September 25, 2019
|October 2, 2019
|September 28, 2019
|-
|Group: Titanic GP Project
|Completed
|September 25, 2019
|October 2, 2019
|September 30, 2019
|}

== October 2, 2019 ==

=== Class Notes ===
Titanic GP Presentations:
* Don't use select best because that is single objective
* Changed selection to selNSGA2
* Bound the pareto front between 0 and 1
* Select Tournament DCD for sort then tournament
* Video comparison is good, picture of what an individual looks like
* Use logicals such as less than or greater than
* Evolutionary settings should be laid out
=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class notes
|Completed
|October 2, 2019
|October 9, 2019
|October 6, 2019
|-
|Individual: Install EMADE
|Completed
|October 2, 2019
|October 9, 2019
|October 6, 2019
|}

== October 9, 2019 ==

=== Class Notes ===
Introduction to EMADE
* EMADE- evolutionary multi objective algorithm design engine
* Combines multi objective with high level primitives to design ML algos
* Start EMADE by navigating to top level of directory
* look at the README
* Takes XML as input
* Input file configure all moving parts of EMADE
* set reuse to 1 to use same database, set 0 to wipe all individuals
* data is split into folds
* average score from all folds
* prevents overfitting
* last column reserved for fitting models and scoring
* Keep workersPerHost at 2-3
* Everybody should use the same XML file
=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class notes
|Completed
|October 9, 2019
|October 16, 2019
|October 12, 2019
|-
|Individual: Set up mysql
|Completed
|October 9, 2019
|October 16, 2019
|October 12, 2019
|-
|Group: Run EMADE as a group
|Completed
|October 9, 2019
|October 21, 2019
|October 19, 2019
|}

== October 16, 2019 ==

=== Class Notes ===
In Class Work Session
* Get emade installed with one person in the group as the server and everyone else as workers
AAD Hackathon 10/19
* Got all group members as workers 
* My machine was the master
* Running generations overnight
EMADE Presentation
[[files/Dominance Function.png|none|thumb|I wrote a dominance function to get rid of dominated individuals from the results of EMADE evolution.]]
[[files/Paretocode.png|none|thumb|I wrote the function to derive a pareto front.]]
[[files/Screen Shot 2019-10-21 at 5.23.25 PM.png|none|thumb|This is the resulting pareto front from EMADE generations.]]

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class notes
|Completed
|October 16, 2019
|October 21, 2019
|October 18, 2019
|-
|Set up masters and workers
|Completed
|October 16, 2019
|October 21, 2019
|October 19, 2019
|-
|Run generations on database
|Completed
|October 16, 2019
|October 21, 2019
|October 20, 2019
|}

== October 21, 2019 ==

=== Class Notes ===
Full VIP Meeting- Presentations
* Our pareto front has values greater than 1 which is wrong
* We need to find the total number of positives and negatives from the dataset to find the actual False Negative and Positive Rates
* Age is not the same as generations
* Our oldest individuals was 23 generations

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class notes
|Completed
|October 21, 2019
|October 28, 2019
|October 22, 2019
|}

== October 28, 2019 ==

=== Class Notes ===
* I joined the Summarization team for NLP

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class notes
|Completed
|October 28, 2019
|November 4, 2019
|October 29, 2019
|}

== November 1, 2019 ==

=== NLP Meeting Notes ===
* Reviewed subteams under NLP
** Text Summarization- extractive, primitives from text
** Text Classification- primitives from text, stemming/ lemmatization, sentiment analysis
** Neural Networks- add new layers, 
* I switched to Neural Network subteam
* Get branch for subteam running

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Individual: Get Branch on Computer
|Completed
|November 1, 2019
|November 4, 2019
|November 2, 2019
|-
|Review meeting notes
|Completed
|November 1, 2019
|November 4, 2019
|November 2, 2019
|}

== November 4, 2019 ==

=== Class Notes ===
* Overview of NLP
* Familiarize yourself with primitives
* Get Emade running- my clone did not work
* Recloning emade, editing input file

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Individual: Run emade branch
|Completed
|November 4, 2019
|November 11, 2019
|November 7, 2019
|}

== November 11, 2019 ==

=== Class Notes ===
* Start to make some benchmark architectures on nlp and image datasets so that we can use them as seeds
* Specifically, look at the news dataset and the image dataset. Try to get >85% accuracy
* Image classification Keras tutorial to learn
* All my datasets are missing
* Need to download just the datasets from Github
* Learn about Keras

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Group: Benchmark Architectures
|Completed
|November 11, 2019
|November 18, 2019
|November 17, 2019
|}

== November 15, 2019 ==

=== NLP Meeting Notes ===
* Looking over movie reviews data set
* Switch to news dataset
* downloaded all zip files from github
* make a Keras model
* can't pickl at beginning of Keras modeling
* Downgraded tensorflow version to 1.14
*[[files/News DataSet.png|none|thumb|This is my initial result from training on the Movie Reviews Dataset. I need to improve the accuracy to 0.85.]]
https://github.gatech.edu/bsu32/emade/blob/master/datasets/movie_reviews/neuralNetwork.ipynb

Link to movie reviews Jupyter Notebook

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review Meeting Notes
|Completed
|November 15, 2019
|November 22, 2019
|November 18, 2019
|-
|Individual: Get 85% accuracy on movie reviews dataset
|Completed
|November 15, 2019
|November 22, 2019
|November 18, 2019
|}

== November 18, 2019 ==

=== Class Notes ===
[[files/Tuned Paramters.png|none|thumb|I decreased parameters in the evolutionary process to improve my score.]]
[[files/Results.png|none|thumb|The training accuracy resulted in a score of something greater than 0.85.]]

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review Class Notes
|Completed
|November 18, 2019
|November 25, 2019
|November 20, 2019
|}

== November 15, 2019 ==

=== NLP Meeting Notes ===
* Get testing accuracy above .85 too for movie reviews
*Get news dataset accuracy to be above .85
*find only the subtitles for news dataset
*avoid the string to float error
*drop column one in news data set using iloc

* https://keras.io/

*This site gave me the base documentation for Keras.
=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review Meeting Notes
|Completed
|November 22, 2019
|November 25, 2019
|November 23, 2019
|-
|Individual: Get 85% accuracy on news dataeset
|In Progress
|November 22, 2019
|November 25, 2019
|
|}

== November 18, 2019 ==

=== Class Notes ===
* News dataset is stuck at .2473 accuracy
* How to increase accuracy?
* Add models?
* Change parameters?- doesn't seem to help
* https://www.infoworld.com/article/3336192/what-is-keras-the-deep-neural-network-api-explained.html
* This article talked about Dense Layers, types of Keras models, and layers. I wanted to find out more about why the news dataset is hard to predict.

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review Class Notes
|Completed
|November 25, 2019
|December 2, 2019
|November 25, 2019
|-
|Group: Get 85% accuracy on news dataeset
|In Progress
|November 22, 2019
|Dec 2, 2019
|
|}

== December 2, 2019 ==

=== Class Notes ===
==== Final Presentations ====
*[[files/Presentationslide.png|none|thumb|This is the slide I presented during the final presentation.]]
* Comment: check the accuracy of our news dataset
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review Class Notes
|Completed
|Dec 2, 2019
|December 9, 2019
|December 7, 2019
|-
|
|
|
|
|
|}