== Team Member ==
Team Member: Cameron Whaley

Sub-Team: NLP

Email: cameron.whaley@gatech.edu Cell Phone: 770-823-5610

Interests: everything?

==Final Presentation Notes==
'''EzCGP:'''
* Huge train/validation accuracy difference. Amazing how much dropout layers helped this
* A lot of their workflow is "we noticed this problem so we decided to reduce the primitive search space to avoid it" when it feels like time could be spent on a more general solution
'''Modularity:'''
* Excited to see more results next semester
'''Market Analysis:'''
* I think they should keep experimenting with optimization objectives, seems like there's a lot of finance metrics that could be tried

==Week of April 26, 2021: Presentation Prep==
'''Main Meeting Notes:'''
* Everyone is making presentations and gathering data, not much to report
'''NLP Sub-Team Meeting:'''
* Dr. Zutty joined to talk about the efficacy of MinQueueSize and LaunchSize evolution parameters
** We currently have it set at 200, but could have it much lower since it takes so long to evaluate a network
** EMADE has it set at 200 by default because it might evaluate that many sklearn models in the time it takes to start the next generation
** We're going to experiment with lowering this to stop us from getting to gen 20 10 minutes in with no valid individuals
* Did a lot of presentation work this week: https://docs.google.com/presentation/d/13PfLTDQnA1Lct5-SkOJLb8uzvkISPMzfuC6GnMvAmsk/edit#slide=id.gc84dce302c_2_50
** Shoutout to Karthik and Nishant for putting in a lot of effort
* We decided to mainly test how much EMADE is improving over seeded individuals during the evolution process, using AUC as a metric
** Dr. Zutty wasn't a fan of this but I don't think I understood his concerns; will ask for clarification at some point
* We found that emade is making improvements over seeds, but the seeded population isn't very diverse so it's not a huge victory
* Next semester, I think the most beneficial things we can do are
** New mating/mutation functions
** Re-examining the nnm.LayerList and if it can be tweaked to improve survivability of offspring
** Returning to CV, but doing non-multilabel classification (maybe cifar10)
'''Individual Notes:'''
* Made a pull request to cacheV2, incorporating pace functionality and my tree visualization script: https://github.gatech.edu/emade/emade/pull/194
* Made visualizations for runs in aggregate: https://colab.research.google.com/drive/1oKltZODK1JEkNUpllT0X7w2h7UF56xIT

{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Submit pull request for cacheV2
|Complete
|4/25/2021
|4/26/2021
|4/27/2021
|-
|Finish Presentation
|Complete
|4/26/2021
|4/30/2021
|4/30/2021
|-
|Do 5 seeded runs of EMADE
|Complete
|4/25/2021
|4/28/2021
|4/28/2021
|}

==Week of April 19,2021: Multiple Worker Nodes on PACE==
'''Main Meeting Notes:'''
* Modularity struggling to find individuals that evaluate.
** Gabe thinks they need more generations and more objectives
** Dr. Zutty said that only one objective leads to an ElitePool size of one, meaning the selection criteria is only that one individual + offspring (so too low). Definitely need to look into this
* Dr. Zutty talked with NLP about experiments we'll be running in preparation for final presentations. Mentioned that initial population of runs, regardless of if we "seeded", will be the same because EMADE uses a set seed
'''NLP Sub-Team Meeting Notes:'''
* Dr. Zutty joined us and talked about implementing Learners' MakeFeatureFromClass method into NNLearners & enabling NNLearners as subtrees
* Discussed changing objectives as well. Majority of us will start using FPR and FNR for more diversity. Will compare results here vs accuracy in final presentation (still using num_params in both cases)
* Went over how to seed database before runs in PACE
* Cameron B asked if running EMADE and looking at individuals' performance is a good way to find ways to improve evolution. We agreed that this was the best plan for the rest of the semester.
* Planned final presentation practice for Wednesday, 4/28
** Code freeze will occur on noon of that day, so that's the deadline for those working on debugging/primitives
* Nishant managed to connect to mysql on PACE using MySQL workbench. 
** This is super useful, because we can't connect to mysql on PACE from command line unless a local mysql instance is running, and we can't start a local instance if emade is running because the port is taken
'''Individual Notes:'''
* Worked with Dr. Zutty this week to test GPU functionality when using multiple worker nodes on PACE
* Was quite difficult, found that worker nodes were competing for same hardware, and worker processes within nodes were doing the same
** There's an "exclusive process" gpu flag that doesn't seem to work
** Short-term solution is to set workersPerNode to 1 and restrict worker nodes to unique users
* Implemented this into nn-vip, but GPU availability is limited so we'll be doing CPU runs for now.
** Commit: https://github.gatech.edu/emade/emade/commit/8514294f7c505d3f14e67a04aa7e748a67345ebf
*** I accidentally, re-introduced the bug in EMADE.py from last week, but fixed it the next day
* I'll submit a pull request to cacheV2 sometime next week

{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Test PACE functionality in cacheV2
|Complete
|4/19/2021
|4/26/2021
|4/25/2021
|-
|Pull PACE functionality into nn-vip
|Complete
|4/19/2021
|4/26/2021
|4/25/2021
|-
|Submit pull request for cacheV2
|Incomplete
|4/25/2021
|4/26/2021
|
|-
|Do 5 seeded runs of EMADE
|In Progress
|4/25/2021
|4/28/2021
|
|}

== Week of April 12, 2021: Run Results & A Few Branch Changes==
'''Main Meeting Notes:'''
* Dr. Zutty said an old bug in cacheV2 branch has been fixed. Will need to carry change over to nlp branch(es)
* Market Analysis discussed different tests they can conduct for significance
* ezCGP is looking at individuals being generated vs selected: almost all of those selected have 5/6 nodes -- curious
** (more complex ones are being generated)
* Modularity had few valid individuals after a small run -- solution is apparently just to run for more generations
** Memory overhead of MNIST could also be an issue
* Dr. Zutty requested that NLP incorporate the PACE GPU fix into a PACE functionality pull request & submit a PR to incorporate into cacheV2
** Also commented on PACE walltime limits. Recommended just re-seeding pareto front to compensate in the short run
** Long run fix would mean moving to a different computing environment or adding a "continue" flag to maintain the full run (good for a long-run goal)
'''NLP Sub-Team Meeting Notes:'''
* Did updates; most new members are done with PACE setup. Some returning members are a bit behind
* Discussed run results; Steven had a 24 hour run (submitted from command line so no walltime or GPU) and I had 3 8-hour runs
* Still no new individuals beating seeded ones -- need to do longer runs
** PACE walltime basically limits us to repeatedly re-seeding the pareto front across runs
* Went over tasks for rest of semester. Everyone will self-assign by Friday here: https://docs.google.com/document/d/1V-etbhOdzUfgjwMLX7qtFNQEVGNnmrx5GfaQxfeosJ4/edit
'''Individual Notes:'''
* Am working on long 'run' where I repeatedly seed with the old pareto front
** Did 3 sequential 8 hour runs & got decent results. Still nothing out-performing the LSTMs we are seeding with, but there were some novel architectures that did nearly as well (~90% accuracy)
** This individual happened around (summed) "generation" ~10 with 90% accuracy:
** NNLearner(ARG0, OutputLayer(DenseLayer(10, defaultActivation, 10, MaxPoolingLayer1D(6, EmbeddingLayer(100, ARG0, heWeights, InputLayer())))), 100, SGDOptimizer)
* Am implementing PACE functionality into CacheV2. I made all changes I think are necessary but still need to do some testing
* Pushed a bunch of small changes to our branch: https://github.gatech.edu/emade/emade/commit/e601753e23c53b47ee645c9ae1e1a0252c62d1d5
** incorporated CacheV2 database bug fix
** Added reduced amazon train set
** changed seeding file name and seeding_from_file.py to make things more straightforward (basically so we always clear the database before seeding, regardless of input xml file), etc.

{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Task Somebody with fixing pretrained embedding layers
|Complete
|4/3/2021
|4/5/2021
|4/12/2021
|-
|Come up with tasks for rest of semester
|Complete
|4/9/2021
|4/12/2021
|4/12/2021
|-
|Add PACE functionality to cacheV2 (fix old PR)
|Complete -- Needs testing
|4/12/2021
|4/19/2021
|4/19/2021
|-
|Pull cacheV2 DB fix
|Complete
|4/12/2021
|4/19/2021
|4/19/2021
|}


== Week of April 5, 2021: Resolving Final PACE Issues==
'''Main Meeting Notes:'''
* We're all mad that the vip wiki is getting deprecated
* Dr. Zutty recommended that NLP just reduce the training dataset size and move on for now
* Dr. Zutty lectured on hypothesis testing; most people stayed for this
'''NLP Sub-Team Meeting:'''
* Most people were troubleshooting PACE setup issues on Monday
* Steven split amazon training dataset into k=20 folds. We'll stick with using one fold for now (still using normal test set).
* Moved Anshul's NN/NLP lecture to Friday due to the hypothesis testing lecture
** Presentation went well and was very thorough. Went long so nnMethods lecture and new-member-tasking will happen next week.
'''Individual Notes:'''
* Found a resolution to the "Mysql operational error 2003: Can't connect to MySQL server on 'atl1-1-02-012-5-l'
** These "atl..." host names seem to be dynamic. Usually the one listed above works, but I've noticed that if a lot of other PACE users are running things, I often get the error above
** solution: run mysql pbs script, then run 'qstat -n' to find the host name. Copy/paste it into the input xml file and the issue should be solved
* Was getting GPU issue with CUDA dynamic libraries ("Failed to load dynamic library libcudnn.so.8") in PACE. 
** Resolved by adding '''export LD_LIBRARY_PATH="/usr/local/pace-apps/manual/packages/cuda/11.1/lib64"''' to launchEMADE.pbs file
* Got confirmation from PACE OIT that walltimes are permanently reduced to 8 hours

{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Resolve dataset memory issue
|Complete
|3/31/2021
|4/9/2021
|4/5/2021
|-
|Task Somebody with fixing pretrained embedding layers
|Incomplete
|4/3/2021
|4/5/2021
|
|-
|Fix GPU Dynamic Library Issue
|Complete
|4/5/2021
|4/12/2021
|4/11/2021
|-
|Come up with tasks for rest of semester
|In Progress
|4/9/2021
|4/12/2021
|
|}

== Week of March 29, 2021: Amazon Memory Issue, New Member Initiation==
'''Main Meeting Notes:'''
* Market Analysis covered Dr. Zutty's proposed use of Monte Carlo method for establishing a baseline that they can use for hypothesis testing
* Dr. Zutty covered some lines in EMADE.py that redirect stdout during runs. Was to help NN debug NNLearner but the issue was more complicated
'''NLP Subteam Meeting:'''
* Did introductions with new members
** Covered basics of EMADE during Friday meeting
* Discussed logistics of getting everyone on PACE, but issues with the wiki might slow things down
* Tokenized Amazon Dataset is 14GB. Discussed different solutions to running out of memory
** Reducing max sequence length (currently hard-coded to 1000) or parsing dataset to determine it
** Reducing instances of train dataset
** Using a scipy sparse matrix instead of a numpy array (courtesy of Cameron B.)
'''Individual Notes:'''
* I made a presentation on EMADE basics for our branch: https://docs.google.com/presentation/d/1v33k5I9b-_MIR9f3QhO4U81HJaBRwWqt6xzoSecDsoA/edit?usp=sharing
* Discovered a bug in NNLearner code meant to change input size for individuals using Pretrained Embeddings with text data. The code breaks things so it's commented out now
** It attempts to edit the Keras model directly by converting to JSON and editing, but editing it is not straightforward
* Made a video guide to setting up PACE: https://www.youtube.com/watch?v=LashYCCJF3E
** Mostly meant for NN/NLP team but most of it should carry over

{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Resolve why NNLearners are failing
|Complete
|3/21/2021
|3/29/2021
|3/31/2021
|-
|Develop working individuals for seeding
|Complete (they were not broken)
|3/21/2021
|3/29/2021
|3/31/2021
|-
|Resolve dataset memory issue
|Discussing options
|3/31/2021
|4/9/2021
|
|-
|Task Somebody with fixing pretrained embedding layers
|Incomplete
|4/3/2021
|4/5/2021
|
|}

== Week of March 22, 2021 - Midterm Presentations ==
'''Presentation Notes:'''
* Market Analysis:
** Interesting analysis of their unique individual. 
** Conversation on evolvability was interesting. Technical Indicator primitives had a lot of parameters which led to a lot of potential for failure
*** highly relevant to failure-rate of NNLearners. Will want to discuss this with Dr. Zutty in the future
* ezCGP:
** REALLY good background information on what CGP is and how it differs from EMADE
** great overview on their architecture, how it works, its intuition, etc
* Modularity
** I think their identification of the potential for loss of genetic information was really keen
*** their solution was also well-thought-out
* Bootcamp 1: their need to connect to remote databases will be good practice for platforms like PACE
* Bootcamp 2: Thought their use of string matching for imputing features was smart
'''NLP Sub-Team Meeting Notes:'''
* Discussed our plans for rest of semester. The goal is to have everyone focus on getting nontrivial results and put everything else to the side
** Everyone other than Steven and I will get set up on PACE within the next week so that we can debug in a consistent environment
* Still unsure why NNLearners are not evaluating, but we've narrowed the source of the issue down to the NNLearner primitive code.

{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Resolve why NNLearners are failing
|In Progress
|3/21/2021
|3/29/2021
|
|-
|Develop working individuals for seeding
|In Progress
|3/21/2021
|3/29/2021
|
|}

== Week of March 15, 2021 - Seeding DB, Runs Galore, Examining Why Individuals Fail ==
'''Team Meeting Notes:'''
* Market Analysis:
** Finished their run of EMADE. Only 2-3 non-seeded individuals were able to be evaluated
*** They identified that many individuals were erroring because the mode mode and axis were not set properly; otherwise they seemed like promising individuals
*** This is a problem that NN is encountering as well. I would like to take a page from their book and examine more deeply *why* so many of our individuals fail
* EZCGP:
** Their work to add dense layers is difficult due to shape mismatches -- they think that CGP is a hard framework in which to get this right
*** they'll probably have to do more checking/preprocessing post-midterm to get this to work
* Modularity:
** Testing on the Depth Problem is nearly complete, will start experiments soon
** Testing for Genetic Duplicates is a little further behind, but should be done by EoW
'''NLP Sub-Team Meeting Notes:'''
* The MySQL error from seeding the DB on PACE was resolved -- solution was to run pbsmysql.pbs before running seeding_from_file.py instead of starting a mysql instance from terminal -- credit goes to Anish (as usual)
** to reiterate, seeding your database before a run is done as follows in terminal:
 qsub pbsmysql.pbs

 python src/GPFramework/seeding_from_file.py templates/input_amazon.xml seeding_test_toxicity # the given arguments are template file & seeding file, respectively

 qsub launchEMADE_amazon.pbs 
* Once this worked, we went through several iterations of deprecated seeding files or individuals with typos
* nn and nn-vip were merged 
* Anshul attempted to replicate another Kaggle notebook on Colab & got his runtime disconnected *again* when he tried to fit the model...
* Alex is creating SOTA-ish models as NNLearners, but his first attempt used a model that is very hard to represent as a tree
** TL;DR is that some nodes needed to refer to parents-of-parent nodes

* Completed a run, but since all NNLearners are failing (see next section) and individuals that are not encapsulated by NNLearners fail by design, we had a pareto front of INFs
** Discussed making NNLearners as subtrees and how much time is devoted to non-NNLearner individuals that are certain to fail

* Presentation development notes:
** wrote most of the presentation on Friday and did a practice-run on Sunday
** Since we do not have results, devoted most of the presentation to triviality investigation and discussion of errors
** slides: https://docs.google.com/presentation/d/1bpIN_1nL6PB8fMq1yvEDQnuy_ktcSY87HV2nxNsvmas/edit#slide=id.gc84dce302c_2_50
*** I covered PACE development and why individuals fail
'''Individual Notes:'''
* Using a script Sumit wrote last semester, I'm examining .out files to understand why individuals fail
** using results from last semester on the toxicity dataset
** Wrote code to compile dataset labeled as {1: evaluated, 0: did not evaluate (INF)} with indicator data on which primitives were used
** Used Gini information gain to determine feature importance
** Analyzing an arbitrary top n most important primitives, found those with a failure rate higher than 97.5 (see below)
** in the future, will find a more sophisticated way to rank features & will look for common error messages
** goal is to use this as a tool to debug and improve evaluation outlook for individuals
[[files/Failure prone primitives.png|none|thumb|428x428px]]
* Tried very hard to get run results for midterms, didn't pan out. Here's a list of errors we ran into this week:
** errors in NN-related mutation functions: add layer, remove layer, swap layer, modify layer all had the following issue. 
** The code checks that len(iprims) !=0, but fails to consider that the "type_ == prim.ret" condition in the list comprehension could lead to an empty list
*** added a second check for this in all 4 cases -- fixed
[[files/Mutation error.png|none|thumb|889x889px]]
** eval_methods.py had an error for calculating accuracy -- forgot to cast lists to numpy arrays -- fixed
** '''All NNLearners are failing'''. Got a specific threading error for all NNLearners using Pretrained Embeddings, but even removing those led to errors & seeded individuals still do not evaluate
*** The formats of several neural network primitives appear to have changed over winter break & this appears to be what's breaking things...not 100% sure though
* '''Pushed changes''' '''for fixed errors''' above: https://github.gatech.edu/emade/emade/commit/b9ea1ea1ec218b9ca39732a2c90c32fdfad7082b
** also added working .yml file for my conda environment
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Push working .yml file to github
|Complete
|2/22/2021
|3/22/2021
|3/21/2021
|-
|Resolve database seeding issue on PACE
|Complete
|3/12/2021
|3/19/2021
|3/15/2021
|-
|Seed database with new seeding file from Anish
|Complete
|3/15/2021
|3/17/2021
|3/16/2021
|-
|Examine .out files with Sumit's script -- Find commonalities between failed individuals
|Complete
|3/15/2021
|3/19/2021
|3/19/2021
|-
|Midterm Presentation Slides
|Complete
|3/15/2021
|3/22/2021
|3/21/2021
|-
|Resolve why NNLearners are failing
|In Progress
|3/21/2021
|3/29/2021
|
|-
|Develop working individuals for seeding
|In Progress
|3/21/2021
|3/29/2021
|
|}

== Week of March 8, 2021 - Enabling GPU on PACE, Learning How to Seed Runs ==
'''Team Meeting Notes:'''
* Market Analysis:
** PLR and exponential smoothing primitives are ready
** Confused on how their working paper is finding the optimal threshold using its genetic algorithm. Their plan is to determine it themselves because it probably won't matter a lot.
** Planning on doing a run of emade within a week
* EZCGP:
** Have results from 7 hour run. 
** Unsure if preprocessing steps are helping a lot
** Dense layers are not being added, planning on looking into why that's the case
** Dr. Zutty discussed the idea of tweaking individuals and re-evaluating them to see how they would hypothetically do
*** Also discussed possibility of overfitting given train vs test loss
* Modularity:
** Has individual functions for addressing "depth problem" written. Just needs to combine/test
** Added function to insert new randomly created individuals at the end of each generation 
*** in case genetic material shrinks too much over time due to forming of ARLs.
'''NLP Sub-Team Meeting Notes:'''
* went over results for steven and I's runs on pace-ice:
** steven's has been going for many hours and is on generation 20+. His pbs scripts set a walltime of 2 hours... very confused why it didn't stop there
** my run DID stop at 2 hours. Didn't get past generation 1. Looked at my .err files with the team and discovered GPU is not being used due to this [https://github.com/tensorflow/tensorflow/issues/45930 libcudart.so.11.0 error]
*** anish suggested doing "conda install cudatoolkit=11.0" but I got tons of environment conflicts
**** solution: see individual notes
*** Anish said that good runs typically last a couple days... the max walltime I'm able to set is 8 hours so this is another problem
* Anshul, Sumit, and Alex are still working on getting a baseline run in a notebook -- looking for different architectures to involve the disconnected session issue.
* Jon said he will be using PyTorch Lightning (TM) for the refactor due to the simplicity in its implementation.
* With GPU access, runs are still not great, so Anish and Alex went over how to use seeding_from_file.py with Steven and I
** This file populates an empty(?) database with hand-selected NNLearners that have done well in the past
** EMADE is currently unable to evolve quality NNLearners, so our current solution is to kick-start the evolutionary process with these individuals ruling the gene pool
** We can't run this successfully on PACE yet (see individual notes).
'''Individual Notes:'''
* Fixed the GPU issue. The pbs script in the guide was simply not configured to request anything other than CPUs
** needed to update launchEMADE.pbs script to use the pace-ice-gpu queue and request GPU nodes. I've updated this wiki's [[Guide to Using PACE-ICE|PACE guide]] so others won't have this problem
* Now that I know to use the pace-ice-gpu queue, runs on PACE can now go up to 16 hours. Better, but still not at the level we need. We will probably have to look for another computing solution in the future
* 8 hour run with GPU still did not get past generation 1... most individuals are erroring during evaluation
* PACE runs are not seeded, so that's the next step
* unfortunately, my conda environment inexplicably lost more than half of its packages, so I had to spend some time re-configuring that
* Running seeding_from_file.py is giving Steven and I a [https://stackoverflow.com/questions/18150858/operationalerror-2002-cant-connect-to-local-mysql-server-through-socket-v MySql Error] that is complaining about socket paths.
** No idea why because the current database configurations work just fine when running EMADE (see next week for solution)
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Push working .yml file to github
|On-Pause
|2/22/2021
|
|
|-
|Fix GPU issue
|Complete
|3/7/2021
|3/14/2021
|3/10/2021
|-
|Resolve database seeding issue on PACE
|In-Progress
|3/12/2021
|3/19/2021
|
|}

== Week of March 1, 2021 - Debugging & Examining Bad Run Results ==
'''Team Meeting Notes:'''
* Market Analysis:
** Wrote implementations for several price-related technical indicators; now looking into volume-related indicators
*** looking into implementing a python library that could implement hundreds of indicators for them
** got new data from AlphaVantage which is more consistent with the paper they are working with
** Implemented Exponential Smoothing proof-of-concept
* EZCGP:
** Resolved a few bugs in their pipeline that were affecting reported accuracy
** ran cifar-10 without transfer learning, didn't reflect much on results.
* Modularity:
** "boring week". Contuing work on depth problem and database storage. 
** Wrote a new function to find ARLs, but this requires almost everything else in their pipeline to be updated.
'''NLP Sub-Team Meeting Notes:'''
* Steven and I both ran into the classic tourney select error for deap:
 ValueError: selTournamentDCD: individuals length must be a multiple of 4
* solution: downgrade to deap version 1.2.2; 1.2.0 has also worked for me in the past.
* Steven and I both tentatively have emade working for the Amazon dataset
* Sumit is now dealing with irregularities in hand tuning a model due to the embedding file he is using. He'll switch to the file that we use in emade
* The group discussed a PyTorch refactor vs Dr. Zutty's suggestion of a hybrid refactor. 
** we're a little confused about what this means exactly. IF it means that some individuals exclusively have pytorch/keras features, I don't see the efficacy in doing a run with both as opposed to separate runs -- maybe there is potential for coevolution.
'''Individual Notes:'''
* Upon doing a second run on the amazon dataset, I ran into a mysql error. My error log showed the following:
[[files/Mysql port error.png|none|thumb|457x457px]]
* Found a solution [https://serverfault.com/questions/477448/mysql-keeps-crashing-innodb-unable-to-lock-ibdata1-error-11 here]. TL;DR is that my previous mysql instance did not terminate properly, so the port was still in use. I ran 
 lsof -i:PORTNUMBER # my port number was 3360
* which gave me the PID of my last run. I then did "kill -9 PID" which freed up the port and let me do a run.
* After resolving this issue, I can finally run EMADE, to completion, with no errors, up to 8 hours
* The results are not good though. EMADE is getting hung up on poor individuals, and I have yet to make it past generation 0 or 1
** theory: it's because I'm not using a GPU. My master.err file threw a warning: "Could not load dynamic library 'libcudart.so.11.0...'
* Putting yml file task on-pause because we're trying to merge nn and nn-vip branches before first-semesters join. I'll wait until then
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run EMADE on amazon dataset
|Not Started
|2/26/2021
|3/5/2021
|3/5/2021
|-
|Fix GPU issue
|In Progress
|3/7/2021
|3/14/2021
|
|-
|Push working .yml file to github
|On-Pause
|2/22/2021
|
|
|}

== Week of February 22, 2021 - conda environment issues, debugging PACE runs ==
'''Team Meeting Notes:'''
* Market Analysis:
** will create a monte carlo fold per stock -- so they will create a predictive model for a given stock
** there was confusion on replicating PLR code from their comparison paper, but they've now been able to replicate the results.
* EZCGP:
** got pace-ice set up for their accounts
** made a shared .conda file -- something I want to look into
** running into memory issues on runs though
* Modularity:
** pretty much done with documentation on sphinx
** splitting into two teams to investigate:
*** how to find ARLs
*** how to store them efficiently in databases

'''Sub-Team Meeting Notes:'''
* Jon finishing up documentation, planning on porting to sphinx soon
* Anshul having an issue where colab stops running when he tries to fit his model. Sumit is going to start working with him on that to resolve by end of week
** no resolution as of Friday
* Dr. Zutty dropped by & approved Jon's undertaking of implementing our branch in PyTorch... Jon's first goal will be to complete a PyTorch tutorial (lmao)
* Steven is trying to run the amazon dataset on PACE-ICE but was having trouble because the files weren't properly gzipped.
** The data just storing pointer hash codes... Dr. Zutty said we needed to use git LFS and then pulling the dataset should work
** I gzipped my files manually so I didn't have this issue. Dataset is pinned on the slack
* I ran into a new PACE-ICE problem -- couldn't run reinstall.h without getting "invalid command" errors. Dr. Zutty's solution was to just run python3 setup.py install (replace "install" with "develop" if debugging and NOT actively doing a run if you want to not run it after every change) instead of reinstall
* Several minor issues cumulated, causing Friday to be a major debugging session. By the end, Steven and I could both do runs on PACE. Those creating models in notebooks weren't able to fix things.
** biggest issue: gpframework file in nn-vip github branch did not function correctly. This was overlooked because most runs are made from regular nn branch

'''Individual Notes:'''
* I had emade working on PACE last week, but this was a fluke because my environment was still missing some key packages.
* I attempted to conda install keras-preprocessing, which somehow downgraded me to tf 1.4.1 despite Keras requiring at least 2.0.0
* Decided to delete my .conda folder and reinstall with the emade35.yml file
* finished up dependencies, made change to gpframework.py noted in sub-team notes above, and ran toxicity successfully
* imported amazon dataset and customized the input xml file; no issues with running yet! Will start a seeded run next week.
* Told team I'd maintain a working .yml file so environment setup is easier going forward; will work on that next week as well.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|run emade on amazon dataset on PACE
|IP - extended
|2/8/2021
|2/22/2021
|2/26/2021
|-
|Push working .yml file to github
|Not Started
|2/22/2021
|3/5/2021
|
|-
|Run EMADE on amazon dataset
|Not Started
|2/26/2021
|3/5/2021
|
|}

== Week of February 15, 2021 - setting up mysql on PACE ==
'''Team Meeting Notes:'''
* market analysis:
** did literature search to look for more features to add to branch, settled on new paper.  A lot of building blocks are the same but they're adding some functionality like exponential smoothing, a piecewise-linear representation of prices, and a new dataset (circa 2008 stock info)
** asked about whether they should do individual runs per stock or combine them. Dr. Zutty recommended throwing all the data together and anonymizing the stock ticker label
* ezcgp:
** got pace-ice running for everyone, but process was killed after 2 hours. They hypothesize that this is due to memory constraints (they hit 50 GB). They're working with image data and are looking for ways to minimize memory used by individuals
*** Dr. Zutty was skeptical if 50GB was enough to kill the run, emphasized that they might need to ask for more memory in a job than is given by default
*** he also advised modifying what gets written to error files to see if they can find a more specific issue
* modularity:
** did a lot of documentation [will link page later]
** did some "decide future directions discussions"
*** going to rewrite how ARLs are found so they can increase complexity/depth
'''Sub-Team Meeting Notes:'''
* Sumit and Anshul are working on implementing SOTA-ish amazon dataset models on notebooks. 
** Sumit didn't have updates, Anshul is debugging an issue with the word embedding file.
* I updated my progress on PACE-ICE setup (thru 3rd bullet of indiv notes). 
** No one else has tried to set up PACE-ICE so they recommended I reach out to Maxim or Anuraag for help, but neither of them are in the VIP anymore so I'm not too hopeful
* Steven is running out of disk space when setting up GPFramework environment. 
** We believe it's because he didn't delete the ./git repo in emade before transferring the entire repo onto PACE
** He will re-do the file transfer with that change and report back
* Anish properly has the amazon dataset in emade, now he just has to do a run
* Jon expressed interest in diving into some coding when he's done with documentation (soon)
** we brought up that integrating attention would be much easier if we transitioned to PyTorch --> Jon is interested in working on PyTorch transition
** asked Dr. Zutty for his thoughts; didn't hear back as of Friday 
'''Individual Notes:'''
* 2nd try to upload emade directory to PACE-ICE worked (I deleted the .git folder in bash before uploading this time), setting up MySQL is next
* Maxim's guide (see below for link) is mostly working, but his fix for the "port 3306 is currently in use" error (see pic below) is not. Every solution on Google seems to execute without error (as does maxim's), but doesn't fix the problem
** will ask about it in team meeting. If no one has ideas, I'll try another port number
[[files/Pace mysql port error.png|none|thumb|749x749px]]
* tried port 3360 and it worked fine
* mysql server instance now runs fine
* set myself up as a user on mysql -- the command 
GRANT ALL PRIVILEGES ON *.* TO 'USERNAME'@'%' IDENTIFIED BY PASSWORD 'your-new-password' WITH GRANT OPTION;
* wanted my password in hash form (??), fixed it by dropping "PASSWORD" from the query.
* got conda environment working (after running into a few "disk quota exceeded" errors and realizing that failed attempts let to duplicate packages)
** idk how to link files on here but message me for the yml file i used
* setup.py did not work due to issues from easyinstall... just pip installed all the packages I didn't have cause there weren't that many
* can now run our branch of emade on PACE on toxicity dataset. Will add amazon dataset first thing Monday
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|get emade-nn working on PACE
|Complete
|2/8/2021
|2/19/2021
|2/21/2021
|-
|run emade on amazon dataset on PACE
|IP - extended
|2/8/2021
|2/22/2021
|
|}

== Notebook Self-Evaluation ==
Notes for myself:
* entries could use more reflection + justification
[[files/Self-eval.png|none|thumb|633x633px]]

==  Week of February 8, 2021 - Getting started on PACE ==
'''Team Meeting Notes:'''
* Weekly Updates:
** Market Analysis: reading a paper, doing more "finance" research now that they have a better idea of what emade can do
*** looking into using "fundamentals" of stocks to decide buy/sell point
** EZCGP:
*** still working on getting rid of transfer learning. PACE down for maintenance over the weekend so wasn't able to do testing
*** looking into transformers/using GPT (not specifically GPT-2/3 from openAI - that is NLP specific) as a primitive
** Modularity:
*** Continuing with paper review -- everyone brought their own and are bouncing ideas off of each other
*** unanimously wants to expand complexity (mainly of ARLs?) that can be generated
*** might look at CoDeapNeat paper to explore modularity in neural nets?
*** talked about documenting work since members are still unsure about source code -- using sphinx
** NLP:
*** see sub-team meeting notes for last week
'''Sub-Team Meeting Notes:'''
* Monday:
** Sumit found a kaggle notebook that mostly used keras functionality in EMADE's toolkit & got pretty good accuracy (>>50% (dataset is distributed 50/50)) so he and Anshul will be recreating that with NNLearner code to make sure everything runs fine
** we have the dataset and xml file ready to go, now we just need to make sure it runs in EMADE
*** easiest way to do runs atm is for Anish to use GTRI cluster. He says he'll try to get it done this week
*** If that doesn't pan out, Steven and I will take this opportunity to set ourselves up to do runs on PACE-ICE using [[Guide to Using PACE-ICE]] and [[Notebook Maxim Daniel Geller|Maxim's notebook]]
* Friday
** Anish has dataset in emade, just needs to run it
** Anshul and Sumit are trying different approaches to creating an amazon review classifier with just Keras (both SOTAish), haven't done much implementation since Monday
** Steven uploaded branch of emade into PACE, is working on setting up conda environment
** I am still getting emade onto PACE (got 99% done and then failed -- will investigate more next week)
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|get amazon dataset into emade to test if binary data gives trivial solutions
|Complete
|2/5/2021
|2/12/2021
|2/12/2021
|-
|get emade-nn working on PACE
|IP
|2/8/2021
|2/19/2021
|
|-
|run emade on amazon dataset on PACE
|Not started
|2/8/2021
|2/19/2021
|
|}

== Week of February 1, 2021 - Deciding Team Direction ==
'''Team Meeting Notes:'''
* Discussed team goals for the semester:
** Stocks wants to do more work with technical indicator primitives, examine behavior of their individuals w.r.t. buy/sell points
** Modularity examining ARL tree depth >1; relies on a big assumption though
** EZCGP discussed transfer learning, how they're dividing up work in their small group
** see NLP notes in sub-team section
* Modularity doing literature review to get transfers up to speed
'''Sub-Team Meeting Notes:'''
* Dr. Zutty gave thoughts on team direction, main point was focusing on evolvability of networks, processing data to make emade get better insights,..., basically not primitives.
* Mostly trivial solutions are happening; we need to figure out why
* There's a chance there's some sort of bug or oversight in our code and how we're evolving
* We've matched the LEAF paper in many parts of the pipeline, but it has a much more complexity in evolution that we could look into
* We didn't do many runs last semester. We need to do more investigation into statistical significance & how our branch performs in the long run
* need to look into how networks are doing, how much diversity is in our dataset (only 9% are toxic, so that could be a source of trivialness)
** Working on the Amazon product review dataset could be better since it's SOTA is 60-65% so we'd have more room for improvement.
*** binary classification so can help us do sanity checks w/ NNLearner
*** need to download it and run it with emade-like notebook to see if we can get a nontrivial solution (i.e. our accuracy results are significantly different than the distribution of the classifications)
*** need to find other models for dataset on kaggle/medium, hand-tune model like that, and make sure emade can make something similar
*** Steven and I will work with Anish on getting the dataset going in EMADE, Alex will work with Anshul and Sumit to create a model with Keras
* Jon will work on documenting some NLP primitives to get up to speed
* Established meeting time of Fridays at 4pm
'''Action Items:'''

General theme: sanity checks
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Establish Team Meeting Time
|Complete
|1/25/2021
|2/2/2021
|1/25/2021
|-
|Make a decision on dataset for semester
|Complete
|2/1/2021
|2/8/2021
|2/5/2021
|-
|Schedule talk with Anish about triviality of networks & work he/Mohan/Pulak did over break
|Complete
|2/1/2021
|2/8/2021
|1/26/2021
|-
|get amazon dataset into emade to test if binary data gives trivial solutions
|IP
|2/5/2021
|2/12/2021
|
|}

== Week of January 25, 2021 - Start of Third Semester ==
'''Team Meeting Notes:'''
* First meeting of semester
* checked team status, looks like teams will stay the same this semester
* Jon volunteered to lead NLP team

== Week of November 30 - Final Presentations ==
'''Presentation Notes:'''
* NLP Presentation: https://docs.google.com/presentation/d/1Z8PjzaP_LjhyycpGSeXX7rIHdVYkxHzqg8vaKVEYhdU/edit#slide=id.gade55d12ba_0_17 

* Stocks:
** Gave a good overview and motivation for their new primitives
** When talking about technical indicators, they talked a lot about the "conventional wisdom" behind their use. E.g. if "indicator X" goes down, you'd probably sell
*** I'm unclear if they're hard-coding this expected behavior, or if they're giving the values to EMADE and letting it decide
*** If it's the latter   I'd like to see them analyze if their best individuals behaved according to this expectation
* EZCGP: 
** Their presentation was very good -- graphics, results, and explanations all were impressive. 
** I think the thing they lacked the most was '''motivating''' why they made most decisions. E.g., not using transfer learning, switching to mnist dataset, not using neural networks
* Modularity:
** I like that their presentation is clearly broken up into different experiments, each with a description, motivation, results, and takeaways
** Their results have been impressive; glad they're moving onto MNIST so they can increase the scope of primitives they use and maybe create some more complex ones
** Motivation for datapair restrictions was good -- I like that they had a hunch and did a lot to investigate it
*** IMO, one of NN's biggest flaws is that we spread ourselves too thin; this presentation is a good argument for focusing effort into a few key areas that could improve results.

== Week of November 23 - Finalizing and pushing BERT *Input* Layer ==
'''Team Meeting Notes:'''
* Stocks team is moving on from the original paper whose findings they were replicating. Now that they've established a baseline they can do more original research on top of that.
* EZCGP is drafting their presentation and continuing runs.
* NLP gave an overview of the myriad of runs we're doing, covering the different places we're doing the runs and the different sizes we're doing.
* Modularity has started with their runs. They're still not at statistical significance, but they only have a sample size of 4 so it's by no means conclusive.
'''NLP Sub-Team Meeting:'''
* Anish managed to do a baseline run over the weekend. 
* Tejas is having trouble setting up the conda environment in PACE so we spent some time troubleshooting that. It seems like it's an issue on their side -- when he tries to conda install something he gets a "we've contacted the admin that you're trying to do this error" and can't move forward. Pip installing is finnicky but seems to be a decent workaround.
* Tusheet, Tushna, and John are finishing up their CV primitives and are finishing up their work by consulting with Dr. Zutty. 
* Anshul and Alex are finalizing the adaptive mutation function. They're fiddling with mutation probabilities now -- it seems like something that will need considerable fine-tuning.
* Friday meeting:
** Did a lot of troubleshooting for everyone that's doing runs on pace. Pretty much everyone was running into some sort of error which Anish and Pulak were able to sort out.
** talked about results from new datasets -- disease prediction is giving us 50% accuracy with an extremely small individual performing well; we're thinking that there's something weird going on with our evaluation metrics.
*** we're also confused about the paper that we're comparing our results to. We don't know if they considered a "correct" classification as getting all diseases right, or if they had partial credit
** spent the rest of the time planning the outline of our presentation
'''Individual Notes:'''
* Weird week because of Thanksgiving + final project due dates 
* Built new BERT Input Layer primitive as mentioned last week.
** Everything was pretty straightforward, except handling tokenization: this huggingface BERT model expects sequences to be tokenized by their own tool, so I needed to write code to 
**# Detect if BERTInputLayer was present in an individual &, if so tokenize data within a datapair differently 
**# Write a method to take in a datapair and output train/test sets tokenized for BERT 
* Meanwhile, was still getting "graph disconnected error" with BERT input layer :(
** met with Pulak to see if he could help -- he suggested casting BERT as an input layer, which ran without error, but ended up making identical classifications as individuals without BERT 
** realized I need to place an input layer '''before''' BERT in the layerlist 
** I was '''still(!)''' getting a graph disconnected error though -- for some reason it was expecting BERT to be an input layer 
* Decided to add a bunch of print statements until I found this: 
[[files/BERT nemesis.png|none|thumb|451x451px]]
* Line 781: while recursively going through layerlist & creating model, if it reaches a tensor object in the layerlist, it treats that as an input.
** While this works for native keras layers, huggingface's BERT model is technically a tensor object (despite acting like a keras layer syntactically when added to a model)
** This was my "Ah ha" moment: the line "''model = Model(inputs=input_layers, outputs=outputs)''" always failed because "input_layers" contained BERT, which is not a Keras input layer
** By using the .op method on the layer, I was able to access a string representation of the layer and found that BERT has the string "Identity" in it, which I use as shown:
[[files/BERT input fix.png|none|thumb]]
** I killed 2 birds by adding a boolean flag so that a datapair is tokenized correctly depending on if BERT is present. Can see that code + the tokenizer method in my commit below

* Pushed BERT input layer: https://github.gatech.edu/emade/emade/commit/9295727e6fcf3b4c1eeb42965d6a00ef3898528b 
* Pretty unfortunate that I couldn't get to Attention or a regular BERT layer this semester. I'll be working with several members of the team over break since we're trying to submit a paper at the end of January. Hopefully I'll have made good progress once I'm back in the Spring
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Debug BERT Layer
|Unsure if possible
|November 2, 2020
|?
|
|-
|Write and Debug BERT *Input* Layer
|Complete!
|November 20, 2020
|November 30, 2020
|
|-
|Add attention mechanism into nn-vip branch
|On hold
|October 2, 2020
|?
|
|}

== Week of November 16 - Graph disconnected: cannot obtain value for tensor... ==
'''Team Meeting Notes:'''
* Stocks team wasn't able to replicate one result regarding trends and is planning on reaching out to the authors of the paper that they are trying to replicate. If they use the given (unreproducible) values, they can replicate the rest of the data (which is kind of good)
* EZCGP was able to do their first run of the semester, but had some issues with timing out. They're now looking for a way to resume their run after colab times out. Dr. Zutty suggested exporting the state of their run at the 9.XX hour mark (colab times out at 10 hrs) and then restarting.
* NLP is moving onto experimentation with the exception of those working on adaptive mutation, BERT, and new datasets.
* Modularity had a bit of a slow week. They're mostly doing runs; not much to report in the meantime.
'''NLP Sub-team Meeting Notes:'''
* I updated team on BERT layer almost being done (aside from graph disconnect issues)
* Anish is having trouble in chest xray. Somehow an extra dimension is being inserted into tensor calculations.
* Dr. Zutty suggested we add novelty detection to our branch. Pulak will work on it with extra time.
* We're focusing on baseline runs (outlined below). With time, we will do another 2 runs with novelty detection.
* We also planned our runs:
** large runs on Icehammer, regular ones go wherever (GTRI or PACE, colab is a backup)
** We plan on doing 4 large runs and 10 regular runs (split between toxicity and chest xray).
* Due to BERT layer input issues (see individual notes section), Pulak suggested creating an alternative input layer with BERT attached for the time being
'''Individual Notes:'''
* After taking a closer look at the stack trace, when the keras model is compiling, it fails when adding the BERT layer because it isn't an "Input" tensor. 
* The BERT model is created using an input tensor, but I'm not sure why it's requiring that the entire language model is classified as an input
** editor's note: I find out next week
* I suspect this is because ordinarily, BERT is used at the start of a network, so maybe the input layer that the transformer is initialized with is meant to only take sequences in token/embedding form.
** I brought this up at our Friday meeting and Pulak suggested focusing on a primitive that is only placed at the start of a network for the time being. To do this, I'll essentially create an alternative to an InputLayer primitive that creates a layerlist with BERT as its first element.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Debug BERT Layer
|Unsure if possible
|November 2, 2020
|?
|
|-
|Write and Debug BERT *Input* Layer
|In Progress
|November 20, 2020
|November 30, 2020
|
|-
|Add attention mechanism into nn-vip branch
|On hold
|October 2, 2020
|?
|
|}

== Week of November 9 - Testing NNLearners ==
'''Team Meeting Notes:'''
* Stocks is investigating irregularities in the results of the paper that their project is based on. They're trying to do a sanity check to confirm the performance of their model
* EZCGP has their code running on PACE so they're ready to start doing runs
* NLP found some disappointing results from the CV team, finding that they weren't able to get enough bounding box data to be worthwhile. Also starting on sentiment analysis capabilities. Max also created a guide for getting set up on PACE ICE
* Modularity speculated with Dr. Zutty on why learners aren't the most frequent ARLs after many generations.
'''NLP Sub-Team Meeting Notes:'''
* Maxim set up a guide to set up emade on pace. Not working for toxicity right now but other than that it seems like a great contribution
* Alex and Anshul met over the weekend to work on the adaptive mutation function. They mainly focused on altering the probability of mutation based on an individual instead of using predetermined ratios. They still have a little bit more work ahead of them though.
* Dr. Zutty and Tushna talked about adding new CV primitives, mostly discussing whether it's a good idea (answer was a resounding "yes").
'''Individual Notes:'''
* Figured out why I was still getting errors in standalone_tree_evaluator: the tree couldn't be scored because of an issue in eval_methods.py. 
** Coordinated with Anish and cast lists as numpy arrays where applicable so we didn't get issues like "AttributeError: list object has no attribute 'shape'.
* Can finally run standalone NNLearners; tweaked a functional one to use a BERTLayer and the model failed to compile.
** Got a "graph disconnected" error. The only stackoverflow post I could find was [https://stackoverflow.com/questions/51522848/graph-disconnected-cannot-obtain-value-for-tensor-tensor-input-keras-python here], where someone attached a layer in the same line that they defined it... I don't see anything like that in my code.
* At a loss for how to fix this error; asked around and others were also confused. Will take a closer look at the stack trace next week to see if I find anything
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Troubleshoot standalone_tree_evaluatory.py
|Complete
|November 2, 2020
|November 16, 2020
|Nov 13, 2020
|-
|Debug BERT Layer
|In progress
|November 2, 2020
|November 23, 2020
|
|-
|Add attention mechanism into nn-vip branch
|On hold
|October 2, 2020
|?
|
|}

== Week of November 2 - Debugging BERT layer ==
'''Team Meeting Notes:'''
* Most teams gave updates on what their first semesters will work on
* Modularity had some run results; Dr. Zutty led a dissection into their runs with selection bias towards ARLs
** Not certain but I think the main conclusion was that by introducing this bias, they limited their search space and had less variance (possibly leading to less improvements) compared to the baseline as generations went on (especially notable past gen 20)
'''NLP Sub-Team Meeting Notes:'''
* Discussed new dataset that we might use for more results. Is a sentiment classification challenge from Kaggle (need to go find link from someone's notebook)
* Brought up arxiv papers on optimal sub-architecture extraction. I mentioned that someone with a better algorithms background would be better suited to report on them. Tejas volunteered to do it.
* Also asked about working with some random layerlist so I can test how the BERTLayer interacts with them in an easier way. Alex suggested the standalone tree evaluator file -- had no idea this existed so that was a great suggestion
* Anuraag has results after trying bounding box for CV stuff but found that not enough classification categories are compatible with this approach. Not very well-versed in CV but the overall effect seems to be that bounding box is not something we'll keep pursuing.
'''Individual Notes:'''
* As mentioned last week, the code for the BERT layer is written:
[[files/Huggingface BERT code.png|none|thumb|519x519px]]
** It's followed by a Dense layer so it can easily be "linked" to other keras layers -- it would probably perform fine if I let EMADE add anything to the end but I'll cross that bridge later
* This works fine in isolated models; the next step is to ensure that it functions within EMADE (spoiler: it doesn't)
* As mentioned above, Alex suggested using standalone_tree_evaluator.py to test a NNLearner containing a BERTLayer
* I tried to do that locally but ended up running into a few errors related to tensorflow using my laptop's GPU -- reinstalling tensorflow-gpu resolved it
* I kept getting "malformed node or string" errors when running -- talked to Anish and realized that the standalone NNLearner I was using had a bunch of deprecated primitives (I just altered one that was already in the file."
* After this I am still getting errors/infs when evaluating the tree (which doesn't even have the BERT primitive in it yet)...
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Create BERT layer primitive
|Complete
|September 21, 2020
|November 6, 2020
|November 2, 2020
|-
|Troubleshoot standalone_tree_evaluatory.py
|In progress
|November 2, 2020
|November 16, 2020
|
|-
|Debug BERT Layer
|Not Started
|November 2, 2020
|November 23, 2020
|
|-
|Add attention mechanism into nn-vip branch
|On hold
|October 2, 2020
|?
|
|}

== Week of October 26 - More BERT layer work ==
'''Team Meeting Notes:'''
* Most teams didn't get much done the past week because we just had presentations, but everyone mostly talked about future plans for the rest of the semester
'''NLP Sub-Team Meeting Notes:'''
* Got a few new first semesters. Spent most of the Monday meeting explaining what our sub-team does and walking them through neural_network_methods.py.
* Dr. Zutty also dropped in and recommended we look into defining and adding features from some individuals into some feature set? Honestly it confused me but sounded really interesting. I'm pretty busy with current projects now though so I'll let others look into it.
* Friday meeting was spent discussing tasking for the first semesters. Can be seen in team notebook entry.
* I brought up some papers on optimal sub architecture extraction:
** https://arxiv.org/abs/2010.08512 for the algorithm, https://arxiv.org/abs/2010.10499 for its specific application to BERT
** memory limits are a bit of a concern for BERT so this could be useful to look in to. Unsure about its general use case though
** Tried to give them a deep read but I don't think I have the algorithms background for it (really hoping my ISYE/ECON knowledge will come in handy one of these days)
'''Individual Notes:'''
* Settled on using HuggingFace Transformers for BERT layer implementation. Seems like it will work fine unless we decide we want to change the pretrained weights down the road (not sure why we'd do this though instead of just using our own transformer)
* Using DistilBERT because it's smaller and trains faster. ALBERT is another option if that doesn't pan out. Didn't find much comparison between the two because their approaches are quite different.
* Have written the code for a DistilBERT layer, will post next week once I've validated that it actually works with a layerlist
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Create BERT layer primitive
|In progress
|September 21, 2020
|November 6, 2020
|
|-
|Add attention mechanism into nn-vip branch
|In progress
|October 2, 2020
|November 9, 2020
|
|}

== Week of October 19 - Midterm Presentations ==
'''Notes on Presentations:'''
* Stocks Team:
** Seems that a lot of their work this semester has been to improve regression techniques in emade.
** I think they did a good job giving an overview of things they added, but I thought their visualizations of their results were unclear.
* Modularity:
** Their idea to only create an ARL for something that affects the data is one of those things that's obvious only in hindsight. Really clear that they've been doing their reading and getting creative.
** It seems like they spent a lot of their presentation giving background (presumably for first semesters) compared to us. They're a smaller team & aren't working with as "hype" of a topic so I thought this was a good strategy
** I thought Gabe's discussion on "exploration vs exploitation" wrt ARLs was an interesting insight. I'm curious to see what they do with this in the future.
* First semester teams:
** Their presentations are largely homogeneous, so comments for individual teams would be repetitive, but they still deserve comments so I'll group them.
** First group to go (#3 I think) did very well. They had great visualizations inspired by past semesters & had results that lined up with other semesters
** Second group (#1?) made a good effort, but their # of generations were low and they had some weird errors going on. Namely, their pareto front included the third objective (minimizing complexity) which made it look wrong in 2D. Also, their accuracy numbers must have been calculated weirdly, because they had FP/FN numbers around 20% (normal) but accuracy that was MUCH lower (<10%). They also did a normalization of their pareto front to transition from counting FP/FN that was maybe ill advised; I think they should've transitioned to percentages instead.
** Third group (#2) was good. They did a headless chicken run, which I'm not familiar with, so it was nice to learn something new.
** Last group (#4?) did well but they had some quirks with their FP/FN/accuracy rates for their emade run. There's nothing wrong with this because they've only used emade for a little bit but it's still worth mentioning
* NLP:
** We went way over time but also have a huge group so I think it was understandable. IMO we spent too much time on things that we've researched but have not been implemented.
* EZCGP:
** seems like they're doing a lot of work that uses many ideas that other teams are working on -- it's their implementation that's different.
** That being said, it sounds like they have a lot of work that they want to do but don't have enough members to do it all
** maybe they should take a page out of modularity's book and do more to "advertise themselves" toward first semesters.
'''NLP Sub-Team Meeting Notes:'''
* I missed this week's Friday meeting, but they mostly discussed plans for new first semesters coming to our team next week.
* Will check teammate notebooks to see if they discussed anything else that was notable
'''Individual Notes:'''
* Created some additional slides before the presentation but I didn't get to talk about them much because we were short on time.
* Was swamped with other classwork this week. Hopefully can get more done next week.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Create BERT layer primitive
|In progress
|September 21, 2020
|November 6, 2020
|
|-
|Add attention mechanism into nn-vip branch
|In progress
|October 2, 2020
|November 9, 2020
|
|}

== Week of October 12, 2020 - Evolving Transformer Architecture ==
'''Team Meeting Notes:'''
* Other Teams:
** Stocks is doing a big run in the leadup to midterm presentations
** ezcgp is gearing up for a big run, will discuss research, implementation, and hypotheses if this run is not done in time for presentations
** NLP (us) discussed novelty with Dr. Zutty. Brought up our idea of going for breadth vs just trying to get SOTA in toxicity classification. Zutty seemed lukewarm on this idea, emphasizing other things like optimizing evaluation speed.
** Modularity talked about getting their runs to scale with Colab, but their runs are limited.
'''NLP Sub-Team Meeting Notes:'''
* Dr. Zutty met with us to discuss run results
** A lot of attention was paid to our large run - who has 10x more individuals than a regular run - had a MUCH higher % of individuals evaluating to infinity. Individual pool size shouldn't be affecting this, so we'll need to figure out what's going on.
** He recommended looking at tree complexity
** On the novelty topic, he recommended applying to new problems, discussing where our version of EMADE is weak vs strong, and emphasizing our wide range of primitives that are working together (e.g. signal methods, spatial methods, in addition to our ML/NN methods) -- emphasizing if we have "mixed individuals" that perform well.
'''Individual Notes:'''
* On creating and evolving transformer model: To do this, we're going to need to re-implement neural_network_methods.py in pytorch so that we can keep track of dimensions in a way that TF cannot.
* I'm... not entirely sure of everything that'll be required & will probably be bugging Anish a lot.
* Didn't get a ton of work done this week. I spent a lot of time looking for resources but didn't find a lot that was super helpful, other than this paper https://ai.googleblog.com/2019/06/applying-automl-to-transformer.html which was the main inspiration for this idea. 
* I think that this process will require me to build a transformers from scratch instead of using something like the HuggingFace Transformer library, which will be pretty tough
* Created some slides for midterm presentation
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Create BERT layer primitive
|In progress
|September 21, 2020
|November 6, 2020
|
|-
|Add attention mechanism into nn-vip branch
|In progress
|October 2, 2020
|November 9, 2020
|
|}

== Week of October 5, 2020 - Altering Tasks ==
'''Team Meeting Notes:'''
* Other teams:
** Stocks added more technical indicators. Also added more regression methods, but noticed that their standard error was insanely high. I sent them a message saying to check for multicollinearity in their data, since values close to 1 can cause standard error to tend toward infinity
** ezcgp has their environment up and running and is able to start contributing more novel research
** For NLP, we updated Dr. Zutty on our crossover-only runs, which showed similar results to the run that also had optimizers. Also told him about individuals evaluating to infinity; Zutty said that the important thing to do is to make sure these kinds of individuals "fail quickly" so that their time loss is minimized.
*** Dr. Zutty also walked us through some places where we could implement the core idea of adaptive mutation, which was really helpful since we haven't put many ideas to code yet. The mutate method in EMADE.py
** Modularity has added a new selection method to get a more significant amount of ADFs. They also fixed a bug that was causing useful ARLs to not be created (because of something to do with argument passing in emade datapairs).
'''NLP Sub-Team Meeting Notes:'''
* Anish mentioned that my transformers tasking is very urgent not sure it'll be done by midterm presentations though
** I asked about how it would work wrt emade, noting that I'd only ever seen attention as a standalone architecture. We then decided it might be fruitful to write Attention as its own primitive, outside of the scope of NNLearner primitives
*** I think this is a good idea, at least for the start. If it doesn't work well, I'll experiment with integrating it with NNLearner as well
** Mohan worked on this over the summer, so I need to contact him to see what's left to do (though I might start my own implementation from scratch
** My work with transformers has mostly worked with PyTorch so far, but we are using Keras right now. I might need to adjust any code I write to ensure compatibility.
*** Anish said to not worry about it too much, since he wants to move towards using PyTorch in the future anyway.
'''Individual Notes:'''
* Messaged Mohan about incorporating attention to emade. 
** he advised against using Keras' Attention layer, so that will make this harder than anticipated. I asked if constructing a transformer architecture and evolving that would be more productive and he agreed.
** I spoke with Anish about this too. We think it'll be interesting to evolve a transformer architecture by changing its individual components, similar to a neural architecture search. Will look into this more next week.
* I finished going through the guide on creating embeddings with BERT, but Anish and I ended up having a different vision of how this would be incorporated into EMADE, so I'm going to need a little more time for development.
** I thought we'd just fine-tune a BERT model at the beginning and use that similarly to how we use something like glove, but he wants to create a "bert layer" using a smaller bert model (probably albert) and let EMADE incorporate that into network architecture
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Go through BERT guide
|Complete
|September 21, 2020
|October 12, 2020
|October 11, 2020
|-
|Use BERT to create embeddings for toxicity classification --> Create BERT layer primitive
|task changed
|September 21, 2020
|November 6, 2020
|
|-
|Add attention mechanism into nn-vip branch
|In progress
|October 2, 2020
|unsure
|
|}

== Week of September 28, 2020 ==
'''Team Meeting Notes:'''
* Pulak updated Dr. Rohling on the results of our previous runs and what we're thinking in terms of future work (see previous weeks' entries to see what those are). 
* Anish asked a series of questions about why we have so many individuals evaluating to inf(inity) and why we can't seem to do better than 0.035 error. 
** Rohling suggested to check if there's elitism in our mating process so we can confirm that our best individuals are carrying through to future generations. 
** His advice on why individuals are evaluating to inf was less clear -- we basically have to do some digging and try to find some trends.
* Modularity is working on implementing some signal processing techniques that our CV sub-sub-team could use down the road.
'''NLP Sub-Team Meeting Notes:'''
* Our CV team is having a lot of PACE issues right now. We're starting to seriously question the long-term viability of PACE due to how often code-breaking changes are made. 
* We did a run without optimizers and only mating, but noticed a lot of individuals with infinite values. See team meeting notes for Dr. Rohling's advice. 
* Most of our team's tasking is staying constant. CV team a bit stagnant due to PACE, GP people are working on adaptive mutation, NN people working on embeddings, and others are working on streamlining the evaluation of individuals. 
* Anish mentioned that the attention mechanism currently coded into the branch isn't functional -- something I did not know. I volunteered to work on that. I really need to understand how transformers work so this will be great motivation 
'''Individual Notes:'''
* This is another particularly busy week for me. Should have much more time next week to catch up on tasks
* Finished Intro to PyTorch module. Mostly just walked through datatypes & things like that, so I definitely have a lot more to learn.
* I'm still following along with the guide (https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#1-loading-pre-trained-bert) I found last week.
** It's been a little slow. The transformer architecture is still confusing to me & I'm really trying to understand the flow of information
* Speaking of transformers, I'm now re-trying an implementation of attention into nn-vip. This was added to my list of tasks at the end of this week, so I'll give more details later

''The following set of tasks is all I will work on probably for the rest of the semester''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Go through BERT guide
|In progress
|September 21, 2020
|October 12, 2020
|
|-
|Use BERT to create embeddings for toxicity classification
|In progress
|September 21, 2020
|October 12, 2020
|
|-
|Add attention mechanism into nn-vip branch
|In progress
|October 2, 2020
|unsure
|
|}

== Week of September 21, 2020 - HF Transformers & PyTorch/CUDA ==
'''Team Meeting Notes:'''
* No big events. In scrums, stocks talked about their confusion in how technical indicators are used w/ market trajectory in training. Seems like Dr. Zutty was able to give them good advice. Modularity is having trouble with the DB they're using with pace. Typical advice like port-forwarding was given. ezcgp was hard to follow.
'''NLP Sub-team meeting Notes:'''
* Alex pushed the new NN crossover function and anish pushed terminal mutation, which are both a big deal. Alex is joining adaptive mutation group.
** Anish started a run with these two new things + new optimizers, but we didn't see much improvement. He's going to remove the new optimizers and just do a run with the new Genetic Programming concepts to see if we can get a better idea of what's happening.
** Anish also noted that this run was a lot slower than others have been in the past. We hypothesize that this 1) because the state space is larger due to new optimizers and 2) because we were previously only using adam, which is faster than most of the new optimizers we introduced.
* Now that this low hanging fruit is gone, we're going to lean a little more heavily into adaptive mutation (jury still out on if this is a good idea) and embeddings. I'm also going to write a custom regularization function based on a paper I mentioned last week.
** We talked about some other things we can do for improvements. Pulak suggested that batch normalization could help speed up the training of our individuals and make them more consistent. 
* Didn't hear much from CV team this week.
'''Individual Notes:'''
* I found a few good resources to learn about BERT implementation. See entries in previous weeks for good papers to read on the theory.
** The main resource I'm using is this: https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#1-loading-pre-trained-bert
** Since BERT is pre-trained on a large unsupervised corpus, this walks through how to load that pre-trained state + how to fine tune with your supervised data.
** The main code resource is the transformers module developed by huggingface, which is dependent on tensorflow (but works seamlessly with PyTorch afaik): https://pypi.org/project/transformers/#description. Documentation (confusing in my opinion) is here https://huggingface.co/transformers/
** I mention tensorflow because I was running into some issues when first using this module, getting the "has no attribute: 'swish'" problem reported here https://github.com/huggingface/transformers/issues/7333
** This is a problem with TF 2.1, so upgrading to 2.2 fixed it for me.
* The resource I'm using relies on PyTorch, which I needed to learn anyway, so I decided to do the intro to PyTorch module: https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py
* This led me down a bit of a rabbit hole. In short, my GPU has never been activated when doing deep learning tasks and I've never understood why. Running torch.cuda.is_available() returns false, and I couldn't find anything online telling me how to fix this...
** Until I found this guide that walked me through the entire process: https://medium.com/datadriveninvestor/installing-pytorch-and-tensorflow-with-cuda-enabled-gpu-f747e6924779
** Some things that might be useful to know: Cuda 9.0 is required. Visual Studio <=2017 is required; you need to make a developer account to get anything older than 2019 though (it's free). Everything else should be clear from the guide.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Find 1-3 resources on using BERT word embeddings
|Complete
|September 11, 2020
|September 25, 2020
|September 21, 2020
|-
|Learn how word embeddings are used in EMADE
|Complete
|September 11, 2020
|September 25, 2020
|September 25, 2020
|-
|Enable GPU functionality so I can code transformers
|Complete
|September 21, 2020
|September 28, 2020
|September 23, 2020
|-
|Go through intro to PyTorch module
|In progress
|September 21, 2020
|October 5, 2020
|
|-
|Go through BERT guide
|In progress
|September 21, 2020
|October 12, 2020
|
|-
|Use BERT to create embeddings for toxicity classification
|In progress
|September 21, 2020
|October 12, 2020
|
|}

== Self Graded Notebook Rubric (September) ==
[[files/Self graded notebook rubric.png|none|thumb|694x694px]]

== Week of September 14, 2020 - More on embeddings ==
'''Team Meeting Notes:'''
* Pulak mentioned to Dr. Zutty that some of us couldn't push to emade. I've put together a list of everyone in the same boat and am emailing it to Dr. Zutty to get this resolved.
** 1 day later, the entire NLP team can push to EMADE
* Other teams are adding new primitives to their branches & doing other things to expand what emade has to work with
'''NLP Sub-Team Meeting:'''
* Anish has been doing a lot of runs lately, and we're getting really close to the performance of our "paper to beat"
* Now that we've added terminals for activations, optimizers, and weight initializers, emade is performing even better
* We're also getting close to adding a more thorough crossover algorithm to emade. This is becoming a top priority & we think it will really improve our numbers
* We're also experimenting with adaptive mutation, which takes some of the randomness out of the mutation of our individuals
** Anshul is doing some research in this topic:
*** https://ieeexplore.ieee.org/document/5381807 , https://www.researchgate.net/publication/220117106_A_Genetic_Algorithm_with_Adaptive_Mutations_and_Family_Competition_for_Training_Neural_Networks , https://www.researchgate.net/publication/224619893_Using_genetic_algorithm_with_adaptive_mutation_mechanism_for_neural_networks_design_and_training , https://ieeexplore.ieee.org/abstract/document/1007058 , https://ieeexplore.ieee.org/abstract/document/5473303
*** Recommend looking at his notebook for commentary. This isn't an area I'm focused on.

* It looks like Pulak and Anish are also going to be looking into the memory constraints of BERT/ELMo, which is relevant to the work I'm doing
'''Individual Notes:'''
* Got push access to emade, so optimizers are officially in.
** '''Don't know how to link my commit. Will look into this later.'''
* Had a really busy week from classes & individual research, so I wasn't able to get a lot done
* read some papers:
** adversarial smoothing: helps generalize (reduces overfitting) by adding a regularization term calculated by inserting adversarial training examples and maximizing the KL divergence of the model with and without this new data. It's a low-computation method that improved the performance of some NLP benchmarks by a lot. I think it could be useful to implement if I have the time http://arxiv.org/abs/1911.03437v2
** a deeper dive into BERT: http://arxiv.org/pdf/2002.12327v1.pdf
** a paper that uses BERT for tasks with sparsely labeled data, adding in their own method of distant supervision (similar to bootstrapping): http://arxiv.org/pdf/2006.15509v1.pdf
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Find 1-3 resources on using BERT word embeddings
|In progress
|September 11, 2020
|September 25, 2020
|
|-
|Learn how word embeddings are used in EMADE
|In progress
|September 11, 2020
|September 25, 2020
|
|-
|Read 2-4 more papers on word embeddings
|Complete
|September 11, 2020
|September 16, 2020
|September 16, 2020
|-
|Read our team's "paper to beat"
|Complete
|September 11, 2020
|September 18, 2020
|September 18, 2020
|}

== Week of September 7, 2020 - Conda & Github Woes ==
'''Team Meeting Notes:'''
* Labor day weekend, no official meeting
'''NLP Sub-Team Meeting:'''
* We had a short meeting on Monday to give updates on our work
* Pulak suggested that we use our Friday meeting times to discuss papers, since many of us are working individually and there isn't much collaboration happening during these meetings.
** 1st paper to read is our team's "paper to beat" https://arxiv.org/pdf/1902.06827.pdf
'''Individual Notes'''
* Optimizers have been implemented, but I was unable to test them because I cannot get my environment set up right
** In short, we have conda environments stored in yml files that should make this trivial. However, for some reason, yml files created by mac users sometimes aren't usable by windows users - regardless of any specifications made when creating the file
** I tried, to no avail, to set my environment up like this, but nothing seemed to work. It doesn't look like there's a windows user on the team with an environment set up, so I'm going to have to find the time to do this by hand eventually
* Instead, I reviewed my code with Anish and Pulak and we determined it was fine for me to push... but I don't have emade push access so I couldn't do that either. Will need to email Dr. Zutty about this on Monday (writing this during the weekend)
* Tried to push by forking emade, but not all branches were showing when I did this, including nn-vip, and Anish and I couldn't figure out that one either.
* Decided to just send Anish my files and read some papers since everything else was at a standstill
* Focused on word embeddings, with my goal being to fully understand the background of BERT:
** Introduction of Skip-gram method: https://arxiv.org/abs/1301.3781
*** Predicts context words, given center word (complement of CBOW)
** Follow-up paper adding additional methods: https://arxiv.org/abs/1310.4546
*** They used many novel methods to improve their embeddings, like negative sampling and phrase tokenization
* After these readings, I decided to expand our word embedding repertoire, with the goal of implementing some form of BERT (though we might not have enough memory for that). 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read 2-3 more NLP-related papers/articles
|Complete
|August 24, 2020
|September 11, 2020
|September 9, 2020
|-
|Push Optimizer changes to nn-vip branch
|Complete (sort of )
|August 28, 2020
|September 14, 2020
|September 13, 2020
|-
|Read 2-4 more papers on word embeddings
|Not Started
|September 11, 2020
|September 16, 2020
|
|-
|Read our team's "paper to beat"
|Not Started
|September 11, 2020
|September 18, 2020
|
|-
|Find 1-3 resources on using BERT word embeddings
|Not Started
|September 11, 2020
|September 25, 2020
|
|-
|Learn how word embeddings are used in EMADE
|Not Started
|September 11, 2020
|September 25, 2020
|
|}

== Week of August 31, 2020 - Adding New Optimizers ==
'''Team Meeting Notes:'''
* Pulak updated Dr. Zutty on the goals of all of our mini-teams. We're having some trouble performing runs on the GPU cluster & they (basically Pulak and Anish) consulted Dr. Zutty on that.
* Other teams continue to do things like paper reviews and working toward doing runs later in the semester
'''NLP Sub-Team Meeting Notes:'''
* Much of the team is working on either PACE setup (CV team), identifying best individuals (& automating this process), working on evolutionary capabilities (e.g. mutation functions), or setting up Colab for unit tests
* Anish has added a terminal for activation functions, which is great because I can use that as a reference for optimizers (see below)
'''Individual Notes:'''
* I'm mostly working on my own at the moment. Am learning more about EMADE's code base to figure out how to add a primitive properly (for optimizers)
* Before getting into the technical detail, I'll motivate the reason for expanding our optimizer selection.
** In short, while adam generally performs well and is quite fast, it has its downsides and doesn't generalize as well as others (e.g. nadam). Here's a short summary of the topic: https://shaoanlu.wordpress.com/2017/05/29/sgd-all-which-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment/
** I'm hoping that by expanding our selection of optimizers, the training of some networks can be improved
* gp_framework_helper.py is using a method called addPrimitive, but I can't find any instances of that (only addPrimitiveS) within src at the moment
** Traced through emade and realized that this is a method from deap:
*** https://deap.readthedocs.io/en/master/api/gp.html
*** See addPrimitive and addTerminal methods (can't post screenshot bc of VIP rules)
** At this point, I realized that I should be using terminals instead of primitives for this task. 
*** Terminals are objects/fxns without parameters that can be added to the pset, saving compute time
*** For now, I've opted to use optimizers that come with the Keras API, using their default hyperparameters. Thus, I only need to pass a string to specify the optimizer, meaning terminals are the better choice
* From here, everything is pretty straightforward:
[[files/Optimizer Class in nnmethods.png|none|thumb|490x490px|In neural_network_methods.py, create optimizer class that inherits from Enum (will explain why below). Each attribute in this class equals a string identify used by Keras for an optimizer]]
Next, within the NNLearner primitive, I added an "optimizer_enum" parameter, defined "optimizer = optimizer_enum.value" within the body of the primitive (.value is method inherited from Enum class) so the variable "optimizer" points to the string we want to use. Then, near the bottom of the primitive where we create our model, I set "optimizer = optimizer." Keras handles the rest from there.
[[files/New NNlearner param.png|none|thumb|1230x1230px|In gp_framework_helper.py, add optimizer input to nnlearner primitive]]
[[files/Optimizer terminal.png|none|thumb|660x660px|Finally, I added the terminals to the pset for each optimizer. Note how there is no input specification because we are using a terminal and not a primitive]]

Overall, this was a pretty simple process, but it really helped me get a better understanding of emade and how it works.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read 2-3 more NLP-related papers/articles
|In progress
|August 24, 2020
|September 11, 2020
|September 9, 2020
|-
|Add more optimizers to neural_network_methods.py
|Complete
|August 28, 2020
|September 7, 2020
|September 4, 2020
|-
|Push Optimizer changes to nn-vip branch
|Not Started
|August 28, 2020
|September 14, 2020
|
|}

== Week of August 24, 2020 - Adding New Optimizers ==
'''Team Meeting Notes:'''
* Got last bit of housekeeping out of the way; Pulak updated Dr. Zutty with our team goals & meeting times. Goals can be found in last week's notebook entry.
* Most other teams seem to be doing either literature reviews and setting up things like PACE
'''NLP Sub-Team Meeting Notes:'''
* We're splitting into 2 sub-sub-teams: Neural Networks and Computer Vision. We want to decide on team leaders for each of these by the end of the week
* I've decided to join the NN sub-sub-team. I'll start off by adding new optimizers to neural_network_methods.py; as of now, we are only using adam.
* From what I've read, adam prioritizes speed but tends to overfit. Anish says we use a technique called early stopping to circumvent this (https://en.wikipedia.org/wiki/Early_stopping)
** My knee-jerk reaction is that this might cause us to get hung up on local minima -- I'll have to read more to see if this is true
** Regardless, I decided to join some others in a tutorial by Anish on reading output files. I plan to go through these at some point to see (a) if our loss functions are converging and (b) if we're overfitting
'''Individual Notes:'''
* I wasn't able to generate deliverables this week due to family commitments
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Decide on sub-sub-team
|Complete
|August 17, 2020
|August 28, 2020
|August 26, 2020
|-
|Read 2-3 more NLP-related papers/articles
|In progress
|August 24, 2020
|September 11, 2020
|
|-
|Add more optimizers to neural_network_methods.py
|Not Started
|August 28, 2020
|September 7, 2020
|
|}

== Week of August 17, 2020 - New Semester ==
'''Team Meeting Notes:'''
* First meeting of the semester -- mostly went over housekeeping stuff wrt to the pandemic
* Most people chose their sub teams. I considered joining the new stocks sub team, but given that I'm doing NLP research with Dr. Tuo Zhao this semester, I figure I should stay with NLP and concentrate my efforts.
'''NLP Sub-Team Meeting Notes:'''
* Anish and Mohan made a lot of changes over the summer -- on the nn branch
** these changes can be seen on neural_network_methods.py -- they went over the changes very quickly, so I'll have to read into the code to get a better idea of what they did.
** for the mutations stuff, emade_operators.py is the place to go
* Pulak and Anish Outlined our main goals for the semester:
*# Optimize mating a mutation functions in EMADE
*# Integrating new primitives into the NLP branch
*# Integrating CV capabilities into the branch
*# Getting the branch to work on Google Colab so we can start messing with individuals
'''Individual Notes:'''
* I realized over the summer that while my maths/programming background is fine, there's a lot I need to learn about deep learning & NLP in order to be effective. I self studied Stanford's CS 229 class, which taught me a lot about machine learning. Armed with this knowledge I think I can get a lot more out of the VIP this semester. 
* Unsure which part of the sub team I will work on this semester
* In the meantime, I'm going to read a lot on sequence modeling & really try to understand the nuance of why LSTMs, GRUs, and Transformers are so powerful. My research advisor has given me a lot to read for this area, so hopefully by the midpoint of this semester I'll be able to pivot to a more impactful role.
* What I read this week:
** https://towardsdatascience.com/understanding-encoder-decoder-sequence-to-sequence-model-679e04af4346
*** brief article on encoder-decoder architecture for sequence-to-sequence models
** https://towardsdatascience.com/deep-learning-4-embedding-layers-f9a02d55ac12
*** brief article on embedding layers
** https://arxiv.org/abs/1706.03762
*** Attention is all you need; have been holding off on reading this for a while because I didn't have the prerequisite knowledge to fully understand it
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Decide on sub-sub-team
|In Progress
|August 17, 2020
|August 28, 2020
|
|}

== Week of April 20, 2020 (Final Presentation) ==

==== Notes on group presentations ====
* '''ADF Team:'''
** I found it interesting that using ADFs had the largest impacts in earlier generations (specifically 15-20) before losing its statistical significance 
** If it wasn't already clear, their starting point for next semester should be addressing their generation of ADFs: They found that many ADFs were made up of other ADFs & most didn't perform well so fixing this could lead to more significant results
** My internet crashed at this point so I missed a significant chunk of their presentation
** Overall I think they did a good job of visualizing their AUC progress with error bars and following that up with a graph of p-values. 
*** they also did a grid analysis comparing AUC of all different variations of ADFs with each other + vanilla emade, using a color gradient. I think this was really useful for comparing all the different changes they've made.
* '''Research Fundamentals:'''
** I liked the self-awareness they had when explaining their rationale in choosing speciation over other bloat-control methods -- increasing computational complexity is antithetical to their purpose, so they made the simple (but not necessarily obvious) decision to maintain simplicity.
** I didn't like their use of a log-scale in their graph of hypervolume.  At first glance, it looks like larger generations increase the gap between baseline, but the reality is that, as both lines are decreasing, the % difference is what's changing. Log scales aren't bad but I think it's important that they're pointed out.

* '''NLP-NN, non-time conflict (my group):'''
** Overall, I thought our presentation could've been better
** Instead of going with other groups' presentation style of [where we left off from midterm, what we've added since then, new results], I feel like our presentation came off as more disorganized.
** Gifs were used to show changes in things like AUC, but I thought that ended up looking worse than stacking different runs and color-coding.
** There was also a lot of problems that people were running into that had solutions given by people in other sub-teams or Dr. Zutty. I feel like this was a symptom of not having enough team interaction & thus not having enough opportunity for members to bounce ideas off of each other.
** Assuming I stay with this team for further semesters (which I hope to do because I find the content really interesting), I hope to take a larger role in establishing things like team trajectory and an overall thesis so that we can come off more like a unit rather than a bunch of people working on their own assignments.
* '''NLP, Time conflict:'''
** I liked that they spent a lot of time directing other teams to the resource they made on using PACE. Most teams seems to be diverting resources toward it so I think it's smart if we all coordinate
** Instead of doing multilabel classification, this team was looking at summary data, which seemed daunting given the complexity.
** I liked their results-focused approach in their presentation of new primitives that they added.
** They also talked about what their primitives did...in the context of NLP, which I think was helpful for intuition.
* '''ezCGP:'''
** I liked that they tried out different architectures/networks based on other papers. 
** One thing I noticed what this group did (in addition to others) was contextualize each of their topics within their overall framework. The ezCGP group kept coming back to their "pipeline", what each layer did + changes were made to them.
*** even when terminology or maths-concepts went over my head, I understood how things were contributing to the big picture, which was really helpful for this group in particular because I'm unfamiliar with cartesian genetic programming.

== Week of April 13, 2020 ==
'''Team Meeting Notes'''
* We broke out into sub-teams pretty quickly so nothing much to report here. Most groups were gearing up for runs to have data for the final project. Although NLP had gotten Google Collab working, we weren't able to run it for long enough before timing out, so we went back to PACE.
'''Sub-Team Meeting Notes'''
* First-semesters updated the rest of the team on their progress in implementing new primitives into emade. Most people were still working on theirs -- the veteran members told us there wasn't a huge rush since there were lots of other new things being implemented & they weren't sure they'd be able to do sufficient testing of emade with the new primitives. 
* The veterans were all finishing up with their own assignments (getting PACE working, working on compatibility issues with the new toxicity dataset, etc) in preparation for our final runs of the semester.
'''Individual Notes'''
* I had a test and 4 projects due this week, so I wasn't able to get as much done as I wanted.
* My assignment was to try and code attention into emade. I started off by looking at the tensorflow.keras documentation: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention
* I was originally told to look at how the other layers had been coded in neural_network_methods.py and to imitate that form. However, Attention is a little more complicated because rather than working in series with all the other layers in the neural network, it works in parallel, storing information gradually as things progress through the network. 
* I noticed that the keras documentation for this layer was pretty barebones + there were virtually no instances of keras' attention being used on sites like machinelearningmastery.com , which was to my dismay.
* Once I became aware of this additional layer (pun not intended) of complexity, I started reading some papers on the subject. My rationale being that I wouldn't be able to code this properly unless I understood on a deeper level what it was doing. Here are some of my more general takeaways:
** Attention appears to be a relatively new thing in the field of neural networks. Although there were some older papers, the vast majority were from 2016-2018.
** I could only find one instance of attention being used for multilabel classification; fortunately I was able to get a pretty intuitive understanding from the paper: https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/16114/16253
** To oversimplify, I learned that as the initial information (photo, paragraph of text) is encoded first into vector form & then changed during its progression through the network, the hidden state is passed to the attention layer and concatenated to what's called a "context vector." As the information propagates through the network, the context vector amasses information and passes it to the layers of the network to "remind" them of the initial state. In effect, this helps reduce error propagation in a network. According to the paper's findings, this can also help recognize co-occurrences in multi-label classification.
* With this information in hand, I started to work on figuring out how code an attention primitive capable of amassing the encoded states of all other layer primitives that would be in-use in a generated network. Unfortunately, between the really busy week I was having with my other classes, I wasn't able to cover much ground before the final presentation & thus don't have any meaningful code to report. This is something I'll definitely be working on during the summer though and I hope I'll be able to report a net-positive contribution to the NLP-NN branch of emade by Fall 2020.
* Here's the relevant slide from our final presentation:
[[files/Spring2020presentationslide.png|none|thumb|581x581px]]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Add slide(s) on attention to final presentation powerpoint
|Complete
|April 6, 2020
|April 13, 2020
|April 10, 2020
|-
|Add attention primitive into emade
|In limbo
|April 6, 2020
|April 17, 2020
|
|}

== Week of April 6, 2020 ==
'''Team Meeting Notes'''
* 2nd online meeting -- Anish got Google Collab working so that was news for the rest of the teams looking for a non-PACE option
* During the sub-team updates, it seemed like the other teams had a clearer trajectory in terms of what everyone needed to be doing in order to have results for the final presentation, while NLP definitely seemed to have a less centralized approach where everyone seems to be working in parallel on tangentially related things. Obviously I've only been on this team since the semester moved online so I'm not sure if this individual-based workflow is the norm, but I will mention that I think it's beneficial to, as a team, have a concrete end-goal to be jointly working toward.
'''Sub-Team Meeting Notes'''
* Anish got Google Collab working for EMADE and gave everyone a run-down on using it + setting up a remotemysql database so that several people could still write data to the same location.
** Anish also mentioned the possibility of port-forwarding instead of remotemysql but we decided to go with the latter due to simplicity.
* The veterans also put together a (long) list of things to add as far as new layers and activation functions to EMADE. First-semesters were told to self-assign and integrate them into the nlp branch by altering the neural_network_methods.py file and adding the primitive to GPFrameworkHelper
'''Individual Notes'''
* In the previous week I had tried to run the NLP-NN fork of EMADE on the movie reviews dataset (I believe this was from kaggle). i ended up running into an error related to deap's tournament selection (erro was "selTournamentDCD: individuals length must be a multiple of 4") & fixed it by getting a newer (not yet stable) version from their repo. Several people started running into this issue on their own locally or on Google Collab so it was good that I already had the solution handy.
* One thing I noticed while debugging the previous error was how common it was for individuals to be invalid & have an error string in the mysql output. I mentioned this to Anish, who had been helping me a lot with getting my run set up, and he didn't seem too concerned, but I think it might be interesting to look in to how we might be able to generate more valid individuals + see if there are any especially problematic primitives that might not be working properly.
* I started reading up on attention layers in neural networks as that was the thing I decided to try and implement into our branch of EMADE. Unfortunately, I hadn't fixed the issue with deap until late in the week so I wasn't able to get much done.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|fix deap selTournamentDCD divide by 4 error
|Complete
|April 5, 2020
|April 10, 2020
|April 10, 2020
|-
|start researching attention layers in neural networks
|In progress
|April 6, 2020
|April 13, 2020
|April 10, 2020
|-
|Add attention primitive into emade
|Not Started
|April 6, 2020
|April 17, 2020
|
|}

== Week of March 30, 2020 ==
'''Team Meeting Notes:'''
* First official meeting after spring break
* The veterans on my sub-team are still trying to get google collab working.
'''Sub-Team Meeting Notes:'''
* First-semesters were assigned to work on one of two datasets from kaggle: the wikipedia toxicity dataset or the chest xray dataset
* the point is to learn about the different concepts of neural networks and play around with changing things like activation functions, initializers, and optimizers.
'''Individual Notes:'''
* I worked on the chest xrays and way able to get to 90% accuracy by switching to the Adam optimizer. It seemed that a uniform initialization distribution worked best. I tried switching activation functions on the hidden layers to leaky relu and increasing the learning rate, but that didn't seem to have any effect on accuracy.
* I figured that increasing the learning rate would lead to a higher training accuracy and more severe symptoms of overfitting, but it seemed like no matter what I changed, training accuracy would cap at 92.29% and I'd always get between 86-90% testing accuracy. I didn't pay too much mind to this as the point of the exercise was to get more acquainted with neural networks concepts, which I feel I've done.
* Relevant coding block:
[[files/Nnxray.png|none|thumb]]
(sorry if this looks blurry I'm not sure what's causing it)
* Not seeing signs of overfitting:
[[files/Nnxray graph.png|none|thumb]]
* My next steps will be to run the NLP branch of emade locally on the movie reviews dataset and see how that goes, as we as seeing if Anish and Mohan need help with the google collab.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish analyzing chest x-ray dataset and do better than 82% accuracy
|Complete 
|March 30, 2020
|April 6, 2020
|April 3, 2020
|-
|run NLP branch of EMADE on movie reviews data
|In progress
|April 3, 2020
|April 6, 2020
|April 5, 2020
|-
|see if neural_network_methods.py needs any new 
methods added from tf.keras
|In progress
|April 3, 2020
|April 13, 2020
|April 6, 2020
|}

== Week of March 23, 2020 ==
'''Team Meeting Notes:'''
* Met during the "trial week" on Bluejeans.
* Sub teams updated Dr. Zutty and Dr. Rohling on what their plans were for the rest of the semester + how they planned on integrating first-semesters
'''Sub-Team Meeting Notes:'''
* Virtually met my new sub-team
* Learned that they're still having problems with PACE and are going to try and run emade on google collab
* first-semesters were assigned to read an article on neural network activation functions. Specifically regarding multiclass multilabel problems. The article specifically pointed out that using the softmax function is ill-advised when things can be classified with multiple labels
[[files/Softmax function.png|none|thumb]]
k represents # of labels (5 in this case)
* because the probability of a classification c is in part determined by the values for all labels, classifications of labels cannot be made independently of one another. Because of this, the article stresses using a sigmoid function instead (appears to be the same as the logistic function).
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read Article on Neural Networks
|Complete 
|March 23, 2020
|April 6, 2020
|April 2, 2020
|}

== Week of March 16, 2020 ==
'''General Notes:'''
* Between spring break and covid-19 happening, I didn't put any work into the VIP
* Decided to indicate a preference for joining the NLP sub-team because I view it as the most application focused (what I'm most interested in) and I think the opportunity to see how something new (neural networks) can be integrated into emade.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Decide on a sub-team
|Complete 
|March 9, 2020
|March 22, 2020
|March 23, 2020
|}

== Week of March 9, 2020 ==

==== Midterm Presentation Notes: ====
* Link to my group's presentation: https://docs.google.com/presentation/d/1iNP9DulbISM50C56AO8q42UDRdOHJoHvaQ5nB_NIF0M/edit?usp=sharing

* Other Bootcamp groups:
** The other groups largely did the same things as my group and got the same results, sans any additional background they added on (for instance, some specific machine learning algorithms)
** One thing that a group did that I found interesting was that, instead of running a master process with several workers, they all ran ~30 generations individually and then aggregated their data.
** Many groups did not convert their False Positive and False Negative numbers correctly into FP/FN rates. As stated in last week's notes, we divided false positives and false negatives by 109.8 and 68.4 respectively, the max values for all the data points.
* Non-Bootcamp groups:
** Most of the information in these groups' presentations went over my head, as I was mostly focusing on my own imminent presentation, but I do have some takeaways.
** In terms of potential to improve emade, I thought that the Automatically Defined Functions group seemed like they had the most potential, but their presentation showed that they had made almost no improvement to the titanic problem, which was disappointing.
** The ezCGP group seemed like they were working with an interesting dataset but I honestly couldn't tell what they were actually testing, as their presentation was poorly made. 
** I felt like I got a bad first impression of Natural Language Processing because both groups had practically no results as a result of PACE going down right before presentations.
** Overall, there was no group that jumped out to me as something I'd want to join. Personally, I'm more interested in applications than purely working to improve emade and continuously testing on the same titanic data set. I believe there used to be a group involved with financial trading, which sounded more interesting to me, but I guess it's been discontinued.  {| class="wikitable" !Task !Current Status !Date Assigned !Suspense Date !Date Resolved |- |Decide on a sub-team |in progress  |March 9, 2020 |March 22, 2020 |March 23, 2020 |} {| class="wikitable" !Task !Current Status !Date Assigned !Suspense Date !Date Resolved |- |Decide on a sub-team |Complete  |March 9, 2020 |March 22, 2020 |March 23, 2020 |}

== Week of March 2, 2020 ==

==== Sub-Meeting Notes - Pre Midterm presentation: ====
* Dr. Zutty gave us the time to work on the midterm assignment again. Only 3 members of my sub-team (myself, Tri, and Alex) were at the Wednesday meeting and the other two hadn't communicated with us for awhile, so we were starting to fear that they had dropped the class or something.
* Alex and I met with Dr. Zutty on March 6th, where he helped us resolve some issues with deap's version and finally get through the first generation. He also gave some good advice on troubleshooting / answering any questions on emade. This was useful for Alex and I because neither of us have a very strong CS background. Basically, the advice boiled down to using ctrl+shift+f in sublime to search whole folders to find where functions or other relevant pieces of code might be located.
* Me, Alex, Tri, and Chido met on Saturday and Sunday to get ready for the presentation. We got 21 completed generations after Alex and Tri ran emade the entire night. To get the data out of mysql, we ran the following query:
** select individuals.tree, individuals.`FullDataSet False Positives`, individuals.`FullDataSet False Negatives` from paretofront inner join individuals on individuals.hash=paretofront.hash where paretofront.generation=(select max(paretofront.generation));
* We tried using the visualization.py file that was in emade but I was getting a series of errors stemming from incompatible module versions. Wrote the following code to export our pareto individuals to a csv file and create a pareto front using the same method as we did for MOGP.
* [[files/Pymysqlcode.png|frameless|371x371px]]
* The resulting pareto front was:
* [[files/Current emade pareto front.png|frameless|359x359px]]
** We optimized using three equally weighted minimization objectives: False Positives, False Negatives, and Num Elements (loosely means the length of an individual's tree, according to somebody on slack). Because of this, the pareto front of our FPR and FNR was not as strong as it could've been. The blue (codominated) points are ones who were on our 3-objective pareto front, but were not pareto in the revised objective space. 
** The titanic xml input file, by default, gives #s of false positives and false negatives. To convert these to percentages, we divided false positives and false negatives by 109.8 and 68.4 respectively, the max values for all the data points. We were unsure about this scaling, but Dr. Zutty told us it was approximately correct 
*** ''many other groups either did not scale or did it incorrectly, giving them bizarre pareto fronts''
** The individual with the lowest euclidean distance from origin (note: a bad way to do it as this is 1) not accuracy, and 2) is ineffective if we have uneven data) had 16 false positives and 18 false negatives. {| class="wikitable" !Task !Current Status !Date Assigned !Suspense Date !Date Resolved |- |run 20+ generations for midterm presentation |Complete  |February 19, 2020 |March 9, 2020 |March 7, 2020 |- |get rest of team up to date on running emade |Complete |February 19, 2020 |March 9, 2020 |March 7, 2020 |- |create visualizations and presentation |Complete |February 19, 2020 |March 9, 2020 |March 8, 2020 |}

== Week of February 24, 2020 ==
'''Team Meeting Notes:'''
* Dr. Zutty gave us the class time to work on the titanic assignment. 
'''Sub-Team Meeting Notes'''
* Most of my team was still working on getting emade cloned and getting mysql installed. We decided to wait on running emade until all 5 of us were ready to run simultaneously.
* I realized I had the wrong version of mysql installed (I'd been using ver 8 for another class), but Dr. Zutty said it was fine as long as I wasn't the master.
'''Hackathon Meeting Notes:'''
* Alex and I were the only ones who showed up to the 'hackathon' so, we decided to utilize that time to actually run emade.
* We realized that git didn't clone emade's default input files right, so Dr. Zutty helped us figure out how to fix that without fully re-cloning emade (it was complicated and I won't pretend to understand how he did it). 
* I was having trouble connecting to Alex's mysql server and thus couldn't see the results of emade. His computer's firewall was giving us issues, but Dr. Zutty helped us find a way around it by creating a new mysql user with a wildcard hostname, which I could connect to.
* I wrapped up my time at the hackathon by beating everyone at super smash bros. It turned out that Dr. Zutty wasn't very good, which was disappointing. Maybe he can evolve an Amiibo that will fight in his place next time.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|run 20+ generations for midterm presentation
|in progress 
|February 19, 2020
|March 9, 2020
|March 7, 2020
|-
|get rest of team up to date on running emade
|in progress
|February 19, 2020
|March 9, 2020
|March 7, 2020
|-
|create visualizations and presentation
|in progress
|February 19, 2020
|March 9, 2020
|March 8, 2020
|}

== Week of February 17, 2020 ==
'''Team Meeting Notes:'''
* Dr. Zutty gave a overview of how to use EMADE and how we'll be using it to re-do the Titanic Problem.
* While using Anaconda to install opencv and the various modules needed, I ran into a "solving environment" problem. This was solved by creating a new environment and specifying Python 3.7; I was using 3.8 which wasn't compatible with everything.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Download EMADE
|Complete 
|February 12, 2020
|February 26, 2020
|February 19, 2020
|-
|Set up MySQL Server
|Complete
|February 12, 2020
|February 26, 2020
|February 19, 2020
|}

== Week of February 10, 2020 ==
'''Team Meeting Notes:'''
* Groups presented their results from the MOGP titanic project.
* Overall Dr. Rohling seemed pleased, saying everyone "was learning exactly what they needed to be learning from this assignment."
* Some groups outperformed mine in some key areas, which I've noted below:
** Other groups made a graphic representation of their best individual's tree, which was a nice touch we had not considered.
** One group graphed the pareto fronts of their ML results and their GP results on top of each other, allowing for a more convenient comparison. {| class="wikitable" !Task !Current Status !Date Assigned !Suspense Date !Date Resolved |- |Download EMADE |Complete  |February 12, 2020 |February 26, 2020 |February 19, 2020 |- |Set up MySQL Server |Complete |February 12, 2020 |February 26, 2020 |February 19, 2020 |}

== Week of February 3, 2020 ==
'''Team Meeting Notes:'''
* Dr. Rohling gave us the rundown on what's necessary for our presentation next week, where we'll be showcasing our pareto frontier and methodology for solving the Titanic Problem.
* He gave a lot of detail to making sure we understood the sorting and plotting methods of the pareto optimal frontier and emphasized that he wanted our powerpoint slides to be quite detailed.
'''Sub-Team Meeting Notes:'''
* For this project, I was in group 4. Our code and presentation can be found on the wiki.
* My team spent the 2/5 meeting constructing a pareto frontier from our ML results. The rest of the work was done in a series of very long coding sessions in Crossland/CULC.
* Machine Learning Pareto Frontier:
[[files/ML paretoFrontier.png|none|thumb|485x485px]]
* One mistake we made was not changing the scale of the axes. This visualization would've been a lot better had we zoomed in on the actual data points rather than keeping the trivial corner solutions in the picture.

* We decided to use eaMuPlusLambda as a '''placeholder''' until we were done debugging pre-evolution stuff.
[[files/MOGP eval.png|none|thumb|552x552px]]
* Most important thing to note of is our use of strongly typed GP -- we divided each data point by its maximum value (unsure why we hard coded the max values, but we forgot to change that) and rounded the result to either 0 or 1.
* For our evolutionary algorithm, we pretty much just used the one from lab 2, tweaking things like mutation rates.
* Our Pareto frontier, as well as information about our individual with the least distance from the origin:
[[files/MOGP pareto frontier.png|none|thumb|401x401px]]
* '''AUC for this front was 0.2147''', which was better than what we got for the ML algorithms, but I suspect that this was simply a byproduct of having more data points. The ML algorithms on the first pareto front had better FP/FN rates than our best individuals from GP.
[[files/MOGP bestIndTree.png|none|thumb|766x766px]]
[[files/MOGP bestIndConfusionMatrix.png|none|thumb]]'''Takeaways:'''
* Other than Chido and Rohith, my team was quite inexperienced in both coding and ML/GP knowledge, so that made every hurdle we encountered all the more difficult.
* The biggest problem we were having was that our population would evolve so that individuals would almost exclusively predict that passengers would die/survive, resulting in FP/FN results of either [0,1] or [1,0] (or floats quite close to these extremes. We tried '''a lot''' of things to fix this like tweaking the weighting of the minimization, changing the initial seed, and increasing the mutation rate. '''However,''' what finally ended up working was changing the selection process to NSGA II. Our best individuals from each generation were almost always ones who predicted a 100% death. With our initial selection process, this caused them to be the parents in almost every generation, but NSGA II, which takes crowding distance into account, allowed us to diversify this process and get more individuals with low distance from the origin in the FP/FN objective space.
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review MatPlotLib
|Complete 
|February 5, 2020
|February 12, 2020
|February 9, 2020
|-
|Complete Titanic Assignment
|Complete
|January 29, 2020
|February 12, 2020
|February 12, 2020
|}

== Week of January 27, 2020 ==
'''Team Meeting Notes:'''
* Dr. Zutty assigned groups and tasked us to solve the "titanic" problem from Kaggle.
* My group talked about what columns from the train data we could disregard, getting rid of everything except for SibSp, Age, Sex, and Pclass
* We planned to meet on Sunday to tackle the rest of the problem.
'''Sub-Team Meeting Notes:'''
* My team met and was able to pre-process the data quickly due to our simplistic approach.

* [[files/Titanic_data_pre-processing.png|frameless|651x651px]]
* All data that we used was numerical except for Sex, which we mapped to binary values (not very woke).
* We considered parsing through other data fields like Name and Cabin, hoping that we could get important information like titles (captain, lieutenant, etc) or relative locations of the passengers (i.e. people residing in the same letter section might have similar survival rates), but neither of these cases seemed fruitful since the names were simplistic and cabin data was sparse.
* Each member of the group got a confusion matrix using a new scikit algorithm. I used GaussianProcessClassifier() and got the following:
[[files/Titanic Confusion Matrix.png|frameless|342x342px]]
* I tried constructing a pareto frontier with the results of all of the ML algorithms that my team used, but I ended up getting a pretty bizarre graph. Lucky, Dr Rohling gave us the code necessary to do this in the next meeting.
'''Weekly Notes:'''
* I skimmed the rest of Dr. Zutty's dissertation, mostly focusing on parts pertinent to what we've done in the first 5 weeks of this semester. I'll be periodically looking back at it to get more context as we learn more things (especially once we get into EMADE).

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish Reading Dr. Zutty's dissertation
|Complete 
|January 15, 2020
|February 5, 2020
|February 5, 2020
|-
|Pre-process data and find other algorithms to use in the Titanic problem
|Complete
|January 29, 2020
|February 5, 2020
|February 5, 2020
|}

== Week of January 20, 2020 ==
'''Team Meeting Notes:'''
* Dr. Zutty presented lecture 3, which introduced multi-objective programming
* After establishing metrics like True Negative (TN), True Positive (TP), False Negative (FN), and False Positive (FP), he introduced a way of showing the phenotype of individuals (genomes) in the objective space (a multivariate graph)
* The essence to the objective space is constructing Pareto Frontiers comprised of non-dominated individuals
* As an economics major, I really enjoyed this lecture because I got to compare this VIP's use of Pareto Optimality with how it's applied in economic concepts like Production Possibility Frontiers and Indifference curves. 
** One particular thing I noted was that the microeconomic assumption that consumers want balanced bundles (so they prefer an equal amount of good X and Y compared to an imbalanced combination with the same euclidean distance from the origin) and this VIP's preference for non-dominated individuals both result in a concave graph resembling the 1st quadrant of the graph of 1/x. These heuristics seem unrelated at first glance, but I think there's more to explore as to why they result in the same indifference curve/pareto frontier.
'''Weekly Notes:'''
* While finishing part 2 of lab 2, I had a lot of trouble reducing the area under the curve of the pareto optimal front. I tried using different algorithms that might've been more efficient than eaMuPlusLambda, but after looking at everything in that section of the Deap documentation, I either got less optimal frontiers or got an error that I could not resolve (eaGenerateUpdate being the only latter example). I tried to use piazza to get help on this but didn't get a response in time
* After reading more Deap documentation, I realized that I was either reading things I already knew (through the labs) or reading things that were irrelevant to what we've been doing in this VIP. I think I'll focus more time on reading Zutty's dissertation (since I've been procrastinating on that) instead of reading much more documentation.
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete second half of Lab 2
|Complete
|January 22, 2020
|January 29, 2020
|January 28, 2020
|-
|Finish Reading Dr. Zutty's dissertation
|WIP 
|January 15, 2020
|February 5, 2020
|
|-
|Finish reading the "creating types" part of deap's documentation
|Complete
|January 22, 2020
|January 29, 2020
|January 28, 2020
|}


== Week of January 13, 2020 ==
'''Team Meeting Notes:'''
* Dr. Zutty presented lecture 2, which moves from genetic algorithms to genetic programming
* instead of having a function evaluate an individual, with GP, the individual is the function
'''Weekly Notes:'''
* When working on lab 2, I encountered frequent errors/trouble when choosing different primitives. Even when I found a group of primitives that didn't result in an error, choosing a different type of mutation from deap's documentation could end up invalidating that. I don't think I have a deep enough understanding of how the trees are being formed, but to me it seems that I should steer clear of primitives that cannot take all real numbers as inputs (like division and sqrt).
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete First half of Lab 2
|Completed
|January 15, 2020
|January 22, 2020
|January 21, 2020
|-
|Finish Reading Dr. Zutty's dissertation
|WIP 
|January 15, 2020
|February 5, 2020
|
|-
|Do some reading on deap's documentation
|Completed
|January 15, 2020
|January 22, 2020
|January 22, 2020
|}


== Week of January 6, 2020 ==
'''Team Meeting Notes:'''
* Dr. Zutty Introduced the AAD VIP and began to go over basic vocabulary for genetic algorithms.
* Installed deap
* Outlined the process for optimizing a population:
# Randomly initialize a population
# Determine the fitness of a population
# Repeat...
## Select parents from the population (randomly for now)
## Perform crossover creating population
## Mutate population
## Determine fitness of population ....until best individual is good enough
'''Weekly Notes:''' 
* Began reading Dr. Zutty's dissertation to get a better perspective on EMADE.
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Lab 1
|Completed
|January 8, 2020
|January 15, 2020
|January 15, 2020
|-
|Create VIP Notebook
|Completed 
|January 8, 2020
|January 15, 2020
|January 9, 2020
|}