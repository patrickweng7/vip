'''Email:''' cbauer32@gatech.edu
'''Cell:''' 312-898-5398

==September 1st, 2021==
Week 2 focused on learning genetic programming trees.

===Lab 2: Genetic Programming and Multi-Objective Optimization===
Individuals of gp.PrimitiveTree are trees like discussed in bootcamp. We create a tree and added primitives including two of my choice:

pset.addPrimitive(np.maximum, arity=2)
pset.addPrimitive(np.reciprocal, arity=1)

We assigned individuals to outputs of gp.genHaldandHalf given our primitive set and max and min depth. After defining the evaluation function as the mean squared error of the tree's output and points (we used evenly numbers between -1 and 1 as points but the values are less important than the fitness). Then we registered mutations including mine below:

toolbox.register("insert_mut", gp.mutInsert, pset=pset)

Multiple Objectives: We made a new, more complex evaluation function by including sin, cos, and tan as primitives and include a second objective, the tree size. We created a pareto dominance function to compare the fitness of two individuals. We created a 300-individual population and sorted it by comparison to a separate individual. Our genetic algorithm was a mu plus lambda algorithm with mu individuals selected for the next generation and lambda children produced at each generation.

The success of the algorithm was inversely measured by the least squares area under the curve -AUC- of our pareto front (i.e. plot of mean squared error by tree size). The original lab algorithm produced AUCs between 2 and 5. I'm not quite sure but I think changing my mu to 100 decreased the AUC.

Other: Strongly typed primitives require a certain type of terminal input. Terminals generated by functions are called ephemeral constants. Also, DEAP trees must be kept within their 91-depth limit through bloat control.

===Bootcamp Notes: Genetic Programming===
Genetic programming trees have nodes called primitives that represent functions and leaves called terminals that represent inputs. 

Example 1 function: 3*4+1

Example 1 parse tree: [+,*,3,4,1]

Example 3 (symbolic regression): y=sinx 3rd Degree Taylor polynomial

Example 3 parse tree: [-,x,/,*,x,*,x,x,*,3,2]


==August 25th, 2021==
First Week! I was introduced to the team, wiki, genetic algorithms, and DEAP.

{| class="wikitable"
!Task
!Current Status
!Date As
signed
!Suspense Date
!Date Resolved
|-
|Lab 1
|Complete
|8/25/2021
|9/1/2021
|8/31/21
|-
|Walkthrough
|Complete
|8/25/2021
|9/1/2021
|8/30/21
|-
|}

===Lab 1: Genetic Algorithm Problems===
One Max Problem: The algorithm tried to make the max-fitness individual all 1s in 40 generations using tournament selection, crossover, and mutation. The population had 300 individuals of 100 Boolean numbers each. The tournament size was 3, crossover probability 0.5, mutation (random new 0 or 1) probability 0.2.

N Queens Problem: The algorithm found how to position n queens on an nxn board so that none could take each other. The algorithm minimized the number of diagonal conflicts and reached a stable bend in the minimum (and average) in around 25 generations.


===Walkthrough: DEAP===
The walkthrough demonstrated how to use base, creator, and tools to create a population of two individuals with one hundred Bernoullis.

===Bootcamp Notes: Genetic Algorithms===
#Randomly initialize population
#Determine fitness using objective
#Repeat i-iv until the best individual is good enough
##Select parents from population (fitness proportionate or tournament)
##Perform Mate/Crossover – choose a point (or multiple) to switch lists after
##Perform Mutation – random modifications of values to maintain diversity
##Determine fitness of population

When? Search space is very large, discontinuous, non-linear, local extrema dense
