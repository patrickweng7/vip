== Team Member ==
[[files/GeorgiaTechBuzz.jpg|thumb|123x123px]]
Team Member: David Socher Wolfson

Email: dwolfson7@gatech.edu

Cell Phone: 586-999-2299

Interests: Machine Learning, Python, Football, Basketball, Frisbee
==April 30, 2021==
====Team Meeting Notes:====
* Stocks team presented first
** I presented the primitive analysis section
* EzCGP presentation notes
** The experiments run were very informative
*** Didn't get better performance when using dense layers, which is interesting, and had low diversity in population
** The new visualization is much easier to understand and better for debugging issues with the evolutionary algo
** Symbolic regression paper was very interesting
*** Should investigate meta evolution more
** Mating vs. no mating experiment was good, but missing more tests
* NLP presentation notes
** Very good approach to optimize hyper-parameters using GP
** Good idea to use simple datasets over multi-class datasets for developing Emade
** Consider using Google Colab to set up Emade
*** Very easy for multiple people to work on and use
** Love the documentation
** Good baseline model (FastTex)
*** Also a primitive in Emade, so Emade should atleast do as well as FastTex
*** Changed seeds to mediocre seeds to improve evolution
*** Getting non-trivial solutions, so there is improvement
** Nice discussion of pareto individuals
** Discussing mis-classifications was very informative and gives a glance of how they debug Emade
* Modularity presentation notes
** Good idea to move away from probability of sub-tree in populations and using size/fitness instead
*** Allows for better "performing" sub-trees to be added as new primitives
** Now allowing sub-trees with depth greater than
*** This should find better sub-trees
** Changing objectives improved Emade performance
** Good experiment to run with and without seeds
*** Another possible experiment is changing the objectives and see how performance changes
** Experiment analysis is a little confusing
** Integrating new models and datasets (future work) should improve performance
==April 26, 2021==
====Team Meeting Notes:====
* Discussed team's most recent run
* Mainly discussed what team will present during presentations
** Each team member will do their own slide and present it
** Team will discuss the best performing individuals we have found
*** Will discuss monte carlo simulation and compare that as baseline to individuals
*** Another baseline is buy and hold strategy
** Will discuss some changes we want to implement in Emade based on last semester
====Sub-team Meeting Notes:====
* Went over presentation
** Most members have put their slides in, presentation looking good
** Made sure everyone has a slide to present
* Discussed the most recent run
** No novel individuals
* We are not going to have time to run experiments that team discussed last week
** This will be for next semester
====Individual Notes:====
* Discussed with Abhiram and decided that a heatmap was the best and fastest way to determine relevancy of TI's
** Have working code that generates heatmap based on performance (cdf) of indviduals that implement a given TI
*** Check commit hash e53c19fba1710c35ff56cac57efbb6b14440e7c9
*** Wasn't able to upload the heatmap image to wiki. Just run script to see the heatmap
* Also investigating how individual TI's can affect trigger points
** To do this, I am creating trigger points based solely on a single TI and comparing it to the trigger points of the individuals
** Still a work in progress. Will work on this next semester.
*** Check commit hash 051a5df099466d319cbcb34031eef074fa41d156
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish script to detect TI's relevancy
|Complete
|April 22, 2021
|April 30, 2021
|April 29, 2021
|-
|Update team presentation with heatmap and discussion about it
|Complete
|April 27, 2021
|April 30, 2021
|April 29, 2021
|-
|Investigate using single TI's to find trigger points
|Complete
|April 27, 2021
|April 30, 2021
|April 29, 2021
|}

==April 19, 2021==
====Team Meeting Notes:====
* Discussed team's most recent run
** Found very interesting results
*** One individual performed very well with our stocks
* Discussed new TI's team plans to add in
** ADX,Stochastic RSI, Aroon, VWAP, VWMA 
====Sub-team Meeting Notes:====
* Discussed in depth about the individual that performed very well
* We continued the run with the individual as a seed, but didn't find any other individuals that performed as well
** I brought up that this individual may be a clue that we need to pursue to improve out algorithm
*** Individual was very simple, and was based on bollinger bands
*** Team will add more simple individuals with bollinger bands to seed
* Discussed different experiments we should run
** Want to have one run with very simple (not complex) individuals seeded
** Want another run to have no seeds
*** These tests will tell us if seeds are good or bad for our program and if complexity of individuals is relevant
* Discussed trying to figure out which TI's are actually impactful
** I will be leading this effort
* Discussed presentations next week
** Each person will write their own slide about their work
====Individual Notes:====
* Discussed with team how I should approach detecting relevancy of TI's
** My idea was to work backward from results and figure out relevancy, but wanted team's input
** One suggestion is to take top 5 or 10 individuals and see correlation between their data and the TI's
*** Will start with this suggestion
*** Need to understand how TI's are used in Emade
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Write script to detect TI's relevancy
|In progress
|April 22, 2021
|April 29, 2021
|April -, 2021
|-
|Go through TI code in our repo
|Complete
|April 22, 2021
|April 22, 2021
|April 29, 2021
|}

==April 12, 2021==
====Team Meeting Notes:====
* Revisited adding stocks to data set
* Discussed how stock team will split into "work groups" to make team more efficient
* Discussed some issues with Emade the team is having
====Sub-team Meeting Notes:====
* Team officially split into groups
* Again, discussed adding more stocks to data set
** I suggested we try to generalize our Emade by concatenating all stock data sets into one large data set instead of training on individual stock data
*** Seemed to be outside of scope for team
*** But team not against the idea, possible future project
====Individual Notes:====
* Begin writing data analysis script for Emade
* Need to investigate concatenating all stock data into one data set and see how Emade performance changes
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Write skeleton code for data analysis script
|Complete
|April 12, 2021
|April 19, 2021
|April 18, 2021
|-
|Run Emade on concatenated data set
|Complete
|April 12, 2021
|April 19, 2021
|April 19, 2021
|}

==April 5, 2021==
====Team Meeting Notes:====
* Jason discussed expanding the stock data
**Possibly use more stocks
====Sub-team Meeting Notes:====
* Team discussed adding more stocks to data set
** Not at the moment, but maybe a future project
* Team discussed splitting up into different "work groups" due to size of team
** One team will find technical indicators, another team will analyze Emade data, another team will implement changes to Emade based on other groups' findings
====Individual Notes:====
* I volunteered to join the data analysis group
** Need to iron out tasks of this group with the team
* Also will help with TI's to try and improve Emade performance
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Discuss scope of data analysis group
|Complete
|April 7, 2021
|April 12, 2021
|April 12, 2021
|-
|Investigate adding stocks to data set
|Complete
|April 5, 2021
|April 12, 2021
|April 11, 2021
|}

==March 29, 2021==
====Team Meeting Notes:====
* Missed team meeting due to Jewish holiday - Passover
* Rewatched lecture
** Stocks team discussed using monte carlo as a baseline to test how good or bad each individual is
*** Discussed difficulties with this, and clarified some misunderstandings of the team
====Sub-team Meeting Notes:====
* Team discussed monte carlo approach
** Will be implemented by Max
** Team to support
====Individual Notes:====
* I am joining the stocks team
** Installing stocks team version of Emade on desktop
** Read through research paper
*** Think about how to apply TI's to improve individual performance 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install new version of Emade
|Complete
|March 29, 2021
|April 5, 2021
|April 1, 2021
|-
|Reach research paper
|Complete
|March 29, 2021
|April 5, 2021
|April 2, 2021
|}

==March 22, 2021==
====Team Meeting Notes:====
* Presented to full class the Titanic problem
* Emade groups presented to full class to explain to bootcamp students what each group does
====Sub-team Meeting Notes:====
* Went over our team presentation
** Discussed any final issues with Emade for team mates
* Investigated Emade implementation of GP
** Tried changing the eval function in Emade to fit our objective, and successfully changed it
====Individual Notes:====
* Reviewed our GP evolutionary algorithm for presentation since I am presenting that
** Went over mutation methods and selectors 
* Reviewed Emade input file to get better understanding of what Emade is doing
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Hold team meeting to go over presentation
|Complete
|March 22, 2021
|March 22, 2021
|March 22, 2021
|-
|Submit group ranking
|Complete
|March 22, 2021
|March 29, 2021
|March 24, 2021
|}

==March 17, 2021==
====Team Meeting Notes:====
* Went over teams issues with Emade
** MySQL issues still persisting
* Reminded class that we will be presenting on Monday
** Full VIP class will be there
* Different groups in VIP will also present on Monday and we should see which one we like
====Sub-team Meeting Notes:====
* Made sure team have correct IP for input
** Gave each team member a unique username to access server as workers
* Assigned team members things to do
** Everyone needs to find parameters that get best results for them
* Discussed changing the splitter file to match team's preprocessing for Titanic problem with ML and MGOP
====Individual Notes:====
* Still trying to figure out Python issue
** Emade is not running because of this
* Running on personal laptop first before I connect to master server
* Finally figured out issue, running on my laptop and finding parameters
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Hold team meeting to go over presentation
|Complete
|March 17, 2021
|March 22, 2021
|March 22, 2021
|-
|Find setup parameters that gives me best performance
|Complete
|March 17, 2021
|March 22, 2021
|March 22, 2021
|-
|Connect to master and run as worker
|Complete
|March 17, 2021
|March 22, 2021
|March 22, 2021
|}


==March 10, 2021==
====Team Meeting Notes:====
* Went through issues class is having with Emade
** Many MySQL issues
** Suggested teams be on VPN to assist in connecting to master server
====Sub-team Meeting Notes:====
* Set up master sever
* Team having issue connecting to master server
** Not everyone was on VPN
** Decided to try to connect to server without VPN
====Individual Notes:====
* Already had MySQL 8.x on my laptop, so worked on resolving this issue
* Investigated to the input file setup
** Find different parameters that worked best
* Tried running Emade on my laptop first
** Running into issues with not finding Python
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Hold team meeting to get everyone on same page for Emade input file setup
|In Progress
|March 10, 2021
|March 17, 2021
|March 17, 2021
|-
|Get MySQL 5.x installed on laptop
|Complete
|March 10, 2021
|March 17, 2021
|March 17, 2021
|}


==March 3, 2021==
====Team Meeting Notes:====
* Finished up Titanic presentations
** Our team presented this week
* Introduced class to the EMADE framework
** Assigned class to have EMADE repo cloned and set up by next week
====Sub-team Meeting Notes:====
* Discussed who on our team would host the server for EMADE
* Team went over MySQL and how to remotely access a database
====Individual Notes:====
* Worked on setting up EMADE on my laptop
* Investigated remotely accessing a database with MySQL
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Hold team meeting to go EMADE setup
|Complete
|March 3, 2021
|March 10, 2021
|March 8, 2021
|-
|Setup EMADE on my laptop
|Complete
|March 3, 2021
|March 10, 2021
|March 10, 2021
|}

==February 24, 2021==
====Team Meeting Notes:====
* Started Titanic presentations
** Several teams used boost ML algorithms and they worked well
** Some teams had ML produce better results than MOGP, which was interesting
* Jason discussed that in AUC plots, if plot doesn't have the points (1,0) and (0,1), must add them to get accurate AUC calculations
** Those points are the bounds
* Ran out of time, so our team presenting next week
====Sub-team Meeting Notes:====
* Discussed different ways of improving our evolutionary algorithm
** Adding more primitives, more generations, more variety to population (more mutations and mating)
** Discussed which selector would work best for our algorithm
*** NSGA2 produced better results
* Made minor adjustments to powerpoint
* Practiced powerpoint again
** Made sure everyone was up to speed on if any changes were done to evolutionary algorithm
====Individual Notes:====
* Helped bring other team members up to speed on any changes to presentation
* Brought up discussion about whether or not our algorithm was overfitting to our data
** Originally, our GP alg was training and testing on same data
** Pointed out that we need to test on different data than what alg trained on 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Hold team meeting to go presentation
|Complete
|February 25, 2021
|March 3, 2021
|February 28, 2021
|-
|Work on tweaking parameters off team's GP algorithm to see if get any better performance
|Complete
|February 24, 2021
|March 3, 2021
|February 28, 2021
|}

==February 17, 2021==
====Team Meeting Notes:====
* Reviewed different team's approaches to solving the Titanic problem
** Explored different pre-processing methods
** Touched on stratified sampling to un-balanced data, since the Titanic dataset is heavily un-balanced which can skew your results
* Introduced the second part of the assignment: using genetic programming to solve the Titanic problem
** Explored different relevant primitives
** Reviewed strongly-typed vs. loosely-typed primitive sets
====Sub-team Meeting Notes:====
* Our main discussion was regarding the evaluation function
** This function had to be agreed upon by all team members, as it is probably the most important part of this genetic programming
*** Decided that we would try to minimize FPR and FNR
**** Other possibility was to minimize error, i.e. subtract real survival data from whatever each individual predicted
**** Team felt that we should avoid this approach as it adds an extra step that we don't need
* Agreed to investigate on our own different selectors, mutation and crossover methods
====Individual Notes:====
* My main focus was finding a good selector
** The three main selectors I focused on were NSGA2, NSGA3, and SPEA2, as these algorithms are very helpful in multiple objective optimization
*** SPEA2 worked best for my algorithm
* I analyzed how different min and max tree heights for the generator functions affected my algorithms performance
** For me, smaller trees resulted in better performance
* I explored how the size of the primitive set affects the performance of the algorithm
** I found that when running evolutions with a small number of generation (<500), having a large set of primitives actually diminishes the performance of my algorithm
*** This makes sense, as the population maybe too diverse, and the algorithm doesn't have enough "time", i.e. generations, to learn what the good characteristics are and evolve superior individuals
** Large primitive sets are very helpful when running the evolutionary algorithm on a large number of generations (>500) and greatly increase the performance of the algorithm
* I also investigated running two evolutions, first minimizing the prediction error of each individual and getting the pareto frontier of that evolution, and then running another evolution to minimize FPR and FNR
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Hold team meeting to go over results of everyone's models
|Complete
|February 17, 2021
|February 23, 2021
|February 21, 2021
|-
|Investigate different selectors, such as NSGA2, NSGA3 and SPEA2
|Complete
|February 17, 2021
|February 23, 2021
|February 21, 2021
|-
|Integrate different selectors into genetic programming algorithm and compare results
|Complete
|February 21, 2021
|February 23, 2021
|February 23, 2021
|-
|Investigate using two fitnesses, first minimizing each individuals prediction error, then running evolution again to minimize FPR and FNR
|Complete
|February 23, 2021
|February 24, 2021
|February 24, 2021
|}

==February 10, 2021==
====Team Meeting Notes:====
* Formed sub teams to work on the Titanic problem
** I am on sub team 5
* Discussed the Titanic problem
** Walked through the notebook
** Stressed importance of preprocessing and how individuals can work on their own preprocessing
====Sub-Team Notes:====
* Discussed our approach to tackling the Titanic problem
** Discussed which features were relevant and which can be dropped
*** Dropped Name, Cabin, Ticket
** Discussed creating ranges for Age and Fare and replacing those features with the ranges 
** Discussed creating a new feature to capture whether or not passenger was alone, i.e. had no siblings, spouse, parents, or children on board with him/her
*** Dropped SibSp and Parch features and replaced with IsAlone feature
* Discussed using cross-validation on our models
** Decided not to use CV as it is not necessary for this assignment
* Discussed changing the train-test split from 0.66/0.33 to 0.8/0.2
** Decided against the change because the dataset is small and we were afraid using a larger train set would skew the results
====Individual Notes:====
* Worked on preprocessing data
** Explored using cut and qcut to create ranges for Age and Fare
*** Used cut for Age, as the ages could be split into ranges based on value because it had no outliers
*** Used qcut for Fare, as it had a few outliers and using cut would not have been a good representative of the data
* Explored using SVM classifier to classify data
** Used GridSearchCV to find the kernel, 'C' and 'gamma' values that would optimize the classifier for our dataset
*** Optimized parameters: kernel=rbf, C=1000, gamma=0.01
** Even with optimal parameters, FPR and FNR were pretty high
*** FPR = 0.0785, FNR = 0.413
** Optimized SVM did not put my model in the pareto front for our group, so I had to explore other models
* Explored KNN classifier to see if it would perform better than SVM classifier
** Found the optimal number of neighbors by looping through number of neighbors ranging from 1-100 and seeing which number of neighbors minimized the FPR
*** Optimal number of neighbors was 89, with 2 false positives
*** 2 neighbors resulted in 7 false positives
** Decided to go with 2 neighbors to avoid bias to the dataset that would be present with a large number of neighbors
*** FPR = 0.0366, FNR = 0.471
* Plotted FPR x FNR plot for everyone's model in sub-team 5
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Hold team meeting to go over results of everyone's models
|Complete
|February 15, 2021
|February 17, 2021
|February 16, 2021
|-
|Investigate using cut and qcut for binning age and fare features
|Complete
|February 16, 2021
|February 17, 2021
|February 16, 2021
|-
|Investigate using GridSearchCV to optimize SVM classifier parameters, such as kernel type, 'C' and 'gamma' values
|Complete
|February 16, 2021
|February 17, 2021
|February 16, 2021
|-
|Find optimal number of neighbors for KNN classifier
|Complete
|February 16, 2021
|February 17, 2021
|February 17, 2021
|}

==February 3, 2021==
====Team Meeting Notes====
* Introduced multiple objective genetic programming
* Introduced several methods of scoring algorithms
** In this course, we will focus on two scores, False Positive Rate (FPR) and False Negative Rate (FNR)
*** A false positive is when something is falsely classified as positive or true, when it was actually false
*** A false negative is when something is falsely classified as negative or false, when it was actually true
*** FPR is calculated simply by dividing the number of false positives by the number of actual positives
**** FPR = FP/N = FP/(FP+TN)
*** Similarly, FNR is calculated by dividing the number of false negatives by the number of actual negative
**** FNR = FN/P = FN/(TP+FN)
** The goal in this class is to find algorithms that minimize both the FPR and FNR
*** The FPR and FNR evaluate to a number less than 1 (a percentage), and therefore can be plotted on a graph where FPR and FNR are on x and y axes and range from 0 to 1
**** This graph is called the objective space
**** The goal is to find the algorithms whose scores are closest to the origin, or 0,0 in the objective space
*** An individual (algorithm) in a population is Pareto optimal when no other individuals in the population outperforms (has better scores) the individual in ALL objectives
**** Another individual in the population can have a better score in one objective, as long as they don't have better scores in ALL objectives
** Other scorings methods include NSGA II and SPEA2
* Introduced the second part of lab 2 noteboook, which focuses on multiple objective genetic programming
* Assigned a self assessment of my notebook
====Individual Notes:====
* Continued working on lab 2 notebook
** Ran into issues when adding primitive operators to my primitive set
*** I added logical operators which return boolean values, and the evaluate function did not work since it trying to apply the operators to the points values which are floats and to boolean values returned by the individual, which clearly will not work
** I also played with the max depth of the genHalfAndHalf function
*** Decreasing the max depth of this function allows for a simpler function/individual to be selected as the best individual
*** This also causes the population to be made up of higher scoring functions/individuals
**** This is mainly due to the fact the individuals generated by the genHalfAndHalf() function are simpler since they have a smaller max depth, which will allow the best performing individual to be a simpler function and the population will perform better because they do not vary as much as they would with a larger max depth
***** Further exploration of genHalfAndHalf() function can be found here: https://deap.readthedocs.io/en/master/api/tools.html
** Worked on the multiple objective section of the notebook
*** The big difference between single and multiple objective GP is that multiple objective GP attempts to minimize or maximize 2 or more objectives
**** This is done when creating the fitness using the creator class, the weights parameter is fed a tuple. For single objective GP, one of the weights is 0. For multiple objective, at least 2 of the values in the tuple are non-zero
*** For multiple objective GP, the evaluation function must return two or more fitnesses in order to properly optimize the individuals in the populations.
** Explored eaMuPlusLambda
*** This function performs the entire evolutionary process and returns the optimized population and a Logbook of the statistics of that population.
*** This function uses the varOr() function to implement the variation to each generation
**** Further exploration of the eaMuPLusLambda() function can be fiund here: https://deap.readthedocs.io/en/master/api/algo.html
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Investigate new functions used in part 2 of lab 2, such as ParetoFront(), Statistics(), and eaMuPlusLambda()
|Complete
|February 4, 2021
|February 10, 2021
|February 9, 2021
|-
|Complete Lab 2 notebook
|Complete
|February 2, 2021
|February 10, 2021
|February 4, 2021
|-
|Go over lecture 3 slides
|Complete
|February 3, 2021
|February 10, 2021
|February 4, 2021
|-
|Complete notebook self assessment
|Complete
|February 3, 2021
|February 10, 2021
|February 9, 2021
|}

==January 27, 2021==
====Team Meeting Notes:====
* Introduction to genetic programming. Discussed difference between genetic algorithms and genetic programming
** Genetic algorithms evaluate the individual
** With genetic programming, the individual is a function, and that function is evaluated based on its error relative to what intend it to output
** We define these functions using preordered trees
* Introduced Lab 2, which focuses on genetic programming
====Individual Notes:====
* For genetic programming (GP), the individual class inherits from the PrimitiveTree class, not a list
** This means the individuals that are created, i.e. the functions that we are trying to create with GP, are primitive trees, not lists as the individuals in genetic algorithms were
*** This is a key difference between GP and genetic algorithms
* Once the individual is created, the primitive set needs to be initialized and populated with operators that act on the nodes of the primitive tree
** These operators can be any type of operation, like a logical or, a subtraction, multiplication, etc.
** These operators require the number of arguments they take, which is called the arity
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Investigate GP library in DEAP, including PrimitiveTree, PrimitiveSet, and generator functions, such as genHalfAndHalf, genFull and genGrow
|In Progress
|February 2, 2021
|February 3, 2021
|February 3, 2021
|-
|Complete Lab 2 notebook part 1
|In Progress
|February 2, 2021
|February 10, 2021
|February 4, 2021
|-
|Go over lecture 2 slides
|Complete
|February 2, 2021
|February 3, 2021
|February 3, 2021
|}

== January 20, 2021 ==
====Team Meeting Notes:====
* Introduction to the basics of genetic algorithms. Discussed process of defining the optimum genetic code through selection. Discussed two different types of selection: fitness proportionate and tournament. Discussed crossover and mutation. Introduced lab 1.

====Individual Notes:====
* Did some digging into different functions in DEAP module to understand Lab 1 better
** Creator class creates types that will be later initialized using the toolbox
** Toolbox registers partial functions that are used to conduct operations on the individuals in the population
*** The register function takes the alias name, the function to run, and the arguments to pass to that function when called as inputs
*** The operator can be called by its alias name using toolbox.alias_name after being initialized in the toolbox
** Genetic operators in Tools class operate on an individual (mutation) or several individuals (crossover) in place, i.e. the individuals that are involved in the crossover have their objective changed
*** Those individuals are NOT removed from the population and replaced with the new offspring
*** This means that genetic operators do NOT change size of population, only change genetic makeup of individuals in the population
** When a fitness value is "deleted" using the "del" function, this causes the fitness to be invalid
*** It does not delete the individual from the population
*** This function is used after a genetic operator is applied to an individual
**** This is because the genetic makeup of the individual has been changed by the genetic operator, so the fitness value that it had before is now incorrect, so it is deleted/invalid
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Watch first lecture again to understand how to use and update my notebook
|Completed
|January 20, 2021
|January 27, 2021
|January 25, 2021
|-
|Complete Lab 1 notebook
|Complete
|January 20, 2021
|January 27, 2021
|January 27, 2021
|-
|Go over lecture 1 slides
|Completed
|January 20, 2021
|January 27, 2021
|January 26, 2021
|-
|Understand different functions and classes in DEAP module, such as Fitness class, register, selTournament, cxTwoPoint
|Complete
|January 22, 2021 
|January 27, 2021
|January 26, 2021
|}