=Team Member Info=
Name: Dhruv M Patel

Subteam: Image Processing

2nd semester in AAD

Email: dmpatel@gatech.edu

Cell Phone: 919-537-5060

Interests: Weightlifting, hiking & backpacking, software engineering, cybersecurity

=Fall 2021=
'''General Info'''
* Image Processing subteam
** Teammates: [[Notebook Harris Barton|Harris Barton]], [[Notebook Maxim Daniel Geller|Maxim Geller]], [[Notebook Monil Manish Kaneria|Monil Kaneria]], [[Notebook Aryaan Anuj Mehra|Aryaan Mehra]], [[Notebook Temiloluwa Orefoluwa Ogunsanya|Temi O]], [[Notebook Heidi Mae Yap|Heidi Yap]]
** New teammates from bootcamp: [[Notebook Rohan Batra|Rohan Batra]], [[Notebook Elan Grossman|Elan Grossman]], [[Notebook Austin Tinghao Peng|Austin Peng]], [[Notebook Eashan Sinha|Eashan Sinha]]
* VIP meetings 5-5:50pm on Mondays
* Subteam meetings 5:45-6:45pm on Wednesdays

==Nov 29th, 2021==
===Meeting Notes===

===Subteam Notes===

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|
|In Progress
|Nov 29, 2021
|Dec 6, 2021
|
|-
|Update Wiki Notebook
|In Progress
|Nov 29, 2021
|Dec 6, 2021
|
|-
|}


==Nov 22nd, 2021==
===Meeting Notes===
* Hackathon went well
* Everyone continue working on your goals and approach code freeze soon
* Peer Evals will be released on Monday 11/29
* Primitive should be taking in instance of data (ex. array) not the file

===Subteam Notes===
* No subteam meeting this week due to Institute holiday (Thanksgiving break)

''' Work Notes '''
* Harris and I know what we need (what runs to conduct) for final presentation
* Not much other work done this week due to Thanksgiving Break Wed-Sun

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Flesh out needs for final pres
|Complete
|Nov 22, 2021
|Nov 29, 2021
|Nov 28, 2021
|-
|Update Wiki Notebook
|Complete
|Nov 22, 2021
|Nov 29, 2021
|Nov 29, 2021
|-
|}

==Nov 15th, 2021==
===Meeting Notes===
* Reminder from Jason to document your personal contributions in your individual notebook
* Hackathon Details: Sunday 11/21, 1-5pm
* Our elevator pitch: We are researching how we can improve EMADE’s performance on image processing tasks; this semester in particular we are looking at multi-class image classification. Using a baseline run of EMADE on the dataset we processed, success for us looks like seeing improvements in ROC and (second metric? Lol i don’t remember unless we are keeping # params) compared to the baseline run when evaluated independently and in combinations.

===Subteam Notes===
* Keep working on task, hackathon on Sunday
* Max is working on getting a new environment ready for TF 2.6. Will also create new documentation for it when finished

''' Work Notes '''
* Still troubleshooting the 3D array problem
* Invalid value encountered in subtract
** <code> ft = fitness - best_point  # line 571 in emo.py </code>
** <code> A = extreme_points - best_point  # line 588 </code>
** <code> fn = (fitnesses - best_point) / (intercepts - best_point)  # line 608 </code>
* Problematic line is 614
** <code> distances = numpy.sum(fn * reference_points, axis=2) / norm.reshape(1, -1) </code>
* Titanic dataset, ran NSGA3 with Titanic to make sure it’s not a problem with the CheXnet image dataset
** Titanic XML file needed some tweaking to accommodate PACE
** Encountered the same error! The same line caused <code> ValueError: operands could not be broadcast together with shapes (315,560,3) (560,14) </code>
** Maybe NSGA3 doesn’t play well with EMADE
* Mismatch between selection function’s reference points, expecting 14-long tuple for individual’s fitness values but individuals only tracking 2-long tuples. Objectives problem
* Now going to try changing objective count and raise p to accommodate an adequate number of individuals
* Tried changing objective count to 2 and p to 8 in my sel_nsga3 method
** <code> File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/GPFramework-1.0-py3.6.egg/GPFramework/EMADE.py", line 1240, in <listcomp> print([ind.fitness.crowding_dist for ind in elitePool]) </code>
** <code> AttributeError: 'FitnessMin' object has no attribute 'crowding_dist' </code>
** Now I’m getting this error, for some reason crowding_dist variable not being read

* Got a run to finally work! Although, some individuals are not evaluating AUCs correctly (see below)
** [https://pastebin.com/rWfDDhmZ Individual Errors]
* Best individual that evaluated
** Precision AUC = 0.0938091 (improve from 0.0938667)
** NNLearner(ARG0, Conv1DLayer(0, tanhActivation, 7, 2499, trueBool, 150, GlobalAveragePoolingLayer2D(InputLayer())), 45, AdagradOptimizer)
* “Worst” of individual that evaluated
** Precision AUC = 0.0981862
** NNLearner(ARG0, OutputLayer(BatchNormalizationLayer(InputLayer())), 70, AdamOptimizer)

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Fix NSGA3 errors
|Complete
|Nov 15, 2021
|Nov 22, 2021
|Nov 21, 2021
|-
|Run NSGA3
|Complete
|Nov 15, 2021
|Nov 22, 2021
|Nov 21, 2021
|-
|Update Wiki Notebook
|Complete
|Nov 15, 2021
|Nov 22, 2021
|Nov 22, 2021
|-
|}

==Nov 8th, 2021==
===Meeting Notes===
* We will likely have a finals hackathon the weekend of 11/20-21
* Another word for semantic: behavioral performance...try this out! It might be easier to find something in literature for this.
* Keyword: behavioral genetic programming
* Keep our final prezo deadline in mind! May not have enough time for this
* Use new install script for env, specify TF version
* pace-check-queue pace-ice-gpu to check GPU queues

===Subteam Notes===
* No subteam notes, workday during 11/10 subteam meeting

''' Work Notes '''
* Final comparison: NSGA II on 3, NSGA III on 14 obj, Lexicase on 14, Lexicase on Testcase with 3 for pareto optimal
* Tried to do some runs but couldn’t uninstall GPFramework (during the reinstall.sh script call) which I needed to do so my new changes were used. Blinking cursor stuck after “y” prompt
** Update: fixed this issue, but sometimes re-occurs
* Pushed up changes where NSGA3 is called in Emade.py code
** [https://github.gatech.edu/emade/emade/commit/085d297c4abe02689bfcae198e071b4dd0f265bb Code Link]
* Getting File "/storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/lib/python3.6/site-packages/deap/tools/e$    distances = numpy.sum(fn * reference_points, axis=2) / norm.reshape(1, -1) ValueError: operands could not be broadcast together with shapes (45,560,2) (560,14)
** Basically the fn variable seems to be a 3-dimensional matrix for some reason while the ref_points is (correctly) 2-dimensional. 560 comes from the nsga3 formula. In addition, I can't just cast the fn variable as it is part of the actual deap code rather than my code (I don't think it's a good idea to edit import'd code).
** I have no idea why the fn variable becomes 3-dimensional. It is created inside the emo.py (deap file) using the best_point and reference_points parameter. Best_points is default set to numpy.min(...) as I do not pass one in.
* Still can’t set up a new environment because package not found errors when using yaml script. Also can’t test NSGA3 with Titanic data because of the above error


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Try to test NSGA3 again
|Complete
|Nov 8, 2021
|Nov 15, 2021
|Nov 20, 2021
|-
|Update Wiki Notebook
|Complete
|Nov 8, 2021
|Nov 15, 2021
|Nov 22, 2021
|-
|}

==Nov 1st, 2021==
===Meeting Notes===
* Consideration: reprocess data to just have single label for train/test (if there are not too too many multi-label cases), look at distribution of labels to ensure this will produce enough data
* To get vector out: dump out the numpy array inside the evaluation method, reinstall GPFramework, and then run individual with database or standalone tree evaluator script
* Lexicase on test cases
* Food for thought: what about where in the image a disease is present, not just whether it exists or not (room for future work here! A bounding box for object detection!)

===Subteam Notes===
* The p-value was very high which was causing the selection methods to fail. 
* Next steps:
** Fix environment errors
** Testing the new changes for nsga 3
** New member and Harris will try out Lexicase
** Test the current version and talk to Jason more about exactly what the difficulties are
* Errors with the load environment problems on the standalone tree evaluator and trying to debug the new problem once PACE is back online
* Trying out implementing a new hyper feature:
** Sharpening features in addition to the edge detectors
* Need to create new dataset
* (Will add in the discussion for mating mutations)
* Max has been working on fixing bugs for the baseline run that we worked on
* Someone new can definitely work on squashing bugs for the emade runs (since the data types don’t match)
* New team assignments:
** Rohan - hyper features
** Elan - infrastructure, doing runs on pace
** Austin - selection methods
** Eashan - mating, mutations

''' Work Notes '''

''' Code pushes '''
* Need to try NSGA3 again with updated p value
* Pushed up a yaml script to create our anaconda environment on win-64
** [https://github.gatech.edu/amehra37/emade/commit/fc461e35c63224b981673a01816bda8a98e64058 Code Link]
* Removed the output file redirect so that pace uses the default output file for the master process
** [https://github.gatech.edu/amehra37/emade/commit/2c96ca6be67ca6ae4441de1ad5a7084fd7d299c3 Code Link]

''' Run attempts '''
* PACE was under maintenance for a few days
* Tried to get NSGA3 running on Pace again with new environment changes and p-value changes
* Kept running into error after error (e.g. stop_words being renamed to _stop_words, some tabs where there should have been spaces, odd multiplication errors, etc.)
* Started resolving them one-by-one, but got very tired (was very sick this past week) and could not find the end of this pile of runtime errors (a new one emerged when solve the previous)
* We need to update our environment’s Tensorflow and Python version, along with ALL the dependencies if not compatible with the new tensorflow

* Finally able to do a run but got weird occurence, worker job would be stuck at queued. Probably PACE issue

''' NSGA3 Paper '''
* Loosely, many-obj means 4 or more objectives due to visualization purposes
** NSGA3 is good for 4 to 15 objectives
* Random chosen set of objective vectors become exponentially large as number of objectives increase → higher computing power required
* Difficulties in many-obj problems
** Large fraction of pop is non-dominated → slows down process because most EMO emphasize non-dominated solutions
** Identification of crowding in solutions becomes computationally expensive in larger objective spaces
** Recombination operation may be inefficient → special recomb op needed, else distant parent solutions produce offspring that’re distant from parents
** Performance metrics also become computationally expensive
* NSGA-3 maintains diversity through well-spread reference points
* H = (M + p - 1) choose p
** H number of reference points
** M number of objectives
** p divisions along each objective
** Usually, we roughly want H = pop. size
* Doesn’t require additional parameters to be set unlike MOEA/D

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Try doing NSGA3 run (after pace maintenance)
|Complete
|Nov 1, 2021
|Nov 8, 2021
|Nov 6, 2021
|-
|Read NSGA3 paper
|Complete
|Nov 1, 2021
|Nov 8, 2021
|Nov 7, 2021
|-
|Update Wiki Notebook
|Complete
|Nov 1, 2021
|Nov 8, 2021
|Nov 8, 2021
|-
|}

==Oct 25th, 2021==
===Meeting Notes===
Mid-sem presentations

''' NLP: '''
* Trying to simulate the Bi-DAF model by first creating a word embedding and obtaining an output based on the context of the word
* Using the SQUAD dataset from Stanford with 100,000 answered and 50,000 unanswered questions.
* Trying to get close to the SOTA which is an F1 of 93.214
* They are also trying to get new evaluation metrics. For example, F1(new type), EM, MAP and MRR
* Haven’t completed all the primitives yet such as the output layer which is why they do not have any results yet.
* They are planning on using Facebook’s dataset. Dynamic/Episodic memory is the best as of now. 

''' NAS: '''
* Hard for emade to outpace the seeded runs
* Long training times due to nesting
* Overall goal is to make EMADE competitive with VGG16 and other large structure architectures
* Objectives: minimize accuracy errors and number of parameters
* Used time stopping of 600 vs 2500 seconds, latter ended in 1500 but generated less valid individuals and slightly better accuracy error (-0.05)
* Higher number of layers → higher num of error individuals (though 2-5 was less than baseline)
* Used only dense layers and convoluted layers
* Tracking layer frequencies across generations
* Created NNLearner table to track NNLearner individuals’ statistics

''' Stocks: '''
* Objectives: use EMADE for regression on time series data and optimize market trading algorithm ; beat SOTA using EMADE
* They are trying to model papers and use technical indicators to predict price change points
* What are the best primitives to use: modelled TI’s versus the different regression techniques that are implemented
* Maximize profit percentage and average profit per transaction, minimize CDF of profit and variance of profit per transaction (four obj functions total)
* Best performance was with the least complex tree (only one TI)
* They are using minimization rather than maximization functions since they work better on EMADE.
* Having struggles with replicating the paper, primarily the fuzzy logic
* Hope to end the semester with a research paper

''' Modularity: '''
* ARL: adaptive representation through learning
* ARL’s are implemented between the genetic operations and the evaluation phase
* Must be a complete tree
* It basically abstracts away complexity
* ARL’s should allow the population to converge faster
* Goal: allow search function to consider larger subtrees depth. Improve ARL candidate selection through a new weighting function (occurrences * ARL size / fitness of individual)
* Runs with both the old ARL’s and newer ARL’S are worse than with no ARL’s
* More data is needed to see effects of ARL complexity on performance
* Size != usefulness
* Using ARLs with Stocks
* Used various technical indicators
* Problems with Google Colab’s limited computing power and merging stocks’ codebase into the ARL codebase
* Individuals not evaluating because of cachev2 updates
* Study if selection during runs is biased
* Look into ARL construction (changes to hyperparameters, amount, etc.)
* More TI from stocks subteam

''' Image Processing (our team) '''
* Presentation is linked in previous week's notebook entry

===Subteam Notes===
* CheXNet data was looking for just pneumonia (1 for pneumonia, 0 for everything else)
** Binary → {1, 0}
* We can continue pursuing this, or change our dataset labels (to do multilabel classification)
** Multilabel → { [1, 2,...], [3, 6, …] … }
* Challenge in how EMADE looks at labels for each images
* Decided to pursue binary classification for disease detection
* Temi: refactor semantic crossover and mutation to receive expected data type
* Monil: Build a tree, open a pull request 
* Heidi: reprocess data
* Aryaan: literature search geometric crossover and mutation
* Dhruv: test NSGA3 locally and see if you can find errors. Otherwise, revert changes (aside from toolbox register), test to make sure it works with reverted changes, and push changes + create pull request.
* Harris: PACE-ICE run, lexicase
* Max: bug squashing tree errors

''' Work Notes '''
* Test normal code works (so it’s not a Pace issue)
** Not working, master process still kills itself
** Could be a Pace issue or an issue with my account on Pace
** Contacting Dr.Zutty to try and troubleshoot 1 on 1
** Terminates between lines 1093 and 1103 (1093 prints, 1103 doesn’t)
** adjustForDataset method doesn't exist in the base.py file of DEAP (file where class Toolbox is defined. I'm using the pace conda environment so it's not a deap-version issue
** Line 300 registers it, line 1859 defines it

* Trying it out with the main Image-Proc(nn-vip) branch rather than my selectionImageProc offset
** If it works, then that means it’s my branch issue. Otherwise it is a pace issue
** Result: master still dies a few minutes in
** This is a Pace problem / my account on Pace problem

* Get Anaconda environ YAML script file working for Windows
** Found a lot of channel issues and resolved them (use anaconda, conda-forge, prometeia, and defaults rather than just defaults)
** Anaconda 4.4 has a bug which interferes with certain package installations
** Currently using 4.4 because it is (I think) the latest Anaconda that uses Python 3.6

* Test registering NSGA3 works (but call NSGA2 in the code) → then push code up
* Test actual NSGA3 works (again), may need to carefully check code to see where error could be occurring due to lack of error logs

* gene_pool = _inst.toolbox.selectNSGA3(gene_pool, len(gene_pool))
* The GPFramework in the environment has this line instead of selectNSGA2 (using my nsga3 method in selection_methods.py) -- needs permissions to call ./reinstall.sh
* p might be too big in the reference points generator → overage on memory usage
** Should use (m + p - 1) choose p = pop. size
** Try with p = 3


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Troubleshoot EMADE run
|Complete
|Oct 25, 2021
|Nov 1, 2021
|Oct 31, 2021
|-
|Update Wiki Notebook
|Complete
|Oct 25, 2021
|Nov 1, 2021
|Nov 1, 2021
|-
|}

==Oct 18th, 2021==
===Meeting Notes===
* Presentation is NEXT WEEK!
* When doing your runs:
** 1 master - 1 core is constant
** CPU hours should add up to how much time is left in the class
** Number of hosts means how many worker jobs
** Number of CPU per worker is core count per worker
* Design an experiment to test your changes/parameters
* With all these different parameter tweaks, give thought to how will we show that we made improvement
** Pair things together?
** Do one parameter change at a time?
* We should each run EMADE in our pairs, individual changes
* Use those to compare against the baseline

===Subteam Notes===
* Max tested PACE and it works, though primitives are erroring out for the nn tree
* nsga2 is hard-coded
** Need to register nsga3 into toolbox
** Call it in the code
** Why’s it not pulling from the XML
* We have four changes from the baseline, test all of them SEPARATELY
** Geo. Crossover
** Semantic Crossover
** Hyper Features
** NSGA-3 selection
** Compare which of these four had the best changes
* Objectives are: area under PR curve, and number of parameters

'''Work Notes'''
* Checking status
** Qstat command
** -n lists node the job is on
** -u <user> specifies the user’s jobs
** qstat -q pace-ice-gpu to check GPU usage
** qsub pbsmysql.pbs
* PACE-ICE config
** MySQL has 8hr walltime
** EMADE use 7:40hr walltime
** # hosts is 1, # workers per host is 1
** RAM per host/master is 8GB
** Anaconda Environment /storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/
* PACE-ICE Anaconda environment
** First log in
** Module load anaconda3 /2020.02
** Loads anaconda environment in your pace
** conda activate /storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/
** Once you’re in the environment, you can run reinstall script. When editing src folder, need to run reinstall script.
* Launch scripts (courtesy of Maxim)
** MySQL launch script: Pace files/pbsmysql.pbs
** To start mySQL, cd into /usr/ and then mysqld_safe --datadir='/storage/home/hpaceice1/USERNAME/scratch/db’
** EMADE one is Pace files/launchEMADEchest.pbs
** First time you run, you need to seed the run (see the launchEMADEchest script)

'''Problems'''
* Some minor SQL problems solved
* Changed relative paths in XML to absolute paths
* EMADE_master terminating after few minutes but worker keeps going
** No individuals for worker to evaluate because waiting for master
** Aryaan getting same issue
** Error logs are bare, doesn't tell why job is killed

'''Mid-semester Presentation'''
* [https://docs.google.com/presentation/d/100keUAjam-8e1-SMLtejP9ZQN38nmCJ_yA1t2HW-JPs/edit?usp=sharing Presentation Link]


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Run comparison trials
|Complete
|Oct 18, 2021
|Oct 25, 2021
|Oct 23, 2021
|-
|Create mid-sem presentation
|Complete
|Oct 18, 2021
|Oct 25, 2021
|Oct 24, 2021
|-
|Update Wiki Notebook
|Complete
|Oct 18, 2021
|Oct 25, 2021
|Oct 25, 2021
|-
|}

==Oct 11th, 2021==
===Meeting Notes===
* Fall Break -- no vip general meeting

===Subteam Notes===
* Start making presentation early next week 10/19
* Reminder: mid-sem presentation is on 10/25
* Do comparison run after merging our changes in
* Be prepared to talk about what we worked on individually/in your pairings (will need to put it on the slides)
* Before Monday goals: verify changes don't screw up the code, commit changes, create PR, review others' PR, merge changes

''' Work Notes '''
* Due to fall break, this was slow week
* Peer reviewed others' code
* Merged in my changes

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Tie loose ends
|Complete
|Oct 11, 2021
|Oct 18, 2021
|Oct 17, 2021
|-
|Update Wiki Notebook
|Complete
|Oct 11, 2021
|Oct 18, 2021
|Oct 18, 2021
|-
|}

==Oct 4th, 2021==
===Meeting Notes===
* Peer evals are open! Due this Friday 10/8
* We are trying to minimize area under curve for precision recall
** Reason: we have multi-label data, traditional accuracy metrics do not work.
* Focus now: what we added is working correctly and generate comparison data (baseline data almost done)
* Anything put in the shared folder counts against personal quota (based on file ownership), Zutty can change it to his account and make it read-only
** We will test if we can do this with a conda environment
** Possibly database as well!
* Max needs to commit his changes to codebase to our fork of the repo. It will allow anyone to run on pace-ice-gpu
* Our datasets in PACE are stored in:
** /storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/datasets/chest_xrays/

===Subteam Notes===
* 224x224 size images
* Maxim gonna send his PACE setup so we can run EMADE on our pace-ice
* Aiming for end of fall break, getting runs working
* Monil working on testing some hyper features in EMADE, works locally
** Don’t need to launch emade run to test it, can use stand-alone tree evaluator
** There are template trees to help you
** Can use directly with your primitive, assigns fitness scores to tree
* Dhruv/Harris are going to test NSGA3 (don’t need image dataset)
* Will need actual EMADE run before mid-sem presentation to check improvement from baseline or not
* Aryaan/Temi looking at mating and crossover methods
* '''Goals before mid-sem presentation:''' Need baseline run and comparison runs
** Can show improvement OR deterioration
** What works, what doesn’t. What to try next.
** Most of us can make comparison runs

'''Work Notes'''
* Just use Titanic or another template dataset to test if the method works
* Inside the template file, we use <selection> to specify the selection method
** Nested inside <selections> (list of <selection>)
*** Nested in <evolutionParameters> (where we also specify <mutations>, <matings>, etc.)

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Ensure NSGA3 works in run
|Complete
|Oct 4, 2021
|Oct 11, 2021
|Oct 11, 2021
|-
|Update Wiki Notebook
|Complete
|Oct 4, 2021
|Oct 11, 2021
|Oct 13, 2021
|-
|}

==Sept 27th, 2021==
===Meeting Notes===
* No important general meeting notes
* Everyone make sure you are collaborator on Aryaan’s fork of emade and that you can push up changes
* Branch off of the Image-Processing(nn-vip) branch of Aryaan’s emade fork when doing work
* Check if PACE ICE is working for y’all
* Dhruv and Harris work on testing NSGA3

===Subteam Notes===
* Temi is implementing geometric-semantic selection method, aiming to have it down by Monday
* Harris and Dhruv will test the NSGA3 implementation they made (after baseline)
** Tweak p parameter and possibly test different reference points
* Talk to Max for PACE issues
* Monil was finding ideas for hyper-features to implement, will find more for the next meeting Monday
* Aryaan was gonna work on crossover/mutation stuff with Temi
* Problem with seeded runs for NN learners

'''Work Notes'''
* Created branch for selection methods related changes
** [https://github.gatech.edu/amehra37/emade/tree/selectionImageProc selectionImageProc branch]
** selectionImageProc branch was made off the Image-Processing(nn-vip) branch
* Need to change a couple other files before we can test NSGA3
** [https://github.gatech.edu/emade/emade/blob/30535a480b4ba633d6808721250fc8bff0a615e2/src/GPFramework/didLaunch.py didLaunch file]
** Call selection methods here (add them to the emade run) after implementing them

* Update: Baseline was run on Monday 10/4, will be able to start comparing runs

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Set up sel methods for testing
|Complete
|Sept 27, 2021
|Oct 4, 2021
|Oct 3, 2021
|-
|Fix your PACE-ICE issues
|Complete
|Sept 27, 2021
|Oct 4, 2021
|Oct 3, 2021
|-
|Update Wiki Notebook
|Complete
|Sept 27, 2021
|Oct 4, 2021
|Oct 4, 2021
|-
|}

==Sept 20th, 2021==
===Meeting Notes===
* Zutty says (if we want a direct comparison to another study) you cannot change the test data, however you can change training data however you want
* Essentially want to say one can outperform another algorithm on the same test

===Subteam Notes===
* We should create our own branch off Image-Processing(nn-vip) to start doing our own work.
* Tasks for me: Dhruv and Harris begin implementing a selection method. We (should) have a baseline now thanks to Aryaan

'''NSGA3 Implementation'''
* Attempting to implement NSGA3 by next Monday
* [https://github.com/DEAP/deap/blob/d328fe6b68e7528b2d2d990bb2ab1ad1786e6f58/deap/tools/emo.py Deap's NSGA3]
* Edit selection_methods.py file
* To push changes, will need to fork emade and upload changes to that because we can't push to or edit branches
* tools.uniform_reference_points(nobj=14, p=?)
** Using this to generate reference points if not passed in as parameter in our sel_nsga3()
** Not too sure what p is, scales linearly with depth. Might needa play around with it. Setting to 14 initially.

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Implement NSGA3 into code
|Complete
|Sept 20, 2021
|Sept 27, 2021
|Sept 26, 2021
|-
|Update Wiki Notebook
|Complete
|Sept 20, 2021
|Sept 27, 2021
|Sept 27, 2021
|-
|}

==Sept 13th, 2021==
===Meeting Notes===
* Self-evals due today 9/13
* We have pace ice access, use shared folder
** /storage/home/hpaceice1/shared-classes/materials/vip/AAD
* Image processing uses a lot of OpenCV and needs a lot of data coercion to get into the right format 
* Being careful with primitives and casting to correct form
** So many image processing primitives, how do we help search do the right thing?
** E.g. a lot of primitives serve similar purposes like window functions, determine “same flavor”
*Need to decide to do classification or detection (Dr.Zutty says EMADE would work better with classification)

===Subteam Notes===
* Team will focus on using EMADE over cheXNet for X-ray image lung disease detection
* [https://paperswithcode.com/paper/chexnet-radiologist-level-pneumonia-detection CheXNet paper]
* Notes from Jason's feedback:
** Changing the selection methods for many objectives
** NSGA 3 for example or lexicase, hypervolume Indicator - can use one for the parent and one for the child and see what works best
** Good crossovers and mutations
** There is nothing that compares primitives to each other (for making the search better)
** Can we make a primitive that combines/compares existing ones i.e. put them together like an ADF
** Down-sample the data with fewer rows and images.
** Make the images gray-scale or make them smaller
** Take it down to 64 by 64 and cut the data in half
** Need objectives that are uncorrelated
** Demonstrate an improvement in EMADE
** Come up with something novel
** Compare with LEAF AutoML

'''What Success Is'''
* Demontrate improvement in EMADE
* Novel algo
* Outperform LEAF

'''Starting tasks'''
* Data preparation
** Downsample (greyscale, lower resolution, balancing)
** Talk to Anish
* Try it out with EMADE as is
* Selection methods
** NSGA3, Lexicase, etc.
** Hypervolume indicator
* Hyper-feature packaging
* Clever mating and mutation
** Improve existing primitives
** Semantic crossover

'''Selection Methods Research'''
* General
** [https://www.researchgate.net/publication/272985206_Review_of_Feature_Selection_Methods_in_Medical_Image_Processing Paper] on selection for medical image processing
** Might want to explore hybridizing selection methods later this semester

* NSGA3
** NSGA2 is already implemented but not NSGA3
** https://deap.readthedocs.io/en/master/examples/nsga3.html
** Implemented in DEAP and in PyMoo (references)
** Better than NSGA2 because we have multiple objectives
** Didn’t find much/anything about NSGA3 and image processing

* Lexicase
** Sel_Lexicase is already implemented (not sure if they’re the same)
** Random training case → eliminate individuals with errors but can accidentally choose bad cases because can stop early and auto-use remaining ones
** Might not be worth using because it could choose worse algorithms as the parents for the next generation (unless we implement it in a way that the best algorithm from ALL parents AND children are chosen to be the next parents -- but children are optimally always better than parents)

* Hypervolume indicator
** Gives score to measure quality of an algorithm/individual
** Whether it’s feasible or not will depend on how many objectives we have
** Definitely useful in selecting the algorithms closest to optimal, relative to the other algorithms
** Didn’t find any image processing papers using hypervolume indicator, but I think we should try it out

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Research Selection methods
|Complete
|Sept 13, 2021
|Sept 20, 2021
|Sept 19, 2021
|-
|Update Wiki Notebook
|Complete
|Sept 13, 2021
|Sept 20, 2021
|Sept 20, 2021
|-
|}

==Sept 6th, 2021==
===Meeting Notes===
* No meeting due to Labor Day

===Subteam Notes===
* Maxim is team leader
* Re-familiarize yourself with EMADE
* Read previous team's paper
* Possibly add primitives to EMADE
* Everyone find image processing paper
* Incl. potential data sets

Notes on previous team's paper:
* Neural architecture search using EMADE
* Automates determining best layer combo and optimal hyper-parameters
* Search space, search strategy, and candidate network performance estimation strategy
* Manipulating input data, current systems lack data pre-processing in search space
* Uses CIFAR-10’s image database for benchmarking
* EMADE extensions: LayerTree, Layer Primitives, Pre-trained layer primitives, and Neural Network Learner
* Hovering at 73-74% accuracy

'''Exploratory research paper''' for ideas:
* [https://doi.org/10.1016/j.irbm.2013.01.010]
* Diabetic retinopathy screening (diabetes eye condition). “combines pathological pattern mining methods, with specific lesion detection methods, to extract information from the images”.
* Computes abnormality risk
* Both datasets: [https://www.adcis.net/en/third-party/e-ophtha/]
** Fill out form for access, def allowed for research/educational purposes

Notebook [https://docs.google.com/document/d/1fPIo8kQ-2McLnTW_2NwNI80QNv_KwnIb/edit?usp=sharing&ouid=111956644347073534620&rtpof=true&sd=true Self-Eval]


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Re-familiarize yourself with EMADE
|Complete
|Sept 6th, 2021
|Sept 13th, 2021
|Sept 12th, 2021
|-
|Read prev sem's research paper
|Complete
|Sept 6th, 2021
|Sept 13th, 2021
|Sept 11th, 2021
|-
|Find interesting ip papers
|Complete
|Sept 6th, 2021
|Sept 13th, 2021
|Sept 12th, 2021
|-
|Do self-eval
|Complete
|Sept 6th, 2021
|Sept 13th, 2021
|Sept 13th, 2021
|-
|Update Wiki Notebook
|Complete
|Sept 6th, 2021
|Sept 13th, 2021
|Sept 12th, 2021
|-
|}

==Aug 30th, 2021==
===Meeting Notes===
* Deciding on subteams based on rankings

===Subteam Notes===
* Joined Image Processing subteam for this semester

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Join Subteam Slack
|Complete
|Aug 30th, 2021
|Sept 6th, 2021
|Sept 1st, 2021
|-
|Update Wiki Notebook
|Complete
|Aug 30th, 2021
|Sept 6th, 2021
|Sept 4th, 2021
|-
|}

==Aug 23rd, 2021==
===Meeting Notes===
* Brainstormed new teams

===Subteam Notes===
* N/A

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Create subteam ranking list
|Complete
|Aug 23rd, 2021
|Aug 30th, 2021
|Aug 30th, 2021
|-
|Update Wiki Notebook
|Complete
|Aug 23rd, 2021
|Aug 30th, 2021
|Aug 30th, 2021
|-
|}

=Spring 2021=
'''General Info'''
* New Students meet Wednesdays 5:00-5:50pm
* March 22nd 5-8pm presentation meeting
* Then, meet Mondays 5:00-5:50pm

==Apr 26th, 2021==
===Meeting Notes===
*Notebooks are due Saturday at 11:59 (easiest to just have it done by Friday midnight)
*If it’s not documented, you didn’t do it. Have everything in your notebook

===Subteam Notes===
*Discussed final presentation
*What slides to include / not to include
*What to talk about/cover in the presentation
*Few ideas/plans for next semester

'''Link:''' Final [https://docs.google.com/presentation/d/1Ve_3G6xkq_y0QRFFXv0Mv7hAi-348cVPt48Zessnv_s/edit?usp=sharing Presentation]


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Finish Final Presentation
|Complete
|Apr 26th, 2021
|Apr 30th, 2021
|Apr 29th, 2021
|-
|Update Wiki Notebook
|Complete
|Apr 26th, 2021
|Apr 30th, 2021
|Apr 29th, 2021
|-
|}

==Apr 19th, 2021==
===Meeting Notes===
*Final presentations 4/30 6-8:50pm
*Notebooks will be due on that day at 6pm (however technically due Saturday)
*Peer Evals due 4/28

===Subteam Notes===
*Doing EMADE run today
*Using four indicators total
**Stochastic RSI - good for choppier and neutral trends
**Aroon - focuses on time relative to price. Good for spotting emerging trends and smaller reversals
**VWAP - volume indicator that takes into account price and volume. Good for entry and exit points of day trading
**VWMA - combines price moving averages with volume to determine trend strength. Fixed time period → cuts off data
*Increasing the window size to 40 or 50 for this run
*'''Thursday Meeting'''
*MyBollingerBand worked kinda well as result of our run (round 12000 total individuals)
*The individual: Learner(MyBollingerBand(ARG0, 2, 61, falseBool), LearnerType('DECISIONTREE_REGRESSION', None), EnsembleType('SINGLE', None))
*Fibonacci Replacement code was tested, may use in the next run
*We should learn to add primitives in our Stocks EMADE, so can implement technical indicators
*Might change crossover and mutation percentages for runs, depending on how much they’d affect them
*Might split into two test groups just so we can cover more options before the presentation
*ETF might be useful but it will generally be bullish depending on industry
*Avoid recession and corona time frames (use 2010-2019)
*Remove profit percentage and replace with cdf for next run
*Possibly remove variance of profit per transaction but keep average profit per transaction because we’re more interested in the end-goal of maximizing money made rather than find a way to consistently make some amount of money


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Conduct EMADE run
|Complete
|Apr 19th, 2021
|Apr 26th, 2021
|Apr 19th, 2021
|-
|Start creating Final Pres
|Complete
|Apr 19th, 2021
|Apr 26th, 2021
|Apr 25th, 2021
|-
|Update Wiki Notebook
|Complete
|Apr 19th, 2021
|Apr 26th, 2021
|Apr 25th, 2021
|-
|}

==Apr 12th, 2021==
===Meeting Notes===
*Show invariance between different stocks
*How tied to the data are your solutions
*Explore how seeding affects the output

===Subteam Notes===
*I will do the Data Analysis of EMADE runs and individuals sub-subteam
*Planning on doing another run on Thursday
*Which new stocks to use or keep current and add more features
*Focus on making a model that works with many/ideally all stocks rather than individualizing predictions for certain stocks
*Need to find technical indicators that have less lag (less time between actual min/max and the predicted buy/sell points)
*Expand data range for the stocks we have (currently ~1 year, expand to 2-3 years)
*Come up with more metrics to compare individuals
*Something kinda opposite of profit percentage (minimize to 0 rather than maximize to infinity)
*Loss percentage? If some individuals make a net loss then minimize that
*'''Thursday meeting'''
*No need to have separate EMADE for individual stocks, since they generally perform the same with the same algorithm
*[https://en.wikipedia.org/wiki/Ichimoku_Kink%C5%8D_Hy%C5%8D Ichimoku Kink]
**Builds on candlestick charting to improve the accuracy of forecast price moves
*[https://en.wikipedia.org/wiki/Fibonacci_retracement Fibonacci Retracement]
**Method of technical analysis for determining support and resistance levels
**Markets will retrace a predictable portion of a move, after which they will continue to move in the original direction
*Some members will try out Fibonacci
*Fix any EMADE issues and explore visualization tool


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Fix EMADE issues and work on vis tool
|Complete
|Apr 12th, 2021
|Apr 19th, 2021
|Apr 18th, 2021
|-
|Update Wiki Notebook
|Complete
|Apr 12th, 2021
|Apr 19th, 2021
|Apr 18th, 2021
|-
|}

==Apr 5th, 2021==
===Meeting Notes===
*Why and how algorithms work is useful for implementing technical indicators for stocks

'''Statistics for EMADE'''
*We collect data on lot of metrics: obj scores, processing times, AoC, HoF #, etc.
*We can do A/B testing (make a baseline run, change something, and run again)
*Mean (first moment aka expected value)
**μ = E[x]
*Variance is deviation from the mean of values
**σ^2 = E[x^2] - E[x]^2
**Standard Deviation is square root of variance
*Hypothesis testing: If I gave you a mean and std dev that represents distribution of EMADE values
*Compute probability of observing a sample at least as extreme as ours given assumption of the underlying truth P(sample | hypothesis is true) → p-value
**Threshold α sets a confidence/significance value, it is probability of a false negative (Type I error)
**Probability of false positive is β (Type II error)
*Student’s T-test
**T-test is good way to test our observed values (due to unknown std dev)
**One-tailed and two-tailed test (is one mean greater/less than another vs is mean in between two values)
**Use n-1 degrees of freedom
**t-table is used to look up t values (can/should use calculator to be more precise)
*p-value found from t-test is basically chance that our observations are false
**If less than (usual) threshold of 0.05, we accept our observations as good/plausible
*Welch’s t-test (aka unequal variance t-test)
**Test the hypothesis that two populations have equal means
**Probability that both our samples came from the same place
**Used to find whether the chances we made actually made a change in the results of our trials/EMADE runs
**Useful for us because we are interested in comparing individuals and determining who is superior
*The greater the t-statistic, more unlikely the chance of observing the sample given the hypothesis

===Subteam Notes===
*We could possibly apply these statistics to our stocks’ performance
*Profit percentage as random variable
*Our 5 stocks may not form a normal distribution though
*Have EMADE set up for another run before Thursday
*Thursday meeting:
*Break into three “sub-subteams”, not strict but just general goals/guides for everyone
**Literature Review and Research (reading about TIs and figuring out which to use, reading other research papers for ideas)
**Data Analysis of EMADE runs and individuals
**Implementation in EMADE
*Got connected to the database
**emade/templates/input_stocks.xml in stocks-base branch has connection info
*Created worker ipynb notebook file
*Started run with Google Collab


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Execute EMADE run with everyone
|Complete
|Apr 5th, 2021
|Apr 12th, 2021
|Apr 8th, 2021
|-
|Update Wiki Notebook
|Complete
|Apr 5th, 2021
|Apr 12th, 2021
|Apr 12th, 2021
|-
|}

==Mar 29th, 2021==
===Meeting Notes===
*Teams assigned
*Note new meeting times
*VIP '''Stocks''' team meets:
**Monday after main meeting and goes till 6:30pm
**Thursday at 5:30-6:30pm

===Subteam Notes===
*1st years will make technical indicator primitives using EMADE
**Technical Indicators are what analysts use to predict stock price (like moving averages, momentum, etc.)
**If we know the best indicator, we can predict the stock price
**Best to do on a per-stock basis since different stocks may have different best indicators of price trends
**[https://www.investors.com/etfs-and-funds/etfs/best-technical-indicators-for-etf-investors/ TIs like these]
*EMADE handles preprocessing, finding/manipulating features, and tweaking which machine learning models to use
*ARG0 is the EMADE data pair
*EmadeDataPair class:
**Train, Test, and Target data
**Train data and Test data are EmadeData classes
*EmadeData class:
**Stream Data and Feature data
**Stream is useful for time-series and image reps (not used to train)
**Feature data is what’s used as input to ML
*Stocks code
**Stream data holds raw price, volume, etc.
**Each line in data represents window of past 20 days with 6 consecutive data (Day, Close Price, Volume, Day High, Day Low, Open Price) repeat
**Write functions to calculate technical indicators
**Primitive functions (like MySMA) runs for every line in dataset, making new feature
*Primitive functions can be stacked on top of each other and compute set of features to train with regression model
*Example
[[files/Stocks_example_individual_Dhruv_Patel.PNG]]

Paper: [https://www.sciencedirect.com/science/article/pii/S1568494611000937 Link] to research paper


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Read stock trading detection paper
|Complete
|Mar 29th, 2021
|Apr 1st, 2021
|Apr 1st, 2021
|-
|Update Wiki Notebook
|Complete
|Mar 29th, 2021
|Apr 5th, 2021
|Apr 3rd, 2021
|-
|}

==Mar 22nd, 2021==
*Bootcamp presentations!
*Click [https://vip.gatech.edu/wiki/index.php/Group_5 Here] to see our team wiki
*[[files/Titanic_EMADE_Team_5.pptx|Titanic EMADE Presentation]]

===Titanic EMADE===
'''Results Summary'''
*See presentation for full algorithm used with EMADE
*Minor note: SQL server was not used through GT VPN, rather we port-forwarded on a teammate's home network
*Ran for ~4 hours with total of 37 generations
*AUC was 0.2374 and HOF count was 22
**Could bring HOF count higher if we run for longer time. AUC can be lowered through tweaking the algorithm


[[files/EMADE_vs_GP_vs_ML_Curves_Group_5.PNG|none|thumb|EMADE is Green, ML is Blue, GP is Red]]

AUC EMADE: 0.2374 

AUC ML: 0.2379 

AUC GP: 0.1305 

EMADE HOF 22 

ML HOF 5 

GP HOF 45


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Update Wiki Notebook
|Complete
|Mar 22nd, 2021
|Mar 29th, 2021
|Mar 23rd, 2021
|-
|}

==Mar 17th, 2021==
*No lecture notes

===Subteam Notes===
*Team sync
*Finished setting up remote SQL
*Continue working on EMADE Titanic


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Finish work on Titantic using EMADE
|Complete
|Mar 17th, 2021
|Mar 22nd, 2021
|Mar 21st, 2021
|-
|Finish final team presentation
|Complete
|Mar 17th, 2021
|Mar 22nd, 2021
|Mar 22nd, 2021
|-
|Update Wiki Notebook
|Complete
|Mar 17th, 2021
|Mar 22nd, 2021
|Mar 22nd, 2021
|-
|}

==Mar 10th, 2021==
*No lecture notes

===Subteam Notes===
*Continue working on assignment


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Continue working on Titantic using EMADE
|Complete
|Mar 10th, 2021
|Mar 17th, 2021
|Mar 17th, 2021
|-
|Update Wiki Notebook
|Complete
|Mar 10th, 2021
|Mar 17th, 2021
|Mar 17th, 2021
|-
|}

==Mar 3rd, 2021==
===Lecture Notes===
*Evolutionary Multi-objective Algorithm Design Engine
**Automate process of designing ML algorithms
*We will try to run our Titanic data and see the best algorithm EMADE decides
*Running EMADE: python src/GPFramework/launchGTMOEP.py templates/input_file.xml
**Second parameter is the Input File
**There is example input file we can try out (input_titanic.xml)
*Input File - XML document that configures all moving parts in EMADE
**First block is for configuring Python
***Point to where we installed EMADE and its dependencies
***Point to where python is installed
**Next block configures the MySQL connection
***If running locally, server can be localhost or 127.0.0.1
***Username/Password are for MySQL
***Database is the database’s name
***Grant users remote access to database
**Datasets block is next, EMADE can run across multiple datasets
***Data is preprocessed into gz csv files
***Each trial is another cross-fold
**Objectives section describes our goals
***Names will be used as database’s columns
***Weight specifies minimizing (-1.0) or maximizing (1.0)
***<evaluationFunction> specifies name of method inside evalFunction.py
***Achievable and goal are used for steering the optimization, lower and upper are for bounding
**Some more parameters
***<workersPerHost> specifies how many evaluations to run in parallel (keep it to 2-3 on a standard laptop, can increase for a desktop)
***Evaluation specify how much memory each worker is allowed (cause our computers aren’t infinite) and where eval functions live
**Evolution parameters
***Control various “magic constants” aka hyperparameters that affect evolutionary process
*Data to run through EMADE: Each row corresponds to an instance (e.g. a passenger in Titanic example), each column is feature, final column is truth data
*Connecting worker process to peer
**Use -w flag to run as a worker not a master


===Subteam Notes===
*Zhao will host the Database
*Everyone get EMADE running and attempt configuration


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Work on Titantic using EMADE
|Complete
|Mar 3rd, 2021
|Mar 10th, 2021
|Mar 8th, 2021
|-
|Set up MySQL and team's single database
|Complete
|Mar 3rd, 2021
|Mar 10th, 2021
|Mar 10th, 2021
|-
|Update Wiki Notebook
|Complete
|Mar 3rd, 2021
|Mar 10th, 2021
|Mar 8th, 2021
|-
|}

==Feb 24th, 2021==
===Lecture Notes===
*Group presentations of Titanic using GP
*Group 5 did not have a chance to go, will be presenting March 3rd

'''Team Results and Presentation'''

Click [[Group 5]] to go to our team page

The presentation can be found [[files/Titanic GP Team 5.pptx|here]]


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Complete peer evals
|Complete
|Mar 1st, 2021
|Mar 5th, 2021
|Mar 2nd, 2021
|-
|Install EMADE
|Complete
|Feb 24th, 2021
|Mar 3rd, 2021
|Feb 28th, 2021
|-
|Update Wiki for Notebook check
|Complete
|Feb 24th, 2021
|Mar 3rd, 2021
|Feb 28th, 2021
|-
|}

==Feb 17th, 2021==
===Lecture Notes===
*Talked about the Titanic problem
*What’s useful and what’s not
*What algorithms/strategies worked best
*Create multi-objective evolutionary algorithm on same Titanic data
*Use genetic programming, but not allowed to use pre-made evolutionary algorithms
**Have to design our own evolutionary algorithm
**Can mess around with different populations, generations, tournament sizes, etc.
*6 minute team presentation on:
**How we processed the data
**What ML algos and considerations we made/why
**How we designed the evolutionary algorithm and what considerations we made/why
**Comparison of results from MOGP and the standard ML
**Any other interesting things to share
*Use DEAP library

===Subteam Notes===
*Refer to Lab 2 Genetic Programming
*Our output is 0 and 1, so how do we measure success
**Normalization of each individual’s output, so it ranges from 0 to 1
*Individuals = the arithmetic function that tries to predict whether an individual survives or not
*Can’t use TournamentSelect (which is single-objective), have to find another way to compare fitnesses and determine best-fit individuals
*Few options on what we can minimize in our algorithm, e.g. minimize FNR and/or FPR
**FNR = FN/(FN+TP)
**FPR = FP/(FP+TN)
*Change the actual evaluation function itself
*See how long 100 generations takes to run, then increase/decrease accordingly
*deap.tools.selTournament(individuals, k, tournsize, fit_attr='fitness') -- Select the best individual among tournsize randomly chosen individuals, k times (k number of tournaments). The list returned contains references to the input individuals.
*Cleaning Data: keep Pclass, Sex, Embarked, IsAlone, Age, and Fare
**Replace Sex with 0 for Male and 1 for Female
**Replace Embarked with category codes
**isAlone will be determined by (SibSp + Parch) == 0
**Age ranges should be grouped using pandas.cut
**Fare ranges should be grouped similarly
**All this is to try to normalize features so results aren’t wildly different numbers
**Standardize all numbers using MinMaxScaler()

===Titanic with GP===
'''My Results'''
*Best individual is: add(minimum(square(add(square(ARG1), multiply(add(ARG0, ARG0), ARG2))), add(multiply(minimum(minimum(ARG0, ARG2), minimum(ARG2, ARG5)), multiply(multiply(ARG1, ARG3), add(ARG2, ARG1))), minimum(subtract(ARG3, ARG0), minimum(subtract(ARG5, ARG5), multiply(ARG1, ARG2))))), minimum(square(multiply(ARG1, ARG3)), minimum(square(ARG4), minimum(ARG4, square(ARG1)))))
*with fitness: (0.0, 0.8872180451127819)
*Area Under Curve: 0.17440055362286314
*Used cxOnePoint crossover function, mutNodeReplacement mutation, and max height 7. Primitives included add, subtract, multiply, minimum, and square.

[[files/TitanicGP_Fitness_Dhruv_Patel.PNG|none|thumb|Fitness tracked over many generations]]

[[files/TitanicGP_FPRFNR_Curve_Dhruv_Patel.PNG|none|thumb|Pareto frontier's FPR-FNR curve]]


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Discuss requirements/approaches with group
|Complete
|Feb 17th, 2021
|Feb 24th, 2021
|Feb 18th, 2021
|-
|Complete Titantic GP assignment
|Complete
|Feb 17th, 2021
|Feb 24th, 2021
|Feb 23rd, 2021
|-
|Create ppt slides
|Complete
|Feb 17th, 2021
|Feb 24th, 2021
|Feb 23rd, 2021
|-
|Update Wiki
|Complete
|Feb 17th, 2021
|Feb 24th, 2021
|Feb 24th, 2021
|-
|}

==Feb 10th, 2021==
===Lecture Notes===
*Bootcamp Subteams made, mine is Group 5
*Team members: Kakkar, Wolfson, Moses, and Zhao
*Titanic ML project
*[https://www.kaggle.com/c/titanic Titanic] -- Use this data
*View emade/datasets/titanic on GitHub for test data
*Scikit-Learn - machine learning library for Python that underlies many of the primitive learner functions
**Examples and documentation found at [https://scikit-learn.org/stable/ Scikit Learn]

===Subteam Notes===
*Decided on how to clean the Titanic data as follows
*Replace indexes with PassengerID, delete PassengerID column
*Survived remove for comparison
*Remove Name
*Remove Fare
*Remove Ticket
*Possibly remove Embarked
**Could we use miles from crash or days from boarding as useful data?
*Remove cabin numbers
*Change genders to numbers (0 male, 1 female)
*Fill NaNs with means
*Keep 33% as test_size
**Possibly try 20%
**KFold size 5 → 20% validation
**KFold size 3 → 33% validation
*Use cross_validation instead of train_test_split due to limited data set so we can have just (train data, test data) rather than (train data, validation data, test data)
**Initialize model (using “clf = …” but don’t fit it) before using cross_validation
**Cross_val_score method to get score, also Cross_val_predict to get prediction
**Cross_validation splits the data and fits the model (no need to train_test_split)
**Don’t use fit(), feed clf into cross validation
*Fit doesn’t validate, so there’s no point in using KFold and feeding it into fit() method
**Feed KFold output into cv parameter of Cross-validation

===Titanic ML===
[https://www.kaggle.com/c/titanic Titanic Skaggle]
*Team shares common set of processed/folded data
*Make prediction model and review scores and confusion matrix
'''Notes'''
*I'm using Cross_val_predict instead of Cross_validate due to small fold count (caused by small data set) to get predictions of model
*Accuracy_score method can calculate score, or can use cross_val_score (use same KFold instance)
**I will be using Accuracy_score, but it shouldn't make a difference.
*KFold should have shuffle=True and random_state=1 (or other number, but be consistent) so we are dealing with the same random splits each time, needed for proper experimental design
*For confusion matrix, y_pred is our output of cross_val_predict and y_truth is all the values of y_train because we aren’t splitting normally, we’re doing a KFold split

'''Trial 1'''
*Used KFold n_splits 5 (which is 20% validation set) with a KNeighborsClassifier model
*Accuracy score: 0.77665544332211
*Confusion Matrix
**True Negatives 475
**False Positives 74
**False Negatives 125
**True Positives 217

[[files/TitanicKFold5KNN_Matrix_Dhruv_Patel.PNG|none|thumb|Confusion Matrix for KNN 5Folds]]

'''Trial 2'''
*Used KFold n_splits 3 (which is 33% validation set) with same KNeighborsClassifier model
*Wanted to see how a bigger validation set would affect the prediction
*Verdict: Likely caused by our relatively-small dataset, KFold 5 works better because a smaller validation set means we get a greater training set
*Accuracy score: 0.7564534231200898
*Confusion Matrix
**True Negatives 456
**False Positives 93
**False Negatives 124
**True Positives 218

[[files/TitanicKFold3KNN_Matrix_Dhruv_Patel.PNG|none|thumb|Confusion Matrix for KNN 3Folds]]

'''Trial 3'''
*Used KFold n_splits 5 with DecisionTree Classifier Model
*Accuracy score: 0.7867564534231201
*Confusion Matrix
**True Negatives 466
**False Positives 83
**False Negatives 107
**True Positives 235

[[files/TitanicKFold5DT_Matrix_Dhruv_Patel.PNG|none|thumb|Confusion Matrix for DecisionTree 5Folds]]

'''Trial 4'''
*Used KFold n_splits 5 with NeuralNetwork MLP Classifier Model
*Accuracy score: 0.8260381593714927
*Confusion Matrix
**True Negatives 493
**False Positives 56
**False Negatives 99
**True Positives 243

[[files/TitanicKFold5MLP_Matrix_Dhruv_Patel.PNG|none|thumb|Confusion Matrix for NeuralNetwork 5Folds]]


'''Verdict'''
*KFold with 5 splits works best for the dataset
*<u>NeuralNetwork classifier model</u> provided the best accuracy score
**<u>Score 0.8260381593714927</u>
**False Positives: 56/891 = 0.06285072951
**False Negatives: 99/891 = 0.11111111111
*See raw prediction results [https://drive.google.com/file/d/1ZifBQS5bbXJSaQST1SECqDc_mQpmZDef/view?usp=sharing here]


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Set up Discord with group
|Complete
|Feb 10th, 2021
|Feb 17th, 2021
|Feb 14th, 2021
|-
|Complete Titantic Skaggle assignment
|Complete
|Feb 10th, 2021
|Feb 17th, 2021
|Feb 16th, 2021
|-
|Update Wiki
|Complete
|Feb 10th, 2021
|Feb 17th, 2021
|Feb 16th, 2021
|-
|}

==Feb 3rd, 2021==
===Lecture Notes===
'''Genes'''
*Gene pool - set of genome to be evaluated during current generation
*Genome - genotypic description of an individual, GA = set of values, GP = tree structure
*Search Space - set of all possible genome / set of all possible algorithms
*Evaluation of a Genome associates individual with set of scores
**True Positive (TP) - how often we identify desired object
**False Positive (FP) - how often we identify something else as desired object
**Also False Negative and True Negative
**Ex1. Predict T and actual is T → true positive
**Ex2. Predict F and actual is T → false negative
*Objectives - set of measurements each genome/individual is scored against (phenotype)
*Objective Space - set of all objectives
*Evaluation - maps genome/individual from search space to objective space

'''Measures'''
*Minimization
*Take the False Negative Rate (things we classified improperly as negatives)
**To clarify, we find FNR by doing (trials false negatives)/(total number trials)
**FNR = 1 - TPR
**FPR = 1 - TNR  = 1 - SPC

*Other Measures
*Precision or Positive Predictive Value (PPV)
**PPV = TP / (TP + FP)
**Bigger is better
*False Discovery Rate
**FDR = FP / (TP + FP)
**FDR = 1 - PPV
**Smaller is better
*Negative Predictive Value (NPV)
**NPV = TN / (TN + FN)
**Bigger is better
*Accuracy (ACC)
**ACC = (TP + TN) / (P + N)
**AXX = (TP + TN) / (TP + FP + FN + TN)
**Bigger is better

'''Objective Space'''
*Each individual is evaluated using obj functions
**Mean square error, cost, complexity, tpr and fpr, etc.
*Obj scores give each individual a point in obj space
*Extensible to N number of objectives (usually use two because 2D graph is easy)


'''Pareto Optimality'''
*Individual is Pareto Optimal if there’s no other individual in population that outperforms the individual on all objectives
**Basically, the best of the best for each objective
*Pareto Frontier - set of all Pareto individual
*These individuals represent unique contributions

'''Non-Dominated Sorting Genetic Algorithm 2'''
*Population is separated into non domination ranks
*Individuals are selected using binary tournament
*Lower Pareto ranks beat higher ranks
**Ties are broken using crowding distance (summation of normalize Euclidean distances to all points within front and higher crowding distance wins)

'''Strength Pareto Evolutionary Algorithm 2'''
*Each individual is given strength S
**S = how many others in pop individual dominates
*Each individual receives rank R
**R is sum of S’s of individuals that dominate it
**Pareto individual → rank of 0
*Distance to kth nearest neighbor is calculated (σk) and fitness of R + 1/(σk + 2) is obtained


===Self-Evaluation===
Click [https://drive.google.com/file/d/1qOsTSRS-lDaP3YeipnDqN1UaHII2nVHJ/view?usp=sharing Here] for the completed self-evaluation form

===Lab 2: MOGP===
*Our goal was to minimize Mean Squared Error (MSE) and Tree Size -- hence multi-obj
'''Results from Initial Run'''

Best individual (second graph) is: negative(cos(multiply(add(cos(sin(cos(sin(cos(tan(x)))))), cos(x)), tan(x)))) with fitness: (0.2786133308027132, 15.0)
Area Under Curve (third graph, lower the better): 2.3841416372199005

[[files/Lab_2_ObjSpace_Dhruv_Patel.PNG|none|thumb|Objective Space - blue is selected individual, black are incomparable, green are dominated by our individual, and red dominate our individual]]
[[files/Lab_2_MSEandTree_Dhruv_Patel.PNG|none|thumb|Orange/Red are tree sizes and Blue/Green are MSE]]
[[files/Lab_2_Pareto_Front_Dhruv_Patel.PNG|none|thumb|List of pareto individuals after evolution, mapped onto a graph based on their MSE and Tree Size]]

'''Better Algorithm'''
*Improve the Area Under Curve (AUC) by at least 25%
*Given our previous trial, our target is AUC <= 1.78810622791

*I initially changed the mutation function from mutUniform to mutInsert. The AUC improved (19%) but the fitness did not make a significant difference.
Best individual is: negative(cos(add(sin(sin(x)), x))) with fitness (0.2823325619375455, 7.0)

AUC: 1.9403264638709314
[[files/Lab_2_Insert_MSEandTree_Dhruv_Patel.PNG|none|thumb]]
[[files/Lab_2_Insert_Pareto_Front_Dhruv_Patel.PNG|none|thumb]]

*Then, I decided to change the mutation function to mutNodeReplacement, which yielded similar results.
*However, changing the tournament size seems to affect the AUC greatly, and while 4, 6, and 7 all yielded odd values, a tournsize=5 was found to be the optimal solution.
*An improvement of 59% was observed. In addition, a lower fitness value was also seen.
Best individual is: negative(cos(x)) with fitness: (0.49416153493347187, 3.0)

AUC: 0.9798779140805436
[[files/Lab_2_NodeReplace_MSEandTree_Dhruv_Patel.PNG|none|thumb]]
[[files/Lab_2_NodeReplace_Pareto_Front_Dhruv_Patel.PNG|none|thumb]]

===Action Items===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Finish Lab 2
|Completed
|February 3rd, 2021
|February 10th, 2021
|February 8th, 2021
|-
|Complete Self-Evaluation Assignment
|Completed
|February 3rd, 2021
|February 10th, 2021
|February 6th, 2021
|-
|Update Wiki for Week 3
|Completed
|February 3rd, 2021
|February 10th, 2021
|February 8th, 2021
|}

==Jan 27th, 2021==
===Lecture Notes===
'''Diversity in Genetic Computing'''
*Genotypic diversity - actual genetic difference in individuals
**E.g. How similar is your N queens placement to another placement (how many same indices)
*Phenotypic diversity - expression of your genes
**Physical/shown traits of the solution
**E.g. 3+7, 4+4+2, 9+1+0, are all genomically diverse BUT phenotypically the same (all add to 10)

'''Genetic Programming'''
*The individual is the function itself
*Rather than having an individual and running it through a function evaluator to determine individual’s objective score (their worth)
**In GP individual determines its worth through input/output of data, while in GA a machine determines an individual’s worth based on certain metrics and I/O

'''Tree Representation'''
*Represent program as tree structure
*Nodes are “primitives” and represent functions
*Leaves are “terminals” and represent parameters 
*Input is a particular type of terminal
*Output is produced at root of tree
*Tree is converted to a lisp preordered parse tree

*E.g. parse is written in pre-order [+,*,3,4,1] and is read in-order (3 * 4) + 1
**Can also write parse as operator, operator input 1 (if input is operator, next digits will be input of that operator), operator input 2
**Notice: each child is one of two inputs of its parents

[[files/TreeRepresentation1.png]]

*Crossover is done by simply exchanging subtrees
*Randomly pick a point, everything below it and point itself is the subtree
*Resulting trees after exchange are the children

'''Mutation in GP'''
*Insert, delete node/subtree, or change node
*E.g. Symbolic Regression -- evolve a solution to y=sin(x) using GP
**Primitives include: + * - /
**Terminals include integers and variable x
**Solution: Taylor series (for sin(x))
**Third-order Expression: [-,x,/,*,x,*,x,x,*,3,2]
**Feed inputs into function and calculate error (b/c Taylor series are infinite) between outputs and truth
**Some primitives can make this easier, like Power() and Factorial() -- EMADE’s goal!


===Lab 2: Symbolic Regression===
'''Original Program'''

*Best individual is <code>add(multiply(add(multiply(multiply(x, x), x), multiply(x, x)), x), add(x, multiply(x, x)))</code>
*Best Fitness score: 1.0760604870374914e-16
*Utilized Uniform Mutation function

[[files/Lab_2_Graph_1_Dhruv_Patel.PNG|none|thumb]]


'''With Node Replacement Mutation'''

*Best individual is <code>add(add(multiply(multiply(add(multiply(x, x), x), x), x), x), multiply(x, x))</code>
*Best Fitness score: 1.1712944886774969e-16

  toolbox.register("mutate2", gp.mutNodeReplacement, pset=pset);
  
  #Inside evolution
  for mutant in offspring:
    if random.random() < 0.2:
      toolbox.mutate(mutant)
      del mutant.fitness.values

[[files/Lab_2_Graph_2_Dhruv_Patel.PNG|none|thumb]]


'''With new primitives and Node Replacement mutation'''

*Best individual is <code>add(multiply(maximum(maximum(maximum(x, add(x, x)), add(x, x)), add(multiply(multiply(maximum(x, add(x, x)), x), x), x)), x), x)</code>
*Best Fitness score: 0.061699757972298035

  pset.addPrimitive(np.maximum, arity=2)
  pset.addPrimitive(np.square, arity=1)

[[files/Lab_2_Graph_3_Dhruv_Patel.PNG|none|thumb]]


'''Results'''
*Best program was the node replacement mutation without new primitives
*There is a random element to this experiment which we must keep in mind when analyzing the results
*For the future, other mutation functions should we tried and best fitnesses compared to each other

===Action Items===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|First part of Lab 2
|In progress
|January 27, 2021
|February 3, 2021
|January 31, 2021
|-
|Update Wiki for Week 2
|In progress
|January 27, 2021
|February 3, 2021
|January 31, 2021
|}

==Jan 20th, 2021==
===Lecture Notes===
'''Genetic Algorithms'''
*Each new generation is made through mating/mutation of individuals in prev pop
*Numerous operations product the best individual -- one with best fitness
*Keywords:
**Individual - specific candidate in population (particular solution to our problem)
**Population - group of individuals whose properties will be altered
**Objective - value used to characterize individuals that you’re optimizing (increase object through evolution)
**Fitness - relative comparison to other individual
**Evaluation - a function that computes objective of individual
**Selection - represents “survival of the fittest”
***Preference to better individuals → pass on genes
***Fitness proportionate - greater the fitness value, higher the probability of being selected for mating (bigger slice of roulette wheel)
***Tournament - several tournaments among individuals and winners are selected for mating (the most fit)
**Mate/Crossover - mating between individuals
**Mutate - introduces random modification, maintain diversity
***Ex. Flip a bit from a 1 to 0 or 0 to 1 (like a gene change)
**Algorithms - various evolutionary algorithms create a solution
***Steps:
***1. Randomly initialize first pop
***2. Determine fitness of first pop
***3. Analyze population
****Select parents
****Perform crossover on parents
****Perform mutation
****Determine fitness of new population
***Repeat Step 3 until best individual is good enough

===Lab 1: DEAP===
'''Max One Problem'''
*I followed instructions from the ipynb on the GitHub
**[https://github.gatech.edu/emade/emade/blob/master/notebooks/Lab%201%20-%20Genetic%20Algorithms%20with%20DEAP.ipynb Lab Link]
*After defining objective function and initial population, we ran the evaluation, mate, mutation, and select functions (genetic algorithm)
*Algorithm was ran for 40 generations
*Consistently found 99.0 to 100.0 as max through multiple trials
**Did not always achieve the optimal 100.0 max, but 99.0 is very close

'''N Queens Problem'''
*Objective function defined -- minimization problem, initial pop created
*Evaluation function - # of collisions along diagonals
*Matings - crossovers PartiallyMatched() and TwoPoint()
*Mutations - ShuffleIndexes()
*Algorithm was ran for 100 generations with various parameters/functions
*Overall fitness decreases as the generations increase -- successful minimization


[[files/Lab_1_N_Queens_Dhruv_Patel.png|center|thumb]]

===Action Items===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Join Slack Channel
|Completed
|January 20, 2021
|January 27, 2021
|January 20, 2021
|-
|Install Jupyter Notebook
|Completed
|January 20, 2021
|January 27, 2021
|January 21, 2021
|-
|Setup Wiki Notebook Page
|Completed
|January 20, 2021
|January 27, 2021
|January 21, 2021
|-
|Finish Lab 1
|Completed
|January 20, 2021
|January 27, 2021
|January 22, 2021
|}