== Elan Grossman ==

Team Member: Elan Grossman

Email: egrossman3@gatech.edu
Cell Phone; 770-595-8339

[[files/Elan.jpg|thumb|123x123px]]

Interests: Machine Learning, Robotics, Puzzles, AR/VR


== September 1st, 2021 ==
'''Team Meeting Notes:'''
* Reviewed Wiki How-Tos
* Covered using GP to generate functions instead of optimizing a solution
* An example is generating a mathematical function such as sin(x)
* What you could do is generate the inputs and outputs and then use GP to generate an equation that maximizes the accuracy of the solution
* This is similar to machine learning, except you don't use gradient descent to optimize the algorithm, but a fitness function
* Functions are represented as trees with two types of nodes
** Nodes (or Primitives) which represent transformations such as addition, subtraction, summation, factorials, etc.
** Leaves (Or Terminals) which represent data such as constants or even variables (x, y, z)
* Leaves cannot have children and Nodes must have 2 children
* Tree can be represented as a recursive tree structure
** [-, 2,* 3, x] is equivalent to 2-3*x
* Crossover is now exchanging nodes between trees
** For example, we could change [-, 2,* 3, x] to [-, -,4,x,* 3, x] to be 4-x-3x where [-,4,x] is a node in a tree
* Mutation is not only changing a node, but deleting one or adding a new node 

'''Lab 2 Notes'''

I worked through the module adding two more primitives, the sin function and a maximum function to the tree. The tree generation method, genHalfAndHalf where half the time it generates a tree with equal depth for each node, and the other half does not (or at least does between a minimum and maximum depth)

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Work through Regression Notebook
|In Progress
|September 1, 2021
|September 7, 2021
|September 7, 2021
|}

== August 25th, 2021 ==
'''Team Meeting Notes:'''
* Covered Course Syllabus and Individual Responsibilities
* Intro to genetic programming
** Individual = a single subject defined as a set of features
** Population = a collection of individuals
** Objective = Maximization of a goal
** Fitness = Objective score relative to other individual scores
** Selection = Method to determine which experiment to try next through choosing a number of individuals to succeed
*** Emade algorithm uses a combination of tournament and proportionate selection techniques
** Mating = Exchanging features between individuals
** Mutation = Changing features in an individual
* Basic Genetic Programing algorithm is:
** Randomize or seed population
** Determine Objective and Fitness
** Repeat: Selection -> Mating -> Mutation -> Fitness Evaluation
* Used One-Max problem as an example of Genetic programming
* Covered Jupyter notebooks

'''Lab 1 Notes''' 
I began the lab by running each cell in the Jupiter notebook step by step, but started to get lost in the details. The creator method of the DEAP framework in particular is capable of producing multiple types of objects with the same function call. I assume this is to create a directed graph similar to tensorflow or spark. So I went over to the documentation at [[https://deap.readthedocs.io/en/master/]] to read more.

The creator method is a way to create classes on the fly using methods instead of files. In the documentation the example is that
 create("Foo", list, bar=dict, spam=1)
Is equivalent to
 class Foo(list):
    spam = 1
    def __init__(self):
        self.bar = dict()

Therefore,
 creator.create('Individual', list, fitness=creator.FitnessMax)
Is creating a class called "Individual" that inherits a list and contains an attribute that is an instance of the FitnessMax class.
This is better summarized in [[https://deap.readthedocs.io/en/master/tutorials/basic/part1.html#creating-types]]

I was able to run through the rest of the lab with no problems and began to become familiar with the conventions of the DEAP framework and how we can register the various fitness, mutation, and mating functions to our toolbox. One thing of note is to use the copy method from tools when mating and mutating individuals. This is to ensure that we do not modify individuals in the population when creating the offspring.

'''Duplicates'''

What struck me as odd was the selection of the offspring. The tournament selection was set to evaluate 3 individuals at a time, but it was also set to create 300 offspring. Our population is also 300. According to the documentation, n individuals are chose k times. In this case n=3 and k=300. This means that there is a good number of duplicate individuals in the population. I also suspected that the number of duplicates would increase over each generation. The populations will converge to all 1s, so the probability of two sets with 99 ones each at different positions generating the same set increases. The counts of duplicates at each generation was as follows:
 [34, 65, 76, 48, 51, 48, 54, 49, 50, 62, 57, 58, 52, 40, 62, 38, 57, 72, 67, 96, 81, 93, 92, 100, 117, 116, 131, 150, 173, 175, 202, 196, 197, 211, 220, 215, 231, 229, 236, 238]. 

Perhaps there needs to be a clean up set to reduce duplicates and increase the search space. The effect of duplicates is that it increases the probability that a solution will be selected during the tournament, and therefore weighs the optimal solution towards these individuals. I read an article on maintaining diversity in in a population.

Gupta, Deepti and S. Ghafir. “An Overview of methods maintaining Diversity in Genetic Algorithms.” (2012). [[https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.413.7546&rep=rep1&type=pdf]]

One reason to maintain diversity is to prevent the GA from converging onto a local optima. Randomly generating new individuals is likely to fail because their fitness is initially too low and they would die off in the next generation. Alternatively, you can increase the mutation chance or number of mutations in your individuals in order to encourage solutions with strong fitness.
Notable solutions to these problems include:

*Crowding
**Having an offspring replace the most similar individual and only a percentage of the population mates
*Restricted Mating
**There are conditions under which a pair can mate, usually determined by the hamming difference (number of changes required to make the pair equal)
*Sharing
**The fitness function of an individual is shared with it's neighbors. This means that the survival probability is a function of a many individuals and not just one. This increases the number of computations required to compute optima and is best used for problem domains where solutions are generally known
*Multiploidy
**Individuals can recover information from a previous generation

There are more, but each of these deserves their own topic of research

'''N Queens'''

The next exercise was to evaluate the N queens problem, where you must place a queen on each column and each row such that there are no diagonals. We were given two mutation methods to experiment with, PartiallyMatched and TwoPoint. Two Mapped will swap queen positions from between two random points and Two Point will also switch places of queens so that they are not redundant. For example, in Two point, two indexes are chosen, one for each individual, then individual one swaps the queen that is selected for the second individual with whatever they had at that location. This way, there are not multiple queens in the same column.

Next, I evaluated how quickly the algorithm converged. This happened around the 30th generation. By changing the evaluation method to calculate the square of the conflicts in each row, the genetic algorithm converged more quickly. However this was just a visual effect as the the values were still squared. Because the values are ordered, a linear equation will have no noticeable effects. You would need to add a second metric to the sum to get converging values. Getting 1 queen remaining was very common and can be explained by having low genetic diversity such that many changes are required to move away from the 7 queen solution.

I also tried to play around with the crossover, mutation, and selection functions. I did not have time to set up an automated analysis by running each experiment around 20 times and taking the average, but I did look at qualitative data. Increasing the tournament selection up to 5 had very little effect since it just increased the chance that a high fitness individual would be chosen. If a low fitness individual is required to move away from the current solution, it would not be picked. I also looked into the cxUniformPartiallyMatched, but it did not improve performance as expected. Increasing the probability for the crossover too high would be no better than generating a new random sample. 

I also tried to restrict the algorithm from reaching a fitness score of 1. The reason being is that more often than not, solving for 7 queens is trivial compared to solving for 8. In order to correct, I would need to backtrack the solution to a state that is close to the solution that was visited in the past. By restricting the minimum to not include 1, that meant the mutation has to make 2 correct moves at once. This can be a bad thing because it makes it more lucky to have a correct solution, but if we account for duplicates being the majority of selected individuals, then we have a good shot at getting to the minimum. This did not work in practice, and I am still testing out new ways to measure the fitness function. There should be a second metric to combine with the sum such that we get the same fitness with different diagonals found.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Work through DEAP tutorial notebooks
|Completed
|August 25, 2021
|August 31st, 2021
|August 31st, 2021
|}
