== Elan Grossman ==

Team Member: Elan Grossman

Email: egrossman3@gatech.edu
Cell Phone; 770-595-8339
Sub Team: [[Bootcamp Subteam 1]]

[[files/Elan_Profile.jpg|thumb|80x80px]]

Interests: Machine Learning, Robotics, Puzzles, AR/VR

== December 10th ==

'''Lab Notes'''

Final Presentations

* Image Processing
** This was our team

* NLP


*Time Series Analysis

''' My Work'''

==== Helping Others with Emade ====

In order to have enough trials to compare with before the final presentation, everyone had to run an experiment or two. I helped two of my teammates with starting PACE-ICE jobs.

To make sure myself and everyone could run the trials in repeatable steps, I followed these guidelines:

* Download correct files
** Input XML that we will all use
** launchEmadechest_final.pbs
** Most recent GPFramework from img-proc branch
* Make sure mysql.pbs is running for 8 hours
** ssh into mysql server and confirm you can connect to mysql and that your database exists
** If not, you need to create a new database and make sure all users can access it.
* Input mysql server and database info into template file
* Make sure Launch file is pointing to correct xml
* Make sure launch file is using correct environment
* Run the launch file
** Confirm that worker and master jobs are running in qstat
* Check logs
** EMADE_master.oXXXXX will show you the master log
** EMADE_worker.oXXXXX will show you the worker logs for individual evaluations. This is where you can check for errors

If there are no errors in the worker logs and the master worker doesn't die (it happens!), then it's good to go.
Lastly, you can check the database to make sure individuals are being created and evaluated as a paretofront.


== December 6th ==

''' Lab Notes '''

Focus is on getting the environments set up correctly. Everyone has a yml file to install the correct Conda environment.
My task is to run Second Mate mutations with Rohan. I will download an xml file and run that job on PACE and report back with findings

''' My work '''

ROC vs F1

It was brought into question what space we would be comparing between the two fields. I had this to say:

the F1 score is really just a weighted (harmonic?) mean of two scores, or another way of handling multi-objective functions by condensing them into 1. You’re rewarding the algorithm for performing well in both precision and recall and not one or the other. You lose out on being able to set thresholds for each measure individually such as recall > 0.9, precision > 0.7.

ROC is comparing how much better you TPR is than your FPR at different classification thresholds (default is X > 0.5 = True). Let’s say the threshold is at X > 0.9 = True. If your TPR is greater than your FNR, that means that your predictions are really robust and easily distinguishable. The AUC for the ROC is a single number that reflects its ability to distinguish between the two classes. However, this only works if the labels are weighted equally. If your dataset is always made up of positive individuals, your TPR will always be extremely high because it can always choose to predict the trivial case of X = True for all values.

A large F1 score could somewhat couter-act an unbalanced ROC because the trivial case mentioned above is analogous to having perfect recall, but low precision. However, F1 score is not precision. In this unbalanced example, if recall is 0.95 and precision is 0.3, your F1 score is 0.456. But now you’re just comparing precision and recall. Everything I read says to just use precision-recall curves instead for unbalanced datasets. This is because for unbalanced datasets, the change in FPR and FNR provide little change in ROCAUC. It’s actually extremely difficult to change the ROC for unbalanced data.
[[https://towardsdatascience.com/demystifying-roc-curves-df809474529a]]
[[https://www.biostat.wisc.edu/~page/rocpr.pdf]]
[[https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification]]

Dr. Zutty suggested splitting up F1 into Precision and Recall. Since Recall is the TPR, we only need to compare these values with the FPR and NPV which are the same metrics but for the other class. For example, your recall can be calculated for positive and negative examples and their relationship is not necessarily linear, but they do tend to correlate.

Tree Vis

By default the tree vis doesn't take into account adfs. Take this tree:
<code>tree|FullDataSet ROC AUC|FullDataSet Num Parameters
NNLearner(((((ARG0)))), GlobalMaxPoolingLayer2D(adf_1(Conv2DLayer((Conv2DFilterUnit16), (seluActivation), (Conv2DKernelSize5), adf_4(InputLayer)))), ((((falseBool)))), ((((((((AdadeltaOptimizer)))))))))\nadf_1: Conv2DLayer(Conv2DFilterUnit16, (tanhActivation), (Conv2DKernelSize1), MaxPoolingLayer2D(Conv2DKernelSize5, InputLayer))\nadf_4: Conv2DLayer((Conv2DFilterUnit16), (defaultActivation), (Conv2DKernelSize5), MaxPoolingLayer2D(Conv2DKernelSize5, ARG0))</code>

This is actually made up of a single tree with references to two adfs, adf_1 and adf_4. We can rearrange the graph like so:

<code>NNLearner(((((ARG0)))), GlobalMaxPoolingLayer2D(Conv2DLayer(Conv2DFilterUnit16, (tanhActivation), (Conv2DKernelSize1), MaxPoolingLayer2D(Conv2DKernelSize5(Conv2DLayer((Conv2DFilterUnit16), (seluActivation), (Conv2DKernelSize5), Conv2DLayer((Conv2DFilterUnit16), (defaultActivation), (Conv2DKernelSize5), MaxPoolingLayer2D(Conv2DKernelSize5, ARG0)))), ))), ((((falseBool)))), ((((((((AdadeltaOptimizer)))))))))</code>

But this produces a weird tree that looks a little busy:

[[files/egrossman3/bad_tree.png|thumb|80x80px]]

We can instead remove unnecessary parentheses to make the tree look slimmer:

<code>NNLearner(ARG0, GlobalMaxPoolingLayer2D(Conv2DLayer(Conv2DFilterUnit16, tanhActivation, Conv2DKernelSize1, MaxPoolingLayer2D(Conv2DKernelSize5(Conv2DLayer(Conv2DFilterUnit16, seluActivation, Conv2DKernelSize5, Conv2DLayer(Conv2DFilterUnit16, defaultActivation, Conv2DKernelSize5, MaxPoolingLayer2D(Conv2DKernelSize5, ARG0)))), ))), falseBool, AdadeltaOptimizer)</code>

[[files/egrossman3/good_tree.png|thumb|80x80px]]

Maybe we can write code to clean the trees and produce the visuals by replacing the adfs and removing the extra parentheses.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Prepare Presentation
|In Progress
|December 1st, 2021
|December 10th, 2021
|-
|-
|Run more experiments
|Not Started
|December 6th, 2021
|December 10th, 2021
|-
|}

== December 1st ==

''' Lab Notes '''

I was sick this day. Please refer to the team notes

''' My Work '''

Do to the holidays, I didn't get much done. However I did reset my environment.
My new goal is to help out with presentations and anything else worth investigating.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Prepare Presentation
|In Progress
|December 1st, 2021
|December 10th, 2021
|-
|}

== November 24th ==

''' Lab Notes '''

We had our hackathon on Sunday. During this time I was was able to make progress on getting Emade to work, but there were many more packages I needed to have installed. I found out at the end that Max had built a new shared environment.
These were the steps I coppied form Max to set up the environment:

module load tensorflow-gpu/2.6.0
module load cuda/11.2
module load anaconda3/2021.05
conda create -n tf2.6 python=3.8.5

conda config --add channels conda-forge
conda install -c conda-forge cudnn=8.1.0.77


''' My Work '''

When Running Emade:
After running the default chest X-ray input xml, all files ended up with “Tree missing valid primitive for data type At least one objective returned inf” even after 200 or so generations.
It turns out that there were issues in my environment. I was able to find out why later, but essentially, I was using the shared environment that was installed with a different version of GPFramework than the one I had uplaoded.
To correct this, I uploaded the merged in files from our branch. However, someone had installed a version of GPframework that was experimental, so I could not get it to work even then. I settled with creating my own environment all over again.
Ultimately, my lesson was to get everything working on my workstation at home first and then use PACE.

I also helped the other new members with their code and getting setup in emade. There seems to be issues with getting the socket to work correctly for mysql.


'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Run simulations for Emade
|In Progress
|November 8th, 2021
|November 22nd, 2021
|-
|}

== November 17th ==


''' My Work '''



My job is to use the single tree evaluator to investigate files
TO do this, I had to modify src/GPFramework/standalone_tree_evaluator.py so that the NNLearner in question could be evaluated.

I investigated this error:

Received: NNLearner(MorphOpenCross(ECDF(mySelPercentile(ARG0, TriState.STREAM_TO_FEATURES, 50, trueBool), passTriState(passTriState(TriState.STREAM_TO_FEATURES)), passAxis(Axis.FULL), passInt(3)), passTriState(passTriState(TriState.STREAM_TO_FEATURES)), passAxis(Axis.FULL), equal(ifThenElseFloat(falseBool, 10.0, 10.0), myFloatMult(4.367807167497753, 100.0)), greaterThanEqual(myFloatIntSub(0.1, -4), myIntToFloat(50))), InputLayer(), 83, AdamOptimizer)
	With Hash 3616875e8b8637f3866689ac17bedd5d62883832eefa649a7888be1d13920bd5
	Computed in: 40.843586444854736 seconds
	With Fitnesses: (inf, inf)
	With Age: 0
	With Error:  **********y should be a 1d array, got an array of shape (2500, 15) instead.Traceback (most recent call last):

Error is with mySelPercentile(ARG0, TriState.STREAM_TO_FEATURES, 50, trueBool)
According to https://github.gatech.edu/emade/emade/blob/4fd66103f8713517765c534956f42ab714d5e59e/src/GPFramework/feature_selection_methods.py, this implements the selectPercentile method in tensor flow: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html

It takes in a scorefunc and a percentile:
SelectPercentile(chi2, percentile=10)
Score_Func: “Function taking two arrays X and y, and returning a pair of arrays (scores, pvalues) or a single array with scores. “

In this case, the method is taking in a 2d array when it should be processing a 1d array. It's unclear why it's doing that but it is probably related to the TriState


FSW wrapper - allows all different primitives to work with ARG0 and TRISTATE
TRISTATE- how to treat the data
STREAM2STREAM - keeps it raw
STREAM2FEATURES - cannot go back to stream




'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Get set up on PACE-ICE
|Complete
|November 3rd, 2021
|November 8th, 2021
|November 9th, 2021
|-
|Investigate Errors in NNLearner
|Complete
|November 8th, 2021
|November 15th, 2021
|November 15th, 2021
|-
|Run simulations for Emade
|Not started
|November 8th, 2021
|November 22nd, 2021
|-
|}

== November 10th ==

''' Lab Notes '''
This was the first weeks where we were assigned tasks to work on. I was assigned to help out with general bug fixing and explanation of failed trees.

The general breakdown of branches are:
Master -> CacheV2 -> sub teams -> nn-vip -> Image-Processing(nn-vip)
This means that we want to merge with nn-vip most of the time keep up with changes to NNLearners

Laundry list of problems
- CV2Transposed takes in particular data type
- Tristate - how to treat stream data - > feature data -> other features
- Local variablele current layer referenced before assignment

Script in Emade  to debug -> standalone tree evaluator
- Stringstoeval (paste in string), xml file
- databasetree_evaluator -> puts in hash and looks up in database



''' My Work '''

* Got Emade running on PACE-ICE
** I used SVN commands to copy over specific files from the branch since my local computer was OOM
** These commands allowed me to download files and uplaod them to emade
1) svn checkout https://github.gatech.edu/amehra37/emade/branches/Image-Processing\(nn-vip\)/src .
2) scp -r  GPFramework egrossman3@pace-ice.pace.gatech.edu:/storage/home/hpaceice1/egrossman3/projects/emade/
** We do not need download the necessary files and can instead reference dir:/storage/home/hpaceice/shared-classes/materials/vip/AAD/id_group

* Set up mysql server to run asynchronously
** The Pace set up guide [[Guide to Using PACE ICE]] has an old guide and new guide. However, the new guide does not have the #PBS lines required to run PACE jobs.
** Combining the #PBS lines from the old guide to the scripts in the new guide solved my problem
* Had some trouble connecting to database
** Took a few tries to make sure the socket was in the right place and permissions were granted accordingly
** Other interns had this problem too. Triple checking all of the paths in the files I ran was key. Recreating the database with the correct myconf file was also helpful
* Also had issues with conda environment due to not installing everything needed
** There exists a shared env out there somewhere. This will make it easier to get everything working
** One thing that is frustrating is that as new modules are added to the codebase, the requirements file is not updated. This means I have to keep running the code to find out what was not installed.
* One issues is that I was running mysql with 1 hour, but Emade for 8 hours
** In the future, I can set the mysql server to run for longer to prevent having to reset the database and find out that all my jobs fail instantly

ChexNet Paper

[[https://arxiv.org/pdf/1711.05225v3.pdf]]
This paper covered the research we are trying to compare against. The authors generated a single CNN architecture that could then train individually on 14 different binary classifiers to determine which disease was present in a chest X-ray image. Originally, our team's research was to have each of these 14 diseases as an objective in the dataset, but that created a complex paretofront. The question that I raise is "Is Emade successful if it can generate a single architecture that can perform well on each disease or if it should generate a unique architecture for each disease?"

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Get set up on PACE-ICE
|In Progress
|November 3rd, 2021
|November 8th, 2021
|-
|-
|Investigate Errors in NNLearner
|Not Started
|November 8th, 2021
|November 15th, 2021
|-
|-
|Read ChexNet
|Complete
|November 3rd, 2021
|November 8th, 2021
|November 4th
|-
|}

== November 3rd, 2021 ==

'''Lab Notes'''

* We want comparison to be closer to chest-x-ray paper by modifying dataset. The paper individuals compares the presence of one disease with every other image and trains the same classifier on the 14 different diseases. We will do something similar, but with less data.
* Switching to a multi-class instead of multi-label algorithm. This means we will only evaluate cases where one disease exists

TASKS:
* Get set up on PACE-ICE
* Clone fork ‘Image Processing(nn-vip)
* Read ChexNet
* Review VIP paper

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Get set up on PACE-ICE
|In Progress
|November 3rd, 2021
|November 8th, 2021
|-
|-
|Read ChexNet
|In Progress
|November 3rd, 2021
|November 8th, 2021
|-
|-
|}



== November 1st, 2021 ==
'''Lab Notes'''
Today we choose teams. I got put on the Image Processing Team!

Everyone did standup and discussed what changes they made in the previous week and what work they were going to work on this week.

== October 25th, 2021 ==

'''Lab Notes'''
Today was a presentation around Emade for sub teams and bootcamepers. Presentation is at [[Bootcamp-Subteam-1]]

5 Teams other than us presented:
* NLP
** Currently trying to get LSTM networks to work
** Trying to implement solution that is competitive with distilBert
** Use SQUAD dataset that contains questions and answers

* Neural Architecture Search
** This team is responisible for making Nueral Networks work with Emade
** Currently have difficulty outperforming seeds - random solutions don't converge without a bit of help
** Implemented time stopping to end computations early if they do not have much promise
** Also working on speeding up preprocessing which is currently very slow for text tokenization
** Reward novelty by keeping networks that are less frequent

* Image Processing
** Use image classification for multi-label algorithms to detect 14 deseases from chest x-ray images
** Because there are 14 objectives, it's difficult to get good results (Always same AUC)
** Experimenting with adding hyper-features for image processing - combine 2 or more primitives into one
** Uses the high performance computing cluster for testing

* Market / Time Series Analysis
** Implementing trading algorithms
** Use price and volume data to determine when is best to buy and sell
** Are trying to compare methods with SOTA papers

* Modularity
** Find ways to keep multiple leaf nodes as a single primitive known as an ARL
** By keeping ARLs, better solutions can be found because this prevents leaf level mutations. Instead, you introduce sections of the tree that work
** Currently only looking at tree depths that are 1 but are looking at more
** Not successful in getting AUC lower with newer ARLs
** Make sure ARLs get passed on. To next generation without mutation
** Looking to write a paper


'''Personal Notes'''
This week was spent getting test results from our titanic experiment. We ran two seperate tests in order to make sure we were doing the right thing
* Using our own preprosessed titanic data files on the default input_titanic.xml
* Running the same files but with a modified xml

Unfortunately, we found out pretty late that the files we generated were missing the labels and the test set was created from test.csv and not a part of our train.csv file.
This meant that our algorithm might have been predicting null values. In fact, our pareto set found an AUC of 0 because one of the algorithms computed NULL.
We reran our dataset and were able to achieve an AUC of 0.134 for the default controls

We made a few modifications to our xml
* Headless Chicken percent was doubled - this acts similar to a mutation so we also lowered those values
* Cross over was changed to 0.4 and headless chicken to 0.2
* Ephemeral was kept the same
* All other mutation methods were set to 0.025 to account for headless chicken

After 115 generations, our AUC was 0.131, lower than our previous dataset
[[files/sub-team-one-files/G12021EmadePresentation-20.png|thumb|20x10px]]


'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Use Emade on Titanic
|Completed
|October 5th, 2021
|October 25th, 2021
|October 25th, 2021
|-
|Choose a team
|Not Started
|October 25th, 2021
|October 29th, 2021
|-
|}

== October 20th, 2021 ==

'''Lab Notes'''
This week was a working session to get emade set up and working. We also had a weekend event.


'''Personal Notes'''

* I had gotten Emade to begin processing titanic dataset using the default data. The AUC was calculated to be around 0.14 after 70 generations
* This is without changing any of the default parameters
* I spent a good deal of time helping the other members set up their environments. The goal was to get them to connect to my master job on my remote server and provide thier own evaluations from their local machines
* After both working sessions, all of my team-mates were able to connect to my database.
* There are issues with the evaluation finding a lot of inf values, which are inadequate

Next steps were to modify the algorithm and have it run on our own datasets

Work to be done:
* Generate new csv.gz files for processing by emade using our previous preprocessing script
* Examine the default xml file and determine what parameters we wish to change
* Generate new pareto front for project



'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Peer Evaluations
|Completed
|October 4th, 2021
|October 8th, 2021
|October 6th, 2021
|-
|Get Emade set up locally
|Completed
|October 5th, 2021
|October 13th, 2021
|October 15th, 2021
|-
|Use Emade on Titanic
|In Progress
|October 5th, 2021
|October 25th, 2021
|
|}

== October 13th, 2021 ==

'''Lab Notes'''

This week was dedicated to getting emade set up on our machines.

* Set up a mysql server on my local machine and port-forwarded it for other team members to access.
* Default Titanic example ran for 72 generations and created a Pareto dataset
* System crashed due to memory loss

== October 6th, 2021 ==

'''Lecture Notes'''
It's finally here! EMADE!!!

Things we covered
* Configuration of python and mysql db connection
* Datasets: 
** Must be saved as csv.gz files
** Creates a dataset pair for each training and testing set
** Can use multiple data sets if using k-fold
* Objectives can be added through the evaluationFunctions.py file
* We can optimize the algorithm by restricting values or creating upper and lower bounds
* We can also limit the memory consumption of Emade to 30% of the CPU
* Can use multiple workers in parallel by using clusters of computers
** One computer is the master and the rest are workers
* Paretofront can be found by querying database

Our task:
* Run Emade algorithm on our titanic dataset for multiple generations
* Plot Pareto Front on top of ML and GA algorithms
* Try to use different evaluation functions

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Peer Evaluations
|In Progress
|October 4th, 2021
|October 8th, 2021
|October 5th, 2021
|-
|Get Emade set up locally
|In Progress
|October 5th, 2021
|October 13th, 2021
|
|-
|Use Emade on Titanic
|Not started
|October 5th, 2021
|October 25th, 2021
|
|}

== September 29th, 2021 ==

'''Lecture Notes'''
Each team presented thier research in applying GA to the titanic problem.
Of interest, these were interesting
* Using constants in the primitive tree set. I actually tried this, but didn't see an increase or decrease in AUC
* One team used loosely typed primitives and boolean values in their tree
* One team penalized the tree hight
* The use of a Hall of Fame to keep track of individuals that were in the pareto set for previous iterations. This was used to build a better pareto front, but they were suggested to also use them in sampling
* Penalizing the tree height by multiplying by a constant if it was too large
* One team took each combination of embarkment and sex and set the null values to the mode of each of the six combinations
* Some teams used the NSGA II algorithm, but apparently it does not work out of the box as described in class

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Peer Evaluations
|In Progress
|October 4th, 2021
|October 8th, 2021
|
|}

== September 22nd, 2021 ==
'''Team Meeting Notes'''

* Assignment for week was to use DEAP to generate Pareto optimal solutions to titanic problem
* Solution to problem is located at [[Bootcamp Subteam 1]]

'''Lab Notes'''
* I worked with the team to develop the genetic algorithm using DEAP step by step.
* We started with the same code and seed we used last week to generate the test, train and validation sets for the titanic dataset so that we had parity when comparing our solutions
* Next we had to define an individual. We choose to use the primitive tree that we used in a previous lab, but with two minimization functions representing FPR and FNR
* The primitive Tree used:
** Add
** Subtract
** cos
** Multiply
* We implemented the evaluation method that returned the FPR and FNR when comparing the compiled function on the training set with the testing labels
* For the selection method, we implemented a version of selection tournament for multi-parameters. This method would select the dominant individual as the survivor or in the case of only partial dominance, the lowest combined score. I originally tried to implement this with selecting more than two individuals in the tournament, but it was too slow. The reason was that we were sampling until we selected a different individual. However, individuals were not easily compared so I used their fitness to compare. This caused the algorithm to slow down as it converged in many copies of the same winner.
* The mate function chosen was to exchange nodes using the cxOnePointLeafBiased method with a random probability
* The mutation method was a single node replacement with a randomly chosen primitive

Initially, our methods proved a slightly lower AUC using this method than our ML AUC. However, when tweaking the model we were able to get slightly better results and reduced the AUC by 40%. One thing was to play around with the maximum size of the tree. It was initially set to 2 which meant each tree could only have 4 parameters each. My increasing the maximum nodes, it increased performance significantly

[[files/egrossman3/MLvsGA.png|thumb|20x10px]]

'''Extra Credit'''
For my robotics class, we had an opportunity to implement particle filters for extra credit. I used DEAP to make a modified version of the particle filter algorithm where I used genetic algorithms to randomize and select particles as opposed to using a probability function. It was able to converge much more quickly to the true values, but was not as accurate over time. This is because the robot continues to move, so individuals lose a level of certainty over time and other individuals succeed. However, it does cover a wider range of solutions than the particle filter which converges completely.


'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Work with sub-team on Titanic Dataset for GP
|In Progress
|September 22nd, 2021
|September 29th, 2021
|September 29th, 2021
|}


== September 15th, 2021 ==
'''Team Meeting Notes:'''
* We reviewed the Titanic Dataset hosted by Kaggle: [https://www.kaggle.com/c/titanic/data]
* Dr. Zutty walked through a Jupiter Notebook showing us how to clean and prepare data
** A test.csv and train.csv were given to us, which is a splitting of the data of the passengers of the titanic.
** This included data such as gender, ticket number, cabin number, age, ticket fare, and port of embarkation.
** The test.csv did not contain whether or not the passengers survived, but the train set did.
** The Train set removed cabin number, name, and ticket as they are not continuous or discrete variables
** Then the train set was split into a different train and test set for modeling
** Multiple models were shown to us without any hyper-parameters set
* Our goal as a team was to work together to modify the training and test sets and build an algorithm, one for each member, such that each was co-dominate with each other. In other words, no one algorithm would be dominant for number of False Positives and False Negatives, but one or the other



'''Lab Notes'''
* The Output of our work is located on our team page [[Bootcamp Subteam 1]]
* For my algorithm, I choose the Random Forest Classifier
* I was able to obtain an algorithm that produced 25 False Positives and 29 False Negatives
* For the passengers who died, I obtained a precision and recall score of 86% and 87% respectively
* For the passengers who survived, I obtained a precision and recall score of 75% and 73% respectively
* I also played around with the hyper-parameters such as max_depth which controls how deep the nodes can get in a forest and min_samples_split which determines how many samples are required for a split to occur. By default max_depth is not set and you only need 2 samples to split with
* Changing min_samples_split did not decrease the number of incorrect classification. This is because there is not enough data for there to ever be 3 or more items to split on
* Changing the max depth to 4 did produce the results listed above, which were greater than anything else I tried
* For further tuning, I referenced [https://scikit-learn.org/stable/modules/grid_search.html] to explore using the RandomizedSearchCV and GridSearch APIs. For example, I used
<blockquote>
model_params = {
    "max_depth": range(2, 40),
    "min_samples_leaf": range(1, 5),
    "min_samples_split": range(2, 5),
}
</blockquote>
This produced a range of hyper parameters to experiment with. Grid Search searched through all combinations of variables, and the Randomized search searched through 100 random combinations of the variables. Neither solution produced an optimal outcome compared to my previous experiments

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Work with sub-team on Titanic Dataset
|Completed
|September 15th, 2021
|September 22nd, 2021
|September 21st, 2021
|}

=== Self Assessment ===

{| class="wikitable"
!Area
!Score
!Notes
|-
|Notebook Maintenance
|25
|
|-
|Meeting Notes
|15
|
|-
|To Do Items
|5
|
|-
|To do list consistency
|10
|
|-
|To do list items checked and dated
|5
|
|-
|Level of Detail
|13
|I could do a better job of linking my sources and going into detail on relevant literature
|-
|References
|8
|I had trouble with the uploading pictures during the first few weeks and didn't save my data at the time. I do make references to documentation and papers when I can, but it could be improved
|-
|Useful Resource for team
|14
|The journal I write contains my thoughts as I work through the lab and is not merely a list of completed tasks. I hope this detail is sufficient for someone else to understand the motivations behind my research and experimentation so that they can follow along and offer suggestions or improvements
|-
|}

Total Grade: 95

== September 8th, 2021 ==

'''Team Meeting Notes'''
* Focus on optimization of GAs
* Learned about Pareto Optimality
** Something is Pareto optimal if there is no other individual that out performs it in all fitness measurements
** If an individual is Pareto optimal, we say that it is non-dominated by individuals that it outperformsgs
** The collection of individuals that are Pareto optimal create a curve known as the Pareto front. This front is a the area under which more optimal solutions could be found. By minimizing or maximizing the area under the curve, one can find a solution space that is more optimal.
* We learned about optimizing for multiple fitness evaluation
* We covered the confusion matrix and associated measures such as sensitivity, precision, and accuracy:[https://en.wikipedia.org/wiki/Precision_and_recall]
[[files/egrossman3/Precisionrecall.svg]]
* We covered 2 tournament algorithms
** Nondominated sorting genetic algorithm II
*** This algorithm assigns a rank to each individual. The rank is computed by finding all of the Pareto optimal individuals and assigning them the current rank (starting at 0) and then removing them. The rank is increased by 1 and the next set of non dominated individuals is found and assigned the current rank.
*** Tie-breakers are resolved by computing the crowding distance which favors individuals with fewer individuals close to itself that are also in the same front. This means that individuals that are further away from other individuals are favored to promote diversity
** SPEA2 - Strength Pareto Evolutionary Algorithm [https://kdd.cs.ksu.edu/Courses/CIS830/Handouts/P8.pdf]
** Zitzler, E. et al. “SPEA2: Improving the strength pareto evolutionary algorithm.” (2001).
*** First the strength of an individual is calculated by how many other individuals it dominates
*** Then the rank is computed as the sum of strengths of individuals that dominate it. This means that the Pareto front individuals all have rank 0
*** Tie breakers are determined by an extra factor that is the inverse distance to a kth nearest neighbor

'''Lab 2 Notes Continued'''

I kept trying to decrease the area under the curve of the Pareto front, but I found that the results of the optimization changed drastically every time it was ran. Because my results were so low initially, it was difficult to reduce them by 25%. This is especially true if you take into account that you might run the algorithm multiple times before getting a low number.
[[files/egrossman3/pareto_front.png]]

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Finish Regression Notebook
|Completed
|September 1, 2021
|September 15, 2021
|September 7, 2021
|}

== September 1st, 2021 ==
'''Team Meeting Notes:'''
* Reviewed Wiki How-Tos
* Covered using GP to generate functions instead of optimizing a solution
* An example is generating a mathematical function such as sin(x)
* What you could do is generate the inputs and outputs and then use GP to generate an equation that maximizes the accuracy of the solution
* This is similar to machine learning, except you don't use gradient descent to optimize the algorithm, but a fitness function
* Functions are represented as trees with two types of nodes
** Nodes (or Primitives) which represent transformations such as addition, subtraction, summation, factorials, etc.
** Leaves (Or Terminals) which represent data such as constants or even variables (x, y, z)
* Leaves cannot have children and Nodes must have 2 children
* Tree can be represented as a recursive tree structure
** [-, 2,* 3, x] is equivalent to 2-3*x
* Crossover is now exchanging nodes between trees
** For example, we could change [-, 2,* 3, x] to [-, -,4,x,* 3, x] to be 4-x-3x where [-,4,x] is a node in a tree
* Mutation is not only changing a node, but deleting one or adding a new node 

'''Lab 2 Notes'''

I worked through the module adding two more primitives, the sin function and a maximum function to the tree. The tree generation method, genHalfAndHalf where half the time it generates a tree with equal depth for each node, and the other half does not (or at least does between a minimum and maximum depth).

When building the toolbox methods, I added an insert method to generate a new primitive in the tree through insertion instead of replacement. Lastly, I installed the networkx library to visualize the graph. When running my code for the first time, my optimization found this individual:
Best individual is maximum(add(multiply(maximum(add(multiply(add(x, multiply(x, x)), x), x), x), x), x), x), (1.298785972010402e-16,)
This is equivalently: max(x+x*max(x+x*(x^2 + x),x),x) which with the maxes removed becomes: x+(x^2 + (x^4 + x^3)) which is equivalent to our evaluation method, but with maximum added in.

Next, we tried a much harder problem to solve:
-x + sin(x^2) + tan(x^3) - cos(x)

We also defined Pareto Dominance. This property means that for an individual outperforms another individual in all fitness values. This is equivalent to saying that there is no trade-off between selecting an individual in a multi-objective fitness optimization. Then I implemented the statistics and algorithms package in DEAP. The algorithm we used, eaMuPlusLambda can be found at [https://deap.readthedocs.io/en/master/api/algo.html?highlight=eaMuPlusLambda]. What's nice about this functionality is that we don't have to write the GP algorithm from scratch and we also get a very nice summary of each generation with statistics. This cuts down on code we have to write and reduces the output to something readable.

We also generated a visual to represent the Pareto front. This is a list of best individuals that minimize the area under the curve between two fitness objectives. Essentially, this represents a boundary that estimates the minimum error we can obtain and the trade-off between multiple fitness objectives.

{| class="wikitable"
!Mu
!Lambda
!CXP
!MUTPB
!Result
|-
|50
|100
|0.5
|0.2
|2.36
|-
|50
|150
|0.5
|0.2
|4.043
|-
|50
|50
|0.5
|0.2
|2.33
|-
|50
|100
|0.3
|0.2
|3.702
|-
|50
|75
|0.6
|0.7
|2.34
|}


'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Work through Regression Notebook
|Completed
|September 1, 2021
|September 7, 2021
|September 7, 2021
|}

== August 25th, 2021 ==
'''Team Meeting Notes:'''
* Covered Course Syllabus and Individual Responsibilities
* Intro to genetic programming
** Individual = a single subject defined as a set of features
** Population = a collection of individuals
** Objective = Maximization of a goal
** Fitness = Objective score relative to other individual scores
** Selection = Method to determine which experiment to try next through choosing a number of individuals to succeed
*** Emade algorithm uses a combination of tournament and proportionate selection techniques
** Mating = Exchanging features between individuals
** Mutation = Changing features in an individual
* Basic Genetic Programing algorithm is:
** Randomize or seed population
** Determine Objective and Fitness
** Repeat: Selection -> Mating -> Mutation -> Fitness Evaluation
* Used One-Max problem as an example of Genetic programming
* Covered Jupyter notebooks

'''Lab 1 Notes''' 
I began the lab by running each cell in the Jupiter notebook step by step, but started to get lost in the details. The creator method of the DEAP framework in particular is capable of producing multiple types of objects with the same function call. I assume this is to create a directed graph similar to tensorflow or spark. So I went over to the documentation at [[https://deap.readthedocs.io/en/master/]] to read more.

The creator method is a way to create classes on the fly using methods instead of files. In the documentation the example is that
 create("Foo", list, bar=dict, spam=1)
Is equivalent to
 class Foo(list):
    spam = 1
    def __init__(self):
        self.bar = dict()

Therefore,
 creator.create('Individual', list, fitness=creator.FitnessMax)
Is creating a class called "Individual" that inherits a list and contains an attribute that is an instance of the FitnessMax class.
This is better summarized in [[https://deap.readthedocs.io/en/master/tutorials/basic/part1.html#creating-types]]

I was able to run through the rest of the lab with no problems and began to become familiar with the conventions of the DEAP framework and how we can register the various fitness, mutation, and mating functions to our toolbox. One thing of note is to use the copy method from tools when mating and mutating individuals. This is to ensure that we do not modify individuals in the population when creating the offspring.

'''Duplicates'''

What struck me as odd was the selection of the offspring. The tournament selection was set to evaluate 3 individuals at a time, but it was also set to create 300 offspring. Our population is also 300. According to the documentation, n individuals are chose k times. In this case n=3 and k=300. This means that there is a good number of duplicate individuals in the population. I also suspected that the number of duplicates would increase over each generation. The populations will converge to all 1s, so the probability of two sets with 99 ones each at different positions generating the same set increases. The counts of duplicates at each generation was as follows:
 [34, 65, 76, 48, 51, 48, 54, 49, 50, 62, 57, 58, 52, 40, 62, 38, 57, 72, 67, 96, 81, 93, 92, 100, 117, 116, 131, 150, 173, 175, 202, 196, 197, 211, 220, 215, 231, 229, 236, 238]. 

Perhaps there needs to be a clean up set to reduce duplicates and increase the search space. The effect of duplicates is that it increases the probability that a solution will be selected during the tournament, and therefore weighs the optimal solution towards these individuals. I read an article on maintaining diversity in in a population.

Gupta, Deepti and S. Ghafir. “An Overview of methods maintaining Diversity in Genetic Algorithms.” (2012). [[https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.413.7546&rep=rep1&type=pdf]]

One reason to maintain diversity is to prevent the GA from converging onto a local optima. Randomly generating new individuals is likely to fail because their fitness is initially too low and they would die off in the next generation. Alternatively, you can increase the mutation chance or number of mutations in your individuals in order to encourage solutions with strong fitness.
Notable solutions to these problems include:

*Crowding
**Having an offspring replace the most similar individual and only a percentage of the population mates
*Restricted Mating
**There are conditions under which a pair can mate, usually determined by the hamming difference (number of changes required to make the pair equal)
*Sharing
**The fitness function of an individual is shared with it's neighbors. This means that the survival probability is a function of a many individuals and not just one. This increases the number of computations required to compute optima and is best used for problem domains where solutions are generally known
*Multiploidy
**Individuals can recover information from a previous generation

There are more, but each of these deserves their own topic of research

'''N Queens'''

The next exercise was to evaluate the N queens problem, where you must place a queen on each column and each row such that there are no diagonals. We were given two mutation methods to experiment with, PartiallyMatched and TwoPoint. Two Mapped will swap queen positions from between two random points and Two Point will also switch places of queens so that they are not redundant. For example, in Two point, two indexes are chosen, one for each individual, then individual one swaps the queen that is selected for the second individual with whatever they had at that location. This way, there are not multiple queens in the same column.

Next, I evaluated how quickly the algorithm converged. This happened around the 30th generation. By changing the evaluation method to calculate the square of the conflicts in each row, the genetic algorithm converged more quickly. However this was just a visual effect as the the values were still squared. Because the values are ordered, a linear equation will have no noticeable effects. You would need to add a second metric to the sum to get converging values. Getting 1 queen remaining was very common and can be explained by having low genetic diversity such that many changes are required to move away from the 7 queen solution.

I also tried to play around with the crossover, mutation, and selection functions. I did not have time to set up an automated analysis by running each experiment around 20 times and taking the average, but I did look at qualitative data. Increasing the tournament selection up to 5 had very little effect since it just increased the chance that a high fitness individual would be chosen. If a low fitness individual is required to move away from the current solution, it would not be picked. I also looked into the cxUniformPartiallyMatched, but it did not improve performance as expected. Increasing the probability for the crossover too high would be no better than generating a new random sample. 

I also tried to restrict the algorithm from reaching a fitness score of 1. The reason being is that more often than not, solving for 7 queens is trivial compared to solving for 8. In order to correct, I would need to backtrack the solution to a state that is close to the solution that was visited in the past. By restricting the minimum to not include 1, that meant the mutation has to make 2 correct moves at once. This can be a bad thing because it makes it more lucky to have a correct solution, but if we account for duplicates being the majority of selected individuals, then we have a good shot at getting to the minimum. This did not work in practice, and I am still testing out new ways to measure the fitness function. There should be a second metric to combine with the sum such that we get the same fitness with different diagonals found.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Work through DEAP tutorial notebooks
|Completed
|August 25, 2021
|August 31st, 2021
|August 31st, 2021
|}
