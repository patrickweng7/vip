== Elan Grossman ==

Team Member: Elan Grossman

Email: egrossman3@gatech.edu
Cell Phone; 770-595-8339

[[files/Elan_Profile.jpg|thumb|80x80px]]

Interests: Machine Learning, Robotics, Puzzles, AR/VR

== September 22nd, 2021 ==
'''Team Meeting Notes'''

* Assignment for week was to use DEAP to generate Pareto optimal solutions to titanic problem
* Solution to problem is located at [[Bootcamp Subteam 1]]

'''Lab Notes'''
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Work with sub-team on Titanic Dataset
|Completed
|September 22nd, 2021
|September 29th, 2021
|September 29th, 2021
|}

== September 15th, 2021 ==
'''Team Meeting Notes:'''
* We reviewed the Titanic Dataset hosted by Kaggle: [https://www.kaggle.com/c/titanic/data]
* Dr. Zutty walked through a Jupiter Notebook showing us how to clean and prepare data
** A test.csv and train.csv were given to us, which is a splitting of the data of the passengers of the titanic.
** This included data such as gender, ticket number, cabin number, age, ticket fare, and port of embarkation.
** The test.csv did not contain whether or not the passengers survived, but the train set did.
** The Train set removed cabin number, name, and ticket as they are not continuous or discrete variables
** Then the train set was split into a different train and test set for modeling
** Multiple models were shown to us without any hyper-parameters set
* Our goal as a team was to work together to modify the training and test sets and build an algorithm, one for each member, such that each was co-dominate with each other. In other words, no one algorithm would be dominant for number of False Positives and False Negatives, but one or the other

'''Lab Notes'''
* The Output of our work is located on our team page [[Bootcamp Subteam 1]]
* For my algorithm, I choose the Random Forest Classifier
* I was able to obtain an algorithm that produced 25 False Positives and 29 False Negatives
* For the passengers who died, I obtained a precision and recall score of 86% and 87% respectively
* For the passengers who survived, I obtained a precision and recall score of 75% and 73% respectively
* I also played around with the hyper-parameters such as max_depth which controls how deep the nodes can get in a forest and min_samples_split which determines how many samples are required for a split to occur. By default max_depth is not set and you only need 2 samples to split with
* Changing min_samples_split did not decrease the number of incorrect classification. This is because there is not enough data for there to ever be 3 or more items to split on
* Changing the max depth to 4 did produce the results listed above, which were greater than anything else I tried
* For further tuning, I referenced [https://scikit-learn.org/stable/modules/grid_search.html] to explore using the RandomizedSearchCV and GridSearch APIs. For example, I used
<blockquote>
model_params = {
    "max_depth": range(2, 40),
    "min_samples_leaf": range(1, 5),
    "min_samples_split": range(2, 5),
}
</blockquote>
This produced a range of hyper parameters to experiment with. Grid Search searched through all combinations of variables, and the Randomized search searched through 100 random combinations of the variables. Neither solution produced an optimal outcome compared to my previous experiments

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Work with sub-team on Titanic Dataset
|Completed
|September 15th, 2021
|September 22nd, 2021
|September 21st, 2021
|}

=== Self Assessment ===

{| class="wikitable"
!Area
!Score
!Notes
|-
|Notebook Maintenance
|25
|
|-
|Meeting Notes
|15
|
|-
|To Do Items
|5
|
|-
|To do list consistency
|10
|
|-
|To do list items checked and dated
|5
|
|-
|Level of Detail
|13
|I could do a better job of linking my sources and going into detail on relevant literature
|-
|References
|8
|I had trouble with the uploading pictures during the first few weeks and didn't save my data at the time. I do make references to documentation and papers when I can, but it could be improved
|-
|Useful Resource for team
|14
|The journal I write contains my thoughts as I work through the lab and is not merely a list of completed tasks. I hope this detail is sufficient for someone else to understand the motivations behind my research and experimentation so that they can follow along and offer suggestions or improvements
|-
|}

Total Grade: 95

== September 8th, 2021 ==

'''Team Meeting Notes'''
* Focus on optimization of GAs
* Learned about Pareto Optimality
** Something is Pareto optimal if there is no other individual that out performs it in all fitness measurements
** If an individual is Pareto optimal, we say that it is non-dominated by individuals that it outperformsgs
** The collection of individuals that are Pareto optimal create a curve known as the Pareto front. This front is a the area under which more optimal solutions could be found. By minimizing or maximizing the area under the curve, one can find a solution space that is more optimal.
* We learned about optimizing for multiple fitness evaluation
* We covered the confusion matrix and associated measures such as sensitivity, precision, and accuracy:[https://en.wikipedia.org/wiki/Precision_and_recall]
[[files/egrossman3/Precisionrecall.svg]]
* We covered 2 tournament algorithms
** Nondominated sorting genetic algorithm II
*** This algorithm assigns a rank to each individual. The rank is computed by finding all of the Pareto optimal individuals and assigning them the current rank (starting at 0) and then removing them. The rank is increased by 1 and the next set of non dominated individuals is found and assigned the current rank.
*** Tie-breakers are resolved by computing the crowding distance which favors individuals with fewer individuals close to itself that are also in the same front. This means that individuals that are further away from other individuals are favored to promote diversity
** SPEA2 - Strength Pareto Evolutionary Algorithm [https://kdd.cs.ksu.edu/Courses/CIS830/Handouts/P8.pdf]
** Zitzler, E. et al. “SPEA2: Improving the strength pareto evolutionary algorithm.” (2001).
*** First the strength of an individual is calculated by how many other individuals it dominates
*** Then the rank is computed as the sum of strengths of individuals that dominate it. This means that the Pareto front individuals all have rank 0
*** Tie breakers are determined by an extra factor that is the inverse distance to a kth nearest neighbor

'''Lab 2 Notes Continued'''

I kept trying to decrease the area under the curve of the Pareto front, but I found that the results of the optimization changed drastically every time it was ran. Because my results were so low initially, it was difficult to reduce them by 25%. This is especially true if you take into account that you might run the algorithm multiple times before getting a low number.
[[files/egrossman3/pareto_front.png]]

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Finish Regression Notebook
|Completed
|September 1, 2021
|September 15, 2021
|September 7, 2021
|}

== September 1st, 2021 ==
'''Team Meeting Notes:'''
* Reviewed Wiki How-Tos
* Covered using GP to generate functions instead of optimizing a solution
* An example is generating a mathematical function such as sin(x)
* What you could do is generate the inputs and outputs and then use GP to generate an equation that maximizes the accuracy of the solution
* This is similar to machine learning, except you don't use gradient descent to optimize the algorithm, but a fitness function
* Functions are represented as trees with two types of nodes
** Nodes (or Primitives) which represent transformations such as addition, subtraction, summation, factorials, etc.
** Leaves (Or Terminals) which represent data such as constants or even variables (x, y, z)
* Leaves cannot have children and Nodes must have 2 children
* Tree can be represented as a recursive tree structure
** [-, 2,* 3, x] is equivalent to 2-3*x
* Crossover is now exchanging nodes between trees
** For example, we could change [-, 2,* 3, x] to [-, -,4,x,* 3, x] to be 4-x-3x where [-,4,x] is a node in a tree
* Mutation is not only changing a node, but deleting one or adding a new node 

'''Lab 2 Notes'''

I worked through the module adding two more primitives, the sin function and a maximum function to the tree. The tree generation method, genHalfAndHalf where half the time it generates a tree with equal depth for each node, and the other half does not (or at least does between a minimum and maximum depth).

When building the toolbox methods, I added an insert method to generate a new primitive in the tree through insertion instead of replacement. Lastly, I installed the networkx library to visualize the graph. When running my code for the first time, my optimization found this individual:
Best individual is maximum(add(multiply(maximum(add(multiply(add(x, multiply(x, x)), x), x), x), x), x), x), (1.298785972010402e-16,)
This is equivalently: max(x+x*max(x+x*(x^2 + x),x),x) which with the maxes removed becomes: x+(x^2 + (x^4 + x^3)) which is equivalent to our evaluation method, but with maximum added in.

Next, we tried a much harder problem to solve:
-x + sin(x^2) + tan(x^3) - cos(x)

We also defined Pareto Dominance. This property means that for an individual outperforms another individual in all fitness values. This is equivalent to saying that there is no trade-off between selecting an individual in a multi-objective fitness optimization. Then I implemented the statistics and algorithms package in DEAP. The algorithm we used, eaMuPlusLambda can be found at [https://deap.readthedocs.io/en/master/api/algo.html?highlight=eaMuPlusLambda]. What's nice about this functionality is that we don't have to write the GP algorithm from scratch and we also get a very nice summary of each generation with statistics. This cuts down on code we have to write and reduces the output to something readable.

We also generated a visual to represent the Pareto front. This is a list of best individuals that minimize the area under the curve between two fitness objectives. Essentially, this represents a boundary that estimates the minimum error we can obtain and the trade-off between multiple fitness objectives.

{| class="wikitable"
!Mu
!Lambda
!CXP
!MUTPB
!Result
|-
|50
|100
|0.5
|0.2
|2.36
|-
|50
|150
|0.5
|0.2
|4.043
|-
|50
|50
|0.5
|0.2
|2.33
|-
|50
|100
|0.3
|0.2
|3.702
|-
|50
|75
|0.6
|0.7
|2.34
|}


'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Due Date
!Date Resolved
|-
|Work through Regression Notebook
|Completed
|September 1, 2021
|September 7, 2021
|September 7, 2021
|}

== August 25th, 2021 ==
'''Team Meeting Notes:'''
* Covered Course Syllabus and Individual Responsibilities
* Intro to genetic programming
** Individual = a single subject defined as a set of features
** Population = a collection of individuals
** Objective = Maximization of a goal
** Fitness = Objective score relative to other individual scores
** Selection = Method to determine which experiment to try next through choosing a number of individuals to succeed
*** Emade algorithm uses a combination of tournament and proportionate selection techniques
** Mating = Exchanging features between individuals
** Mutation = Changing features in an individual
* Basic Genetic Programing algorithm is:
** Randomize or seed population
** Determine Objective and Fitness
** Repeat: Selection -> Mating -> Mutation -> Fitness Evaluation
* Used One-Max problem as an example of Genetic programming
* Covered Jupyter notebooks

'''Lab 1 Notes''' 
I began the lab by running each cell in the Jupiter notebook step by step, but started to get lost in the details. The creator method of the DEAP framework in particular is capable of producing multiple types of objects with the same function call. I assume this is to create a directed graph similar to tensorflow or spark. So I went over to the documentation at [[https://deap.readthedocs.io/en/master/]] to read more.

The creator method is a way to create classes on the fly using methods instead of files. In the documentation the example is that
 create("Foo", list, bar=dict, spam=1)
Is equivalent to
 class Foo(list):
    spam = 1
    def __init__(self):
        self.bar = dict()

Therefore,
 creator.create('Individual', list, fitness=creator.FitnessMax)
Is creating a class called "Individual" that inherits a list and contains an attribute that is an instance of the FitnessMax class.
This is better summarized in [[https://deap.readthedocs.io/en/master/tutorials/basic/part1.html#creating-types]]

I was able to run through the rest of the lab with no problems and began to become familiar with the conventions of the DEAP framework and how we can register the various fitness, mutation, and mating functions to our toolbox. One thing of note is to use the copy method from tools when mating and mutating individuals. This is to ensure that we do not modify individuals in the population when creating the offspring.

'''Duplicates'''

What struck me as odd was the selection of the offspring. The tournament selection was set to evaluate 3 individuals at a time, but it was also set to create 300 offspring. Our population is also 300. According to the documentation, n individuals are chose k times. In this case n=3 and k=300. This means that there is a good number of duplicate individuals in the population. I also suspected that the number of duplicates would increase over each generation. The populations will converge to all 1s, so the probability of two sets with 99 ones each at different positions generating the same set increases. The counts of duplicates at each generation was as follows:
 [34, 65, 76, 48, 51, 48, 54, 49, 50, 62, 57, 58, 52, 40, 62, 38, 57, 72, 67, 96, 81, 93, 92, 100, 117, 116, 131, 150, 173, 175, 202, 196, 197, 211, 220, 215, 231, 229, 236, 238]. 

Perhaps there needs to be a clean up set to reduce duplicates and increase the search space. The effect of duplicates is that it increases the probability that a solution will be selected during the tournament, and therefore weighs the optimal solution towards these individuals. I read an article on maintaining diversity in in a population.

Gupta, Deepti and S. Ghafir. “An Overview of methods maintaining Diversity in Genetic Algorithms.” (2012). [[https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.413.7546&rep=rep1&type=pdf]]

One reason to maintain diversity is to prevent the GA from converging onto a local optima. Randomly generating new individuals is likely to fail because their fitness is initially too low and they would die off in the next generation. Alternatively, you can increase the mutation chance or number of mutations in your individuals in order to encourage solutions with strong fitness.
Notable solutions to these problems include:

*Crowding
**Having an offspring replace the most similar individual and only a percentage of the population mates
*Restricted Mating
**There are conditions under which a pair can mate, usually determined by the hamming difference (number of changes required to make the pair equal)
*Sharing
**The fitness function of an individual is shared with it's neighbors. This means that the survival probability is a function of a many individuals and not just one. This increases the number of computations required to compute optima and is best used for problem domains where solutions are generally known
*Multiploidy
**Individuals can recover information from a previous generation

There are more, but each of these deserves their own topic of research

'''N Queens'''

The next exercise was to evaluate the N queens problem, where you must place a queen on each column and each row such that there are no diagonals. We were given two mutation methods to experiment with, PartiallyMatched and TwoPoint. Two Mapped will swap queen positions from between two random points and Two Point will also switch places of queens so that they are not redundant. For example, in Two point, two indexes are chosen, one for each individual, then individual one swaps the queen that is selected for the second individual with whatever they had at that location. This way, there are not multiple queens in the same column.

Next, I evaluated how quickly the algorithm converged. This happened around the 30th generation. By changing the evaluation method to calculate the square of the conflicts in each row, the genetic algorithm converged more quickly. However this was just a visual effect as the the values were still squared. Because the values are ordered, a linear equation will have no noticeable effects. You would need to add a second metric to the sum to get converging values. Getting 1 queen remaining was very common and can be explained by having low genetic diversity such that many changes are required to move away from the 7 queen solution.

I also tried to play around with the crossover, mutation, and selection functions. I did not have time to set up an automated analysis by running each experiment around 20 times and taking the average, but I did look at qualitative data. Increasing the tournament selection up to 5 had very little effect since it just increased the chance that a high fitness individual would be chosen. If a low fitness individual is required to move away from the current solution, it would not be picked. I also looked into the cxUniformPartiallyMatched, but it did not improve performance as expected. Increasing the probability for the crossover too high would be no better than generating a new random sample. 

I also tried to restrict the algorithm from reaching a fitness score of 1. The reason being is that more often than not, solving for 7 queens is trivial compared to solving for 8. In order to correct, I would need to backtrack the solution to a state that is close to the solution that was visited in the past. By restricting the minimum to not include 1, that meant the mutation has to make 2 correct moves at once. This can be a bad thing because it makes it more lucky to have a correct solution, but if we account for duplicates being the majority of selected individuals, then we have a good shot at getting to the minimum. This did not work in practice, and I am still testing out new ways to measure the fitness function. There should be a second metric to combine with the sum such that we get the same fitness with different diagonals found.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Work through DEAP tutorial notebooks
|Completed
|August 25, 2021
|August 31st, 2021
|August 31st, 2021
|}
