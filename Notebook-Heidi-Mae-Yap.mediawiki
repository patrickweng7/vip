== Team Member ==
Team Member: Heidi Yap

Email: hyap7@gatech.edu

Cell Phone: +1 774-405-3099

Interests: Machine Learning, Python, Volleyball, Hiking, Traveling, Working Out

=Fall 2021=
'''General Info'''
* Image Processing subteam
** Teammates: [[Notebook Harris Barton|Harris Barton]], [[Notebook Maxim Daniel Geller|Maxim Geller]], [[Notebook Monil Manish Kaneria|Monil Kaneria]], [[Notebook Aryaan Anuj Mehra|Aryaan Mehra]], [[Notebook Temiloluwa Orefoluwa Ogunsanya|Temi O]], [[Notebook Dhruv M Patel|Dhruv Patel], [[Notebook Rohan Batra |Rohan Batra]], [[Notebook Elan Grossman|Elan Grossman]], [[Notebook Austin Tinghao Peng|Austin Peng]], [[Notebook Eashan Sinha|Eashan Sinha]]
* VIP meetings 5-5:50pm on Mondays
* Subteam meetings 5:45-6:45pm on Wednesdays

==Week 16: December 6th - December 10th==
===Main Meeting Notes===
* Peer evals close Wednesday Dec 8th at 4pm
* Notebooks due Monday Dec 13th at 9am
* Visualizations for prezi: tree structure for algorithms, pareto fronts and AUC, tracking things through time, any mined info from databases
* 20 min for presentation
* everyone is finishing their merges
* Aryaan, Monil, and Dhruv are fixing bugs
* we distributed experiments:
** Baseline runs - Max
** NSGA3 - Dhruv
** Lexicase - Harris & Austin
** Mate Mutations - Eashan & Aryaan
** Second Mate Mutations - Rohan & Elan
** Third Mate Mutations -  Heidi & Temi
** baseline (nsga2) vs nsga3
** baseline vs lexicase
** (maybe) nsga3 vs lexicase?
** baseline(mate mutations) vs some combination of the mating methods?
** (maybe) baseline vs a new selection method AND new mate mutation methods
* finish presentation slides
* New environment for python 3.8: ]
** /storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/img_proc_tf26
* New PBS Script to launch EMADE:
** #PBS -N emade-chest
** #PBS -l nodes=1:ppn=4
** #PBS -l pmem=4gb
** #PBS -l walltime=1:00:00
** #PBS -q pace-ice
** #PBS -o emade-chest.out




==Week 15: November 29th - December 5th==
===Main Meeting Notes===
* We think there is an issue with the memory of the GPU not allowing enough primitives to be used, so we will try experimenting with a smaller batch size to see if that helps
* Monil figured out that there is something wrong with his helper method causing errors for the hyper-feature primitive so he will work on that
* Goal to have code freeze by end of this week
* changing objective to ROC AUC instead of precision AUC for testing NSGA III
* using precision AUC, the results shows actually a slightly better AUC for NSGA II than NSGA III

===Subteam Meeting Notes===
* I am setting up for experiments
* needed to free up disk space
* help debug errors with standalone tree for hyper features
* Error message:
** Received: NNLearner(ContrastSobelHyperfeature(ARG0, passTriState(TriState.STREAM_TO_STREAM), passAxis(Axis.FULL)), OutputLayer(DropoutLayer(0.584087228573285, InputLayer())), 98, AdamOptimizer)
**With Hash 353955d73f3c86294017108be1d7dd7702e3cd4df2f9455969c611dfd5031439
**Computed in: 1057.614228963852 seconds
**With Fitnesses: (inf, inf)
**With Age: 0
**With Error:  **********You must compile your model before training/testing. Use `model.compile(optimizer, loss)`
* Monil and Dhruv running into same bug, which we figured out was due to using an older version of python
* I finished the data preprocessing slides, changed them from midterm because I changed the code from multilabel to single label.
** Link to slides : [https://docs.google.com/presentation/d/1c6c51KhAIRJMMRo2mzNDDFsWm_MkFgXmNa3j7aLppdk/edit?usp=sharing]
* picked sharpening filter, not sure if this will be added to the code.
* Updated code with sharpening filter:
** [https://colab.research.google.com/drive/1RCwdJqF76K7DemVErY5k0GYoj_V3r2As?usp=sharing]

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Prepare for Experiments and add slides for presentation
|Complete
|Nov 29th, 2021
|Dec 5th, 2021
|Dec 3rd, 2021
|-
|Update Wiki Notebook
|Complete
|Nov 29th, 2021
|Nov 5th, 2021
|Nov 5th, 2021
|-
|}

==Week 14: November 22nd - November 28th==
===Main Meeting Notes===
* The baseline run has a very low ROC AUC of 0.48
** possibly due to using NSGAII instead of NSGAIII
* Monil had to deal with an error involving the contrast method, Jason thinks there is something weird about this bug and is going to look into it.

===Subteam Meeting Notes===
* No subteam meeting this week due to Thanksgiving
* No tasks for anyone

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Update Wiki Notebook
|Complete
|Nov 22nd, 2021
|Nov 29th, 2021
|Nov 29th, 2021
|-
|}

==Week 13: November 15th - November 21st==
===Main Meeting Notes===
* ask Zutty for help with lexicase
* continue debugging pace errors for new members
* assign new tasks
* reminder from Jason to add individual contributions to notebook
* Hackathon details: Nov 21, 1-5pm
* Our elevator pitch: We are researching how we can improve EMADE’s performance on image processing tasks; this semester in particular we are looking at multi-class image classification. Using a baseline run of EMADE on the dataset we processed, success for us looks like seeing improvements in ROC and (second metric? Lol i don’t remember unless we are keeping # params) compared to the baseline run when evaluated independently and in combinations.
* Upload the new data to pace


===Subteam Meeting Notes===
* Work session mostly
* NZP files were actually empty
* must debug what is going on with that
* Found errors in the labels.csv file causing a very small amount of data
* fixed errors with the file, but now I must fix other errors with the mapping because the mapping currently is meant for multi-label
* Monil finished stand alone tree but not enough data for results yet
* Fixed all the errors by changing the "get_data" method and changing the test_list.txt file and uploaded new data to pace
* The problem with "test_list.txt" was that it still included the paths to images that were classified as multi-label, and we removed those images from the data frame. 
* now going to work on sharpening filter
* The pull request for new data pre-processing files that I edited:
** [https://github.gatech.edu/amehra37/emade/pull/8/files]

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Finish Data pre-processing
|Complete
|Nov 15, 2021
|Nov 22, 2021
|Nov 17, 2021
|-
|Work on sharpening filter
|Complete
|Nov 15, 2021
|Nov 22, 2021
|Nov 21, 2021
|-
|Update Wiki Notebook
|Complete
|Nov 15, 2021
|Nov 22, 2021
|Nov 21, 2021
|-
|}

==Week 12: November 8th - November 14th==
===Main Meeting Notes===
* lots of pace errors for new members
* help them debug everything
* errors with stand alone tree still 
* We will likely have a finals Hackathon the weekend of 11/20-21
* Another word for semantic : behavioral performance
* Use new install script for env
* pace-check-queue pace-ice-gpu to check GPU queues

===Subteam Meeting Notes===
* work session
* clean up data pre-processing to push into repository and get data set
* created data frame that removed images classified as multi-label with "|"
* also deleted these images from the image folders and mapped the names to match up correctly
* put data set in pace for Max to do baseline run
* help new members set up pace
* start working on sharpening filter
* read papers to figure out ideal filters to try for hyper-features:
** [https://www.semanticscholar.org/paper/Image-Enhancement-using-Sharpen-Filters-Singh/2bc77b60213cb2bbd3cdfeb55665581a7388d839]

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Finish Data pre-processing
|Complete
|Nov 8, 2021
|Nov 14, 2021
|Nov 12, 2021
|-
|Update Wiki Notebook
|Complete
|Nov 8, 2021
|Nov 14, 2021
|Nov 13, 2021
|-
|}


==Week 11: November 1st - November 7th==
===Main Meeting Notes===
* New team members: Elan, Eashan, Rohan, and Austin!
* Zutty asks What if we just remove instances that are multilabel?
* Binary class will make it difficult to test Lexicase and NSGA III, will also make those changes less effective
* Consideration: reprocess data to just have single label for train/test (if there are not too too many multi-label cases), look at distribution of labels to ensure this will produce enough data
* To get vector out: dump out the numpy array inside the evaluation method, reinstall GPFramework, and then run individual with database or standalone tree evaluator script
* Lexicase on test cases
* Food for thought: what about where in the image a disease is present, not just whether it exists or not (room for future work here! A bounding box for object detection!)
* For Wednesday: EMADE crash course for new membs, then nn-vip crash course, then finally introduce new ideas we’ve been working on

===Subteam Meeting Notes===
* New members tasked to set up pace
* I will help new members and explain hyper-feature specifics for those who are interested
* The p-value was very high which was causing the selection methods to fail. 
* Next steps:
** Fix environment errors
** Testing the new changes for nsga 3
** New member and Harris will try out Lexicase
** Test the current version and talk to Jason more about exactly what the difficulties are
** Errors with the load environment problems on the standalone tree evaluator and trying to debug the new problem once PACE is back online
** Trying out implementing a new hyper feature:
** Sharpening features in addition to the edge detectors
** Need to create new dataset 
** Max has been working on fixing bugs for the baseline run that we worked on
** Someone new can definitely work on squashing bugs for the emade runs (since the data types don’t match)

* New team assignments:
** Rohan - hyper features
** Elan - infrastructure, doing runs on pace
** Austin - selection methods
** Eashan - mating, mutations

* I will change the preprocessing to remove instances that are multilabel and keep it as a multiclass
* Ended up being very sick this week so extended task to the next week

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Change Data pre-processing
|Complete
|Nov 1, 2021
|Nov 8, 2021
|Nov 12, 2021
|-
|Update Wiki Notebook
|Complete
|Nov 1, 2021
|Nov 8, 2021
|Nov 7, 2021
|-
|}


==Week 10: October 25th - October 31st==
===Main Meeting Notes===
* Bootcamp and subteam presentations
* Convince new members to join our team!
* our presentation: 
** [https://docs.google.com/presentation/d/100keUAjam-8e1-SMLtejP9ZQN38nmCJ_yA1t2HW-JPs/edit?usp=sharing]

===Subteam Meeting Notes===
* Thinking about changing to binary class
* Working on changing the data pre-processing from multi-class to binary class
* CheXNet data was looking for just pneumonia (1 for pneumonia, 0 for everything else)
* Binary → {1, 0}
* We can continue pursuing this, or change our dataset labels (to do multilabel classification)
* Multilabel → { [1, 2,...], [3, 6, …] … }
* Challenge in how EMADE looks at labels for each images
* Decided to pursue binary classification for disease detection

* Tasks :
** Fix modifications & merge
** Decide on task (binary or multilabel) 
** Onboard new members
** Reprocess data (disease or no disease)
** Change objectives (ROC-AUC, # parameters)
** Create new tasks
** Temi: refactor semantic crossover and mutation to receive expected data type
** Monil: Build a tree, open a pull request 
** Heidi (me) : reprocess data
** Aryaan: literature search geometric crossover and mutation
** Dhruv: test NSGA3 locally and see if you can find errors. Otherwise, revert changes (aside from toolbox register), test to make sure it works with reverted changes, and push changes + create pull request.
** Harris: PACE-ICE run, lexicase
** Max: bug squashing tree errors

* I changed the Preprocessing_Consolidated.py file to preprocess data to be binary 
* link to my new code:
** [https://github.gatech.edu/hyap7/VIP-related-files/blob/main/Preprocessing_Consolidated.py]


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Change Data pre-processing
|Complete
|Oct 25, 2021
|Nov 1, 2021
|Oct 31, 2021
|-
|Clone pre-processing branch and download data
|Complete
|Oct 25, 2021
|Nov 1, 2021
|Oct 31, 2021
|-
|Update Wiki Notebook
|Complete
|Oct 25, 2021
|Nov 1, 2021
|Nov 1, 2021
|-
|}


==Week 9: October 18th - October 24th==
===Main Meeting Notes===
* Dr. Zutty said to think about how we are going to compare our baseline run to the new additions
* We need to help Max with the bugs for getting the first baseline run. 
* Presentation is NEXT WEEK!
* When doing your runs:
** 1 master - 1 core is constant
** CPU hours should add up to how much time is left in the class
** Number of hosts means how many worker jobs
** Number of CPU per worker is core count per worker
* Design an experiment to test your changes/parameters
* With all these different parameter tweaks, give thought to how will we show that we made improvement
** Pair things together?
** Do one parameter change at a time?

===Subteam Meeting Notes===
* We should each run EMADE in our pairs, individual changes
* Use those to compare against the baseline
* Max tested PACE and it works, though primitives are erroring out for the nn tree
* Code not using nsga3, nsga2 is hard-coded
** Need to register nsga3 into toolbox
** Call it in the code
** Why’s it not pulling from the XML?
* We have four changes from the baseline, test all of them SEPARATELY
** Geo. Crossover
** Semantic Crossover
** Hyper Features
** NSGA-3 selection
* Compare which of these four had the best changes
* Objectives are: area under PR curve, and number of parameters
* Checking status
** Qstat command
** -n lists node the job is on
** -u <user> specifies the user’s jobs
** qstat -q pace-ice-gpu to check GPU usage
** qsub pbsmysql.pbs
* PACE-ICE Config: (put in XML)
** MySQL has 8hr walltime
** EMADE has 7:40hr walltime
** # hosts is 1, # workers per host is 1
** RAM per host/master is 8GB
** Anaconda Environment /storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs
* PACE-ICE Anaconda
** First log in
** Module load anaconda3 /2020.02
** Loads anaconda environment in your pace
** conda activate /storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/envs/
** Once you’re in the environment, you can run reinstall script
* Launch scripts (for ease)
** MySQL launch script: Pace files/pbsmysql.pbs
** To start mySQL, cd into /usr/ and then mysqld_safe --datadir='/storage/home/hpaceice1/USERNAME/scratch/db’
** EMADE one is Pace files/launchEMADEchest.pbs
** First time you run, you need to seed the run (see the launchEMADEchest script)

* Monil will work on making our hyper-feature into a primitive.
* I am working on getting in a run
* There were many server issues so this took a very long time. 
* Dhruv and Aryaan could not get their run to work because the run kept killing itself without outputing any errors. 
* I got my pace-ice run to work, but by the time Monil finished getting the hyper-feature into a primitive, my pace-ice wasn't working and it was too late to get a full run in, so I will do this next week. 
* Finish presentation 
* pull request for our combined features into a primitive: 
**[https://github.gatech.edu/amehra37/emade/pull/6/files]

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Make sure I can do an emade run on pace-ice
|Complete
|Oct 18, 2021
|Oct 25, 2021
|Oct 23, 2021
|-
|Finish presentation
|Complete
|Oct 18, 2021
|Oct 25, 2021
|Oct 23, 2021
|-
|Package hyper-features into a primitive
|Complete
|Oct 18, 2021
|Oct 25, 2021
|Oct 24, 2021
|-
|Update Wiki Notebook
|Complete
|Oct 11, 2021
|Oct 18, 2021
|Oct 18, 2021
|-
|}

==Week 8: October 11th - October 17th==
===Main Meeting Notes===
* no class (Fall break)

===Subteam Meeting Notes===
* combine edge detector with contrast method
* add to GP framework and test with EMADE
* Max is having problems with getting the first baseline run done due to mismatched data types and other bugs
* NSGA III has been implemented and just needs to be tested
* Implementing new geometric (simulated binary and blended) and semantic crossover methods to test whether we can improve diversity during the evolutionary process
* Start making presentation early next week
* Reminder: mid-sem presentation is on 10/25
* Do comparison run after merging our changes in
* Be prepared to talk about what we worked on individually/in your pairings (will need to put it on the slides)
* Before Monday:
** Verify changes don’t screw up EMADE
* our code for combined methods:
** [https://github.gatech.edu/hyap7/VIP-related-files/blob/main/hyperfeatures.py]

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Combine Edge Detector with Contrast Method
|Complete
|Oct 11, 2021
|Oct 18, 2021
|Oct 18, 2021
|-
|Add hyper features to GP framework
|In Progress
|Oct 11, 2021
|Oct 18, 2021
|--
|-
|Update Wiki Notebook
|Complete
|Oct 11, 2021
|Oct 18, 2021
|Oct 18, 2021
|-
|}


==Week 7: October 4th - October 10th==
===Main Meeting Notes===
* peer evals due Friday
* Dr. Zutty gave advice on seeding
** if we ever make changes to primitives, we must register them in the primitive set correctly
** common cause of parsing problems
* Dr. Zutty said to check the code for existing use of Sobel filter and gray level transform
* Test our hyper-features with image data and EMADE rate
* We are trying to minimize area under curve for precision recall
* Reason: we have multi-label data, traditional accuracy metrics do not work.
* Focus now: what we added is working correctly and generate comparison data (baseline data almost done)
* Anything put in the shared folder counts against personal quota (based on file ownership), Zutty can change it to his account and make it read-only
* We will test if we can do this with a conda environment
* Our datasets in PACE are stored in:
** /storage/home/hpaceice1/shared-classes/materials/vip/AAD/ip_group/datasets/chest_xrays/

===Subteam Notes===
* Test edge detector with image data
* NSGA III testing with working data sets
* Finding new methods for mating and mutations
* some troubles with seeding. 
* 224x224 size images
* Maxim gonna send his PACE setup so we can run EMADE on our pace-ice
* Aiming for end of fall break, getting runs working
* Monil working on testing some hyper features in EMADE, works locally
** Working with Heidi (me)
* Don’t need to launch emade run to test it, can use stand-alone tree evaluator
* There are template trees to help you
* Can use directly with your primitive, assigns fitness scores to your tree
* Dhruv/Harris are going to test NSGA3 (don’t need EMADE to make sure it works)
* Can try to make PACE-ICE work
* Will need actual EMADE run before mid-sem presentation to check improvement from baseline or not
* Aryaan/Temi looking at mating and crossover methods

* Goals before mid-sem presentation: Need baseline run and comparison runs
** Can show improvement OR deterioration
** What works, what doesn’t. What to try next.
** Most of us can make comparison runs
** Max gets EMADE files for PACE up and running (commit and merge pace functionality PR)
** Monil/Me test hyperparameters
** Harris/Dhruv test selection methods
** Aryaan/Temi test crossovers and mating

* Work Notes
** Inside the template file, we use <selection> to specify the selection method, nested inside <selections> (list of <selection>), nested in <evolutionParameters> (where we also specify <mutations>, <matings>, etc.)

* The image before hyperfeatures:
[[files/beforehyperfeature.png|none|thumb|200x200px|The image before hyperfeatures.]]
*The image with increased contrast:
[[files/contrast.png|none|thumb|200x200px|The image with increased contrast.]]
* The image with increased contrast and edge detector:
[[files/edge_detector.png|none|thumb|200x200px|The image with increased contrast and edge detector.]]


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Test Edge Detector With Image Data
|Complete
|Oct 4, 2021
|Oct 11, 2021
|Oct 10, 2021
|-
|Peer Evals
|Complete
|Oct 4, 2021
|Oct 8, 2021
|Oct 7, 2021
|-
|Update Wiki Notebook
|Complete
|Oct 4, 2021
|Oct 11, 2021
|Oct 11, 2021
|-
|}

==Week 6: September 27th - October 4th==
===Main Meeting Notes===
* We plan how to fork in the github
* assign new tasks for the week and give updates on progress

===Subteam Notes===
* Everyone make sure they are collaborator on Aryaan’s fork of emade and can push up changes
* Need to clone it down from his git repo, different than the main emade
* Branch off of the Image-Processing(nn-vip) branch of Aryaan’s emade fork when doing work
* Check if PACE ICE is working for y’all
* Dhruv and Harris work on testing NSGA3

* Monil and I are implementing a grey level transform that increases contrast and an edge detector filter for our images
* I am coding the edge detector filter using a sobel filter. 
* specifically, I have coded a method that takes an image and a filter and applies the filter
* then I coded a sobel filter np array to put into the method with the images.
* my code:
** [https://github.gatech.edu/hyap7/VIP-related-files/blob/main/sobel_filter.py]

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Implement Edge Detector Filter
|Complete
|Sept 27, 2021
|Oct 4, 2021
|Oct 4, 2021
|-
|Update Wiki Notebook
|Complete
|Sept 27, 2021
|Oct 4, 2021
|Oct 4, 2021
|-
|}

==Week 5: September 20th - September 26th==
===Main Meeting Notes===
* This week we want to start coding. Build NSGA-III, look more into “hyper-features”, and prepare some more versions of the dataset to work on.
** In order to be comparable to the paper, we can freely modify the training data, but the validation and test data should be in the same format as the paper we want to compare to. Since our test data is 224x224, we can either set the training data to that resolution or once we get an algorithm from the smaller scale data and rescale it to the desired resolution.
**Zutty says (if we want a direct comparison to another study) you cannot change the test data, however you can change training data however you want
**Essentially want to say one can outperform another algorithm on the same test

===Subteam Notes===
* We create our own branch off Image-Processing(nn-vip) to start doing our own work.
* Aryaan and Max should work on creating new versions of the dataset. Longer term, we’ll likely want to move the datasets to PACE-ICE as well as run EMADE off the shared class folder on it.
* For Max, figure out getting data on pace-ice and within the shared class folder on the cluster. Do a screen recording to share with everyone.
* Harris and Dhruv can begin implementing a selection method. We (should) have a baseline now thanks to Aryaan
* Temi continues research/work on mating/mutation methods. Incorporate geometric semantic crossover as a possible crossover method?
* Heidi (me) and Monil look at combinations of CV primitives that synergize together.
* Me and Monil are picking what hyper-feature pair to use. 
** Found this paper: [https://www.researchgate.net/publication/236125496_Image_processing_and_recognition_for_biological_images]
** Thinking of using a grey level transform along with an image filter to improve visibility


=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Pick hyper-feature combinations
|Complete
|Sept 20, 2021
|Sept 27, 2021
|Sept 26, 2021
|-
|Update Wiki Notebook
|Complete
|Sept 20, 2021
|Sept 27, 2021
|Sept 27, 2021
|-
|}

== Week 4: September 13th - September 19th ==
===Main Meeting Notes===
* Self evals due 
* Everyone has pace ice access
* Be careful with primitives and casting to correct form
* Decide classification vs detection (Dr.Zutty suggests EMADE works better with classification)
* Find paper to replicate with EMADE
* Image processing uses a lot of OpenCV and needs a lot of data coercion to get into the right format 
* Being careful with primitives and casting to correct form
* So many IP primitives, how do we help search do the right thing?
* E.g. a lot of primitives serve similar purposes like window functions, how do we tell it it’s the “same flavor”
* Need to decide to do classification or detection (zutty says EMADE would work better with classification)
* Using classification, how do we go about usage of neural networks? Do preprocessing then NN or use NNLearners
* Ask Jason to join at 6:00


===Sub-team Meeting Notes===
* We looked at several different papers:
** CheXNet : [https://paperswithcode.com/paper/chexnet-radiologist-level-pneumonia-detection]
** Diabetic retinopathy screeningDiabetic retinopathy screening: [https://doi.org/10.1016/j.irbm.2013.01.010]
** MED-net : [https://arxiv.org/pdf/2001.01005.pdf]
** traffic signs : [https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8215287]
** GP with convolution : [https://ieeexplore.ieee.org/document/8790151]
** hyper-features : [https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9185630]
* We decided that we want to replicate the paper on CheXNet using Genetic Programming
* Dr. Zutty mentions how we must compress the data because it is too large for EMADE 
** (use less images or compress images or greyscale)
* EMADE currently uses NSGAII as a selection method, but others may be better and it may be useful to implement them in EMADE
* Goal will not be to be better than CheXNet because CheXNet is hard to beat; the goal will be to find a way to implement it with EMADE 
* Tasks for the week:
** Me, Harris, and Dhruv will look into selection methods (NSGAII, NSGAIII, Lexicase, AND hypervolume indicator)
** Me and Monil will look at Hyper-feature packaging
** Aryaan and Temi will look at Clever mating and muting in parallel
** Max and Aryaan will do data prep (downsample)
* Stumbling blocks:
** Monil and I struggled to find information on hyper-parameters because it is an uncommonly used buzzword
* Selection methods:
** NSGA II : [https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=996017]
** Lexicase : [ https://arxiv.org/pdf/1907.04736.pdf]
** Hypervolume Indicator : [https://arxiv.org/pdf/2005.00515.pdf]
*Xray examples:
[[files/XrayExamples1.jpg|none|thumb|480x480px|Xray examples.]]

'''Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Research Selection Methods
|Completed
|September 13th, 2021
|September 20th, 2021
|September 18th, 2021
|-
|Research hyper-feature parameters
|Completed
|September 13th, 2021
|September 20th, 2021
|September 20th, 2021
|-
|}

== Week 3: September 6th - September 12th ==
===Main Meeting Notes===
* No meeting (Labor Day)

===Sub-team Meeting Notes===
* I am on the Image Processing subteam!
* I met my team members: Maxim, Harris, Monil, Aryaan, Dhruv, and Temi
* We decided to meet on Wednesdays at 5:45 pm
* We wrote out all of our objectives and assigned tasks to all of us
* Tasks: familiarize with EMADE and read potential Image Processing papers we could use genetic algorithms to approach
* Important to replicate papers with public data sets and methodology that can be automated with EMADE
* We picked Maxim to be our team leader
* I read papers on using image processing to diagnose skin cancer on microscopic images
* [https://arxiv.org/pdf/2001.01005.pdf]
* Self Eval: [https://docs.google.com/document/d/1CWNO6utWwxicxtxJuR4TinZZb9fgxt2C499Eo6MBfJk/edit?usp=sharing]

'''Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Make sure EMADE runs properly
|Completed
|September 8th, 2021
|September 13th, 2021
|September 11th, 2021
|-
|Read past published EMADE paper
|Completed
|September 8th, 2021
|September 13th, 2021
|September 12th, 2021
|-
|Find and read at least 1 paper we could potentially model
|Completed
|September 8th, 2021
|September 13th, 2021
|September 12th, 2021
|-
|}

== Week 2: August 30th - September 5th ==
===Main Meeting Notes===
* Rank top 3 sub-team choices
** 1. Image Processing
** 2. Covid Data
** 3. Stocks
* Since I am taking computer vision this semester and have always been super interested in Image Processing, I decided to choose Image Processing as my first choice for my subteam. 

'''Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Pick Subteam
|Completed
|August 23th, 2021
|August 30th, 2021
|September 3rd, 2021
|-
|}

== Week 1: August 23rd - August 29th ==
===Main Meeting Notes===
* first VIP meeting of the semester!
* learned about all the new and old subteams for the semester
* tasked with brainstorming possible topics for each one

'''Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Brainstorm for subteams
|Completed
|August 23th, 2021
|August 30th, 2021
|August 29th, 2021
|-
|}



=Spring 2021=
'''General Info'''
* New Students meet Wednesdays 5:00-5:50pm
* March 22nd 5-8pm transition meeting
* Then, meet Mondays 5:00-5:50pm

== April 30th, 2021 == 
'''Stocks Team:'''

* Objectives
** Implement TA-Lib indicators 
** Increase "Evolvability of EMADE individuals" 
** Larger dataset
** Statistical evals of individuals

* Background
** Representing price with Piecewise Linear representation
** Predict trade values with EMADE individuals
** Use exponential smoothing to get a threshold for when to do buy and sell prediction

* Objectives in the EMADE Runs 
** maximize profit percentage and average profit per transaction
** minimize variance profit per transaction and normal CDF on distribution

* Future Work
** Do statistical analyses on different seeding types
** Bounded objective functions
** Try trading frequencies, like hourly or weekly

'''ezCGP'''

* Objectives
** Improve neural architecture search
** Recreate CIFAR-10 results without relying on transfer learning
** Improve ability to visualize genomes
** Research, develop, and test new mating methods for Cartesian Genetic Programming

* Future Work
** Research, develop, and test new mating methods
** Incorporate existing Convolutional neural network architecture to develop new genome seeds

'''NLP Feedback'''

* Consider using False Positive Rate, False Negative Rate, and Num Parameters instead of just false positive rate and false negative rate. 

'''Modularity:'''
* Exploring different ways to abstract parts of individuals
* MNIST Run

* Future Work
** Deep ensemble models
** Modify evolutionary selection method and help diversify ARLs
** Diversity measure
** Integrate ARLs with EMADE's original architecture

'''Individual Reflection:'''
I really enjoyed all of the different presentations and I am happy with what everyone has accomplished. I am excited for next semester and the work I will put in for my group in the future. I personally found the stocks presentation the most interesting.

== April 26th, 2021==
'''Team Meeting Notes:'''
* Final presentations April 30th

'''Subteam Meeting Notes:'''
* finish final presentation slides
* Dr. Zutty joined our subteam meeting and talked about the evaluation time of individuals for auto ML
* We are meeting again on Wedensday at 6 pm to go over slides and do a practice runthrough.

'''Individual Reflection:'''
*I did the presentation slide about our resources 
[[files/resources.png]]
*I performed 3 8 hour seeded runs but got some errors along the way
* Run1 optimal individuals:
[[files/run1optimalindividuals.png]]
*run1 fpr :
[[files/run1fpr.png]]
* Run1 tree:
[[files/run1tree.png]]
*Run2 optimal individuals:
[[files/run2optimalindividuals.png]]
*run2 fpr:
[[files/run2fpr.jpg.png]]
* Run2 tree:
[[files/run2tree.png]]
* AUC:
[[files/AUC_heidi.png]]
* Misclassifications:
[[files/misclassifications.png]]
*I helped with visuals for the presentation using this code:
\[https://colab.research.google.com/drive/1COC0IcnuUyjiBiimgyp7xgTB5r24OusY#scrollTo=iVlkPZs_qf1d Link to code for visualization]

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get in a seeded in PACE
|Completed
|April 26th, 2021
|April 28th, 2021
|April 27th, 2021
|-
|Add slide about resources
|Completed
|April 28th, 2021
|April 29th, 2021
|April 28th, 2021
|}

== April 19th, 2021==
'''Team Meeting Notes:'''
* Peer evals are available
* Final presentation Friday, 4/30 6 - 8pm
* Dr. Zutty suggested us to use FPR/FNR as objective functions instead of accuracy

'''Subteam Meeting Notes:'''

* Try to use FPR, FNR, numParameters as objective functions instead of accuracy

* reduce size of training set to not eat memory 

* Cameron changed the seeding file to make seeded run easier

* repull the branch from Github and change what's on PACE

* Cameron showed new members how to seed before running EMADE
** LAUNCH script ahs a "seedAmazon.pbs" script
** Run seeding file from input_amazon.xml

'''April 23rd Subteam Meeting:'''
* prep for final presentation

* Probably going to have code freeze Wednesday ("deadline") at noon

* Goal: get a run of EMADE in PACE with FPR, FNR and start final presentation

'''Individual Reflection:'''
* I worked on seeded runs and practicing using PACE to get more comfortable. 
* PACE runs:

[[files/paceruns.png]]

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Peer Evaluation
|Completed
|April 19th, 2021
|April 27th, 2021
|April 26th, 2021
|-
|Seeded runs
|In Progress
|April 19th, 2021
|April 26th, 2021
|
|}


== April 12th, 2021==
'''Subteam Meeting Notes:'''
* Steven completed a run and presented results
* Cameron gave a presentation about the NNLearners class in the codebase
* Assigned Tasks:
** Evolution(Cam B, Jon, Karthik, Nishant):
***NNLearners cannot get very big so we often get trivial networks
***Theory is that they’re too failure-prone. Need to do runs and find reasons why
***Datatypes aren't always specific enough
***E.g., primitives can specify if an arg is an integer but can’t dictate sign(?). Need to consider instances where a negative number will break things
***Nnlearners can lack integral parts
***Sometimes lack output layers
**NNLearners as subtrees (Hua, Temi, Heidi(me)):
***Learners can take outputs of other learners as a feature vector
***Idea: make NNLearners do this as subtrees
***Work on model hyperparameters as primitives (Temi)
**PACE-ICE Stuff: (Cameron W, Member)
***Merge PACE functionality into cacheV2
***Merge PACE functionality & DB fix into nn-vip
***Create shared python environment by symlinking .conda and .local folders


'''Individual notes'''
* I have finally got PACE all set up and practiced runs. I need to figure out a good application for MAC that is similar to winscp. 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Practice using PACE and finish setup
|Completed
|April 12th, 2021
|April 18th, 2021
|April 18th, 2021
|-
|Work on NNLearners as subtrees
|In Progress
|April 12th, 2021
|April 18th, 2021
|
|}
== April 5th, 2021==
'''Team Meeting Notes:'''
* Hypothesis testing:
** we want to see if what we observe is statistically significant to our expected observation
** statistical tests: Student's t-test and Welch's t-test. 
***Welch's t-test is useful if we don't know our expected observation
** p-value and significance level are used to determine if we should reject or fail to reject our null hypothesis (lower p-value)

'''Subteam Meeting Notes:'''
* Main objective is for new members to finish getting PACE setup

'''Presentation Notes'''
*Supervised vs. unsupervised learning
**Supervised learning- Learn function that maps inputs to a label
**Loss function - how far is trained model from true function (using RMSE)

*Neural Networks: 
**Sigmoid - bad for backpropogation because weights don't change if gradient is zero (squish input to 0 and 1), but it is expensive to compute exponentials because output is not "zero-centered"
**Vanishing gradient - gradient approaches zero when input is very positive or very negative
**ReLU - cheap to compute, but sometimes large gradients can cause weights to update so that neuron never fires

*Train Neural Network:
**Feed Forward - evaluate the model 
**Back Propagation - use gradients to update the weights
**Learning rate - how much are layers changed at each iteration

*Train/test/validation split
**train set - model learns using the training set
**test set - measures performance of model

*Why a model could do poorly?
**Overfitting - model overlearns from training data, but can't generalize well to new data
**Underfitting - too much bias
** find healthy balance between underfitting and overfitting

*Dense/Linear/Standard Layer - fully connected dense layer

*Convolutional Layer - Relate data spatially

*Recurrent Layer- has memory of previous input


'''Individual Notes:'''
* I have been working on setting up PACE and practicing running EMADE, using the wiki and Cameron's youtube video. 
* I am having issues with my cnf file and cloning EMADE and PACE-files

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Practice running EMADE in PACE
|Completed
|April 5th, 2021
|April 9th, 2021
|April 12th, 2021
|-
|Set up PACE environment
|Completed
|March 29th, 2021
|April 3rd, 2021
|April 9th, 2021
|-
|}
== March 29th, 2021==
'''Team Meeting Notes:'''
* I am on the NLP subteam!!!

'''Subteam Meeting Notes:'''
* Intro to NLP subteam goals, challenges, + tools 
* Cameron gave a presentation on PACE and the nlp-nn branch in the EMADE Github
* I have to get PACE set up, clone EMADE, clone PACE files, get mysql setup, and other environmental setups.
* our meeting schedule for subteam meetings is Friday's at 6pm. 

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Set up PACE environment
|Completed
|March 29th, 2021
|April 3rd, 2021
|April 9th, 2021
|-
|}
== Week 10: March 22nd, 2021==
'''Team Meeting Notes:'''
* Presented conclusion, comparing our results between EMADE, MOGP, and ML
* Dr. Zutty gave advice on graphs and MOGP methods
* Watched other presentations
'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Fill out Canvas Poll to rank my subteam preference
|Completed
|March 22nd, 2021
|March 26th, 2021
|March 28th, 2021
|-
|}



==Week 9: Mar 17th, 2021==

===Lecture Notes===
* Help teams with downloading and server issues. 

===Subteam Notes===
*20 generations completed
* Prepare for presentation
* Some slides that we plan on adding including installation, issues faced, and how we resolve these issues.
* Lucas - Output analysis
* Scott - ML/MOG
* I'm doing the conclusion
[[files/ conclusion_heidi.png]]

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Finish work on Titantic using EMADE
|Completed
|Mar 17th, 2021
|Mar 22nd, 2021
|Mar 22nd, 2021
|-
|Finish final team presentation
|Completed
|Mar 17th, 2021
|Mar 22nd, 2021
|Mar 22nd, 2021
|-
|Update Wiki Notebook
|Completed
|Mar 17th, 2021
|Mar 22nd, 2021
|Mar 22nd, 2021
|-
|}

==Week 8: Mar 10th, 2021==
===Lecture Notes===
* Help teams with downloading and server issues. 
===Subteam Notes===
* Individually install Emade and SQL and connect to server or attempt to create server.
*Feature importance:
[[files/feature_importance_heidi.png]]
*Heatmap:
[[files/heatmap_heidi.png]]
*Pareto front:
[[files/pareto_front_heidi.png]]
*Code design:
[[files/code_heidi.png]]
[[files/code1_heidi.png]]
*Pareto front comparison:
[[files/pareto_front_heidi2.png]]
[[files/pareto_front_heidi2.png]]

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Continue working on Titantic using EMADE
|Complete
|Mar 10th, 2021
|Mar 17th, 2021
|Mar 17th, 2021
|-
|Update Wiki Notebook
|Complete
|Mar 10th, 2021
|Mar 17th, 2021
|Mar 17th, 2021
|-
|}


==Week 7:  March 3, 2021 ==
'''Lecture Notes:'''
*Watched three sub team presentations 
*Introduced to the Evolutionary Multi-objective Algorithm Design Engine (EMADE) setup, input file, and structure.
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Familiarize with EMADE library
|Completed
|March 3, 2021
|March 10, 2021
|March 8, 2021
|-
|Familiarize with SQL
|Completed
|March 3, 2021
|March 10, 2021
|March 8, 2021
|-
|Set up database master process with the subteam
|In Progress
|March 3, 2021
|March 10, 2021
|In Progress
|}
== Week 6: February 24, 2021 ==
'''Lecture Notes:'''
*Watched other two sub team presentations
*Presented on the [https://docs.google.com/presentation/d/1y6xUunAgmt_tRH-qFFz3jScmeawIgGDKbXhcWZBMxC4/edit#slide=id.p Presentation on "Predictions on Titanic Survivors with ML and MOGP"] as subteam #1.
*Answered Dr. Zutty's question for the presentation collectively with team members.
'''Team Meeting Notes:'''
*Reviewed our presentation slides and reformatted to Georgia Tech style.
*Rehearsal on our presentation through the bluejeans meeting before the class meeting time.
*Updated our presentation slides on the [[Group 1|subteam #1 Wiki page]].
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install Emade library
|Completed
|February 24, 2021
|March 3, 2021
|March 3, 2021
|-
|Configure MySQL
|Completed
|February 24, 2021
|March 3, 2021
|February 24, 2021
|-
|Update the subteam's Wiki page
|Completed
|February 24, 2021
|February 24, 2021
|February 24, 2021
|-
|Complete team meeting notes
|Completed
|February 24, 2021
|March 3, 2021
|March 3, 2021
|-
|Complete Midterm Wiki notebook checkpoint
|Completed
|February 24, 2021
|March 3, 2021
|March 3, 2021
|-
|Complete Midterm Peer Evaluation on Web
|Completed
|February 24, 2021
|March 5, 2021
|March 1, 2021
|}

==Week 5: February 16, 2021 ==
'''Team Meeting Notes'''
* Created team template for GP models with differing primitives and other characteristics for each member
* use modified tournament approach 
* Finalized  machine learning model for each member through [https://codeshare.io/adXokR CodeShare].
'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Record Confusion Matrix and model accuracy on CodeShare 
|Completed
|February 16, 2021
|February 17, 2021
|February 16, 2021
|-
|Set up [https://docs.google.com/spreadsheets/d/1k6Mu2ls3Y2XNrytOW7CBxwX4uF_81PqJ5AaaeEyl0wQ/edit?usp=sharing Google Sheet] for Pareto optimal check for the subteam
|Completed
|February 16, 2021
|February 17, 2021
|February 16, 2021
|-
|Complete Team Meeting Notes
|Completed
|February 16, 2021
|February 17, 2021
|February 16, 2021
|-
|Submit Titanic ML assignment on Canvas
|Completed
|February 16, 2021
|February 17, 2021
|February 16, 2021
|}


==Week 4: February 10, 2021==
===Lecture Notes===
*Bootcamp Subteams 
*Group 1 team members: Kevin Z, Andrew W, Diptendu M, Lucas Z, Shiyi W, Sriram M, Vishesh G.
*Titanic ML project using [https://www.kaggle.com/c/titanic Titanic]
*Scikit-Learn - machine learning library for Python
*Use classifier for predictions 
**Examples : [https://scikit-learn.org/stable/ Scikit Learn]

'''Subteam Notes:'''
* Setup communication channel to group members
* first group meeting on 13 Feb 4:30 pm
   * Meeting Notes at this link: [[https://docs.google.com/document/d/1DiFwUJEN5xpyITsAEd51G6mbpr2DsT0NN3l6UQVKb1Y/edit]]
* Shared our features selection technique results on Groupme and GitHub [[https://github.gatech.edu/vgupta342/AAD_group1]]
* Second group meeting on 16 Feb 6 pm to finalise feature set and discuss model selection and wrap up.
   * Meeting Notes at this link:  [[https://docs.google.com/document/d/1DiFwUJEN5xpyITsAEd51G6mbpr2DsT0NN3l6UQVKb1Y/edit]]

'''Titanic ML Assignment:'''
* I used a decision tree classifier with criterion set to "entropy" and class_weight set to balanced
* Accuracy: 0.82312925
* [121  26]
* [ 17  59]

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Set up Discord with group
|Complete
|Feb 10th, 2021
|Feb 14th, 2021
|Feb 17th, 2021
|-
|Complete Titantic Skaggle assignment
|Complete
|Feb 10th, 2021
|Feb 16th, 2021
|Feb 17th, 2021
|-
|Update Wiki
|Complete
|Feb 10th, 2021
|Feb 16th, 2021
|Feb 17th, 2021
|-
|}

==Week 3: February 3, 2021==
====Lecture 3====
*Each individual evaluated:
** Mean squared error
** cost
** complexity
** TPR
** FPR
* Objective scores give individual point in objective space (referred to as phenotype)
* Focus: False Positive Rate (FPR) and False Negative Rate (FNR)
** false positive is when something is falsely classified as positive or true, when it was actually false
** false negative is when something is falsely classified as negative or false, when it was actually true
*** FPR = # FP/# P
*** FNR = # FN/# N
** Goal: minimize FPR and FNR
*** The FPR and FNR < 1
**** graph of FPR and FNR is called the objective space
**** goal of objective space is to find the algorithms whose scores are closest to the origin
*** An individual in a population is Pareto optimal when no other individuals in the population outperforms the individual in all objectives
** NSGA II (Non-dominated Sorting Genetic Algorithm) and SPEA2 (Strength Pareto Evolutionary Algorithm) - scoring methods
**NSGA II
*** separated into non-domination 
*** selected using binary search
*** lower Pareto > higher Pareto
** SPEA2
*** strength s and rank R
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Investigate new functions used in part 2 of lab 2
|Complete
|February 4, 2021
|February 10, 2021
|February 9, 2021
|-
|Complete Lab 2 notebook
|Complete
|February 2, 2021
|February 10, 2021
|February 4, 2021
|-
|Go over lecture 3 slides
|Complete
|February 3, 2021
|February 10, 2021
|February 4, 2021
|-
|Complete notebook self assessment
|Complete
|February 3, 2021
|February 10, 2021
|February 9, 2021
|}
== Week 2: Jan.27, 2021 - Feb.3, 2021 ==

=== Lecture 2: '''Genetic Programming''' ===
'''Diversity in Genetic Computing'''
*'''Genotypic diversity''' - genetic difference in individuals
*'''Phenotypic diversity''' - expression of genes
**E.g. 2+8, 4+4+2, 7+3+0, are all genetically diverse but phenotypically the same because they all add to 10

'''Genetic Algorithms'''
*Genetic Algorithms - individuals are mutated and evaluated

* '''Structure-''' Tree Representation
** Read: DFS - Up to Down and Left to Right
** '''Parse Trees-''' represent program as a tree structure with:
*** '''Nodes-''' Primitives and Functions
*** '''Leaves-''' Terminals and Parameters
** '''Input-''' type of terminal
** '''Output-''' Produced at root
** '''Stored-''' preordered parse tree
* '''Crossover in GP'''
** Exchange subtrees: take node and exchange children

* '''Mutation in GP'''
** Insert or delete or change node or subtree

* '''Evaluating a Tree'''
** give input points in a function to get outputs
** Run f(x) and find error between outputs and truth 

=== <u>'''LAB 2 Results'''</u> ===
[[files/lab2first.png|none|thumb|480x480px|This is the graph without any added primitives or mutations. Best individual is add(x, add(subtract(multiply(x, add(x, multiply(x, multiply(x, x)))), subtract(x, x)), multiply(multiply(x, x), x))) and the best fitness score is 8.779634140822522e-17.]]
[[files/lab2second.png|none|thumb|480x480px|This is the graph with my added mutation. Best individual is add(multiply(x, add(x, multiply(x, x))), add(x, multiply(x, multiply(x, multiply(x, x))))) and the best fitness score is  (1.1041911805293318e-16.]]
[[files/lab2third.png|none|thumb|480x480px|This is the graph with added primitives and my added mutation. Best individual is maximum(add(x, add(multiply(x, multiply(x, x)), multiply(x, add(multiply(x, multiply(x, x)), x)))), x), and the best fitness score is 8.779634140822522e-17.]]

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review Slides/Read DEAP Documentation for GP
|Completed
|January 27, 2021
|February 3, 2021
|January 27, 2021
|-
|'''Assignment:''' Lab 2 Pt. 1 - GP
|Completed
|January 27, 2021
|February 3, 2021
|January 27, 2021
|}

== Week 1: Jan.20, 2021 - Jan.27, 2021 ==
'''General Information'''
* Wednesday, 5:00-5:50 PM (New students) 

* Grades
 1. Documentation and records (33%)
 2. Personal accomplishments and contributions to your team’s goals (33%)
 3. Teamwork and interaction (33%)

=== Lecture 1: '''Genetic Algorithms''' ===

* Vocabulary
1. Best individual: one whose fitness is the best in the population and cannot get better. 

2. Individual: one specific candidate in the population

3. Population: a group of individuals whose properties will be altered

4. Objective: a value used to characterize individuals that you are trying to maximize or minimize

5. Fitness: a comparison to other individuals

6. Evaluation: a function that computes the objective of an individual

7. Selection: represents survival of the fittest- better individuals survive and pass their genes more than weaker individuals.

8. Fitness Proportionate: the greater the fitness value, the higher the probability of being selected for mating

9. Tournament: has the purpose of finding winners that are selected for mating

10. Mate/Crossover: mating between individuals

11. Mutate: random modifications- helps maintain diversity

*General algorithm:
#Initialize randomly
#Determine population fitness
#Cycle until objective is reached:
##Select parents
##Crossover
##Mutate
*One Max Problem:
**Goal is to have a population with all 1's

=== <u>'''LAB 1 Results'''</u> ===
[[files/lab1Heidi.png|none|thumb|480x480px|The graph depicts the overall fitness decreasing, which is the goal of an objective minimization problem.]]

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class syllabus
|Completed
|January 20, 2021
|January 27, 2021
|January 20, 2021
|-
|Join EMADE Slack
|Completed
|January 20, 2021
|January 27, 2021
|January 20, 2021
|-
|Install and configure Anaconda, GitHub and Jupyter Notebook
|Completed
|January 20, 2021
|January 27, 2021
|January 20, 2021
|-
|Review class lecture slides with notes
|Completed
|January 20, 2021
|January 27, 2021
|January 20, 2021
|-
|Finish the first part of the DEAP Lab 1: One Max Problem
|Completed
|January 20, 2021
|January 27, 2021
|January 21, 2021
|}