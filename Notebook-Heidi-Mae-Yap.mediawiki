== Team Member ==
Team Member: Heidi Yap

Email: hyap7@gatech.edu
Cell Phone; +1 774-405-3099

Interests: Machine Learning, Python, Volleyball, Hiking, Traveling, Working Out

==Fall 2021==
'''General Info'''
*Meet Mondays 5:00-5:50pm

==September 13, 2021==

==September 6, 2021==


=Spring 2021=
'''General Info'''
* New Students meet Wednesdays 5:00-5:50pm
* March 22nd 5-8pm transition meeting
* Then, meet Mondays 5:00-5:50pm

== April 30th, 2021 == 
'''Stocks Team:'''

* Objectives
** Implement TA-Lib indicators 
** Increase "Evolvability of EMADE individuals" 
** Larger dataset
** Statistical evals of individuals

* Background
** Representing price with Piecewise Linear representation
** Predict trade values with EMADE individuals
** Use exponential smoothing to get a threshold for when to do buy and sell prediction

* Objectives in the EMADE Runs 
** maximize profit percentage and average profit per transaction
** minimize variance profit per transaction and normal CDF on distribution

* Future Work
** Do statistical analyses on different seeding types
** Bounded objective functions
** Try trading frequencies, like hourly or weekly

'''ezCGP'''

* Objectives
** Improve neural architecture search
** Recreate CIFAR-10 results without relying on transfer learning
** Improve ability to visualize genomes
** Research, develop, and test new mating methods for Cartesian Genetic Programming

* Future Work
** Research, develop, and test new mating methods
** Incorporate existing Convolutional neural network architecture to develop new genome seeds

'''NLP Feedback'''

* Consider using False Positive Rate, False Negative Rate, and Num Parameters instead of just false positive rate and false negative rate. 

'''Modularity:'''
* Exploring different ways to abstract parts of individuals
* MNIST Run

* Future Work
** Deep ensemble models
** Modify evolutionary selection method and help diversify ARLs
** Diversity measure
** Integrate ARLs with EMADE's original architecture

'''Individual Reflection:'''
I really enjoyed all of the different presentations and I am happy with what everyone has accomplished. I am excited for next semester and the work I will put in for my group in the future. I personally found the stocks presentation the most interesting.

== April 26th, 2021==
'''Team Meeting Notes:'''
* Final presentations April 30th

'''Subteam Meeting Notes:'''
* finish final presentation slides
* Dr. Zutty joined our subteam meeting and talked about the evaluation time of individuals for auto ML
* We are meeting again on Wedensday at 6 pm to go over slides and do a practice runthrough.

'''Individual Reflection:'''
*I did the presentation slide about our resources 
[[files/resources.png]]
*I performed 3 8 hour seeded runs but got some errors along the way
* Run1 optimal individuals:
[[files/run1optimalindividuals.png]]
*run1 fpr :
[[files/run1fpr.png]]
* Run1 tree:
[[files/run1tree.png]]
*Run2 optimal individuals:
[[files/run2optimalindividuals.png]]
*run2 fpr:
[[files/run2fpr.jpg.png]]
* Run2 tree:
[[files/run2tree.png]]
* AUC:
[[files/AUC_heidi.png]]
* Misclassifications:
[[files/misclassifications.png]]
*I helped with visuals for the presentation using this code:
\[https://colab.research.google.com/drive/1COC0IcnuUyjiBiimgyp7xgTB5r24OusY#scrollTo=iVlkPZs_qf1d Link to code for visualization]

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get in a seeded in PACE
|Completed
|April 26th, 2021
|April 28th, 2021
|April 27th, 2021
|-
|Add slide about resources
|Completed
|April 28th, 2021
|April 29th, 2021
|April 28th, 2021
|}

== April 19th, 2021==
'''Team Meeting Notes:'''
* Peer evals are available
* Final presentation Friday, 4/30 6 - 8pm
* Dr. Zutty suggested us to use FPR/FNR as objective functions instead of accuracy

'''Subteam Meeting Notes:'''

* Try to use FPR, FNR, numParameters as objective functions instead of accuracy

* reduce size of training set to not eat memory 

* Cameron changed the seeding file to make seeded run easier

* repull the branch from Github and change what's on PACE

* Cameron showed new members how to seed before running EMADE
** LAUNCH script ahs a "seedAmazon.pbs" script
** Run seeding file from input_amazon.xml

'''April 23rd Subteam Meeting:'''
* prep for final presentation

* Probably going to have code freeze Wednesday ("deadline") at noon

* Goal: get a run of EMADE in PACE with FPR, FNR and start final presentation

'''Individual Reflection:'''
* I worked on seeded runs and practicing using PACE to get more comfortable. 
* PACE runs:

[[files/paceruns.png]]

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Peer Evaluation
|Completed
|April 19th, 2021
|April 27th, 2021
|April 26th, 2021
|-
|Seeded runs
|In Progress
|April 19th, 2021
|April 26th, 2021
|
|}


== April 12th, 2021==
'''Subteam Meeting Notes:'''
* Steven completed a run and presented results
* Cameron gave a presentation about the NNLearners class in the codebase
* Assigned Tasks:
** Evolution(Cam B, Jon, Karthik, Nishant):
***NNLearners cannot get very big so we often get trivial networks
***Theory is that they’re too failure-prone. Need to do runs and find reasons why
***Datatypes aren't always specific enough
***E.g., primitives can specify if an arg is an integer but can’t dictate sign(?). Need to consider instances where a negative number will break things
***Nnlearners can lack integral parts
***Sometimes lack output layers
**NNLearners as subtrees (Hua, Temi, Heidi(me)):
***Learners can take outputs of other learners as a feature vector
***Idea: make NNLearners do this as subtrees
***Work on model hyperparameters as primitives (Temi)
**PACE-ICE Stuff: (Cameron W, Member)
***Merge PACE functionality into cacheV2
***Merge PACE functionality & DB fix into nn-vip
***Create shared python environment by symlinking .conda and .local folders


'''Individual notes'''
* I have finally got PACE all set up and practiced runs. I need to figure out a good application for MAC that is similar to winscp. 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Practice using PACE and finish setup
|Completed
|April 12th, 2021
|April 18th, 2021
|April 18th, 2021
|-
|Work on NNLearners as subtrees
|In Progress
|April 12th, 2021
|April 18th, 2021
|
|}
== April 5th, 2021==
'''Team Meeting Notes:'''
* Hypothesis testing:
** we want to see if what we observe is statistically significant to our expected observation
** statistical tests: Student's t-test and Welch's t-test. 
***Welch's t-test is useful if we don't know our expected observation
** p-value and significance level are used to determine if we should reject or fail to reject our null hypothesis (lower p-value)

'''Subteam Meeting Notes:'''
* Main objective is for new members to finish getting PACE setup

'''Presentation Notes'''
*Supervised vs. unsupervised learning
**Supervised learning- Learn function that maps inputs to a label
**Loss function - how far is trained model from true function (using RMSE)

*Neural Networks: 
**Sigmoid - bad for backpropogation because weights don't change if gradient is zero (squish input to 0 and 1), but it is expensive to compute exponentials because output is not "zero-centered"
**Vanishing gradient - gradient approaches zero when input is very positive or very negative
**ReLU - cheap to compute, but sometimes large gradients can cause weights to update so that neuron never fires

*Train Neural Network:
**Feed Forward - evaluate the model 
**Back Propagation - use gradients to update the weights
**Learning rate - how much are layers changed at each iteration

*Train/test/validation split
**train set - model learns using the training set
**test set - measures performance of model

*Why a model could do poorly?
**Overfitting - model overlearns from training data, but can't generalize well to new data
**Underfitting - too much bias
** find healthy balance between underfitting and overfitting

*Dense/Linear/Standard Layer - fully connected dense layer

*Convolutional Layer - Relate data spatially

*Recurrent Layer- has memory of previous input


'''Individual Notes:'''
* I have been working on setting up PACE and practicing running EMADE, using the wiki and Cameron's youtube video. 
* I am having issues with my cnf file and cloning EMADE and PACE-files

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Practice running EMADE in PACE
|Completed
|April 5th, 2021
|April 9th, 2021
|April 12th, 2021
|-
|Set up PACE environment
|Completed
|March 29th, 2021
|April 3rd, 2021
|April 9th, 2021
|-
|}
== March 29th, 2021==
'''Team Meeting Notes:'''
* I am on the NLP subteam!!!

'''Subteam Meeting Notes:'''
* Intro to NLP subteam goals, challenges, + tools 
* Cameron gave a presentation on PACE and the nlp-nn branch in the EMADE Github
* I have to get PACE set up, clone EMADE, clone PACE files, get mysql setup, and other environmental setups.
* our meeting schedule for subteam meetings is Friday's at 6pm. 

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Set up PACE environment
|Completed
|March 29th, 2021
|April 3rd, 2021
|April 9th, 2021
|-
|}
== Week 10: March 22nd, 2021==
'''Team Meeting Notes:'''
* Presented conclusion, comparing our results between EMADE, MOGP, and ML
* Dr. Zutty gave advice on graphs and MOGP methods
* Watched other presentations
'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Fill out Canvas Poll to rank my subteam preference
|Completed
|March 22nd, 2021
|March 26th, 2021
|March 28th, 2021
|-
|}



==Week 9: Mar 17th, 2021==

===Lecture Notes===
* Help teams with downloading and server issues. 

===Subteam Notes===
*20 generations completed
* Prepare for presentation
* Some slides that we plan on adding including installation, issues faced, and how we resolve these issues.
* Lucas - Output analysis
* Scott - ML/MOG
* I'm doing the conclusion
[[files/ conclusion_heidi.png]]

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Finish work on Titantic using EMADE
|Completed
|Mar 17th, 2021
|Mar 22nd, 2021
|Mar 22nd, 2021
|-
|Finish final team presentation
|Completed
|Mar 17th, 2021
|Mar 22nd, 2021
|Mar 22nd, 2021
|-
|Update Wiki Notebook
|Completed
|Mar 17th, 2021
|Mar 22nd, 2021
|Mar 22nd, 2021
|-
|}

==Week 8: Mar 10th, 2021==
===Lecture Notes===
* Help teams with downloading and server issues. 
===Subteam Notes===
* Individually install Emade and SQL and connect to server or attempt to create server.
*Feature importance:
[[files/feature_importance_heidi.png]]
*Heatmap:
[[files/heatmap_heidi.png]]
*Pareto front:
[[files/pareto_front_heidi.png]]
*Code design:
[[files/code_heidi.png]]
[[files/code1_heidi.png]]
*Pareto front comparison:
[[files/pareto_front_heidi2.png]]
[[files/pareto_front_heidi2.png]]

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Continue working on Titantic using EMADE
|Complete
|Mar 10th, 2021
|Mar 17th, 2021
|Mar 17th, 2021
|-
|Update Wiki Notebook
|Complete
|Mar 10th, 2021
|Mar 17th, 2021
|Mar 17th, 2021
|-
|}


==Week 7:  March 3, 2021 ==
'''Lecture Notes:'''
*Watched three sub team presentations 
*Introduced to the Evolutionary Multi-objective Algorithm Design Engine (EMADE) setup, input file, and structure.
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Familiarize with EMADE library
|Completed
|March 3, 2021
|March 10, 2021
|March 8, 2021
|-
|Familiarize with SQL
|Completed
|March 3, 2021
|March 10, 2021
|March 8, 2021
|-
|Set up database master process with the subteam
|In Progress
|March 3, 2021
|March 10, 2021
|In Progress
|}
== Week 6: February 24, 2021 ==
'''Lecture Notes:'''
*Watched other two sub team presentations
*Presented on the [https://docs.google.com/presentation/d/1y6xUunAgmt_tRH-qFFz3jScmeawIgGDKbXhcWZBMxC4/edit#slide=id.p Presentation on "Predictions on Titanic Survivors with ML and MOGP"] as subteam #1.
*Answered Dr. Zutty's question for the presentation collectively with team members.
'''Team Meeting Notes:'''
*Reviewed our presentation slides and reformatted to Georgia Tech style.
*Rehearsal on our presentation through the bluejeans meeting before the class meeting time.
*Updated our presentation slides on the [[Group 1|subteam #1 Wiki page]].
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install Emade library
|Completed
|February 24, 2021
|March 3, 2021
|March 3, 2021
|-
|Configure MySQL
|Completed
|February 24, 2021
|March 3, 2021
|February 24, 2021
|-
|Update the subteam's Wiki page
|Completed
|February 24, 2021
|February 24, 2021
|February 24, 2021
|-
|Complete team meeting notes
|Completed
|February 24, 2021
|March 3, 2021
|March 3, 2021
|-
|Complete Midterm Wiki notebook checkpoint
|Completed
|February 24, 2021
|March 3, 2021
|March 3, 2021
|-
|Complete Midterm Peer Evaluation on Web
|Completed
|February 24, 2021
|March 5, 2021
|March 1, 2021
|}

==Week 5: February 16, 2021 ==
'''Team Meeting Notes'''
* Created team template for GP models with differing primitives and other characteristics for each member
* use modified tournament approach 
* Finalized  machine learning model for each member through [https://codeshare.io/adXokR CodeShare].
'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Record Confusion Matrix and model accuracy on CodeShare 
|Completed
|February 16, 2021
|February 17, 2021
|February 16, 2021
|-
|Set up [https://docs.google.com/spreadsheets/d/1k6Mu2ls3Y2XNrytOW7CBxwX4uF_81PqJ5AaaeEyl0wQ/edit?usp=sharing Google Sheet] for Pareto optimal check for the subteam
|Completed
|February 16, 2021
|February 17, 2021
|February 16, 2021
|-
|Complete Team Meeting Notes
|Completed
|February 16, 2021
|February 17, 2021
|February 16, 2021
|-
|Submit Titanic ML assignment on Canvas
|Completed
|February 16, 2021
|February 17, 2021
|February 16, 2021
|}


==Week 4: February 10, 2021==
===Lecture Notes===
*Bootcamp Subteams 
*Group 1 team members: Kevin Z, Andrew W, Diptendu M, Lucas Z, Shiyi W, Sriram M, Vishesh G.
*Titanic ML project using [https://www.kaggle.com/c/titanic Titanic]
*Scikit-Learn - machine learning library for Python
*Use classifier for predictions 
**Examples : [https://scikit-learn.org/stable/ Scikit Learn]

'''Subteam Notes:'''
* Setup communication channel to group members
* first group meeting on 13 Feb 4:30 pm
   * Meeting Notes at this link: [[https://docs.google.com/document/d/1DiFwUJEN5xpyITsAEd51G6mbpr2DsT0NN3l6UQVKb1Y/edit]]
* Shared our features selection technique results on Groupme and GitHub [[https://github.gatech.edu/vgupta342/AAD_group1]]
* Second group meeting on 16 Feb 6 pm to finalise feature set and discuss model selection and wrap up.
   * Meeting Notes at this link:  [[https://docs.google.com/document/d/1DiFwUJEN5xpyITsAEd51G6mbpr2DsT0NN3l6UQVKb1Y/edit]]

'''Titanic ML Assignment:'''
* I used a decision tree classifier with criterion set to "entropy" and class_weight set to balanced
* Accuracy: 0.82312925
* [121  26]
* [ 17  59]

=== Action Items: ===
{| class="wikitable"
!Task
!Status
!Date Assigned
!Due Date
!Date Completed
|-
|Set up Discord with group
|Complete
|Feb 10th, 2021
|Feb 14th, 2021
|Feb 17th, 2021
|-
|Complete Titantic Skaggle assignment
|Complete
|Feb 10th, 2021
|Feb 16th, 2021
|Feb 17th, 2021
|-
|Update Wiki
|Complete
|Feb 10th, 2021
|Feb 16th, 2021
|Feb 17th, 2021
|-
|}

==Week 3: February 3, 2021==
====Lecture 3====
*Each individual evaluated:
** Mean squared error
** cost
** complexity
** TPR
** FPR
* Objective scores give individual point in objective space (referred to as phenotype)
* Focus: False Positive Rate (FPR) and False Negative Rate (FNR)
** false positive is when something is falsely classified as positive or true, when it was actually false
** false negative is when something is falsely classified as negative or false, when it was actually true
*** FPR = # FP/# P
*** FNR = # FN/# N
** Goal: minimize FPR and FNR
*** The FPR and FNR < 1
**** graph of FPR and FNR is called the objective space
**** goal of objective space is to find the algorithms whose scores are closest to the origin
*** An individual in a population is Pareto optimal when no other individuals in the population outperforms the individual in all objectives
** NSGA II (Non-dominated Sorting Genetic Algorithm) and SPEA2 (Strength Pareto Evolutionary Algorithm) - scoring methods
**NSGA II
*** separated into non-domination 
*** selected using binary search
*** lower Pareto > higher Pareto
** SPEA2
*** strength s and rank R
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Investigate new functions used in part 2 of lab 2
|Complete
|February 4, 2021
|February 10, 2021
|February 9, 2021
|-
|Complete Lab 2 notebook
|Complete
|February 2, 2021
|February 10, 2021
|February 4, 2021
|-
|Go over lecture 3 slides
|Complete
|February 3, 2021
|February 10, 2021
|February 4, 2021
|-
|Complete notebook self assessment
|Complete
|February 3, 2021
|February 10, 2021
|February 9, 2021
|}
== Week 2: Jan.27, 2021 - Feb.3, 2021 ==

=== Lecture 2: '''Genetic Programming''' ===
'''Diversity in Genetic Computing'''
*'''Genotypic diversity''' - genetic difference in individuals
*'''Phenotypic diversity''' - expression of genes
**E.g. 2+8, 4+4+2, 7+3+0, are all genetically diverse but phenotypically the same because they all add to 10

'''Genetic Algorithms'''
*Genetic Algorithms - individuals are mutated and evaluated

* '''Structure-''' Tree Representation
** Read: DFS - Up to Down and Left to Right
** '''Parse Trees-''' represent program as a tree structure with:
*** '''Nodes-''' Primitives and Functions
*** '''Leaves-''' Terminals and Parameters
** '''Input-''' type of terminal
** '''Output-''' Produced at root
** '''Stored-''' preordered parse tree
* '''Crossover in GP'''
** Exchange subtrees: take node and exchange children

* '''Mutation in GP'''
** Insert or delete or change node or subtree

* '''Evaluating a Tree'''
** give input points in a function to get outputs
** Run f(x) and find error between outputs and truth 

=== <u>'''LAB 2 Results'''</u> ===
[[files/lab2first.png|none|thumb|480x480px|This is the graph without any added primitives or mutations. Best individual is add(x, add(subtract(multiply(x, add(x, multiply(x, multiply(x, x)))), subtract(x, x)), multiply(multiply(x, x), x))) and the best fitness score is 8.779634140822522e-17.]]
[[files/lab2second.png|none|thumb|480x480px|This is the graph with my added mutation. Best individual is add(multiply(x, add(x, multiply(x, x))), add(x, multiply(x, multiply(x, multiply(x, x))))) and the best fitness score is  (1.1041911805293318e-16.]]
[[files/lab2third.png|none|thumb|480x480px|This is the graph with added primitives and my added mutation. Best individual is maximum(add(x, add(multiply(x, multiply(x, x)), multiply(x, add(multiply(x, multiply(x, x)), x)))), x), and the best fitness score is 8.779634140822522e-17.]]

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review Slides/Read DEAP Documentation for GP
|Completed
|January 27, 2021
|February 3, 2021
|January 27, 2021
|-
|'''Assignment:''' Lab 2 Pt. 1 - GP
|Completed
|January 27, 2021
|February 3, 2021
|January 27, 2021
|}

== Week 1: Jan.20, 2021 - Jan.27, 2021 ==
'''General Information'''
* Wednesday, 5:00-5:50 PM (New students) 

* Grades
 1. Documentation and records (33%)
 2. Personal accomplishments and contributions to your team’s goals (33%)
 3. Teamwork and interaction (33%)

=== Lecture 1: '''Genetic Algorithms''' ===

* Vocabulary
1. Best individual: one whose fitness is the best in the population and cannot get better. 

2. Individual: one specific candidate in the population

3. Population: a group of individuals whose properties will be altered

4. Objective: a value used to characterize individuals that you are trying to maximize or minimize

5. Fitness: a comparison to other individuals

6. Evaluation: a function that computes the objective of an individual

7. Selection: represents survival of the fittest- better individuals survive and pass their genes more than weaker individuals.

8. Fitness Proportionate: the greater the fitness value, the higher the probability of being selected for mating

9. Tournament: has the purpose of finding winners that are selected for mating

10. Mate/Crossover: mating between individuals

11. Mutate: random modifications- helps maintain diversity

*General algorithm:
#Initialize randomly
#Determine population fitness
#Cycle until objective is reached:
##Select parents
##Crossover
##Mutate
*One Max Problem:
**Goal is to have a population with all 1's

=== <u>'''LAB 1 Results'''</u> ===
[[files/lab1Heidi.png|none|thumb|480x480px|The graph depicts the overall fitness decreasing, which is the goal of an objective minimization problem.]]

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class syllabus
|Completed
|January 20, 2021
|January 27, 2021
|January 20, 2021
|-
|Join EMADE Slack
|Completed
|January 20, 2021
|January 27, 2021
|January 20, 2021
|-
|Install and configure Anaconda, GitHub and Jupyter Notebook
|Completed
|January 20, 2021
|January 27, 2021
|January 20, 2021
|-
|Review class lecture slides with notes
|Completed
|January 20, 2021
|January 27, 2021
|January 20, 2021
|-
|Finish the first part of the DEAP Lab 1: One Max Problem
|Completed
|January 20, 2021
|January 27, 2021
|January 21, 2021
|}