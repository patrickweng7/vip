== Team Member ==
'''Team Member''': Hemang Rajvanshy

'''Email''': hrajvanshy3@gatech.edu

'''Cell''' '''Phone:''' 404-819-5287

'''Major''': Computer Science

'''Subteam''': ezCGP

'''Team Members:'''
* Daniel Martin
* Kevin Zheng
* Conner Yurkon
* Justin Hinckley
* Vishesh Gupta
* Monil Kaneria
* Parshva Shah
* Lucas Zhang

= Fall 2019 = 
== August 21, 2019 ==
'''Lecture Notes:'''
* Introduction to genetic programming.
* Learned about fitness proportionate.
* Strategies to create a new generation:
** Mating (cross)
** Mutation (random change to parent)
* Completed Lab 1
** Dummy Genetic Algorithm Problem: One Max Problem
*** Objective: Maximize the sum of array
** Learned DEAP syntax
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Create and Populate Notebook
|Completed
|August 21, 2019
|August 28, 2019
|August 26, 2019
|-
|Go through Lab 1
|Completed 
|August 21, 2019
|August 28, 2019
|August 26, 2019
|-
|Join Slack
|Completed
|August 21, 2019
|August 28, 2019
|August 21, 2019
|}
== August 28, 2019 ==
'''Lecture Notes:'''
* Genetic Programming
** The individual is a function and not data. (The algorithm is what is getting mutates/optimized)
** The function is represented as a tree - the tree is stored as a list [operator, operand 1, operand 2] = operand 1 (operator) operand 2 (Similar to FP)
** Mating: exchange subtrees between parents
** Mutation: randomly change nodes in the tree, add a node/subtree, remove a node/subtree, exchange subtrees within the tree
** Exercises converting between tree, expression, and list
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|August 28, 2019
|September 04, 2019
|August 28, 2019
|-
|Go through Lab 2 First Half
|Completed
|August 28, 2019
|September 04, 2019
|September 03, 2019
|}
== September 4, 2019 ==
'''Lecture Notes:'''
* Kahoot question about tree evaluation
* Discuss the qualities of a good algorithm to motivate multi-objective scoring
* Classification Measures
** Confusion Matrix
*** Type I and Type II Errors
*** Specificity (True Negative; measured by TNR) vs Sensitivity (True Positive; measured by TPR)
*** Kahoot to test knowledge on the confusion matrix
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|September 04, 2019
|September 11, 2019
|September 04, 2019
|-
|Go through Lab 2 Second Half
|Completed
|September 04, 2019
|September 11, 2019
|September 08, 2019
|}
== September 11, 2019 ==
[[files/ParetoFront(TEAM5).png|thumb|402x402px]]
'''Lecture Notes:'''
* Breakup into subteams
* Titanic Problem:
** Scikit learn
** Reviewed James solution to Titanic Dataset
** Review Pandas
* Titanic:
** Assignment: Get 5 Prato optimal algorithms
'''Team Notes:'''
* Created Github repository: https://github.com/HemangRajvanshy/Bootcamp_team5
* Setup the feature set, produced additional features
* Setup pipeline to compute FNR and TNR
* Co-ordinated work on the assignment and ensured completion
* Some code to produce additional features:
 train_data['Alone'] = 1
 train_data['Alone'].loc[train_data['Parch'] + train_data['SibSp'] > 1] = 0
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|September 11, 2019
|September 18, 2019
|September 11, 2019
|-
|Titanic Problem
|Completed
|September 11, 2019
|September 18, 2019
|September 17, 2019
|}
== September 18, 2019 ==
'''Lecture Notes:'''
*Discussed individual team submissions to Titanic Problem
** Learned about vectorization and normalization
** Step mode to render Pareto front. 
'''Team Notes:'''
* Presentation: https://docs.google.com/presentation/d/135VF3btAwb4TciwHfZpWJgexhIikvp3gOYVCUeAbKko/edit#slide=id.p
* Github repository: https://github.com/HemangRajvanshy/Bootcamp_team5
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|September 18, 2019
|September 25, 2019
|September 23, 2019
|}
== September 25, 2019 ==
'''Lecture Notes:'''
* Titanic GP assignment:
** Choose features again
** Multiobjective, use lab 2
** Produce another co-dominant front
** Use primitives: and, or, not, +, -, *, %
** Produce one CSV with multiple predictions
** Final co-dominant Pareto front
** The area under Pareto front should go down with generations.  (Produce plot)
'''Team Notes:'''  
* Decided to use Google Colab with the team
* Ensured completion of tasks
* Created Google Colab document: https://colab.research.google.com/drive/1YhTudsToAegfY9O6Cw3l3nqFHNzdViO4
* Setup data pipeline and DEAP toolbox
* Created the evaluation function and fitness projection
 def eval(individual, pset):
   func = gp.compile(expr=individual, pset=pset)
   
   y_pred = []
   for i, x in X_train.iterrows():
     res = func(*x.values.tolist())
     y_pred += [res > 0]
  
   y_truth = y_train.values
   tn, fp, fn, tp = confusion_matrix(y_truth, y_pred).ravel()
   fpr = fp/(fp+tn)
   fnr = fn/(fn+tp)
   return fpr, fnr
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|September 25, 2019
|October 2, 2019
|September 27, 2019
|-
|Titanic Problem
|Completed
|September 25, 2019
|October 2, 2019
|October 1, 2019
|}
== October 2, 2019 ==
'''Lecture Notes:'''
* Teams presented their findings and results
* Learned about the limitations of DEAP and various selection methods
'''Team Notes:'''  
* Presentation: https://docs.google.com/presentation/d/1a58fzuwzPk_RDDGTq7oGjB52556EpAb1vOH_p2ixLv8/edit?usp=sharing
* Collaborated with Team 4 to share ideas
* Helped generate new prediction CSV
* '''Results:'''
[[files/PltBootcamp team5.png|left|thumb|432x432px]]
[[files/AUCBootcamp 5.png|center|thumb|402x402px|Pareto Front]]
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|October 2, 2019
|October 9, 2019
|October 3, 2019
|-
|Peer Evaluations
|Completed
|October 2, 2019
|October 4, 2019
|October 1, 2019
|-
|Install EMADE
|Completed
|October 2, 2019
|October 9, 2019
|October 9, 2019
|}
== October 9, 2019 ==
'''Lecture Notes:'''
* Introduction to EMADE:
** EMADE: Evolutionary multi-objective algorithm design engine
** Installation
** Running EMADE
** Structure of the configuration file
** Datasets (cross folded 5 times)
** structure of titanic_data_splitter.py
'''Team Notes:'''  
* Assignment:
** Run EMADE as a group
** Run for substantial number of generations 
** Plot non-dominated frontier. Compare to ML and MOGP.
** More plots
** Make presentation on results. 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|October 9, 2019
|October 16, 2019
|October 11, 2019
|-
|Titanic EMADE
|Completed
|October 9, 2019
|October 16, 2019
|
|}
== October 16, 2019 ==
'''Lecture Notes:'''
* Given time to work with Bootcamp team to work on EMADE assignment
'''Team Notes:'''  
* Tried hosting master process on the cloud, but ended up hosting locally
* Used Amazon EC2 instance to do some computation in addition to personal machines
* SQL server was also hosted on an AWS Lightsail instance.
* Collaborated with team 4 to discuss what strategies work and what doesn't work and how to interpret data as well as validate results. 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|October 16, 2019
|October 21, 2019
|October 21, 2019
|-
|Titanic EMADE
|Completed
|October 16, 2019
|October 21, 2019
|October 20, 2019
|}
== October 21, 2019 ==
[[files/Emade result.png|thumb|804x804px]]
'''Lecture Notes:'''
* Bootcamp subteam presentation of EMADE titanic results
* Project subteams presented their results so far this semester and goals for the rest of the semester
'''Team Notes'''  
* Ran for 25 generations
* Final results indicated better individual than ML and GP
* Presentation: https://docs.google.com/presentation/d/1tbXDOfw1_gYL1s2ruF7xssIktI7lRdGGuN-5IxTaif8/edit?usp=sharing
* Choose Project subteam to join
* Asked NLP team questions about their work
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|October 21, 2019
|October 28, 2019
|October 28, 2019
|-
|Choose Subteam
|Completed
|October 21, 2019
|October 28, 2019
|October 28, 2019
|}
== October 28, 2019 ==
'''Lecture Notes:'''
*Choose subteam
*Discuss logistics
'''Team Notes:'''  
* Introductions with all subteam members 
* Learn more about team structure, goals, and meeting times 
* Ask general questions about EMADE and GP 
'''GP Research:'''
 - History:	
 	- Patented by Stanford University computer scientist John Koza in 1988
 	- First proposed by Alan Turing in 1950
 	- Foundation: John Holland's 'Adaptation in Natural and Artificial Systems'
 	- Series of 4 books by John Koza (PhD student under John Holland), starting in 1992[8] with accompanying videos, that really established GP. 
 	- In 2010, Koza[11] listed 77 results where Genetic Programming was human competitive. (<nowiki>http://gpbib.cs.ucl.ac.uk/gp-html/Koza_2010_GPEM.html</nowiki>)
 
 State of the art:
 	- (Why We Do Not Evolve Software? Analysis of Evolutionary Algorithms, 2018) <nowiki>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6287292/</nowiki>
 	- MOGP framework in scala: <nowiki>https://github.com/evvo-labs/evvo</nowiki>
 	- "We're two Northeastern University students, and one professor, who started this project because there were no frameworks that allowed people to productionize evolutionary algorithms by running them in distributed environments. We wanted to make a type-safe, user-friendly interface to a parallel backend that would allow optimization problems to be solved more easily. We have validated the framework, using it in a paper that evolved fair and accurate machine learning models  (<nowiki>https://github.com/julian-zucker/evolving-fair-models/blob/master/paper/evolving-fair-models.pdf</nowiki>). This project is still in early beta, but it is mature enough to be used for proofs of concept and to play with high-performance evolutionary algorithms.
 
 Let us know what you think and how you want to see the project develop! We'd be happy to answer any questions you might have either here or at: julian.zucker@gmail.com and drassaby@gmail.com"
 
 	- "DEAP is great! But these are two different tools with very different use cases.
 	From their docs:
 
 	"DEAP is a novel evolutionary computation framework for rapid prototyping and testing of ideas"
 
 	That makes DEAP wonderful for playing around with new types of evolutionary algorithm or doing, as they say, rapid prototyping. Some features that come from this design goal are weak typing, often using strings to look up values, and support for a wide variety of evolutionary algorithms by default.
 
 	Evvo is more opinionated. You can only run non-generational (aka asynchronous) island-based evolutionary algorithms, but this allows us to optimize the system for that use in particular, enabling better performance. And speaking of performance, having our base language by Scala instead of Python gives all the mutation operators, etc, a roughly 50x speedup, which is critical for optimization problems. Scala is also a strongly typed language, and Evvo leverages generics and typeful programming to catch many bugs in your code before its run. While I personally think that strong types are always a win, most people have to agree that when you are deploying your code to a compute cluster, which can take a significant amount of time, catching bugs at compile time instead of runtime is a huge win.
 
 	Basically, Evvo and DEAP have different design goals and priorities.
 
 	-Julian"
 
 - NEAT: NeuroEvolution of Augmenting Topologies (NEAT) is a genetic algorithm for evolving  neural networks developed by Ken Stanley 2002 at UT Austin <nowiki>https://en.wikipedia.org/wiki/Neuroevolution_of_augmenting_topologies</nowiki>
 - EANT: NEAT's brother? 
 - <nowiki>http://flexgp.csail.mit.edu/</nowiki> MITs GP lab

'''Team Meeting (November 1):'''
* Learned about what all members of team are working on
* Decided on final presentation goals
* Got assigned the task to validate the results from the Neat-GP paper
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|October 28, 2019
|November 4, 2019
|November 1, 2019
|-
|Read Neat-GP Paper
|Completed
|October 28, 2019
|November 1, 2019
|November 1, 2019
|-
|Validate Neat-GP results
|Completed
|November 1, 2019
|November 11, 2019
|
|}
== November 4, 2019 ==
'''Team Meeting:'''  
*Discussed Validation results
*Progress report from all members
*Read NEAT-GP (neat Genetic Programming: Controlling Bloat Naturally)
'''Neat-GP (November 10):'''
* Paper can be found at: https://www.sciencedirect.com/science/article/pii/S0020025515008038
* Learned about NEAT
* Learned about bloat theories like: fitness causes bloat theory (FCBT) and crossover bias theory (CBT)
* Learned about Operator Equalization and (Flat-OE) and how speciation can be used to naturally enforce a flat distribution of tree sizes
*Compared Neat-GP evolutionary loop with EMADE and discussed stratgies to incorporate strategies from Neat-GP into Emade[[files/Neat flow.png|none|thumb|501x501px]]
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|November 4, 2019
|November 11, 2019
|November 10, 2019
|-
|Read Neat-GP Paper
|Completed
|November 4, 2019
|November 11, 2019
|November 10, 2019
|}
== November 11, 2019 ==
'''Team Meeting'''  
*Discussed approaches for bloat reduction and caching
*Calculated computational overhead and feasibility
*Discussed new task to research bloat control methods in other GP frameworks
'''Evvo-Lab (November 12):'''
* Explored https://github.com/evvo-labs/evvo for bloat control strategies
* Even though I couldn't find bloat control strategies the overall distributed architecture was interesting:
** Use of JVM to maintain Islands accross servers with island managers
* Emailed code authors to directly ask about how they handle bloat and if not, why they thought it wasn't an issue
* After some exchange, they suggested that:
 Like Julian says, we don’t deal with bloat (in solution size, however that is defined for a specific problem) directly, but our deletor agents 
 (<nowiki>https://github.com/evvo-labs/evvo</nowiki>) should be able to control it pretty well if they’re explicitly declared. We do have built-in controls to keep population size
 relatively stable, and are planning on adding more of those as well.
* Looked into deletor agents, they are defined as:
 Deletor Agent: often shortened to "Deletor", a Deletor Agent retrieves some number of solutions from the ''population'' and deletes the bad ones (for whatever definition of bad it's working with) from the ''population''.
* Overall Architecture of an "EvvoIsland":
[[files/Evvo island.png|center|thumb|494x494px]]
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|November 11, 2019
|November 18, 2019
|November 12, 2019
|-
|Exploratory Bloat Research
|Completed
|November 11, 2019
|November 18, 2019
|November 12, 2019
|}
== November 18, 2019 ==
'''Team Meeting:'''  
*Decided to start helping with implementing Neat-GP within EMADE
*Decided on best way to split up work
*Reassessed goals and scope for end of semester
'''Tree Distance Metric (Nov 19):'''
* Added helper file with distance methods in commit (borrowed from [https://github.com/saarahy/neatGP-deap neatGP-deap]): https://github.gatech.edu/efrankel6/emade/commit/886f721fc1b2b5510ea482eee83b4630d0810e76
* Distance/Dissimilarity calculated as defined in Neat-GP paper, a weighted average of topological difference in tree size and depth:
[[files/Dissimilarity.png|center|frameless|342x342px]]
* Tested the distance metric and realized that the results were different from expected (same tree returned non-zero distance from itself)
* Tried investigating possible causes and emailed code author
* Located problem to be within a specific method and made attempts to pinpoint the exact cause

 def compare_tree(tree1, tree2):
    """
    This method compare the number of nodes and the depth between two
    individuals.
    Binary version does not enter her
    :param tree1: First Individual
    :param tree2: Second Individual
    :return: a tuple with the number of nodes and the common depth
    """
    nodo = 0
    lista_nivel = list()
    list_tree1 = list()
    list_tree2 = list()
    first_node = False
    expr1 = level_node(tree1)
    expr2 = level_node(tree2)
    for ind1 in expr1:
        for ind2 in expr2:
            if ind1 == ind2 and ind1[0] == 0:
                nodo += 1
                first_node = True
                lista_nivel.append(ind1[1])
                list_tree1.append(ind1)
                list_tree2.append(ind2)
                break
            elif ind1[1] in lista_nivel:
                break
            elif ind1[1] not in lista_nivel and first_node:
                if ind1[1] - 1 in lista_nivel:
                    total = 0
                    nivel_ant = ind1[1]-1
                    for elem in range(len(list_tree1)):
                        prev_node = ind1[0]-1
                        if list_tree1[elem][1] == nivel_ant and prev_node == list_tree1[elem][0]:
                            if list_tree2[elem][2] == list_tree1[elem][2]:
                                total = list_tree2[elem][2]
                                for i in range(1, list_tree1[elem][2]+1):
                                    [list_tree2.append(x) for x in expr2 if (
                                        x[0] == list_tree2[elem][0] + i)]
                                    [list_tree1.append(x) for x in expr1 if (
                                        x[0] == list_tree1[elem][0] + i)]
                    nodo += total
                    if total > 0:
                        lista_nivel.append(ind1[1])
                    break
                else:
                    break
            if not first_node:
                return 1, 1
    return nodo, max(lista_nivel)
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|November 18, 2019
|November 25, 2019
|November 19, 2019
|-
|Tree Distance metric
|Completed
|November 18, 2019
|November 25, 2019
|November 19, 2019
|}
== November 25, 2019 ==
'''Hackathon (November 23):'''
* Setup EMADE to run on branches based on detection-processing branch
* Worked on figuring out faster-testing approaches to test speciation (and other EMADE based program changes)
* Ran into issues with DEAP and initial population sizes
* Helped debug speciation code
'''Team Meeting:'''  
*Created boilerplate presentation
*Discussed final plan to finish up work before the presentation
*Decided to not implement fitness sharing given time constraints
'''Presentation Work:'''
* Completed Peer Evaluations
* Created neat-GP slides
* Verified speciation results 
* Produced graphical results based on speciation results

[[files/Hist final.png|frameless|438x438px]]                                                       [[files/Tree species.png|frameless|509x509px]]

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|November 25, 2019
|December 4, 2019
|December 3, 2019
|-
|Tree Distance metric
|Completed
|November 25, 2019
|December 1, 2019
|November 30, 2019
|}
== December 2, 2019 ==
'''Team Meeting:'''
* Practiced presentation
* Assigned roles for speakers and reviewed slides
* Coordinated plan for next semester 
'''Presentation:'''  
*Link: https://docs.google.com/presentation/d/1hI4GQuZBEOxNT5dWNsQa1xXxLil5w6hd4GZIMAV4qy4/edit?usp=sharing
*Talked about neat-GP: Tree Distance, Speciation, and analysis of neat-GP results
*Learned about PACE-ice
[[files/Tree-distance.png|frameless|597x597px]][[files/Speciation.png|frameless|602x602px]]

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|December 2, 2019
|December 4, 2019
|December 3, 2019
|}
= Fall 2020 =
== August 17, 2020 ==
'''Team Meeting:'''
* Figure out remote logistics
* Discuss time conflict logistics
* Decide what team to work with
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Team Select
|Completed
|August 17, 2020
|August 24, 2020
|August 21, 2020
|}
== August 24, 2020 ==
'''Team Meeting:'''
* Finalize team selection
* Discuss team goals and objectives for the semester:
** Port new primitives to stable version
** Benchmarking
* Delegation and setup
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|August 24, 2020
|August 27, 2020
|August 24, 2020
|-
|Setup ezCGP 
|Completed
|August 24, 2020
|August 27, 2020
|August 25, 2020
|}
== August 25, 2020 ==
'''New Member Orientation:'''
* Meeting with Rodd to get a quick tour of the codebase and some basic principles
* Regular Team Meeting Time: Thursday from 5-6 PM EST
* Topics covered:
** Blocks
** Universe
** Problem
** DAGs and Cartesian GP
* Also discussed logistics and plans for the semester
* We have decided to split into two subteams, one for research and one for development:
** I will be working with the development team
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|August 25, 2020
|August 25, 2020
|August 25, 2020
|}
== August 27, 2020 ==
'''Team Meeting:'''
* Introductions
'''Implementation Team Breakout:'''  
*Concrete next steps
**We want to move code from last semester (https://github.com/ezCGP/ezExperimental/blob/2020S-student-edits/problem_augmentation.py) to the new stable version
**Move them to (https://github.com/ezCGP/ezCGP/tree/2020F-BaseCodeDevelopment/codes/block_definitions/utilities)
**Setup benchmarking on CIFAR10 and cloud environment to do test runs
*Catch up on work done last semester
'''Work Notes'''
* Updated new member instructions: https://github.com/ezCGP/ezCGP/wiki/New-VIP-Student-ToDo's to reflect more up to date setup steps
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|August 27, 2020
|August 31, 2020
|August 29, 2020
|-
|Familiarize with codebase
|In Progress
|August 27, 2020
|August 31, 2020
|August 31, 2020
|-
|Add new Primitives
|In Progress
|August 27, 2020
|September 03, 2020
|August 31, 2020
|}
== August 31, 2020 ==
'''Monday Meeting:'''
* Time conflict
[[files/Test run.jpg|thumb|482x482px]]
'''Thursday Team Meeting (September 3):'''  
*Status updates
*Rediscussed impact of restarting Deep learning operator primitives from scratch
*Discussed incorporating a pull request based workflow to improve code quality and overall team familiarity with codebase (ie doing reviews for code written other team members)
*New Tasks: 
**Implementation team: 
***Add new deep learning primitives (Keras)
**Personal: 
***Documented the proposed branching and pull-request based workflow and sent suggestion to the team
'''Work Notes'''
* Verified all primitives are present
* Cleaned up Github issues and Zenhub, tasking elements for new semester
* Test run on multi-gaussian test problem
* Read through https://github.com/ezCGP/ezCGP/blob/master/codes/universe.py and primitive pipeline
** Clean up universe.py
** Compare code structure from experimental branch and understand differences
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|August 27, 2020
|August 31, 2020
|August 29, 2020
|-
|Add new Primitives
|In Progress
|August 27, 2020
|September 03, 2020
|September 03, 2020
|}

== September 7, 2020 ==
'''Monday Meeting:'''
* Labor Day: No Meeting
[[files/Screenshot from 2020-09-10 00-15-21.png|thumb|509x509px]]
'''Thursday Team Meeting (September 10):'''  
*Presented the new wiki page and code development guidelines to the team
*Discussion based off-of presentation, we agreed on new branch naming convention:
**''feat/issue#_feat_name''
*Took up new task, will add convolution primitives 
**https://github.com/ezCGP/ezCGP/issues/72
'''Work Notes'''
* Worked on presentation and wiki page
** Created guidelines for the team's code development workflow
** Link to wiki: https://github.com/ezCGP/ezCGP/wiki/Code-Development
** Highlights: See Image 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|September 7, 2020
|September 14, 2020
|August 29, 2020
|-
|Workflow presentation
|Completed
|September 3, 2020
|September 10, 2020
|September 10, 2020
|}

== September 14, 2020 ==
'''Monday Meeting:'''
* Time conflict
* Self-grading according to rubric:
<center>[[files/Self-grade.png|center|frameless|1665x1665px]]</center>'''Thursday Team Meeting (September 17):'''  
*Research team presented their work
*Bojun presented some interesting papers, including one on "Regularized Evolution for Image Classifier Architecture Search"
'''Work Notes'''
* Ported convolution2D primitive and added Conv2D transpose primitive
* Created pull request: [https://github.com/ezCGP/ezCGP/pull/87/files https://github.com/ezCGP/ezCGP/pull/87/]
** To ask for feedback and make sure I am following the right format. 
** Contributes towards the issue: https://github.com/ezCGP/ezCGP/issues/72
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|September 14, 2020
|September 21, 2020
|September 19, 2020
|-
|Convolution Primitives
|Completed
|September 14, 2020
|September 21, 2020
|September 19, 2020
|}

== September 21, 2020 ==
'''Monday Meeting:'''
* Time conflict
'''Thursday Team Meeting (September 24):'''
*Went over various steps in the code flow
*Discussing new additions etc. what the code does, discuss if we want to refactor any parts of the code. 
*Team progress update: We are almost ready to start testing the Tensorflow primitives
*Discussion on issue: https://github.com/ezCGP/ezCGP/issues/74
'''Work Notes'''
* Working on issue #74 to add miscellaneous Keras primitives (Gaussian noise, pooling layers etc.)
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|September 21, 2020
|September 28, 2020
|September 26, 2020
|-
|Misc Keras Primitives
|Completed
|September 21, 2020
|September 28, 2020
|September 26, 2020
|}
== September 28, 2020 ==
'''Monday Meeting:'''
* Time conflict
'''Thursday Team Meeting (October 1):'''
*Discussion on the Augmentor pipeline
*Talked about introducing Keras primitives 
*Team progress update: We are done with TF Keras epoch  
'''Work Notes'''
* Working on issue #82 (Pooling Layers) (https://github.com/ezCGP/ezCGP/issues/82)
** Created a pull request: https://github.com/ezCGP/ezCGP/pull/100
** Dynamically select the right layer size based on dimensions of input tensor:
 def avg_pool_layer(input_tensor, pool_height=2, pool_width=2, strides=2):    
     if input_tensor.rank == 1:        
         return tf.keras.layers.AveragePooling1D(pool_size=[pool_height, pool_width], strides=strides, padding="valid")(input_tensor)    
     if input_tensor.rank == 2:        
         return tf.keras.layers.AveragePooling2D(pool_size=[pool_height, pool_width], strides=strides, padding="valid")(input_tensor)    
     if input_tensor.rank == 3:        
         return tf.keras.layers.AveragePooling3D(pool_size=[pool_height, pool_width], strides=strides, padding="valid")(input_tensor)
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|September 28, 2020
|October 05, 2020
|October 03, 2020
|-
|Pooling Layers
|Completed
|September 28, 2020
|October 05, 2020
|October 01, 2020
|}
== October 5, 2020 ==
'''Monday Meeting:'''
* Time conflict
'''Thursday Team Meeting (October 8):'''
*Rodd explained Transfer learning issue #103: https://github.com/ezCGP/ezCGP/issues/103
**Discussed solutions and alternative approaches 
**Overview of current approach and problems with Augmentor
*Discussed implementation strategy for research elements
**Ford decided to work on super convergence and cyclical learning rates
**Bojun decided to work on aging evolution
***based on the paper: https://arxiv.org/abs/1802.01548
'''Work Notes'''
* Collaborated with Daniel to make changes to transfer learning block
** Link to pull request: https://github.com/ezCGP/ezCGP/pull/110
** Issue: https://github.com/ezCGP/ezCGP/issues/103
 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|October 5, 2020
|October 12, 2020
|October 08, 2020
|-
|Transfer Learning
|Completed
|October 5, 2020
|October 12, 2020
|October 11, 2020
|}
== October 12, 2020 ==
'''Monday Meeting:'''
* Time conflict
'''Thursday Team Meeting (October 15):'''
*Divide up presentation among team members
*Reviewed changes to the transfer learning block
**Changed transfer learning block to take in a previous layer, attach the transfer learning model on top, and return the last layer of the new model
**Something like:
 pretrained_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=image_shape, pooling=None) 
 input_layer = pretrained_model.inputs 
 final_layer = pretrained_model.layers[-1].output
'''Work Notes'''
* Work on creating the presentation
** Link: https://docs.google.com/presentation/d/1mDjWHefrsxjaRfNSOVlTNI4f-g0Tl0ANK-P-5Z-d6bw/edit?usp=sharing
* Proof-read and discuss important talking points
* Working on getting a benchmarking plan for CIFAR-10
 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|October 12, 2020
|October 19, 2020
|October 18, 2020
|-
|Midterm presentation
|Completed
|October 12, 2020
|October 19, 2020
|October 18, 2020
|}
== October 19, 2020 ==
'''Monday Meeting:'''
* Presentations:
** Presented with the ezCGP team
*** Link to our presentation: [https://docs.google.com/presentation/d/1mDjWHefrsxjaRfNSOVlTNI4f-g0Tl0ANK-P-5Z-d6bw/edit https://docs.google.com/presentation/d/1mDjWHefrsxjaRfNSOVlTNI4f-g0Tl0ANK-P-5Z-d6bw/]
* Listened to the other team presentations
** NN team having some of the same issues that we are having
* Pitch team to new members and answer questions[[files/Slide 1.png.png|center|frameless|580x580px]]
'''Thursday Team Meeting (October 22):'''
*Discuss quantifiable goals for remaining semester
**Finish CIFAR-10 benchmarking runs
*Brainstorm ideas for new members
**Comparing MNIST performance across ezCGP and emade
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|October 19, 2020
|October 26, 2020
|October 20, 2020
|-
|Brainstorm and create plan for remaining semester
|Completed
|October 19, 2020
|October 22, 2020
|October 20, 2020
|}
== October 26, 2020 ==
'''Monday Meeting:'''
* Time conflict
'''Thursday Team Meeting (October 29):'''
*Introduction with the four new team members. 
*Drafted plan for rest of the semester
**Seeding experiments
**CIFAR-10 experiments
**CV primitive testing
'''Work Notes'''
* Working on issue #102: https://github.com/ezcgp/ezcgp/issues/102
* Finished testing and modifying OpenCV primitives
**Pull request: https://github.com/ezCGP/ezCGP/pull/113
         def do(image):
             if len(image.shape) == 2 or(len(image.shape) == 3 and image.shape[2] == 1):
                 _, dst = cv2.threshold(src=image, thresh=self.thresh, maxval=self.maxval, type=cv2.THRESH_BINARY)
                 return dst
             return image
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|November 2, 2020
|November 2, 2020
|November 12, 2020
|-
|CV primitives
|Completed
|November 2, 2020
|November 2, 2020
|November 8, 2020
|}
== November 02, 2020 ==
'''Monday Meeting:'''
* Time conflict
'''Thursday Team Meeting (November 05):'''
*Discussed work plans for new members
**Concluded they might work to implement emade primitives into ezCGP in order to run comparison tests on titanic
*Discussed progress and pull request from last week (CV primitives)
*Discussed future tasks: Help with PACE CIFAR-10 setup
'''Work Notes'''
* Work meeting on November 7
** Discussed on-going PACE issues
** Worked together with Henry and Ford to figure out ezcgp setup on PACE
** Google doc created by Henry with PACE instructions: [https://docs.google.com/document/d/1fJ0ihQo8l7LGmRLYf76e0w3RjSXIYS6LtabKrxxrZNc/edit https://docs.google.com/document/d/1fJ0ihQo8l7LGmRLYf76e0w3RjSXIYS6LtabKrxxrZNc/]
** Learned about queues and job scheduler available on pace
** Suggested using TMUX for better usability and split terminal functionality
** Example PBS script for ezcgp setup:
 #PBS -N ezCGP_problem_tensorflow_keras          # name of job
 #PBS -l nodes=1:ppn=4                           # resources allocated, 1 node 4 processors
 #PBS -l walltime=5:00:00                        # job will run at most 10 hours
 #PBS -l mem=14gb                          	# job requires 14gb over all nodes
 #PBS -q pace-ice                                # job is submitted to pace-ice
 #PBS -j oe                                      # output and error is combined into the same file
 #PBS -o results.out                             # output file is named gettingStarted.out
 #PBS -m abe                               	# Will send a status email based on any combination of a,b,e.
 #PBS -M hrajvanshy3@gatech.edu       
 cd ~/ezCGP                                
 echo "Started on `/bin/hostname`"               # prints name of compute node job was started on
                               			# computation starts here
 module load anaconda3
 source activate ezcgp-py
 python3 main.py -p problem_tfkeras_transferlearning -t -s 9
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|November 2, 2020
|November 09, 2020
|November 12, 2020
|-
|PACE Setup
|Completed
|November 2, 2020
|November 07, 2020
|November 07, 2020
|}
== November 09, 2020 ==
'''Monday Meeting:'''
* Time conflict, catching up from other people: 
** PACE Setup on Saturday
** Baseline CIFAR-10 scores done should be done by Thursday
** Fixed CV Methods 
*** No more tensor flow errors
'''Thursday Team Meeting (November 12):'''
*Discuss PACE GPU issues 
*Collaborate/talk to NN team about pace-ice setup
*Setup timeline for presentation and rest of the work this semester
'''Work Notes'''
*Assigned issue #115: https://github.com/ezCGP/ezCGP/issues/115
**Create TensorFlow wiki and verify pace-ice GPU usage
***Link to wiki: https://github.com/ezCGP/ezCGP/wiki/PACE-ICE
[[files/Tf wiki.png|center|frameless|561x561px]]
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|November 9, 2020
|November 16, 2020
|November 12, 2020
|-
|Verify Tensorflow is using GPU
|Completed
|November 9, 2020
|November 16, 2020
|November 10, 2020
|}

== November 16, 2020 ==
'''Monday Meeting:'''
* Time Conflict, catching up from other people:
** New members are working on issue: https://github.com/ezCGP/ezCGP/issues/106
** Updates from rest of the team on their progress with respective work
'''Thursday Team Meeting (November 12):'''
*I presented my approach to get TensorFlow to use GPU on pace-ice [[files/Pace gpu.png|center|frameless|413x413px]]
*Plan to do runs now that PACE is setup
*Daniel talked about rm s-art that he has been working on
'''Work Notes'''
*Link to our presentation: [https://docs.google.com/presentation/d/1cbx_daOsFvMZIgBQvVnmiJBmmm-Lvha61Mfe68Ej7c8/edit https://docs.google.com/presentation/d/1cbx_daOsFvMZIgBQvVnmiJBmmm-Lvha61Mfe68Ej7c8]
**I need to create slides for OpenCV preprocessing
*Starting to see some of the initial results from PACE runs
**We are seeing accuracies in the ballpark on 93%
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|November 16, 2020
|November 23, 2020
|November 20, 2020
|-
|Sample CIFAR-10 run
|Completed
|November 16, 2020
|November 23, 2020
|November 20, 2020
|-
|Work on slides
|Completed
|November 16, 2020
|November 23, 2020
|November 20, 2020
|}

== November 23, 2020 ==
'''Monday Meeting:'''
* Time conflict. Catching up from other people: 
** Presented preliminary baseline results
** Discussed plans to generative full results and analysis
** No Thursday meeting because of thanksgiving break
*** Meeting moved to Saturday instead
'''Saturday Team Meeting (November 28):'''
*Went over the presentation and slides
*Discussed talking points, how to present results
**Decided to display Pareto front for all the nine generations 
**Suggested using AUC vs generation graph 
*Suggested adding future work related to CIFAR-10 experiment as part of the direct conclusion of the initial benchmarking experiment 
*Final results from CIFAR-10 runs are looking very good 
[[files/Cifar result.png|center|frameless|432x432px]]
'''Work Notes'''
*Reviewed PACE-ICE GPU notion page
**link to page: https://www.notion.so/PACE-ICE-GPU-for-Ez-CGP-8be7a2e57c6649229f36505d093952dd
*Created slides, talking about work done on CV primitives[[files/Cv preprocessing.png|center|frameless|554x554px]]
*Researched SOTA CIFAR-10 results for benchmark comparisons
**https://paperswithcode.com/sota/image-classification-on-cifar-10
*'''TODO''': Presentation prep: polish slides, practice presentation
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|November 23, 2020
|December 02, 2020
|November 29, 2020
|-
|Presentation Prep
|Completed
|November 23, 2020
|December 02, 2020
|November 30, 2020
|}
== December 02, 2020 ==
'''Presentation Notes:'''
*Trading team:
**Genetic Labeling
**Technical indicator primitives: Maybe too problem specific for a generalizable framework like EMADE?
**Maybe needs more work to show that the problem they are trying to solve is solvable?
*Neural Network: NLP
**Similar to ezCGP: focused on neural architecture search
**The idea of a mutation probability function
***Did they do any experiments to see how performance changed with MUTPB?
**CoDeepNeat: Related to NeatGP?
***ezCGP beat their CIFAR-10 performance
*Modularity Team
**How are they calculating statistical significance?
**Data pair restriction:
***Could the data pair restriction be also used for bloat?
**Diversity measures could be useful 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete and Review Notebook
|Completed
|December 02, 2020
|December 03, 2020
|December 02, 2020
|-
|Presentation Day
|Completed
|December 02, 2020
|December 02, 2020
|December 02, 2020
|}
= Spring 2021 =

== January 25, 2021 ==
'''Monday Meeting:'''
* First Meeting of the semester
** General Notes: Keep notebook up to date etc.
** Team selection: continue work with ezCGP
'''Thursday Team Meeting (January 28):'''
*Decided to work on 2 parallel projects
**1. Implementing new primitives (recurrent neural networks/transformers)
**2. Continue CIFAR-10 experiments to identify bottlenecks in the system and fix them
*Task for next week: Scope both projects out and create reasonable milestones for mid point
'''Work Notes'''
* Research on Transformers and Hyperparameter tuning using genetic evolution: 
** Genetic Algorithm for optimizing Recurrent Neural Network: http://aqibsaeed.github.io/2017-08-11-genetic-algorithm-for-optimizing-rnn/
** Lightweight GPT iimplementation: https://github.com/karpathy/minGPT
** Decided to implement lightweight GPT as a primitive for image classification
 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|January 25, 2021
|February 1, 2021
|January 31, 2021
|-
|Project Tasking and Planning
|Completed
|January 25, 2021
|February 1, 2021
|January 31, 2021
|}
== February 1, 2021 ==
'''Monday Meeting:'''
* Bug fixes from recent changes made last semester almost done
* Started verification of preprocessing block
* We shared our plan of doing 2 parallel projects with the class
** Shared my research on transformers during breakout (January 25 work notes)
* Daniel plans to do a test run on Pace-ice without transfer learning
'''Thursday Team Meeting (February 4):'''
*Discussed concrete details for next week
*Daniel plans to update the problem file to work without transfer learning
*I plan to test minGPT without ezCGP to evaluate suitability for inclusion into the ezCGP framework
'''Work Notes'''
*Tried accessing PACE, had issues getting on, contacted Jason to resolve
*minGPT CIFAR-10 run (https://github.com/karpathy/minGPT)
**Base model can generate CIFAR-10 like images (not classification)
**Trained on Google Colab: 10+ hours of training for decent results
*Other research notes: To perform classification, Datapoints etc.
**"AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE:" https://arxiv.org/pdf/2010.11929.pdf
**Implementation: https://github.com/jeonsworld/ViT-pytorch
**General Idea: Add label to the end of the encoding, then use an image as a prompt
*Conclusion
**Training times are likely prohibitive for the use of untrained architectures within genetic programming applications
**Pretrained transformers are great for performing a multitude of tasks but likely redundant with transfer learning that we are trying to move away from
 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|February 1, 2021
|February 8, 2021
|February 7, 2021
|-
|Run minGPT on CIFAR
|Completed
|February 1, 2021
|February 8, 2021
|February 7, 2021
|}
== February 8, 2021 ==
'''Monday Meeting:'''
* Discussed issues with normalization:
** Issue: https://github.com/ezCGP/ezCGP/issues/131
** Solution: Do histogram normalization, maybe use a CV function
** Daniel talked about the new problem file: https://github.com/ezCGP/ezCGP/commit/82b7ad35ef545ae41a4f6adac89927304b388ced#diff-b41dff833e0a0a03207c9b5c7d30848ea72d137bc55ecf9aaf3578c2cd47aa5a
* Self-grading according to rubric:[[files/Imagerubric self grade.png|center|frameless|1661x1661px]]
'''Thursday Team Meeting (February 11):'''
*Group work session, PACE-ICE sample 
**Figuring out new approach for storage/symlink
***Considering options between single team repository vs shared conda folder
**Bug-fixing some of the unstable new changes
'''Work Notes'''
*Waiting on CIFAR-10 runs from Daniel
**Possible memory issues killing the process after ~30 mins of run-time
*Replaced normalization primitive with equalize
** Link to Pull request: https://github.com/ezCGP/ezCGP/pull/132
** Issue: Normalization does not work with pillow image formatting 
** solution: Use in-built pillow function to perform equalization
 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|February 8, 2021
|February 15, 2021
|February 14, 2021
|-
|Update normalize primitive
|Completed
|February 8, 2021
|February 15, 2021
|February 14, 2021
|}
== February 15, 2021 ==
'''Monday Meeting:'''
* Stock team: Talked about exponential smoothing paper
** New labeling algorithm to test predictions and new fitness function
* ezCGP: Daniel talked about preliminary PACE-ICE results
** Also talked about normalization primitive
'''Thursday Team Meeting (February 18):'''
*Group work session to test run ezCGP without transfer learning
**Had issues with batch size, incompatible shapes
**One hour group work session to figure out what the bug was, more details in work notes. 
'''Work Notes'''
*Added multi-channel support to normalize/equalize 
**Updated PR: https://github.com/ezCGP/ezCGP/pull/132 (merged)
*Did new pace-ice setup 
**Moved symlink to shared repo
**updated personal repository and PBS file
*Batch size bug:
**Commit link: https://github.com/ezCGP/ezCGP/commit/4d5e4552fc49ec71d824bd79600d3e7411df7804
**Had batch size argument in the input layer, meaning that we couldn't train leftover training data if it wasn't evenly divisible
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|February 15, 2021
|February 22, 2021
|February 22, 2021
|-
|Multi-channel support for equalize
|Completed
|February 15, 2021
|February 22, 2021
|February 18, 2021
|}
== February 22, 2021 ==
'''Monday Meeting:'''
* NLP team planning to do PACE runs as well
* Breakout meeting
** Decided to benchmark and fine-tune individual evaluation training times
*** Run experiments to figure out training time and batch size for each individual
*** Seed architectures that are known to perform well
'''Thursday Team Meeting (February 25):'''
*Rodd discovered a bug that increased training times 
**Worked together during the meeting to do a quick fix
**Bug related to pipeline wrapper and variable persistence
**Commit link: https://github.com/ezCGP/ezCGP/commit/452d03194f475db1429b632e3b9d2faf6ffbd8ae
'''Work Notes'''
*The question we are trying to answer:
**ezCGP works well with transfer learning and pretrained weights
**Possible reasons for underperforming otherwise:  
**1) Can it not converge to the right architecture.   OR  
**2) given the right architecture, is it unable to train it sufficiently. => What we hope to figure out based on this test
*Setup transfer learning operators to run without imagenet weights
*Perform runs without pretrained imagenet weights on transfer learning
**Essentially using Resnet architecture to see if ezCGP training parameters are sufficient for converging on CIFAR 10 with a fit individual
**Initial Run:
  234/234 - 8s - loss: 0.1108 - accuracy: 3.7828e-04 - precision: 0.9676 - recall: 0.9618 - val_loss: 1.3538 - val_accuracy: 7.3117e-04 - val_precision: 0.7209 - val_recall: 0.6968
*TODO: Come up with detailed methods to analyze results and fine-tune training parameters accordingly
*TODO: Run with categorical accuracy and bug fix from Thursday
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|February 22, 2021
|March 01, 2021
|February 28, 2021
|-
|PACE runs for tuning training loop
|Completed
|February 22, 2021
|March 01, 2021
|February 28, 2021
|}

== March 01, 2021 ==
'''Monday Meeting:'''
* Figuring out visualization pipeline from last semester
** Visualization: https://github.com/ezCGP/ezCGP/blob/2019F-stable/visualize.py
** Pareto Front: https://github.com/ezCGP/ezCGP/blob/master/post_process/plot_things.py 
** Daniel is going to try to recreate pareto fronts after making necessary changes to the viz pipeline
* I am going to continue working on individual visualization and analyze the individuals once I am done

'''Thursday Team Meeting (March 04):'''
*Quick status updates
**Daniel still working on Pareto front
**I am still working on analyzing training benchmarking results
**Rodd reworked the data object so we can pass multiple ezData objects instead of one object with multiple attributes or with a list
**New CIFAR-10 run with transfer learning to validate changes
'''Work Notes'''
* Started working to get the visualization code updated to work with changes in the framework
** Created pull request: https://github.com/ezCGP/ezCGP/pull/151
* Results:
[[files/Individual no cifar 2.png|center|frame|200px]]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|March 01, 2021
|March 08, 2021
|March 10, 2021
|-
|Visualize Results
|Completed
|March 01, 2021
|March 08, 2021
|March 7, 2021
|}

== March 08, 2021 ==
'''Monday Meeting:'''
* ezCGP:
** Presented individual visualization
** Discussed adding dense layers and removing preprocessing steps
* Breakout Meeting:
** Plan for presentation/new semester student tasks
** Further clarified on task priorities: 
*** Prioritize finishing training benchmarks over dense layer experiment
** Discussed training parameters, number of individuals/epochs etc.
** Rodd proposed automating the pbs scheduling to continue runs beyond 8 hour mark.
'''Thursday Team Meeting (March 11):'''
* Daniel started work on creating Dense Layer Block
* He is going to do a benchmark run for midterm presentation
* Created issues for max pooling: https://github.com/ezCGP/ezCGP/issues/155
* and Dropout: https://github.com/ezCGP/ezCGP/issues/158
'''Work Notes'''
*Worked on producing training time benchmarks outside of ezCGP:
**Replicated the structure to train VGG16 with the same parameters as in ezCGP
***Batch size = 128
***Epochs = 10/20
**Ran the following experiments:
***check convergence with imagenet weights on CIFAR10
***check convergence with no pretrained weights on CIFAR10
**Result:
***We can see that pretrained weights don't affect convergence dramatically
***20 epochs with given batch size is likely sufficient to reach convergence on this dataset with good accuracy. 
***VGG16 seems converge in around 15 epochs, but more complex architectures might need more training. 
***We can consider raising the number of epochs after a few generations of initial training [[files/Test tf convergence.png|center|frameless|404x404px]][[files/Test2 tf noweight.png|center|frameless|412x412px]][[files/Test3 20epoch.png|center|frameless|404x404px]]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|March 08, 2021
|March 15, 2021
|March 10, 2021
|-
|Benchmarking Analysis
|Completed
|March 08, 2021
|March 15, 2021
|March 10, 2021
|}

== March 15, 2021 ==
'''Monday Meeting:'''
* Presented results for benchmarking analysis from last week
* Daniel talked his progress with pooling and dropout primitive runs

'''Thursday Team Meeting (March 18):'''
* Worked on Presentation
** Completed corresponding slides
** Created plot and visualization
*** Pareto fronts for no transfer learning
** Discussed new member projects
*** Improve our ability to visualize genomes
*** Research, develop, and test new mating methods for Cartesian GP
*** Reference existing CNN architectures to develop new primitives and genome seeds
*** Conv block -> dense block

'''Work Notes'''
* Started benchmark run
** Validation accuracy came out to about 56.4%
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|March 15, 2021
|March 22, 2021
|March 21, 2021
|-
|Final midterm run
|Completed
|March 15, 2021
|March 22, 2021
|March 22, 2021

|-
|Work on Presentation
|Completed
|March 15, 2021
|March 22, 2021
|March 22, 2021

|}

== March 22, 2021 ==
'''Monday Meeting:'''
* Midterm Presentations: https://docs.google.com/presentation/d/1fMtCogms23wqFeJDX-Sf56T6UzzbgvGezD7s9RCG6gY/edit
* Stocks
** Overview of the paper they have been talking about during updates on Monday
** Want to implement new technical indicators
** Why do they want to look at crypto?
* Modularity
** Sphinx documentation, maybe we should also consider using Sphinx
* NLP
** Amazon product review dataset
** They also had PACE-ICE issues like we did
** Pytorch functionality in EMADE sounds exciting
* Bootcamp
** Titanic!
** Same old errors haha
'''Thursday Team Meeting (March 25):'''
* Finalize new member projects
* Come up with plan for onboarding and the balance between learning the framework and getting work done in the short time until final

{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|March 22, 2021
|March 29, 2021
|March 28, 2021
|-
|Explore new member projects
|Completed
|March 22, 2021
|March 29, 2021
|March 25, 2021
|}

== March 29, 2021 ==
'''Monday Meeting:'''
* New member introductions
* Decided to split into three subteams in order to keep work modularized
** Mating
** Visualization
** CIFAR-10 Neural architecture search (Daniel and I)
'''Thursday Team Meeting (March 25):'''
* Rodd did another onboarding presentation for new members
* Decided to poll interest to decide who works on what project
* Presented results from pooling run (See work notes below)
* Discussed some observations, such as why dropout layers do not show up in later generations
'''Work Notes'''
* Testing Max Pooling/Dense Layer with Daniel. Found some issues with individual size and lack of diversity.
** Possible bugs in code, need to validate results further
* Got an accuracy of 68.4% (much better than 56% from before)
* Need to perform runs with the new changes
* Link to PR: https://github.com/ezCGP/ezCGP/pull/160 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|March 29, 2021
|April 5, 2021
|April 4, 2021
|-
|Pooling and Dropout Experiments
|Completed
|March 29, 2021
|April 5, 2021
|April 2, 2021
|}

== April 05, 2021 ==
'''Monday Meeting:'''
* Presented our results with working Dropout and Pooling Layers
* Significantly better performance (68.4%) compared to midterm
* Introductory presentation for new members by Rodd to get them familiar with the code 
* This week's objective for me included further analyzing and testing the results from our latest runs by setting up some small experiments
* Daniel and I decided to guide visualization team while Rodd worked with the mating team

'''Thursday Team Meeting (April 08):'''
* New team members are going to work in two teams: visualization and mating (Mating team lead by Rodd)
* Mating Team will replicate results from the following research paper: ([[https://link.springer.com/content/pdf/10.1007%2F978-3-319-77553-1_13.pdf A Comparative Study on Crossover in Cartesian Genetic Programming]) 
* Visualization team finished adding node numbers and showing inactive nodes 
[[files/EzCGP individual tree.png|center|frame|200px]]

'''Work Notes'''
* I ran experiments and analysis motivated by runs from last week:
** I added average pooling to the primitive pool and analyzed the initial population for any interesting trends
** I then Hard-coded some dense layers in order to validate the need for dense layer blocks
* I also explored why individuals in our previous runs only showed 4-5 layer deep networks
** Examining all the individuals before selection seems to have varying sizes 
** Individuals with 6-8 nodes are being generated, but they have poor performance
** Larger architectures likely means more room for mistakes in the architecture in the initial random seed
** Experimented with changing objective score to be loss and accuracy (maybe would help)

{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|April 05, 2021
|April 12, 2021
|April 11, 2021
|-
|Run Experiments: Individual Size, Objective function
|Completed
|April 05, 2021
|April 12, 2021
|April 11, 2021
|-
|Run Experiments: Weighted primitives, Hard-code dense layers
|Completed
|April 05, 2021
|April 12, 2021
|April 11, 2021
|}

== April 12, 2021 ==
'''Monday Meeting:'''
* Discussed possible approached to add parameter names to visualization
* Mating team started working on symbolic regression as an onboarding task for new members
* Decided to give up on seeding project for now in order to work on visualization
'''Thursday Team Meeting (April 15):'''
* Visualization Team 
** Added parameters 
** https://github.com/ezCGP/ezCGP/commit/16a9bfe1ee93c4bab6fdc848c31799953349797c
** Daniel presented the dense layer block that is finally starting to work
** Still can't get past first-generation though
'''Work Notes'''
* Testing Dense Layer block with Daniel.
* We are able to create individuals with a mix of dense layers and dropouts in a separate block
* Run crashes when trying to mate
** Further looking into it showed that it is probably because some individuals crash because of GPU memory issues
** Models likely have too many parameters, but needs more testing
[[files/Dense block.png|center|frame|200px]]

{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|April 12, 2021
|April 19, 2021
|April 18, 2021
|-
|Dense Layers
|Completed
|April 12, 2021
|April 19, 2021
|April 25, 2021
|}

== April 19, 2021 ==
'''Monday Meeting:'''
* PACE ICE issues with training bottleneck for Dense Layers
* Mating team is working on symbolic regression
* Demonstrated visualization tool to rest of the team so they can use it for visualizing their results
** They also worked with One-point crossover and Point mutation

'''Thursday Team Meeting (April 22):'''
* Starting discussion around the presentation
** Assigned slides to team members and create an outline
* Kevin scraped data about neural networks in an attempt to figure out the best primitives to incorporate in ezCGP next
** Interesting strategy, hard to say if it is very useful though
* PAGIE-1 results from mating
'''Work Notes'''
* Created presentation outline
* Tested Dense Layer block along with Daniel to see if capping the number of nodes in dense layer would allow us to bypass the GPU memory issues
* Identified and cleaned up results to present from the pooling and dropout experiment run
[[files/Pooling 41.png|center|frame|200px]]

{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|April 19, 2021
|April 26, 2021
|April 25, 2021
|-
|Visualize results from dropout run
|Completed
|April 19, 2021
|April 26, 2021
|April 26, 2021
|-
|Create Presentation
|Completed
|April 19, 2021
|April 26, 2021
|April 25, 2021
|}

== April 26, 2021 ==
'''Monday Meeting:'''
* Created presentation outline
* Updates on GPU issues with dense layer block

'''Thursday Team Meeting (April 29):'''
* Dry run through the presentation
* Link to completed presentation: https://docs.google.com/presentation/d/1eMU46VktpHKwrQK5wQQ_oSM8ZK6Zzxky1rn5YFm27iw/edit#slide=id.ga25ec3f798_0_0

'''Work Notes'''
* Visualized individuals and Pareto fronts for presentation with Daniel
* Final run with Dense Layer block 
* Worked on presentation slides 

'''Final Presentations (April 30):'''
* Presentation Notes:
* Stocks
** Added TA-Lib primitives to emade
** Added new dataset
** Monte Carlo Individuals performed better than random
** Jason mentioned more rigorous hypothesis testing as part of VIP going forward
* ezCGP
** Link to completed presentation: https://docs.google.com/presentation/d/1eMU46VktpHKwrQK5wQQ_oSM8ZK6Zzxky1rn5YFm27iw/edit#slide=id.ga25ec3f798_0_0
** I presented the developed with CIFAR-10 neural architecture search along with Daniel
* NLP
** Also focused on streamlining testing pipeline like ezCGP
** Amazon Product Review Dataset
** Baseline model achieved 91.73% accuracy
** Best EMADE individual showed 92.8% after 22 generations
** Seems to rely on seeding
* Modularity
** Presented new objective and talked about Cohan score
** Weighted ARL size is interesting idea
** ezCGP has similar issues with trying to produce deeper trees


{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Populate Notebook
|Completed
|April 26, 2021
|May 1, 2021
|May 1, 2021
|}