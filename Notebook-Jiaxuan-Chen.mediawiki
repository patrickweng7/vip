==Team member==
Name: Jiaxuan Chen

Email: jchen813@gatech.edu

Interests: Game AI, Video Games

Cell Phone: 678-549-3504

Sub-team: Anjana Chamarthi, Bryce Jackson, Alex McQuilkin



= Fall 2020 =

=== Week 4: September 9 ===

=== Lecture Notes ===
Self graded rubric: 90/100
* Explored Kaggle and Titanic ML challenge.
** Went over a example of Titanic solution with some data cleaning before any processing such as deleting irrelevant columns and numeric numbers to represent our string data.
* Assigned to a subteam and created a group chat for subteam discussion. 

=== Titanic ML Challenge ===
* Dropped PassengerId, Name, and Ticket number from both train data and test data since they are irrelevant to the end result. 
* Dropped Cabin column because most of the entries are empty thus the remains have no impact to the end result.
* Set entries of sex and embarked to numeric numbers
* Using [https://machinelearningmastery.com/naive-bayes-for-machine-learning/ Gaussian Naive Bayes] while others used Logistic Regression and other classifiers, the accuracy was 0.7985074626865671.
[[files/Confusion Matrix for Bayers.png|thumb]]

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Self graded Rubric
|Completed
|September 9, 2020
|September 16, 2020
|September 16, 2020
|-
|Complete Titanic Challenge
|Completed
|September 9, 2020
|September 16, 2020
|September 16, 2020
|}

=== Week 3: September 2 ===

==== Lecture Notes ====
* Classification Measures
** Moved on to multiple objective optimization
** Pareto dominance can be used to affect probability of mating
**[[files/Classification meauses.png|thumb|Classification Measures]]We have 4 Classification Measures
*** with Maximization measures of 
**** True Positive Rate (TPR) = TP/P = TP/(TP+FN)
**** True Negative Rate (TNR) = TN/N = TN/(TN+FP)
*** and minimization measures of 
**** False Negative Rate (FNR) = 1 - RPR
**** False Positive Rate (FPR) = 1 - TNR = 1 - SPC
*** and other measures of 
**** Positive Predictive Value (PPV) = TP/(TP +FP) bigger the better
**** False Discovery Rate (FDR) = FP/(TP+FP) smaller the bettter
**** Negative Predictive Value (NPV) = TN/(TN+FN) bigger the better
**** Accuracy (ACC) = (TP+TN)/(P+N)

* Objective space
** Each individual is evaluated using objective function such as
*** Mean squared error, cost, complexity, true positive rate...
** Objective scores give each individual a point in objective space
** This can also be referred to as the phenotype of the individual
** An individual is Pareto if there is no other individual which outperforms the individual on all objectives(meaning they are the only point on its axis in objective space)
** Lower Pareto ranks beat higher Pareto ranks while the ties on the same front are broken by crowding distance such that higher crowding distance wins.

===== Second Half of Lab2: =====
**[[files/Original AUC.png|thumb|Original AUC]]At first with 50 of individuals to select for the next generation(Mu) and 100 children to produce at each generation(Lambda), the final AUC was around 2.38.
** I played around with mutation probability, MU, and Lambda and found out that the lower the Lambda is, the lower the AUC is because the tree size is smaller.
**[[files/New AUC.png|thumb|New AUC]]So I set the Lambda and Mu to half of what they were and got 1.07 of AUC.
=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish Second Half of Lab2
|Completed
|September 2, 2020
|September 9, 2020
|September 9, 2020
|-

|}

=== Week 2: August 26 ===

==== Lecture Notes: ====
*Genetic Programming: Individual now serve as a function that takes in primitives and terminals.
** The function represents in the form of tree **
** The operation proceeds from left to right, bottom to top, and the eventually the output is produced at root of the tree.
** The tree can be parsed to list by using Depth First Search starting with the left most node.
**Crossover in GP is swapping subtrees
**Mutation in GP can be done through inserting/deleting/changing the node value.

===== First Half of Lab2: =====
** At first I added the sqrt and sin operation but the function failed because we could not potentially pass in negative value which would not work. So I swapped sqrt to cos and it passed although the fitness scores goes up and down as generations go by.
** I chose mutInsert for the mutation method which inserts a new branch at a random position in individual.
**[[files/Low.png|thumb|GP with low max depth]][[files/High.png|thumb|GP with high max depth]]I also altered min and max depth a bit and found out that the higher max , I have attached the graphs for comparison.
=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish First Half of Lab2
|Completed
|August 26, 2020
|September 2, 2020
|August 31, 2020
|-

|}
== August 19, 2020 ==

=== Lecture Notes ===
* Genetic Algorithms - evolutionary algorithms that goes through various generations of selection by mating and mutating to create a best fit individual.
* Mate/Crossover: represents mating between individuals.
* Mutate: introduces random modifications; purpose is to maintain diversity.
* Selection: represents 'survival of the fittest'; gives preference to better individuals, therefore allowing them to pass on their genes.
* Selection Process:
# Randomly initialize population
# Determine fitness of population
# Repeat the following steps until finding the best fit individual:
## Select parents from population
## Perform crossover(mating) on parents creating population
## Perform mutation of population
## Determine fitness of population
=== Install Jupyter Notebook and Start Lab 1 ===
* Install anaconda
* Open anaconda navigator and install jupyter notebook
* Once finished, open up jupyter notebook in a browser
* Download lab 1 from github and save it with .ipynb
* Open up lab 1 in jupyter notebook
=== Lab 1 ===

* One max is a simple genetic algorithm problem that aims to find a bit string containing all 1s with a set length.
* Through mutation and crossover, the fitness scores of new generation increase. However, the algorithm does not always reach the its objective with the given size of 40 generation due to the probability of mutation/crossover and various factor. By adjusting population size,  probability of mutation/crossover and other factors we can obtain a higher chance of achieving global max fitness.
* The goal is to place n queens in a nxn chessboard in a way that no queen attack others.
* Instead of maximize the fitness as in one max, N Queens aims to minimize the fitness, which is the conflict between queens.
[[files/NQueens11.png|thumb]]

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Create Notebook
|Completed
|August 19, 2020
|August 26, 2020
|August 24, 2020
|-
|Join Slack
|Completed
|August 19, 2020
|August 26, 2020
|August 19, 2020
|-
|Install Jupyter Notebook
|Completed
|August 19, 2020
|August 26, 2020
|August 19, 2020
|-
|Lab 1 - DEAP
|Completed
|August 19, 2020
|August 26, 2020
|August 24, 2020
|-
|}