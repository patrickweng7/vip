== Team Member ==
Team Member: Joo Won (Michael) Lee

Email: jlee3368@gatech.edu

Cell Phone: 770-335-9582

Interests: Machine Learning, Python, Computer Science

== January 7, 2019 ==
'''Bootcamp Lecture Notes:'''
* Got introduced to Genetic Algorithms
* Learned about:
** Individuals, Population, Fitness, Mating
* Introduced to Jupyter Notebook
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Join the VIP Slack
|Completed
|January 7, 2019
|
|January 12, 2019
|-
|Install dependencies
|Completed
|January 7, 2019
|
|January 10, 2019
|-
|Complete Lab 1 - Genetic Algorithms
|Completed
|January 7, 2019
|
|January 13, 2019
|}

== January 12, 2019 ==
'''Individual work:'''
* Installed the dependencies
* Started on the Genetic Algorithms assignment
* Spent some time reading up on the DEAP documentation
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Lab 1
|Completed
|January 7, 2019
|
|January 13, 2019
|}

== January 14, 2019 ==
'''Bootcamp Lecture Notes:'''
* Went through group presentations
* Learned about Genetic Programming
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Lab 2 - Symbolic Regression
|Completed
|January 14, 2019
|
|January 27, 2019
|}

== January 27, 2019 ==
'''Individual work:'''
* Started on the Genetic Programming assignment (Symbolic Regression)
* Spent some time reading up on the DEAP documentation
* Read through the list of numpy math operations to add to the primitive set
** Added the primitives square and absolute
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Lab 2 - Symbolic Regression
|Completed
|January 14, 2019
|
|January 27, 2019
|}

== January 28, 2019 ==
'''Bootcamp Lecture Notes:'''
* Went through group presentations
* Learned about Genetic Programming with Multiple Objectives
* New terms:
** True Positive/Negative, False Positive/Negative, Actual Positive, Negative
** Confusion Matrix
** Sensitivity, Specificity, Fallout, Accuracy
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Lab 2 - Multi Objective GP
|Completed
|January 28, 2019
|
|February 3, 2019
|}

== February 3, 2019 ==
'''Individual work:'''
* Started on the Genetic Programming assignment (Multiple Objective)
* Read through the list of numpy math operations to add to the primitive set
** Added the primitives sin, cos, tan, and square
[[files/MOGP_pareto_front.png|center|thumb|483x483px]]
* Was unable to implement a version of GP that reduces AUC by 25%
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete GP assignment
|Completed
|January 28, 2019
|
|February 3, 2019
|}

== February 4, 2019 ==
'''Bootcamp Lecture Notes:'''
* Went through group presentations
* Introduced to scikit-learn
* Started on the Titanic Data set through Kaggle
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|ML with Titanic Data Set
|Completed
|February 4, 2019
|
|February 9, 2019
|}

== February 10, 2019 ==
'''Individual work:'''
* Read through instructions for the Titanic Data set
* Started on the Titanic Data set ML assignment
* Read some of the Titanic Data solutions to get ideas for my own implementation
** Changed the ages from distinct values to 5 age groups
** Parch and SibSp was combined into one familysize value, then was used to determine whether or not they boarded alone
** The fares were grouped similarly to age, where ranges of fares were banded together
* New x_train.head() :
[[files/new_x_train_head.png|center|thumb|483x483px]]
* Resulting confusion matrix:
** [[163  28]
**   [  33   71]]
* Kaggle score: 0.76555
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Titanic Data Set
|Completed
|February 4, 2019
|
|February 9, 2019
|-
|Submit to Kaggle
|Completed
|February 4, 2019
|
|February 9, 2019
|}

== February 11, 2019 ==
'''Bootcamp Lecture Notes:'''
* Went through group presentations
* Moved on to evaluating the Titanic Data Set through GP
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Titanic Data Set with GP
|Completed
|February 11, 2019
|
|February 17, 2019
|}

== February 17, 2019 ==
'''Individual work:'''
* Converted the ML pre-processing to the GP (single-objective) program
* Changed the evalSymbReg function to work with the Titanic Data set
** Evaluate whether or not the passenger survived, then convert the mean squared error to discrete values of 0 and 1
* Fitness plot over multiple generations:
[[files/2019 Titanic GP Group 5 res.png|center|thumb|483x483px]]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Titanic Data Set with GP
|Completed
|February 11, 2019
|
|February 17, 2019
|}

== February 18, 2019 ==
'''Bootcamp Lecture Notes:'''
* Went through group presentations
* Spent time installing EMADE and its dependencies
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install Emade
|Completed
|February 18, 2019
|
|February 19, 2019
|}

== February 19, 2019 ==
'''Individual work:'''
* Finished installing EMADE dependencies
* Finish cloning the EMADE repository
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish cloning EMADE
|Completed
|February 18, 2019
|
|February 19, 2019
|}


== February 25, 2019 ==
'''Bootcamp Lecture Notes:'''
* Met with group to discuss presentation prep
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run EMADE
|Completed
|
|
|February 25, 2019
|}


== March 4, 2019 ==
'''Bootcamp Lecture Notes:'''
* Met with group to discuss presentation prep
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Make a presentation
|Completed
|February 25, 2019
|
|March 6, 2019
|}


== March 7, 2019 ==
'''Team Meeting Notes:'''
* Planned for group presentations
* Created Google Sheets file to share within group
* Tried to get out a visualization for EMADE data
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish up presentation
|Completed
|February 25, 2019
|
|March 6, 2019
|}


== March 11, 2019 ==
'''Presentation Day'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Pick top 3 groups to join
|Completed
|March 11, 2019
|
|March 25, 2019
|}


== March 25, 2019 ==
'''Team Meeting Notes:'''
* Chose top choices for groups
* Assigned to the EEG group
* Given a brief overview of group's current status
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read up on EEG work
|In Progress
|March 25, 2019
|
|
|}


== March 29, 2019 ==
'''Team Meeting Notes:'''
* First time meeting with entire group
* Introduced to the basics of the EEG process
* Given a book to read on DSP
** Book focuses on DSP applications to neural processes
* Chapters of interest:
** DSP, Morlet wavelets and wavelet convolution
[[files/eeg_book_cohen.jpg|center|thumb|483x483px]]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read chapters of interest
|Completed
|March 29, 2019
|
|March 30, 2019
|}

== March 30, 2019 ==
'''Individual work:'''
* Read a couple of chapters of Analyzing Neural Time Series Data
** Read introductory chapter and chapter on limitations
** Learned why time series data is used to analyze neural processes
** Next chapters to read:
*** DSP, FFT, Morlet wavelets and wavelet convolution
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read chapters of interest
|Completed
|March 29, 2019
|
|March 30, 2019
|}


== April 1, 2019 ==
'''Team Meeting Notes:'''
* Basic Monday meeting
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Come up with ideas based on reading
|In Progress
|April 1, 2019
|
|
|}


== April 5, 2019 ==
'''Team Meeting Notes:'''
* Given the task of figuring out how the EEG data works
* Given a jupyter notebook by Scott to test out primitives
** Try to do any basic operation to familiarize myself with EEG data
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Implement a primitive
|In Progress
|April 5, 2019
|
|
|}


== April 6, 2019 ==
'''Individual Work:'''
* Watched some videos on DSP and FFT
* Read the chapter on Morlet Wavelets and Wavelet Convolution
** Seems interesting as it offers advantages over regular or truncated sine waves
** Morlet wavelets offers both the temporal accuracy of strong temporal weighting
** without the rough edges of the boxcar temporal weighting
[[files/different_waves_vs_eeg.png|center|thumb|483x483px]]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read chapter on Morlet Wavelets
|Completed
|March 29, 2019
|
|April 6, 2019
|-
|Implement a primitive
|In Progress
|April 5, 2019
|
|
|}

== April 8, 2019 ==
'''Team Meeting Notes:'''
* Regular meeting
* Got some clarification on how EEG data works
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Implement a primitive
|In Progress
|April 5, 2019
|
|
|}

== April 15, 2019 ==
'''Team Meeting Notes:'''
* Discussed what we would do for the presentation
'''Individual work:'''
* Directed to Joel to work on some EMADE code
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Work on presentation slides
|Completed
|April 15, 2019
|
|April 22, 2019
|-
|Read some EMADE code
|In Progress
|April 16, 2019
|
|
|}

== April 19, 2019 ==
'''Team Meeting Notes:'''
* Worked on putting together the presentation

'''Individual Work:'''
* Worked with Joel on writing a wrapper class for clustering_methods
** Implemented for all 6 clustering methods
[[files/cm_wrapper.png|center|thumb|483x483px]]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Implement wrapper class
|Completed
|April 15, 2019
|
|April 19, 2019
|-
|Read some EMADE code
|In Progress
|April 16, 2019
|
|
|-
|Work on template to signal methods
|In Progress
|April 19, 2019
|
|
|}

== April 22, 2019 ==
'''Final Presentation Notes:'''
* <u>Stocks</u>
** Use EMADE to predict stock prices (GE stock values)
** Implemented technical indicators as feature construction
** Using time series data
** Some preprocessing methods implemented into EMADE
** Statistical Models used: SARIMA (Seasonal Autoregressive Integrated Moving Average), VARMA (Vector Autoregressive Moving Average), HWES (Holt-Winters Exponential Smoothing)
** Deep Learning Models used: MLP, RNN, LSTM
** Accuracy metrics used to evaluate models: SMAPE (symmetric Mean Absolute Percent Error), MASE (Mean Absolute Scaled Error)
** Results: 
*** Statistical models have lower error than DL models, likely due to Statistical models fitting directly on testing data
*** Results are rather trivial and not applicable to real life
** Problems:
*** Emade timeout errors, workflow of Emade, unfamiliarity with implementation
** Future work:
*** run EMADE, more DL models, Sector market indicators

* <u>Caching</u>
** support all data types that EMADE supports
** Create APIs that give users options to use their own cache invalidation method for their own problem space

** Cache Maintenance - add documentation
*** Dockerizing Cache - simplify, standardize process of running on all OS's - makes updates easier, less work for GCP setup
*** Future updates: standardize outputs, build faster, fix conda version problems, test on other OS's
** Cache Validation
*** Want more optimal system to maximize benefit of subtrees stored
*** Solution: use the Dynamic Programming solution to the Knapsack Problem
*** Problems with solution: time ineffective, time cost is large even when the number of subtrees in cache is very small
*** Potential solutions to those problems: Scale weights, benchmarking, using buckets, etc
** Potential optimization of Knapsack
*** Performance vs precision tradeoff
**** Sacrifice precision with approximation algorithm, greedy, scaling & rounding
*** Parallelism
**** Hypercubes vs irregular mesh
** Scripts/ work done
*** Wrote a script to run EMADE automatically

* <u>EEG (us)</u>
** Presentation link:
*** https://docs.google.com/presentation/d/1UBfFPGBJ5NM3D_9h8j1SWma7n7bXaxWzh4zxxjiS9z8/edit?ts=5cbe4470

* <u>Data Visualization</u>
** Provide a visual interface to be able to interact with EMADE
** Goals for 2019
*** More visualizations
**** Visualizations of pareto front over time
*** Improve usability
*** Refactor Code
*** Make app generalize
*** Visualization of parents: concept
**** Want to have a visualization for where the parent of a dominated from comes from in a front.
** User Study Feedback
*** documentation
**** Clearly state the separation between EMADE and EMADE-visualization
**** more detail on creating an environment
*** UI Feedback
*** Visualization
*** XML Importing
**** Goal:
***** Generalize visualizations for any type of problem and any kind of objective functions
** Pickling First Years
*** Goal Reduce the number of times we make a call to the database in order to increase efficiency
**** Pickling
** Future
*** Make EMADE log meta data in mysql table
*** finish hierarchy visualizations
*** add seed creation GUI
*** GUI for executing sql queries

* <u>DEEP</u>
** Subteam B:
*** Regression Problem Housing Prices
*** Progress since Midterm:
**** identified Kaggle Housing Price dataset
**** incorporated changes into ezCGP to support regression problems
**** Added Average Percent Change (APC) and Mean Absolute Error (MAE) as fitness functions for regression problem
**** used StandardScaler to split and normalize training/testing data and preprocessed the housing dataset
*** Housing Price Dateset:
*** Parameter Choices:
**** restricted primitives to only dense layers, finding optimal number of dense layers
*** Individual with Best APC:
**** uses about 7 dense layers, 6 hidden
**** predicted price is just 1 value: housing price
**** trained best individual for 35 epochs
*** Results on Housing Dataset
**** compared to other kaggle results
**** regularized NN performed slightly better
** Subteam A:
*** Improving structure of ezCGP
*** Progress since Midterm:
**** implemented argument/parameter mutation
**** changed the framework to deal with large datasets
*** Dataset 1: MNIST
**** used because it is easy to evaluate and accessible, population size was 12, epoch set at 1, ran 35 generations
**** Results on MNIST
***** best individual is 95.85% and 98.84%
***** took the individual and trained on full training set
***** got 99.85%
**** Compare to Midterm Results:
***** trained model further, about 42 epochs. best accuracy 99.43%
***** assume since its continuously increasing, will keep going up
*** Dataset 2- CIFAR-10
**** Parameters:
***** pop size 9, epochs to 3, 25 generations
**** Results on CIFAR-10:
***** best accuracy of 79.7%, ran for 100 epochs, increased in accuracy by 1.32%
*** Dataset 3- CIFAR -100
**** Parameters:
***** pop size 9, 5 epochs, 50 generations
**** Results:
***** low accuracy but still improved
***** best individual was bad - just a conv block->max pooling->average pooling
***** trained over 200 epochs because accuracy plateaued
***** cifar-100 model under performed when trained on whole dataset. why?
****** lack of genetic diversity
****** smaller models learn faster
****** larger models learn more defining features and therefore generalize better
***** how to fix?
****** increase number of epochs
****** utilize first and second order gradient information to make better judgement whether its done learning
****** kill smaller individuals

== Semester Summary ==
'''Things I Learned:'''
* Overall, I think I got a good mix of some GP and ML concepts
* Still feels like there's a lot more things that I could learn about these topics
* Got to learn new things about the brain that I've never heard about before
** Different signals in the brain controlling different sensory inputs
** Being able to elicit a muscle response purely through stimulation of the brain

'''Goals for the future:'''
* Further increase my understanding of GP and ML concepts
* Better understand EMADE as I currently have a rather shallow knowledge of how the code works
'''Self-evaluation''':

Overall, I think I deserve an A in the class. As almost the entire semester was spent being caught up to speed with all the knowledge that we needed, I feel that I put in my best effort to learn all the learn material. While I wasn't able to contribute much code-wise to my group, I hope to be able to have much more solid contributions in the future.