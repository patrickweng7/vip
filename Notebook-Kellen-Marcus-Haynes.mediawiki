== Team Member ==
Team Member: Kellen Haynes

Email: khaynes31@gatech.edu
== February 19, 2020 ==
== February 12, 2020 ==
'''Team Meeting Notes'''
* Team presentations
* Discussed notebook due date

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Peer Eval
|Completed 
|Feb 12, 2020
|
|Feb 19, 2020
|-
|Download Emade
|Completed
|Feb 12, 2020
|
|Feb 19, 2020
|}

== February 5, 2020 ==
'''Team Meeting Notes'''
* Talked about File to submit
* Discussed how to present

'''Group Meeting Notes'''
* Talked about ways to go about implementing the Genetic Algorithm
** primitives
***[[files/Image111.png|none|thumb]]
** normalizing data between 0 and 1
***[[files/Image32.png|none|thumb]]
** boolean values -1 false and 1 true (not implemented) 
'''Lab'''
* params[[files/Para.png|none|thumb]]
* Evaluation
 def evalTrainData(individual, table=train_data, pset=pset):
     func = gp.compile(expr=individual, pset=pset)
     train_data_sample = train_data.sample(int(len(train_data['Survived']) / 2))
     guesses = []
     truth = train_data_sample['Survived'].tolist()
     for row in train_data_sample.itertuples():
         y = func(row[2], row[3], row[4], row[5], row[6])
         guesses.append(float(y))
     vals = np.subtract(truth, guesses)
     countFP = 0
     countFN = 0
     countT = 0
     for i in vals:
         if i == 1.0:
             countFP += 1
         elif i == -1.0:
             countFN += 1
         else:
             countT += 1
             
     #dist = np.power(np.power(countFP / len(vals), 2) + np.power(countFN / len(vals), 2), 0.5)
     return (countFN / len(vals), countFP / len(vals))
     #return (1-(countT / len(vals)), )

 def evalTestData(individual, table = test_data, pset=pset):
     func = gp.compile(expr=individual, pset=pset)
     guesses = []
     for row in test_data.itertuples():
         y = func(row[1], row[2], row[3], row[4], row[5])
         guesses.append(float(y))
     return guesses
*Evolution
 # Evaluate the individuals with an invalid fitness
 invalid_ind = [ind for ind in population if not ind.fitness.valid]
 fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)
 for ind, fit in zip(invalid_ind, fitnesses):
     ind.fitness.values = fit
     
 record = stats.compile(population)
 logbook.record(gen=0, nevals=len(invalid_ind), **record)
 
 print(logbook.stream)
 
 for gen in range(1, ngen + 1):
     # Select the next generation individuals
     offspring = toolbox.select(population, len(population))
 
     # Vary the pool of individuals
     offspring = [toolbox.clone(ind) for ind in population]
 
     # Apply crossover and mutation on the offspring
     for i in range(1, len(offspring), 2):
         if random.random() < cxpb:
             offspring[i - 1], offspring[i] = toolbox.mate(offspring[i - 1],
                                                           offspring[i])
             del offspring[i - 1].fitness.values, offspring[i].fitness.values
 
     for i in range(len(offspring)):
         if random.random() < mutpb:
             offspring[i], = toolbox.mutate(offspring[i])
             del offspring[i].fitness.values
 
         # Evaluate the individuals with an invalid fitness
     invalid_ind = [ind for ind in offspring if not ind.fitness.valid]
     fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)
     for ind, fit in zip(invalid_ind, fitnesses):
         ind.fitness.values = fit
 
         # Update the hall of fame with the generated individuals
     hof.update(offspring)
     
     if sum(tools.selBest(population, 1)[0].fitness.values) < sum(best_ind.fitness.values):
         best_ind = tools.selBest(population, 1)[0]
         gen_best = gen
 
         # Replace the current population by the offspring
     population[:] = offspring
* Results after running 
** [[files/Imag.png|none|thumb]]
[[files/Par.png|none|thumb]]

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Meet with team
|Completed
|Feb 5, 2020
|
|Feb 10, 2020
|-
|Make presentation
|Completed 
|Feb 5, 2020
|
|Feb 11, 2020
|-
|Work on GP Lab
|Completed
|Feb 5, 2020
|
|Feb 12, 2020
|}

== January 29, 2020 ==
'''Team Meeting Notes'''

Went over the example on the titanic data set and got divided into teams.

'''Group Meeting Notes'''

Talked about the best ways to clean the data. Decided to combine the sibs/spouse column and the parents/offspring columns into one big family-size feature. Then decided to fill Nan values for age with a random from the non nan values.

'''Lab'''
* Implemented the changes from the group meeting
 X_train['Family Size'] = X_train.apply(lambda row: row.Parch + row.SibSp, axis = 1)
 X_test['Family Size'] = X_test.apply(lambda row: row.Parch + row.SibSp, axis = 1)
 X_train.columns[train_data.isna().any()].tolist()
* Looked at the data visually
** Learned:
*** all of title master were a part of class 3 with an average age of 5 and a max-age of 11 implying they are all poor children
*** all of title mlle were in first class
* Testing hyperparms for SGD
**confusion matrix for best model
**[[files/Image222222.png|none|thumb]][[files/Image3333.png|none|thumb]][[files/Imagelkl.png|none|thumb]][[files/Imagell.png|none|thumb]]
**pareto frontier for the models used
***[[files/Imagepi.png|thumb|none]]
** sweeping max iterations with hinge loss function
 Max_iter:  1 Score:  0.6474576271186441 Max_iter:  2 Score:  0.7491525423728813
  Max_iter:  3 Score:  0.6576271186440678 Max_iter:  4 Score:  0.6305084745762712 
 Max_iter:  5 Score:  0.7593220338983051 Max_iter:  6 Score:  0.6474576271186441 
 Max_iter:  7 Score:  0.6474576271186441 Max_iter:  8 Score:  0.7830508474576271 
 Max_iter:  9 Score:  0.7898305084745763 Max_iter:  10 Score:  0.6474576271186441 
 Max_iter:  11 Score:  0.6474576271186441 Max_iter:  12 Score:  0.7593220338983051 
 Max_iter:  13 Score:  0.8067796610169492 Max_iter:  14 Score:  0.3525423728813559 
 Max_iter:  15 Score:  0.7016949152542373 Max_iter:  16 Score:  0.6474576271186441 
 Max_iter:  17 Score:  0.6474576271186441 Max_iter:  18 Score:  0.735593220338983 
 Max_iter:  19 Score:  0.7389830508474576 Max_iter:  20 Score:  0.6474576271186441
** sweeping max iterations with modified_huber loss function
 Max_iter:  1 Score:  0.6474576271186441 Max_iter:  2 Score:  0.7423728813559322 
 Max_iter:  3 Score:  0.752542372881356 Max_iter:  4 Score:  0.7694915254237288 
 Max_iter:  5 Score:  0.7694915254237288 Max_iter:  6 Score:  0.7694915254237288 
 Max_iter:  7 Score:  0.7016949152542373 Max_iter:  8 Score:  0.6474576271186441 
 Max_iter:  9 Score:  0.48135593220338985 Max_iter:  10 Score:  0.34915254237288135 
 Max_iter:  11 Score:  0.7050847457627119 Max_iter:  12 Score:  0.7491525423728813 
 Max_iter:  13 Score:  0.7762711864406779 Max_iter:  14 Score:  0.7457627118644068 
 Max_iter:  15 Score:  0.6474576271186441 Max_iter:  16 Score:  0.6779661016949152 
 Max_iter:  17 Score:  0.6474576271186441 Max_iter:  18 Score:  0.7694915254237288 
 Max_iter:  19 Score:  0.6474576271186441 Max_iter:  20 Score:  0.34576271186440677
** sweeping max iterations with logistic loss function
 Max_iter:  1 Score:  0.7491525423728813 Max_iter:  2 Score:  0.535593220338983 
 Max_iter:  3 Score:  0.7491525423728813 Max_iter:  4 Score:  0.6474576271186441 
 Max_iter:  5 Score:  0.4576271186440678 Max_iter:  6 Score:  0.7220338983050848 
 Max_iter:  7 Score:  0.6474576271186441 Max_iter:  8 Score:  0.7627118644067796 
 Max_iter:  9 Score:  0.6474576271186441 Max_iter:  10 Score:  0.7762711864406779 
 Max_iter:  11 Score:  0.7661016949152543 Max_iter:  12 Score:  0.7898305084745763 
 Max_iter:  13 Score:  0.7593220338983051 Max_iter:  14 Score:  0.5322033898305085 
 Max_iter:  15 Score:  0.7694915254237288 Max_iter:  16 Score:  0.735593220338983 
 Max_iter:  17 Score:  0.752542372881356 Max_iter:  18 Score:  0.7389830508474576 
 Max_iter:  19 Score:  0.7491525423728813 Max_iter:  20 Score:  0.7457627118644068
* Testing hyperparams for K-nearest neighbors
 Neigbors:  1 Score:  0.6406779661016949 Neigbors:  2 Score:  0.6813559322033899 
 Neigbors:  3 Score:  0.6711864406779661 Neigbors:  4 Score:  0.7152542372881356 
 Neigbors:  5 Score:  0.711864406779661 Neigbors:  6 Score:  0.7254237288135593 
 Neigbors:  7 Score:  0.7389830508474576 Neigbors:  8 Score:  0.7423728813559322 
 Neigbors:  9 Score:  0.7423728813559322 Neigbors:  10 Score:  0.7559322033898305 
 Neigbors:  11 Score:  0.7423728813559322 Neigbors:  12 Score:  0.752542372881356 
 Neigbors:  13 Score:  0.7152542372881356 Neigbors:  14 Score:  0.7491525423728813 
 Neigbors:  15 Score:  0.7457627118644068 Neigbors:  16 Score:  0.7559322033898305 
 Neigbors:  17 Score:  0.752542372881356 Neigbors:  18 Score:  0.7491525423728813 
 Neigbors:  19 Score:  0.7322033898305085 Neigbors:  20 Score:  0.7491525423728813
* Tested hyperparameters for the Neural Network MLPClassifier
** after re-adding the name class and changing it such that the values represented the tiles(with lbfgs and logistic activation):
 1 if 'mlle' 
 2 if 'dr' 
 3 if 'master'
 4 if 'mme' 
 5 if 'miss'
 6 if 'rev'
 0 if  else
 hidden layer sizes:  (5, 2) Scores:  0.7288135593220338
 hidden layer sizes:  (5, 3) Scores:  0.823728813559322
 hidden layer sizes:  (5, 4) Scores:  0.8203389830508474
 hidden layer sizes:  (5, 5) Scores:  0.8271186440677966
 hidden layer sizes:  (5, 6) Scores:  0.8203389830508474
 hidden layer sizes:  (5, 7) Scores:  0.7762711864406779
 hidden layer sizes:  (5, 8) Scores:  0.8033898305084746
 hidden layer sizes:  (5, 9) Scores:  0.8135593220338984
 hidden layer sizes:  (5, 10) Scores:  0.8203389830508474
 hidden layer sizes:  (5, 11) Scores:  0.7966101694915254
** with lbfgs and relu activation
 hidden layer sizes:  (5, 2) Scores:  0.8033898305084746                                                                                                          hidden layer sizes:  (5, 3) Scores:  0.7050847457627119                                                                                                           hidden layer sizes:  (5, 4) Scores:  0.6474576271186441                                                                                                           hidden layer sizes:  (5, 5) Scores:  0.7898305084745763                                                                                                           hidden layer sizes:  (5, 6) Scores:  0.7084745762711865                                                                                                           hidden layer sizes:  (5, 7) Scores:  0.7762711864406779                                                                                                           hidden layer sizes:  (5, 8) Scores:  0.6237288135593221                                                                                                           hidden layer sizes:  (5, 9) Scores:  0.7016949152542373                                                                                                           hidden layer sizes:  (5, 10) Scores:  0.7762711864406779                                                                                                           hidden layer sizes:  (5, 11) Scores:  0.8271186440677966
** with lbfgs and logistic activation
 hidden layer sizes:  (5, 2) Scores:  0.7084745762711865                                                                                                           hidden layer sizes:  (5, 3) Scores:  0.8338983050847457                                                                                                           hidden layer sizes:  (5, 4) Scores:  0.8135593220338984                                                                                                           hidden layer sizes:  (5, 5) Scores:  0.8135593220338984                                                                                                           hidden layer sizes:  (5, 6) Scores:  0.8135593220338984                                                                                                           hidden layer sizes:  (5, 7) Scores:  0.8067796610169492                                                                                                           hidden layer sizes:  (5, 8) Scores:  0.8101694915254237                                                                                                           hidden layer sizes:  (5, 9) Scores:  0.8135593220338984                                                                                                           hidden layer sizes:  (5, 10) Scores:  0.8135593220338984                                                                                                           hidden layer sizes:  (5, 11) Scores:  0.8
** with lbfgs and tanh activation
 hidden layer sizes:  (5, 2) Scores:  0.8169491525423729                                                                                                           hidden layer sizes:  (5, 3) Scores:  0.7050847457627119                                                                                                           hidden layer sizes:  (5, 4) Scores:  0.8                                                                                                                        hidden layer sizes:  (5, 5) Scores:  0.8033898305084746                                                                                                           hidden layer sizes:  (5, 6) Scores:  0.7423728813559322                                                                                                           hidden layer sizes:  (5, 7) Scores:  0.8169491525423729                                                                                                           hidden layer sizes:  (5, 8) Scores:  0.8203389830508474                                                                                                           hidden layer sizes:  (5, 9) Scores:  0.8169491525423729                                                                                                           hidden layer sizes:  (5, 10) Scores:  0.8101694915254237                                                                                                           hidden layer sizes:  (5, 11) Scores:  0.711864406779661

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|meet with group
|Completed
|January 29, 2020
|
|Jan 26, 2020
|-
|finish sklearn lab
|Completed 
|January 29, 2020
|
|Jan 27, 2020
|}

== January 22, 2020 ==
[[files/Download (6).png|thumb|
 Area Under Curve: 5.006
[[files/Download (4).png|left|thumb|
 Area Under Curve: 4.287673661294018
 Percent Change: -83
 Mu:  50 Lambda:  100 Generations:  50 CrossOver Prob:  0.5 Mutation Prob:  0.4
]]
 0959172912405
 Percent Change: -114
 Mu:  50 Lambda:  100 Generations:  100 CrossOver Pro
[[files/Download (5).png|none|thumb|
 Area Under Curve: 3.926191546965761
 Percent Change: -68
 Mu:  50 Lambda:  100 Generations:  50 CrossOver Prob:  0.5 Mutation Prob:  0.5
]]
 b:  0.7 Mutation Prob:  0.1
]]
'''Team Meeting Notes'''
* The evaluation of a Genome associates a genome/individual with a set of scores
** True positive
*** correct evaluation
** False-positive
*** false evaluation
* Classification measures
** Data Set = {positve samples (P) ∪ negative samples(N)} → Classifier → {True positive(TP), False positive(FP), true negative(TN), false negative(FN)}
** Optimization measures
*** Sensitivity= True Positive Rate (#TP / (TP + FN))
*** Specificity = True Negative Rate (#TN / TN + FP))
** Minimization measures
*** False Negative Rate = (FN / (TP + FN)) = 1 - TPR
*** Fallout = False PositiveRate = (TN / (FP + TN)) 1 - TNR
** Other Measures
*** Precision = Positive PRedictive Values = TP / (TP + FP)
**** Bigger better
{| class="wikitable"
!
!Predicted Pos
!Predicted Neg
|-
|Actual Pos
(N = 11)
|TP
(TP = 8)
|FN
(FN = 3)
|-
|Actual Neg
(N = 12)
|FP
(FP = 5)
|TN
(TN = 7)
|}
Objective Space
* Each individual is evaluated using objective functions
** MSE
** Cost
** Complexity
** True Positive Rate
** False Positive Rate
* Objective scores give each indv a point in space
* refereed to as phenotype
Pareto Optimality
* An individual is Pareto if there is no other individual in a population that outperforms that individual on all objects
* the set of all Pareto individuals is known as the Paret Frontier
* These individuals represent unique contributions
** but maintains diversity by giving all individuals some prob of mating
Action Items
* Continuing the lab. Attempted to reduce the ACU bu changing MU and Lamba which resulted in the following Pareto Graphs

== January 15, 2020 ==
'''Team Meeting Notes'''

Genetic Programming
* Program as a tree
** nodes primitives ( functions)
** leaves terminals (params)
** output at root of tree
** terminal given input
** tree stored in lisp
*** f(x) = yx + 1 -> [+, * y, x,1 ]
*** preorder traversal
* for cross over in tree-based GP  exchange subtrees
** pick two random points to swap at
* for mutation
** insert node or subtree
** rmv node or subtree
** change node

'''Action items'''

Results from Lab 2 pt I Genetic Programming
 -- Generation 0 --
   Min 0.4112027678437573
   Max 44958.32301555737
   Avg 1051.3095432607906
   Std 6786.55536625827
 -- Generation 1 --
   Min 0.4112027678437573
   Max inf
   Avg inf
   Std nan
 -- Generation 2 --
   Min 0.4112027678437573
   Max 44958.322999947304
   Avg 601.5955992517611
   Std 5156.37099011047
 -- Generation 3 --
   Min 0.4112027678437573
   Max inf
   Avg inf
   Std nan
 -- Generation 4 --
   Min 0.3185682254736571
   Max 49.68434052199083
   Avg 2.095231668529393
   Std 8.36162283901759
 -- Generation 5 --
   Min 0.159284112731791
   Max 44958.322999947304
   Avg 151.20077578895174
   Std 2591.2692581957863
 -- Generation 6 --
   Min 0.15928411273179102
   Max 44958.322974953386
   Avg 151.25359160998858
   Std 2591.266559568448
 -- Generation 7 --
   Min 0.15928411273179102
   Max inf
   Avg inf
   Std nan
 -- Generation 8 --
   Min 0.159284112731791
   Max inf
   Avg inf
   Std nan
 -- Generation 9 --
   Min 0.159284112731791
   Max 44958.323013045716
   Avg 151.0965317936143
   Std 2591.2753096327756
 -- Generation 10 --
   Min 1.274166880927199e-16
   Max 44958.32299388258
   Avg 150.91887952365116
   Std 2591.284079116672
 -- Generation 11 --
   Min 1.274166880927199e-16
   Max 44546198176.70436
   Avg 148487478.7463223
   Std 2567585904.1759496
 -- Generation 12 --
   Min 1.2012964454916326e-16
   Max 44958.32300662459
   Avg 151.04615203666108
   Std 2591.2778704670536
 -- Generation 13 --
   Min 1.0673185581909057e-16
   Max 44958.32303879147
   Avg 300.72113494673937
   Std 3658.496584803904
 -- Generation 14 --
   Min 1.0673185581909057e-16
   Max 44958.322991014524
   Avg 150.80021794498919
   Std 2591.2905925936348
 -- Generation 15 --
   Min 1.0673185581909057e-16
   Max inf
   Avg inf
   Std nan
 -- Generation 16 --
   Min 1.0673185581909057e-16
   Max 44958.322991014524
   Avg 150.41707658046735
   Std 2591.3096856774587
 -- Generation 17 --
   Min 1.0673185581909057e-16
   Max inf
   Avg inf
   Std nan
 -- Generation 18 --
   Min 1.0321736972101162e-16
   Max inf
   Avg inf
   Std nan
 -- Generation 19 --
   Min 1.0321736972101162e-16
   Max 62.268309410739136
   Avg 1.580560666914197
   Std 7.8668865385344455
 -- Generation 20 --
   Min 1.0321736972101162e-16
   Max inf
   Avg inf
   Std nan
 -- Generation 21 --
   Min 1.0321736972101162e-16
   Max 44958.322990168024
   Avg 150.48817905590317
   Std 2591.3071408273427
 -- Generation 22 --
   Min 1.0321736972101162e-16
   Max inf
   Avg inf
   Std nan
 -- Generation 23 --
   Min 1.0321736972101162e-16
   Max 44546198176.70436
   Avg 148487327.80182135
   Std 2567585912.903988
 -- Generation 24 --
   Min 1.0321736972101162e-16
   Max inf
   Avg inf
   Std nan
 -- Generation 25 --
   Min 1.0321736972101162e-16
   Max inf
   Avg inf
   Std nan
 -- Generation 26 --
   Min 1.0321736972101162e-16
   Max 44958.43256183979
   Avg 450.02420704551645
   Std 4473.256929224919
 -- Generation 27 --
   Min 1.0321736972101162e-16
   Max 49.62341467253612
   Avg 0.7663069832977152
   Std 4.923437480398565
 -- Generation 28 --
   Min 1.0321736972101162e-16
   Max 44958.32301120975
   Avg 150.62940211461833
   Std 2591.3005124316887
 -- Generation 29 --
   Min 1.0321736972101162e-16
   Max 4.436483888583975e+22
   Avg 1.478827962861325e+20
   Std 2.5571325952684427e+21
 -- Generation 30 --
   Min 1.0321736972101162e-16
   Max inf
   Avg inf
   Std nan
 -- Generation 31 --
   Min 1.0321736972101162e-16
   Max 44546198176.70436
   Avg 296974954.85671425
   Std 3625037612.1528435
 -- Generation 32 --
   Min 1.0321736972101162e-16
   Max 44958.32299016803
   Avg 150.836687501913
   Std 2591.2900454379887
 -- Generation 33 --
   Min 1.0321736972101162e-16
   Max 4.436483888583975e+22
   Avg 1.4803082712716136e+20
   Std 2.5571253155410147e+21
 -- Generation 34 --
   Min 1.0321736972101162e-16
   Max inf
   Avg inf
   Std nan
 -- Generation 35 --
   Min 1.0321736972101162e-16
   Max 44958.32299388258
   Avg 150.3692788965479
   Std 2591.312463596538
 -- Generation 36 --
   Min 1.0321736972101162e-16
   Max 44958.32299635152
   Avg 450.70414996464007
   Std 4473.188469213178
 -- Generation 37 --
   Min 1.0321736972101162e-16
   Max 62.268309410739136
   Avg 0.9694961959707339
   Std 6.064354978806498
 -- Generation 38 --
   Min 1.0321736972101162e-16
   Max inf
   Avg inf
   Std nan
 -- Generation 39 --
   Min 1.0321736972101162e-16
   Max 44546198176.70436
   Avg 296975441.9743529
   Std 3625037572.2493834
 -- End of (successful) evolution --
 Best individual is add(add(squareint(multiply(x, x)), x), subtract(multiply(subtract(squareint(x), subtract(x, x)), x), negative(multiply(x, x)))), (1.0321736972101162e-16,)
[[files/Download (1).png|thumb|Graph for Genetic Programming Performance]]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish Lab
|In Progress
|January 15, 2020
|Jan 23, 2020
|
|}

== January 8, 2020 ==
'''Team Meeting Notes:'''

- Discussed the basic principles of Genetic Algorithms
* Reproduction
** Mutation
** Crossover (single and multiple) 
* Fitness
* Population
- Discussed the VIP and the basics of what it would entail

'''Work Done this week'''

[https://github.com/khayne31/Automated-Algorithm-Design/commit/27d8858a9c7838332cf24ab51e621e277152a4d0 Created the GitHub repo and added the lab]

[https://github.com/khayne31/Automated-Algorithm-Design/commit/3e00683d110c5cb7a9816fe9262d85a493551aec Added my changes to the lab]

An example of the results of my new mutation, randomly shuffling fourths of an input array
 shuffle:  [4 1 3 2]
 100
 original:  [76, 60, 67, 37, 73, 82, 27, 44, 18, 56, 7, 68, 59, 0, 50, 39, 11, 16, 24, 1, 52, 90, 79, 88, 20, 72, 69, 23, 66, 99, 83, 32, 80, 57, 55, 49, 47, 14, 15, 29, 17, 21, 42, 45, 62, 71, 63, 22, 86, 95, 78, 12, 41, 51, 81, 64, 53, 40, 48, 54, 34, 8, 96, 94, 89, 35, 46, 33, 3, 77, 93, 36, 98, 70, 92, 61, 43, 58, 25, 65, 19, 38, 2, 84, 91, 31, 10, 13, 9, 4, 75, 5, 6, 30, 26, 87, 97, 74, 28, 85] 
  new:  [61, 43, 58, 25, 65, 19, 38, 2, 84, 91, 31, 10, 13, 9, 4, 75, 5, 6, 30, 26, 87, 97, 74, 28, 85, 76, 60, 67, 37, 73, 82, 27, 44, 18, 56, 7, 68, 59, 0, 50, 39, 11, 16, 24, 1, 52, 90, 79, 88, 20, 78, 12, 41, 51, 81, 64, 53, 40, 48, 54, 34, 8, 96, 94, 89, 35, 46, 33, 3, 77, 93, 36, 98, 70, 92, 72, 69, 23, 66, 99, 83, 32, 80, 57, 55, 49, 47, 14, 15, 29, 17, 21, 42, 45, 62, 71, 63, 22, 86, 95]
[[files/Lab1 Figure.png|thumb]]

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Setup Wiki
|Completed
|January 8, 2020
|
|Jan 14, 2020
|-
|Join Slack
|Completed 
|January 8, 2020
|
|Jan 14, 2020
|-
|Setup Github
|Completed
|January 8, 2020
|
|Jan 15, 2020
|-
|Look over and Run Genetic Algorithm Tutorial
|Completed
|January 8, 2020
|
|Jan 14, 2020
|-
|Finish Lab
|Completed
|January 8, 2020
|
|Jan 15, 2020
|}