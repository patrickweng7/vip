== Team Member ==
Team Member: Kinnera Banda

Email: kbanda3@gatech.edu 
Cell Phone: 616-278-7512

Interests: Chemistry, Data Science, Machine Learning, Design, Dance. 

== January 8, 2020 ==

=== Team Meeting Notes: ===
* Taught how to make a Notebook on the wiki. 
* Presentation: Part 1 - Genetic Algorithm
** Concept:
*** Goal: to produce the best individual who's fitness is better than anyone else's. Done through mating/mutation of individuals from the previous generation.
** Keywords:
*** Individual: one specific candidate in population. It has properties like DNA.
*** Population: Group of individuals. 
*** Objective: A value to characterize individuals being maximized or minimized. 
*** Fitness: Relative comparison to other individuals.
*** Evaluate: used to compute the objective of the individual. 
*** Selection: "survival of the fittest."
**** Fitness Proportionate: greater fitness value, higher the chance being selected for mating. 
**** Tournament: multiple tournaments among individuals. winner mate. 
*** Mate/Crossover: Mating. Single Point. Double Point. 
*** Mutate: random modifications. Maintain diversity. 
*** Algorithms: various evolutionary. 
** One Max Problem:
*** Goal: eventually produce an individual whose list contains all one's.
=== Sub-Team Notes: ===
* N/A - not yet assigned to a team

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Join VIP Slack group
|Completed
|Jan 8, 2020
|Jan 15, 2020
|Jan 13, 2020
|-
|Install DEAP Python package
|Completed
|Jan 8, 2020
|Jan 15, 2020
|Jan 15, 2020
|-
|Review class lecture slides
|Completed
|Jan 8, 2020
|Jan 15, 2020
|Jan 13, 2020
|-
|Finish DEAP Lab 1
|Completed
|Jan 8, 2020
|Jan 15, 2020
|Jan 15, 2020
|}

== January 15, 2020 ==
Team Meeting Notes:
*Genetic Programming
**Population based solution that uses concepts of natural selection to evolve individuals
**Used properties of DNA to change information
[[files/TreeRepresentation1.png|thumb|link=https://vip.gatech.edu/wiki/index.php/files/TreeRepresentation1.png]]
*Tree Representations
**Nodes are called primitives and represent functions
**Note the Tree on the Right: Represents the function (3 * 4) + 1
***Can be stored as an array: [+, *, 3, 4, 1]
**How Crossover Works:
***Select two random points in these trees. Define everything below those points as two sub-trees
***swap the sub-tree to generated a crossover
**Mutation:
***Inserting, Deleting, Changin
**Using a Taylor Series expansion to model non-polynomial functions: e.g. y = sin x
**Evaluating a tree:
***Feed inputs to function
***Get error
**Types of Primitives that would make the process easier: power(), factorial(), sin(), cos(), tan() --> the hidden idea behind EMADE
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review Notes from class
|Completed
|January 15, 2020
|
|January 15, 2020
|-
|Complete Lab 2 Part I
|Completed
|January 15, 2020
|
|January 21, 2020
|}

== January 22, 2020 ==
Team Meeting Notes:
*Instead of trying to maximize or minimize a certain single objective, we can also do the same with multiple objectives
*Bio-inspired Programming:
*#New Gene Pool: the set of the genome to be evaluated during the current generation (in GA a set of values, in GP a tree structure/a string)
*#Evaluation: Associates a genome/individual with a set of scores
*#Genes with Scores: True positive - how often are we identifying the desired object, False Positive - how often are we identifying something else as the desired object
*Classification of algorithms and individuals:
**True positive - how often are we identifying the desired object
**False Positive - how often are we identifying something else as the desired object
**Sensitivity rate/True Positive Rate: the rate at which the classifier predicts true positives (trying to maximize)
**Specificity rate/True Negative Rate: the rate at which the classifier predicts true negatives (trying to maximize)
**False Negative Rate: 1 - TPR (trying to minimize)
**False Positive Rate: 1 - TNR (trying to minimize)
**Objective Spaces:
***Individuals can be evaluated using different objective functions (ex. Mean Squared Error, Cost, Complexity, TPR, FPR, etc.)
***Multiple objectives are represented by multiple axes in the object space (for 2 objectives, 2 dimensions)
***Can judge the accuracy of an individual function by the distance from your goal (1 - ACC)
***Pareto Optimality:
****An individual is pareto is there is no other individual in the population that outperforms the individual on all objectives
****Set of Pareto individuals in known as Pareto Frontier
****Reduce area under the curve.
***Non dominated Sorting Genetic Algorithm II (NDGA II)
****Population is separated into nondominated ranks
****Individuals are selected using a binary tournament
Action Items:
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review Notes from class
|Completed
|January 15, 2020
|
|January 29, 2020
|-
|Complete Lab 2 Part II
|Completed
|January 15, 2020
|
|January 29, 2020
|}

== January 29, 2020 ==
Team Meeting Notes:
* Organized into groups. 
* Create pareto frontier. 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review Notes from class
|Completed
|January 29, 2020
|
|February 5, 2020
|-
|Meet with sub-team group
|Completed
|January 29, 2020
|
|February 5, 2020
|}

== February 1, 2020 ==
'''Sub-Team Notes:'''
*Clean up data by aggregating the Number of siblings and the number of parents and children to make a family size column.
*Enumerated the sex to make Male 1 and Female 0.
*Removed the Name, Embarked variables
*Researched different types of ScikitLearn classification algorithms to test on the data
*Individual Assignment: Test various algorithms to find dominant functions on the Titanic test data

'''Individual Notes:'''
* Used the following classifiers:
** Multilayer Perception Classifier
** Logistic Regression Classifies
** Linear Discrimination Analysis
** Extra Tree Classifier
* Plotted Results on a scatter plot where the axes represented the Type I and Type II Error Percentages of the functions.

== February 5, 2020 ==
'''Team Meeting Notes'''
*Group Assignment: design an evolutionary Genetic Algorithm using multi-object optimization to predict the survived people on the Titanic
*Not allowed to use built-in Deap algorithms
*Develop a spreadsheet showing the different algorithms and their prediction data
*Present out results.
'''Sub Team Notes:'''
* Decided to normalize the data to we could work with arithmetic numbers. 
* Instead of using numpy built in functions, we developed our own. 
* Tree produces a value between 0 and 1. [[files/Screen Shot 2020-02-12 at 2.29.49 PM.png|thumb|666x666px|Primitives Used in Evolution|link=https://vip.gatech.edu/wiki/index.php/files/Screen_Shot_2020-02-12_at_2.29.49_PM.png]]
[[files/Screen Shot 2020-02-12 at 2.30.18 PM.png|thumb|410x410px|Pareto Front|link=https://vip.gatech.edu/wiki/index.php/files/Screen_Shot_2020-02-12_at_2.30.18_PM.png]][[files/Screen Shot 2020-02-12 at 2.29.58 PM.png|none|thumb|1004x1004px|Evaluation Function|link=https://vip.gatech.edu/wiki/index.php/files/Screen_Shot_2020-02-12_at_2.29.58_PM.png]]

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review notes from class
|Complete
|February 5, 2020
|
|February 5, 2020
|-
|Meet with team to decide tasks
|Complete
|February 5, 2020
|
|February 7, 2020
|-
|Build Normalized primitives
|Complete
|February 5, 2020
|
|February 7, 2020
|-
|Design Evolutionary Algorithm
|Complete
|February 5, 2020
|
|February 12, 2020
|-
|Build Pareto Frontier
|Complete
|February 5, 2020
|
|February 12, 2020
|-
|Compile findings into presentation
|Complete
|February 5, 2020
|
|February 12, 2020
|}

== February 19, 2020 ==
'''Team Meeting Notes'''
*EMADE combines the ideas of Machine Learning using classificiation algorithms and Genetic Programming that we have already learned
**Uses MySQL to manage the data coming in and out of the centralized hub
**Project assignment: Develop an EMADE model to predict the survivors of the Titanic using a variety of cleaned data
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review notes from class
|Complete
|February 5, 2020
|
|February 5, 2020
|-
|Install and set up EMADE
|Complete
|February 5, 2020
|
|February 18, 2020
|-
|Meet with team
|Complete
|February 5, 2020
|
|March 8, 2020
|-
|Create Presentation
|Complete
|February 5, 2020
|
|March 8, 2020
|}

== March 23, 2020 ==
'''Main Meeting:'''
* First trial meeting after spring break
* Now part of the ezCGP team. 
'''Subteam meeting:'''
* We decided to meet on March 25, 2020, for the first meeting for the new students for a "workshop" to be caught up on ezCGP.

== March 25, 2020 ==
[[files/Perceptron (or artificial neuron).png|thumb|A perceptron is an artificial neuron can be thought as a function that outputs a single number from the weighted sum of inputs. These functions are called activation functions.]]
'''Subteam Meeting:'''
* We went over some concepts of deep learning. 
* This week's task is to look over the resources that Sam gave the new students (3Blue1Brown videos on NN, CS231n, etc) and understand the theoretical background of deep learning.
* A perceptron takes in a weighted sum of inputs and bias value and outputs a single number. The output is calculated using the activation function. 
* Topics that we went over:
** Perceptrons
** Deep Neural networks.
** Activators. 
** Loss functions. 
** Back Propagation. 
*Some useful resources:
**https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi
**http://cs231n.github.io/
===='''Action Items:'''====
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get familiar with NNs
|Done
|March 25, 2020
|N/A
|March 29, 2020
|-
|Become familiar with the subteam and learn what our goal is.
|Done
|March 25, 2020
|N/A
|March 29, 2020
|}
== April 1, 2020 ==
[[files/EzCGP work model.png|thumb|ezCGP structure]]
'''Subteam Meeting:'''
* This meeting was mainly to go over the general structure of the ezCGP code base. 
* The following diagram was made by Samuel Zhang to help explain the codebase.
* Some helpful resources that Sam compiled for us in order to understand the general structure are follows:
** https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi
** https://www.mitpressjournals.org/doi/pdf/10.1162/evco_a_00253
** https://arxiv.org/pdf/1704.00764.pdf
** https://drive.google.com/file/d/1z8_3fDgsSO6N7iZdQvnxes055WIJ-vLT/view?usp=sharing
** http://cs231n.github.io/
* We also went over concepts of Catesian Genetic Programming and Genetic Programming. 
** https://drive.google.com/file/d/1uyCKKcVulDN0uEIi8WR2CFQVsAPTPvaE/view?usp=sharing
* Asked to run through a TF 2.0 tutorial, read the 2019 CGP paper, and prepare for codebase installation for next Wednesday
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Go over Sam/s resources. 
|Done
|April 1, 2020
|N/A
|April 4, 2020
|-
|Finish the tensorflow tutorial.
|Done
|April 1, 2020
|N/A
|April 4, 2020
|-
|Install VM
|Done
|April 1, 2020
|N/A
|April 8, 2020
|-
|Setup PACE
|Done
|April 1, 2020
|N/A
|April 9, 2020
|}
== April 8, 2020 ==
[[files/Pace.png|thumb|PACE 101 for ezCGP students]]
'''Subteam Meeting:'''
* We went over installing ans setting up PACE and VM. 
* Since I did not have a UNIX based machine, I had to download a Virtual Machine. 
* I did not have much trouble installing this and even setting up PACE since the process was already streamlines for future use. I worked with David on this. 
* Jason also gave the new students a task. 
* We were to implement a CNN architecture and run it both through ezCGP and seperately and compare which did best and why. 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install VM
|Done
|April 1, 2020
|N/A
|April 8, 2020
|-
|Setup PACE
|Done
|April 1, 2020
|N/A
|April 9, 2020
|-
|Find CNN model
|Done
|April 6, 2020
|N/A
|April 13, 2020
|-
|Implement said model
|Done
|April 6, 2020
|N/A
|April 14, 2020
|}

== April 12-15, 2020 ==
[[files/Lenet01.png|thumb|900x900px|LeNet-5 Implementation. ]]
'''Individual Notes:'''
* The architecture that I implemented was the LeNet-5. 
* It was originally built on the MNIST data set with a 99.04% accuracy over 20 epochs. 
* I implemented this on CIFAR-10 without changing any of the values. 
* The code I used to implement the architecture is attached here.
* I kept getting the following error:
** [[files/Cost vs Epoch .png|thumb|Cost vs. Epoch]]  ValueError: Error when checking input: expected conv2d_4_input to have 4 dimensions, but got array with shape (50000, 32, 32, 3, 1)
* I first tried changing the kernal_size but this did not work. 
* I then added the to_categorical to y_train and y_test, and decreased the batch size to 32. I also divided the input data by 255. This seemed to fix the problem. The error was occuring at the model.compile method. 
* I ran the file locally for 75 epochs, The accuracy plateaud at around 10 epoch to I ran it for ten epochs and got an accuracy at around 66%. Running it for 200 epochs would have given it a 75% accuracy according to some research posts online. 
* The graphs I got are attached here. 
* I did accidently plot loss and accuracy on the same graph although not exactly correct. It is also testing and training accuracy and loss instead of of accuracy and validation accuracy respectively. 

== April 16-19, 2020 ==
'''Individual Notes:'''
*After running the model locally, I now was trying to rub the model on ezCGP. 
*We had to make the following changes in order to do so successfully:
**Make changes to problem.py specifying the generation, epoch, and individual limits. 
**Make changes to run_gpu_sam.pbs file to ensure the right names before qsub'ing the file onto PACE. 
**Make a SEED_ROOT_DIR called kinnera_ezCGP_runs/run_1 to store all the data from the files into this. 
*I ran this from wednesday night to saturday afternoon. 
*I then used the evaluator.py file to get the best individual from generation 39 and generation 38. 
*The first errors was the fact that accuracies[] was of size 1 as opposed to size 30 for each epoch. This we figured out was because a for loop was commented out. 
*The other error we kept running into was the fact that the graphs were very haphazard and not decreasing like expected likely because of overfitting.  the graphs for these are attached below:[[files/Gen38.png|thumb|500x500px|The 1-Accuracy vs. Epochs graph for the best individual from generation 38.]]
[[files/Gen39.png|center|thumb|500x500px|The 1-Accuracy vs. Epochs graph for the best individual from generation 39. ]]
*Luke and I later worked on this and found that there was a big error in the evaluator.py file which took 3-4 hours to debug. 
*Under the for look the line epoch = epochs was suppsed to e commented out too, because this would mean that each of the epoch that the indivdual was run for was 30. 
*On fixing this, we were able to then get a pretty good graph. Attached below:[[files/Best.png|center|thumb|434x434px|The 1-Accuracy vs. Epoch graph for the best individual from generation 39 after fixing errors.]]

== April 20, 2020 ==
'''Team Meeting:'''
* Presented team results for the final presentation.

* The following was the LeNet-5 mdel representation that I used to explain my model:
[[files/Lenet02.png|thumb|800x800px|LeNet-5 diagrammatic representation]]

== August 17, 2020 ==
'''Team Meeting:'''
* New Stocks team was formed.
'''Individual Notes:'''
* There was significant interest for a stocks team, so was made interim team lead for stocks until roadmap and next steps were figured. 
'''Subteam Notes:'''
* Made Slack channel and set up initial meeting for stocks. 
* Set up meeting with Jason to get initial idea of process. 

==== Action Items: ====
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Set up Slack channel for Stocks team
|Done
|August 17, 2020
|N/A
|August 20, 2020
|-
|Set up meeting with Jason.
|Done
|August 20, 2020
|N/A
|August 24, 2020
|}

== August 24, 2020 ==
'''Team Meeting:'''
* Stocks team confirmed. 
* made Abhiram and Rishi co-leads instead of me.
'''Subteam Notes:'''
* Intersection of Machine learning and Stocks: initial idea was to emulate day trading. 
* Decided to split into 3 groups:
** Research ML used in trading. (Group A) (Joining this group)
*** What: TI research, strategies, stocks to target.
** (keep features constant) EMADE integration of premade Technical Indicators (Group B) (Joining this group)
*** Using data from TradingView.com technical indicators to train basic EMADE regression to predict a stocks price
** Building Technical Indicators in EMADE (Group C) (On hold until substantial research is completed 
'''Individual Notes:'''
* Set up google drive for meeting notes and file structure.
* Choose meeting times for the sub-sub teams. 
'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Research EMADE code base 
|Pending
|August 28, 2020
|Septemer 4, 2020
|
|-
|Research Technical Indicators
|Done.
|August 27, 2020
|
|September 3, 2020
|}

== September 3, 2020 ==
'''Individual Notes:'''
* Researched the following technical indicators:
** Moving Average Convergence and Divergence:[[files/MACD Formula.png|thumb|MACD Formula ]]
*** MACD measures the relationship between two EMAs, while the RSI measures price change in relation to recent price highs and lows.
*** Relationship between 2 MA’s
*** Subtracting 26-month and 12-month exponential MA
** Relative Strength Indicator
*** calculates average price gains and losses over a given period of time; the default time period is 14 periods with values bounded from 0 to 100.
*** Momentum oscillator
*** >70 overbought <30 oversold
*** Second step smooths the data. So only fall or rise when it is a strongly trending market. 
*** Stable long term might give false positives
** Rate of Change
*** Slope of the line
*** Percentage change over time.
'''Subteam Notes:'''
* Sub team under stocks discussed all indicators in detail. 
* To have a better overview and understanding, we were tasked with reading 3-4 research papers in the particular field that we are targeting. 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Research EMADE code base 
|Pending
|August 28, 2020
|September 4, 2020
|
|-
|Read 3-4 papers
|Done.
|Septeber 4, 2020
|
|September 11, 2020
|}

== September 7, 2020 ==
'''Subteam notes:'''
* Researched papers:
** https://www.sciencedirect.com/science/article/pii/S0957417414006551?casa_token=xf-Mp6PrZFAAAAAA:T_2K_OSIOTa_piYoKV66-838TBKscj2Q04hA5bi2jiqCPp3BQskjoHjfArfdL6oV31RIOOAbfw
** https://ieeexplore.ieee.org/abstract/document/1688575?casa_token=VFylPfEyWLIAAAAA:8F1uCMVMzWfgnHB32ocBJOgHlhZcccXiK6XgnHf_aFnMXIJASzfzVSQ0_NaO9sT7yRpiWgaM
** https://link.springer.com/chapter/10.1007/978-3-319-13560-1_60
** https://ieeexplore.ieee.org/abstract/document/7966019?casa_token=FAqTdlS7G_8AAAAA:uQSD1HshtFRB0UJxq0mN-XqVLjQzT8vAFpF5FwoOJ5fT1PP2TjZAVllmf1FlJ5x_ACTt3pQW
'''Actino Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Research EMADE code base 
|Pending
|August 28, 2020
|Septemer 4, 2020
|
|-
|Read the final decided paper
|Done.
|September 7, 2020
|
|Septemer 14, 
|}

== September 14, 2020 ==
'''Subteam Notes:'''
* Read the following paper decided by the group which is to be implemented for this project. 
** https://doi.org/10.1016/j.jfds.2016.03.002
** All members should try and be able to run EMADE locally. 
* Finish self evaluation before class.
* [https://drive.google.com/file/d/1PRVcKJ1XsRRgewR_HeN2E052js21xHUh/view?usp=sharing notebook ruric self eval]
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Research EMADE code base 
|Complete
|August 28, 2020
|Septemer 4, 2020
|
|-
|Set up EMADE to be run locally
|Complete
|September 17, 2020
|September 24, 2020
|September 30, 2020
|-
|Complete Self evaluation
|Complete
|September 14, 2020
|
|September 21, 2020
|}

== September 24, 2020 ==
'''Individual Notes:'''
* This week was more of setting up my local environment and getting everything up and running on Colab.
* The repo that we used was already set up by Rishi. The branch that we would be working on is '''stocks-base.'''
* I then set up the mySQL dataset that would be connected to the AWS server that worked better than the original cloud platform that we were using, which was 
* Do the run with input_titanic.xml to specify the specific database. We were using this as a test to make sure the local setup was running. 
* Abhiram and Rishi had the google collab notebook on our shared drive already in place that we got from Anishe Tithe. I just had to make a copy of it and run it with a "-w" on the last line. [[https://colab.research.google.com/drive/1lRs1MJkRl5dthHCczokOBQz1O1uqVl4t?usp=sharing Linked here]]
** We named our specific notebooks with our initials to avoid confusion. 
* Encountered an issue with deap but was able to fix it since it was the wrong version. 
* Ran EMADE on the titanic dataset as both worker and master with no issue. 
'''Subteam Notes:'''
* At the meeting, we talked about the paper more in-depth and tasked specific parts of it to each of us.
* We talked about PACE but decided not to move forward with it since our focus for this semester was to first produce some results before experimenting with different platforms.
* We didn't have much information on CEFLANN and did have to research about this and talked about possibly implementing this as a primitive. Will need either an already implemented library or a self-implemented version of it. 
* I was tasked with researching the primitives in the paper. and did deeper into the graphs produced by them.
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Set up EMADE on Collab
|Finished.
|September 17, 2020
|September 24, 2020
|September 30, 2020
|-
|Set up SQL database to connect with AWS
|Finished
|September 17, 2020
|Septemner 24, 2020
|September 30, 2020
|-
|Run the Titanic dataset on collab
|Finished
|September 17, 2020
|September 24, 2020
|September 30, 2020
|-
|Research Technical Indicators implementation
|Finished 
|September 24, 2020
|October 1, 2020
|September 30, 2020
|}

== October 5, 2020 ==
'''Individual Notes:'''
* Researched the 6 primitives used in the paper. The research is as follows:
** Simple Moving Average:
*** Trend indicator that averages out prices over past n days
*** Smooths price data by filtering out noise from short-term fluctuations
*** Function implemented would need to take in a list of prices and also the period on which it would be calculated on using a default of 25.
*** [https://www.investopedia.com/terms/s/sma.asp#:~:text=Key%20Takeaways-,A%20simple%20moving%20average%20(SMA)%20calculates%20the%20average%20of%20a,a%20bull%20or%20bear%20trend. More information]
** Exponential Moving Average
*** Moving average that places more weight to more recent days
*** Function implemented would need to take in a list of prices and also the period on which it would be calculated on using a default of 26.
*** [https://www.investopedia.com/ask/answers/122314/what-exponential-moving-average-ema-formula-and-how-ema-calculated.asp#:~:text=The%20exponential%20moving%20average%20(EMA)%20is%20a%20technical%20chart%20indicator,importance%20to%20recent%20price%20data. More Information]

** Moving Average Convergence and Divergence
*** Reveals changes in the strength, direction, momentum, and duration of a trend
*** Subtracts the 12- and 26-day EMA
*** Signal line: 9-day EMA of the MACD
*** Insights drawn from when, how frequently, and in which direction signal line is crossed
*** Function implemented would need to take in a list of prices and also a given fast and slow periods of time on which the TI would be calculated.
*** [https://www.investopedia.com/terms/m/macd.asp#:~:text=Moving%20Average%20Convergence%20Divergence%20(MACD)%20is%20a%20trend%2Dfollowing,from%20the%2012%2Dperiod%20EMA. More Information]
** Stochastic Oscillator
*** This used both K% and D%.
**** Signals whether a security is overbought/oversold
**** K% essentially min-max normalizes prices over a given period
**** D% is a 3-day moving average of K%
*** [https://www.investopedia.com/terms/s/stochasticoscillator.asp More Information]
** Relative Strength Indicator
*** Measures the magnitude of trends
*** Measures overbought vs. oversold levels
*** The function implemented would need a list of prices and also a period on which to run it. Optimal default period default should be ideally set to 14. 
*** [https://www.investopedia.com/terms/r/rsi.asp More Information]
** William R%
*** Similar to stochastic oscillator
*** it is mostly used to measure overbought vs. oversold levels.
*** The function that will be implemented should take in a list of prices and a period on which to run. 

'''Subteam Notes:'''
* David and Tanishq had research CEFLANN, so they explained their research to us.
* Since it was too complicated, we decided to just implement the primitives and not the CEFLANN architecture. 
* Discussed what new members could potentially work on -> implementing the new primitives. 

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Research Technical Indicators implementation
|Finished
|September 24, 2020
|October 1, 2020
|September 30, 2020
|-
|Look into the graphs implemented in paper
|Finished
|October 5, 2020
|October 15, 2020
|October 13, 2020
|}

== October 15, 2020 ==
'''Individual Notes:'''
* Spent the week finalizing the presentation. 
* Not much work done this week, but mainly gearing up for the presentation.
* Did have some trouble with graphs but pushed it after the midterm presentations since they were not fully complete. 
* Completed my slides for the presentation. [https://docs.google.com/presentation/d/1Fm_pXaKLDFHDEsk-T1rXW1p2UGS8ax2Nvd8k8TIstqs/edit?usp=sharing Link.] 
[[files/Midterm Slide.png|thumb|Slide for midterm presentation]]
'''Subteam Notes:'''
* Got ready for presentation. 
* We had an issue with individuals evaluating with a 0 zero error. Ignore these individuals for the presentation. 

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish Slide and make script for self
|Finished.
|October 12, 2020
|October 19, 2020
|October 18, 2020
|}

== October 26, 2020 ==
'''Individual Notes:'''
* Tasked with the graphs to implement from the paper to better visualize our code and profit margins. 
* Graphs should be similar to the ones in the paper. 
* Did have to change a couple things since the paper was calculating on buying one stock and selling that stock at a time but we were implementing a method to introduce a certain amount of money and the program doing the buying and selling for us in very small amounts. 
* This would be on a 5-day average measure. 

'''Subteam Notes:'''
* First semesters joined our team. Introduced ourselves and gave them a quick update on we have been doing so far. 
* Added them to our shared google drive. 

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish graph implementation
|Finished.
|October 5, 2020
|October 15, 2020
|October 30, 2020
|}

== November 5, 2020 ==
'''Individual Notes:'''
* Now that we finished running on previous or the paper used Technical Indicators, we wanted to go ahead and implement a couple more Technical Indicators. 
* The one that I researched on was the Ease of Movement Technical Indicator. 
* This was because we were having some issues with the identifying the trend signa, therefore,fore this would help with that.
* The default value would be set up to zero of the output in incase not used by the individuals. 
* Rishi sent a link to where to make the changes on the repo. It was [https://github.gatech.edu/rbhatnager3/emade/blob/stocks-base/src/GPFramework/stock_methodsF2020.py Here.]
'''Subteam Notes:'''
* Discussed what we talked about with Dr. Zutty in our meeting. 
* We had to do a sanity check that is to compared to see if our output was the same as that of the paper and the things we were doing different and to make sure we were being cognizant about these changes. 
* First semesters read the paper and asked questions if they had any. 

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Research EVM 
|Finished.
|November 5, 2020
|November 12, 2020
|November 12, 2020
|-
|Implement EVM
|Finished.
|November 5, 2020
|November 12, 2020
|November 16, 2020
|}

== November 12, 2020 ==
'''Individual Notes:'''
* Now that we finished running on the previous or the paper used Technical Indicators, we wanted to go ahead and implement a couple more Technical Indicators. 
* The one that I researched on was the Ease of Movement Technical Indicator. 
* This was because we were having some issues with identifying the trend signa, therefore this would help with that.
* The default value would be set up to zero of the output in incase not used by the individuals. 
* Rishi sent a link to where to make the changes on the repo. It was [https://github.gatech.edu/rbhatnager3/emade/blob/stocks-base/src/GPFramework/stock_methodsF2020.py Here.]
'''Subteam Notes:'''
* Met with Dr. Zutty to talk about implementing our technical indicators and how to go about deciding which ones to use. 
* We also talked about how to test them to make sure they were running right. He mentioned a standalone evaluator in the repo to use. [https://github.gatech.edu/rbhatnager3/emade/blob/stocks-base/src/GPFramework/standalone_tree_evaluator.py Linked here.] 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Research EVM 
|Finished.
|November 5, 2020
|November 12, 2020
|November 12, 2020
|-
|Implement EVM
|Finished.
|November 5, 2020
|November 12, 2020
|November 16, 2020
|}

== November 19, 2020 ==
'''Individual Notes:'''
* Finished implementing the EVM TI. Code comit is [https://github.gatech.edu/rbhatnager3/emade/commit/cd1fd654c4d17ff801ad78261ed8baaa69308e5c#diff-a073d7830283e3a13329950082247e92 here.] 
* Helped others in implementing their TIs
* Work with David Daniel and Tanishq to write Unit Tests for each primitive. 
* We looked at the already written Unit Tests (linked here). 
* [[files/EVM Implementation.png|thumb|Ease of Movement Technical Indicator Implementation]]Realized that the unit tests were implemented not to make sure that the output was the same but to make sure that the input and output shape was the same. 

'''Subteam Notes:'''
* Our talk with Dr. Zutty earlier in the week was helpful. 
* From what we talked with Dr. Zutty on Monday:  Learner(MySMA(ARG0, TriState.STREAM_TO_FEATURES, 7), LearnerType(‘RAND_FOREST’, {’n_estimators’: 100, ‘criterion’:0, ‘max_depth’: 3, ‘class_weight’:0}), EnsembleType(‘SINGLE’, None))Learner(MyEMA(MySMA(ARG0, TriState.STREAM_TO_FEATURES, 7), TriState.STREAM_TO_FEATURES, 7), LearnerType(‘RAND_FOREST’, {’n_estimators’: 100, ‘criterion’:0, ‘max_depth’: 3, ‘class_weight’:0}), EnsembleType(‘SINGLE’, None))Axis.FULL  third argument before the integerLearner(MyEMA(MySMA(ARG0, TriState.STREAM_TO_FEATURES, Axis.FULL, 7), TriState.STREAM_TO_FEATURES, Axis.FULL, 7), LearnerType(‘RAND_FOREST’, {’n_estimators’: 100, ‘criterion’:0, ‘max_depth’: 3, ‘class_weight’:0}), EnsembleType(‘SINGLE’, None))(ARG0 a placeholder for the prices input?)
* And also, our AWS server might have been hit with ransomware. The message: '''1, 'To recover your lost databases and avoid leaking it: visit [link] and enter your unique token 25005943d4584579 and pay the required amount of Bitcoin to get it back. Databases that we have: at_test, colab_3, colab_2, collab, stocks_regress, big_colab_run. Your databases are downloaded and backed up on our servers. If we don't receive your payment in the next 9 days, we will sell your database to the highest bidder or use them otherwise. To access this site you have to use the tor browser [more links] '25005943d4584579'''
* We decided to go ahead and create and use a new AWS server the credentials for which were in the input_stocks_f2020.xml template file.
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Implement EVM
|Finished.
|November 5, 2020
|November 12, 2020
|November 16, 2020
|-
|Meet with Tanishq and David to work on Unit tests
|Finished
|November 19, 2020
|November 28, 2020
|November 23, 2020
|-
|Make an initial version of the Unit Test
|Finished
|November 19, 2020
|November 28, 2020
|November 25, 2020
|}

== November 28, 2020 ==
'''Individual Notes:'''
* Set up a meeting with Firsf semesters to help them with TI implementation. 
* Set up a group slack chanel for them. 
* Linked them to our original Technical Indicators implmentations. 
* Worked on deciding the slides for the presentation that would be this Wednesday. 
* Linked the presentation [https://docs.google.com/presentation/d/1arplCjluOGjVm58LiMHV2zVwXl0GCvCsvgb2Ou7nSN8/edit?usp=sharing here.]
'''Subteam Notes:'''
* Mainly discussed the presentation. 
* Discussed any help that the first semesters might need. 
* Planning on doing a final run sometime this week before the presentation to finalize results. 

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish Presentation
|Finished.
|November 28, 2020
|December 1, 2020
|December 2, 2020
|-
|First Semester TI Implementation
|Finished
|November 25, 2020
|December 2, 2020
|December 2, 2020
|}

== January 25, 2021 ==
'''Individual Notes:'''
* The first meeting of the semester. 
* Decided to stay with the stocks team. 
'''Subteam Notes:'''
* Abhiram made a separate Slack channel: stocks-spring2021.
* Set time to meet on January 28th at 5:00 PM to talk about goals. 
'''Action items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Join Stocks Slack channel
|Finished.
|January 25, 2020
|
|January 25, 2020
|-
|Attend Meeting
|Finished
|Janurary 28, 2020
|
|
|}

== Week of February 1, 2021 ==
'''Individual Notes:'''
* Researched the following papers to discuss at next subteam meeting:
** [https://www.sciencedirect.com/science/article/pii/S0957417410002149 A method for automatic stock trading combining technical analysis and nearest neighbor classification] -> So in this they just three technical indicators along with a k-NN classifier. They measure success mainly through profits. I think the gist of it is they reduce the number of times they buy to minimize risk
** [https://jfin-swufe.springeropen.com/articles/10.1186/s40854-019-0138-0 Predicting the daily return direction of the stock market using hybrid machine learning algorithms] -> Wasn't able to read much about this paper, but looks promising. Mainly used deep learning methods
** [https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.754.9610&rep=rep1&type=pdf Market Index and Stock Price Direction Prediction using Machine Learning Techniques: An empirical study on the KOSPI and HSI] -> Korean and Hong Kong stock market. Predicts the rise and fall of the market and 0 and 1.

'''Subteam Notes:'''
* Dr. Zutty gave us some tips about a direction to choose for the semester. 
* Decided to not move forward with last year's paper but choose another one. Entire team will research different papers to go over for our next meeting.
* Talked about maybe implementing some for of fundamental analysis/sentiment analysis as a way to accomodate the fluctuating market. 
* Decided that volume could be a good indicator of sentiment - will need to look into Technical Indicators that are influenced by volume.
* Also find a dataset that is better used for this sort of problems. Potential sources include - Kaggle competition datasets, paper recommended websites.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Research Papers to base experiments
|Finished.
|February 1, 2021
|
|February 8, 2021
|-
|Reach out to NLP for sentiment analysis 
|Finished
|February 1, 2021
|
|Fenruary 8, 2021
|}

== Week of February 8, 2021 ==
'''Individual Notes:'''
* Read through Abhiram's paper. Following are the key takeaways. 
* I mainly looked into the different datasets that we could potentially use for replicating the paper. If we use more or less the same type of data we would be able to mimic the results of the paper pretty closely.
* The paper uses a form of continuously changing threshold based on which the buy and sell signals are based. 
* The three main ways they divide the stocks are: Bullish, Bearish, and Neutral
* The paper chose a stock for each from both the American stock market and also Taiwan stock market.
* From the NYSE they chose: APPL, VZ, and BA as stocks for Bullish, Bearish, and Neutral respectively. 
* From the Taiwan stock market, they chose: AUO, EPISTAR, UMC.
* Based on our discussion on Monday, we decided to move forward with just American stocks for now. 
* These datasets can easily be found on yahoo finance. Rishi is looking into different API's that we can pull from. 

'''Subteam Notes:'''
* During the Monday meeting, I presented the three papers that I had researched and that I thought would be a good fit to base our research on. They are linked in the previous week's notes. One used DNNs and the other had stocks from FOREX and not a US-based market. We, therefore, decided not to move forward with the papers that I presented. 
* Abhiram had a good paper for which we decided to base our next steps for the entire semester. [https://doi.org/10.1016/j.asoc.2011.02.029 Linked here].
* On the Thursday meeting, we discussed the paper and figured out that we would be basing out baseline for the paper on developing a piecewise linear representation. It would essentially produce buy and sell signals based on how the price points for each stock would be represented. We will also be looking into exponential smothing. 

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read Abhirams proposed research paper
|Finished.
|February 8, 2021
|
|February 11, 2021
|-
|Research PLR algorithm
|Finished
|February 8, 2021
|
|Fenruary 11, 2021
|-
|Research Exponential Smoothing
|Finished
|February 8, 2021
|
|Fenruary 11, 2021
|}

== Week of February 15, 2021 ==
'''Individual Notes:'''
* Mianly researched PLR pseudocode and also learned about Exponential Smoothing to decide the difference between the two and to also learn how they were being used in the context of the paper. 
* Exponential Smoothing:
** Mainly used to smooth time series data. 
** The main difference between this and an moving average is that a moving average assigned weights equally to previous observations but exponential smoothing assigned exponentially decreasing weights over the course of the time. 
** Procedure for making assumptions based on prior data. 
** [https://otexts.com/fpp2/expsmooth.html Helpful Link]
* Looked into the variations of the different Technical Indicators used in the paper.
* Researched different volume base TIs
* Decided to move forward with: On Balance Volume, Chaikin Money Flow, Klinger Volume Oscillator, Volume Price Tend. 
* The main reason for applying some additional and specifically volume based TIs is to account for drastic fluctuations in the graph and to also sort of account for sentiment in a very passive way. 
* Will be implementing OBV and CMF over the next two weeks. 

'''Subteam Notes:'''
* Discussed the data David found on yahoo finance to use for the semester. 
* Discussed Abhiram's implemented PLR method - however he did not incorporate euclidean distance. Since the paper does, we would have to account for the difference in the output. 
* Karthik worked with Abhiram to include the Euclidean distance. 
* David and I explained the concept of exponential smoothing to the team and decided that we would move forward with implementing it to use in our algorithm. 
* Noticed some discrepencies in the paper so we decided to take a deeper dive into the paper to really understand the paper and make sure there are no inconsistencies like last time. Dr. Zutty also offered to read the paper so we could discuss with him the next meeting. 

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Research Volume based TIs
|Finished.
|February 15, 2021
|
|February 25, 2021
|-
|Implement Volume Based Tis 
|Finished
|February 15, 2021
|
|Fenruary 25, 2021
|-
|Look into TI APIs
|Finished
|February 15, 2021
|
|Fenruary 22, 2021
|-
|Understand paper more in depth
|Finished
|February 15, 2021
|
|Fenruary 18, 2021
|}

== Week of February 22, 2021 ==
'''Individual Notes:'''
* Mainly researched a couple of volume-based Technical Indicators. 
** On Balance Volume:
*** It's mainly an indicator of momentum and uses flow of volume to predict changes in the stock price that could in turn help with deciding whether to buy or sell the stock.
*** It mainly works on the difference between hedge funds' high volume investments versus less sophisticated investors by gauging the volume bought and sold. By looking at the volume on the OBV to track higher institutional investments to help make a prediction on the upward or downward trend of the price of a stock. 
*** [[files/OBV_formula.JPG]] 
** Chaiken Money Flow
*** This is also a volume-based technical indicator.  
*** This indicator mainly looks at the accumulation and the distribution of the stock and different time based on if the price is rising towards a high or moving towards a low. The CMF will either have a negative value or a positive value. 


'''Subteam Notes:'''
* Talked about the different PLR improvements made by Abhiram. 
* New Technical Indicators were implemented:
** BIAS, DeltaSMA, DeltaBIAS, DeltaMACD, DeltaSTOCH, DeltaWILLR, DeltaRSI, BiasEMA, and DeltaEMA
* I will be working with a few others on implementing some technical indicators over the week as well. 
* We will need to account for the fact that AAPL data was split after the paper was written - part of the reason for there being a discrepancy between our and their data. 
* As per last week, we found a library [https://github.com/mrjbq7/ta-lib linked here] that has all the technical indicators implemented before-hand which will save time as well as improve accuracies of TIs used as they will not be custom. We will be using a combination of the two - ta-lib and custom indicators - in our runs. 
* Although there were some discrepencies between the two mainly on how the input would be processed considered the special STREAM_TO_FEATURE, max was able to write a wrapper to solve this issue. 
* Karthik was also able to set up a new AWS server since the one over break was shit down. 

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Research Volume based TIs
|Finished.
|February 15, 2021
|
|February 25, 2021
|-
|Implement Volume Based Tis 
|Finished
|February 15, 2021
|
|February 25, 2021
|-
|How does paper implement GA cycle
|Finished
|February 22, 2021
|
|February 29, 2021
|}

== Week of March 1, 2021 ==
'''Individual Notes:'''
* Finished working on CMF TI. [https://github.gatech.edu/rbhatnager3/emade/commit/3100cfb42e38c6ebec34d28325ff891bda1abe71#diff-f164aed185b0b79c3c73b46bee25d11c commit].
* helped few of the new students how to implement Technical Indicators in emade. 
* Wrote test cases for the implemented TIs.
* Exploring [https://mrjbq7.github.io/ta-lib/ TA-lib] currently. It does not have as many volume based technical indicators so will still have to look into some further indicators that we could implement. 


'''Subteam Notes:'''
* PLR now works well and does provide consistent results with the paper. 
* Exponential smoothing was implemented in EMADE as an eval method to use as a fitness function. 
* Trying to set up for a run in EMADE for the next coming week. 
* There was some confusion about how the GA process was in the paper and how the threshold was being set - will be working on it this week.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Explore TA-lib
|Finished.
|March 1, 2021
|
|March 8, 2021
|-
|How does paper implement GA cycle
|Finished
|February 22, 2021
|
|march 8, 2021
|}

== Week of March 8, 2021 ==
'''Individual Notes:'''
* Looking into TA-lib and how it can be incorporated much easier rather than have different functions for each of the TI.
** Ran into some issues with this. Realized that the output for the function is only one value i.e. may not be an output for a list of days 
* Joined EMADE as a worker to speed up results. 
* Analyzed what effects STREAM_TO_FEATURES has on the output/input/data overall.

'''Subteam Notes:'''
* Mostly talked about profit calculations since the paper included tax and transaction costs. Since it would get too complicated and we were only interested in the stocks price fluctuation, we decided to just use the stock prices in themselves and not include tax and transaction costs. 
* Abhiram looked into the GA for the paper and it is still confusing as to how the paper implements - looking to see if we just use a single value threshold.
* We will be using different stock as splits for training. This will help turn each stock into its own chapter thereby creating its own splits into testing and training data. 
* Started an EMADE run on Friday. We did a run for 30 generations that lasted about 4 hours. Created 2 valid individuals and none of them were seeded. 
** looking into decreasing population size to 60 per generation
** looking into decreasing mutation probabilities
** Study affects of STREAM_TO_FEATURES

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Join EMADE run as worker
|Finished.
|March 12, 2021
|
|March 12, 2021
|-
|Understand STREAM_TO_FEATURES
|Finished
|March 8, 2021
|
|March 15, 2021
|-
|Analyze TA-lib
|Finished
|March 8, 2021
|
|March 15, 2021
|}

== Week of March 15, 2021 ==
'''Individual Notes:'''
* Started the midterm presentation.
* updated the slides that had the TIs.
* First semester students will talk about the different Technical Indicators implemented so I decided to talk about the more research aspect of it. 


'''Subteam Notes:'''
* Another EMADE run this week for next week's presentation. 
* The data type for the evaluations affected the output - need to make sure there is a STREAM_TO_FEATURES primitive in the tree. 
* Dr. Zutty helped us with understanding what changes would need to be made since a good number of the individuals did not evaluate since they were using the incorrect mode. 
** Look at EMADE.py at line 1506 - make sure that there is a stream_to_feature primitive in the tree. [https://github.gatech.edu/rbhatnager3/emade/commit/f93eb5178430d6ddef41609d2aeb63e3b4d14f12 commit that fixed]
** Most of our bad trees took less than a couple of seconds and stopped evaluating. 
** Will need to use more than at least 3 objectives to solve this issue. 
** Seed in more individuals 
** Have emade running for a longer time 
** reduce the population size and the queue sizes. 
** From previous week's conversation we decided to reduce the population to around 60 per generation. 
* Profit percent calculation:
** after removing tax and other additional costs, we got a different threshold value from our algorithm than in the paper. 
** Although there are some discrepancies, if unable to fix them, we will move forward with our current output and the threshold value.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Midterm Presentation slides
|Finished.
|March 15, 2021
|
|March 22, 2021
|-
|Analyze TA-lib
|Finished
|March 8, 2021
|
|March 22, 2021
|}

== Week of March 22, 2021 ==
'''Individual Notes:'''
* Created presentation and updated my slide.
* Still looking into TA-lib and better ways to incorporate it into EMADE.
* [https://docs.google.com/presentation/d/1xvS6nfHNZ9N56m4cDXoD4KzHeRoKkhfhsfIDHpysOUE/edit?usp=sharing Link to Presentation]

'''Subteam Notes:'''
* Today was the midterm presentation for the subteams as well as the boot camps. 
* Some pointers about our presentation by Dr. Zutty:
** Will need to check for the evolvability of EMADE individuals by reducing where EMADE outputs an error. This can be mainly done by enhancing the number of Technical Indicators implemented and the way that they are implemented. Will need some check statements to incorporate the first point. 
** Maybe try using Monte Carlo Simulation/Algorithms to compare one individual from the other and to also increase accuracy by exploring multiple paths at once. Mainly achieve this by comparing the profit with the EMADE individual. Decided to do this mainly with a buy and sell or a buy and hold scenario. 
** Dr. Zutty seemed to like the in-depth analysis of each of our individuals - will try to continue this for next presentations too. 

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Midterm Presentation
|Finished.
|March 22, 2021
|
|March 22, 2021
|-
|Analyze TA-lib
|Finished
|March 8, 2021
|
|March 22, 2021
|}

== Week of March 29, 2021 ==
'''Individual Notes:'''
* Read more in depth about the monte-carlo simulation approach. 
* Rishi finished coding up TA-lib primitives before I got the chance to so I decided to spend more time checking to see if the Monte-Carlo approach is a valid one or not. And if it could be used in the context of our paper. 

'''Subteam Notes:'''
* We were a little confused about what Dr. Zutty meant when we asked us to evaluate individuals using the Monte-Carlo simulations and models. 
** Dr. Zutty mentioned that it would not have to be run multiple times for each individual i.e. it would not have to be recomputed for each individual. 
** Since we don't have a benchmark for our results, we will most likely use an equal-likely approach to decide the level of comparison with a more naive solution. 
** Also clarified that the monte-carlo simulation approach is not to implement it as an EMADE evaluator but as a way to understand the behavior of the stocks and decision signal the peaks. 
* Met with the first semesters this meeting. Seem to be interested mainly in looking at different technical indicators - will work with them to help out with any questions that they have. 
* Was able to implement most of the TA-lib primitives although with some errors but works out correctly in the end. 

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|TA-Lib implementation
|N/A.
|March 22, 2021
|
|N/A
|-
|Understand MonteCarlo in context of paper
|Finished
|March 29, 2021
|
|April 1, 2021
|}

== Week of April 5, 2021 ==
'''Individual Notes:'''
* Mainly researched about the Monte-Carlo simulation and how it could be tied with stocks and our paper as well. 
* Investopedia is usually a pretty good source. Here is the link that was very helpful to get a basic general understanding of the simulatinon. [https://www.investopedia.com/articles/investing/112514/monte-carlo-simulation-basics.asp Link]
* So the Monte Carlo is just a random sampling of inputs that would help solve a particular problem. In our case help with producing the buy and sell signals and to also maximize the amount of profit made.
* It mostly used to analyze and predict portfolio returns and helps with portfolio management and financial planning.
* The output of a simulation is mainly a range of NPV or Net Present Values. 
* By predicting the probability of these values - if it is greater than zero then that would be a positive sign relative to the magnitude. 
* It is in some way similar to pricing fixed income securities. 

'''Subteam Notes:'''
* We had a statistics lecture on April 5 that helped us with giving us ideas on the different types of analysis we could do with our data and to also get an in depth understanding of it all. 
* Main goal is to use the Welch's test on individuals' profit percentage. Abhiram said he will run an experiment to do some beta testing. 
* We onboarded the new students. Abhiram and rishi gave a really good presentation. 
* We tried some new fitness function - Maximizing Average Profit per Transaction, Minimizing Variance of Profit Per Transaction.
* Joined the EMADE run as a worker


'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Looking Monte Carlo
|Finished.
|April 1, 2021
|
|April 5, 2021
|-
|Join EMADE Run
|Finished
|April 5, 2021
|
|April 5, 2021
|-
|Look into TIs to work on with the new group
|Finished
|April 5, 2021
|
|April 12, 2021
|}

== Week of April 12, 2021 ==
'''Individual Notes:'''
* Tasked with finding new TIs that could help with improving our results with the Monte Carlo simulation. 
* Worked with David to find the following TIs:
** VWMA: combines price moving averages with volume to determine trend strength. Has a fixed period of time that it takes into account and cuts off data prior to it.
** Aroon: focuses on time relative to price. Used spot emerging trends, identify consolidations, define correction periods and anticipate reversals. Potentially good for downtrends where smaller reversals are harder to see with typical momentum indicators. (Which might improve performance with Verizon)

'''Subteam Notes:'''
* Split the entire team into 3 different groups. These are not strict divisions just as a way to simplify the assignment of tasks. I joined the research team.
** Literature Review and Research (reading about TIs and figuring out which to use, reading other research papers for ideas)
** Data Analysis of EMADE runs and individuals
** Implementation in EMADE
* Abhiram and Rishi mainly talked about different ways we could potentially lower the number of errors: Mainly by using data that does not stop at a certain point and also by looking at our Moving Average Convergence Divergence
* Abhiram made code to help visualize individual results. (Red line indicates profit percentage)

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Understand error checking progress
|Finished.
|April 12, 2021
|
|April 19, 2021
|-
|Look into TIs to solve the issue
|Finished
|April 12, 2021
|
|April 19, 2021
|}

== Week of April 19, 2021 ==
'''Individual Notes:'''
* Started on final presentation - get the general structure ready. 
* Try and brainstorm what to include in the presentation. 
* Mainly brainstorm ways where we could potentially analyze individuals. 
** One way could be to make a confusion matrix and analyze the relevance of different Technical Indicators used by our individuals. This can then be used later to implement better TIs or algorithms. 
** Doing a heavy comparison between buy and hold could also help with this. This would help mainly accounting for a not-predicted organic stock movement. 

'''Subteam Notes:'''
* Abhiram developed two technical indicators: TSF and BETA
* Max and Karthik wrote a CDF eval function. This function mainly looks for the distribution of the closest fit that was process from the stock data random distributions which were calculated for different types of outcomes possible. This is mainly to also analyze the Monte Carlo simulation. 
* Planning on having an EMADE run done for our presentation in the next two weeks. 
* Notebooks due on May 1 and peer evals on Tuesday,
* Rishi will be looking into what changes to push to Cache-V2.
* For next semester, we are planning on dividing the large stocks team into a smaller one that just use the present existing code and see what the trends look for in Bullish, Bearish, and Neutral markets. 

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Work on presentation
|Finished.
|April 19, 2021
|
|April 26, 2021
|-
|Look into ways to analyze individuals
|Finished
|April 19, 2021
|
|April 26, 2021
|}

== Week of April 26, 2021 ==
'''Individual Notes:'''

'''Subteam Notes:'''

'''Action Items:'''