== Team Member ==

Team Member: Leul Wubete

Email: wubete3@gatech.edu
Cell Phone: +1 4047897798

Interests: Soccer, Walking, Eating, Breathing

== Self-Assessment (Sept. 12, 2021) ==

https://drive.google.com/file/d/1vIVbjxiLl1OnBc4eH0AITw4Mx9kTa2xh/view?usp=sharing
*  Student: Leul Wubete
*  Team: N/A
*  Semester: 1

    *  Notebook Maintenance:
    *  Name and contact info: 5
    *  Teammate names and contact are easy to find: 5
    *  Organization: 5
    *  Updated at least weekly: 5
    *  Meeting Notes:
    *  Main meeting notes: 5
    *  Sub-teams' efforts: 5
    *  Personal Work and Accomplishments:
    *  To-do items: clarity, easy to find: 5
    *  To-do list consistency (weekly or more): 5
    *  To-dos and cancellations are checked and dated: 5
    *  Level of detail: personal work and accomplishments: 15
    *  Useful Resource:
    *  References: 10
    *  Useful resource for the team: 15
    *  Total: 100/100

== Sept. 8, 2021 (Week 3) == 

=== Lecture Notes: ===

* Pareto optimality: https://www.youtube.com/watch?v=cT3DcuZnsGs
* Multi-objective problems: https://www.youtube.com/watch?v=56JOMkPvoKs
* Euclidian distance: https://www.youtube.com/watch?v=1jcnOEDnwLI
* Pareto frontier: https://www.youtube.com/watch?v=9sXEBzI1R5Q

==== MultiObjective Optimization ====
*  Multiple metrics together, like finding a mate in nature
* you look for many things in a person, the personality, attractiveness...
*  Algorithms: reliability, memory usage, consistency, accuracy, speed
*  Genome = description of an individual's algorithm
    *  DNA
    *  GA = set of values
    *  GP = input for functions (tree structure, string)
    *  Drive selection by favoring Pareto optimal individuals (But also want to maintain diversity by fiving all individuals some possibility of mating)
* Classification measures:
    - positive and negative for now {0, 1}
    - multiclass: it can be in this set of things, e.g. {0, .. , 9}
    - look at the confusion matrix
* Maximization measurements:
    - to work on maximizing, focus on true positives and true negatives.
    - True positive rate = # of true positives / total positives (true positive + False Negative)
    - Going to try to put our Pareto frontier (1, 1)
* Minimization measure:
    - pareto frontier to (0, 0) 
* Accuracy:
    - given you have a positive given from algorithm, what percent of the time is it accurate?
* nondominated:
    - best"Pareto optimal" individual you have found so far.
*  (NSGA II) Nondominated sorting genetic algorithm II 
    * If we remove the pareto frontier, then the next set of points becomes the next rank, and then loop doing that.
    *  Lower ranked individuals beat higher ranked individuals
    *  Ties are broken by “crowding distance” (summation of normalized Euclidian distances to all other points within the front)
    *  Higher crowding distance wins
*  (SPEA2) Strength Pareto evoluationary algorithm 2   
    *  Each individual has strength S (number of others in the population it dominates)
    *  Each individual has rank R (sum of the S’s of individuals that dominate it)
    *  Paretos are nondominated and have rank 0
    *  Fitness = R + 1/(dk + 2), where dk is the distance to the kth nearest neighbour

=== My Status/Notes: ===
*  Finished Lab 2:  "Multi-Objective Genetic Programming"
*  Created fitness/individual classes for the multi-objective question - aim to minimize objectives: 'mean squared error', 'tree size'.
*  sin, cos, tan, add, multiply, subtract primitives added to the upset including with parity 1.
*  evaluation function's objectives were added, by combining primitive functions with 'points' in mean squared term.
*  pareto_dominance() function initialized to visualize objective space. 
*  Initialized population of 300 with an additional individual for comparison.
*  With respect to the comparison individual, Sorted population into dominated and dominators.
*  Plotted the resulting sorted population in objective space.
*  After running the original main evolutionary algorithm.
    *  Best individual is: negative(cos(multiply(add(cos(sin(cos(sin(cos(tan(x)))))), cos(x)), tan(x)))) with fitness: (0.2786133308027132, 15.0)
    *  Area Under Curve: 2.3841416372199005
*  Objective: To reduce the area under the graph by 25%
    *  I first tried to make everything arity 2 from my pset, but I got an error telling me I was missing ARG1.
    * This error occurred because I gave main an arity of 2 with only ARG0 provided. I did not realize this at the time.

      random.seed(25)
      pset = gp.PrimitiveSet("MAIN", arity=2)
      pset.addPrimitive(np.add, arity=2)
      pset.addPrimitive(np.subtract, arity=2)
      pset.addPrimitive(np.multiply, arity=2)
      pset.addPrimitive(np.negative, arity=2)
      pset.addPrimitive(np.sin, arity=2)
      pset.addPrimitive(np.cos, arity=2) 
      pset.addPrimitive(np.tan, arity=2)
      pset.renameArguments(ARG0='x')


     --> 3     sqerrors = (func(points)-(np.negative(points) + np.sin(points**2) + np.tan(points**3) - np.cos(points)))**2
      4 
      5     return (np.sqrt(np.sum(sqerrors) / len(points)), len(individual))
   * I then immediately turned Main's arity to arity = 1 and left everything the same. The results were too hot to handle.
      - Best individual is: negative(x, negative(multiply(x, x), multiply(x, x))) with fitness: (0.0007884709018408653, 9.0)
   * Area Under Curve: 0.35362638208500674 Vs. 2.3841416372199005
   * Percent decline: ~ 85.17%

TypeError: <lambda>() missing 1 required positional argument: 'ARG1'
  

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Self-Grade Rubric
|Complete
|September 8, 2021
|September 15, 2021
|September 12, 2021
|-
|Update Weekly Notebook
|Complete
|September 9, 2021
|September 15, 2021
|September 12, 2021
|-
|Complete "Lab 2 - Genetic Programming and Multi-Objective Optimization.ipynb" with JupyterLab
|Complete
|September 8, 2021
|September 15, 2021
|September 12, 2021
|}

== September 1, 2021 (Week 2) == 
===Lab 2 Notes:===
* Genetic Programming:
    - Tool used for automated algorithm design. Just like genetic algorithms, we still need fitness and individual classes.

* Instead of lists that we use for genetic algorithms, we use what data structure?
    - gp.PrimitiveTree, individuals represented as a tree structure

* Trees are made of?
    - functions and variables are called primitives AKA the normal nodes.
    - Terminals are the leaf nodes.
    - Root node is considered primitive.

* How to add math operations and rename default arguments? How to add primitives?
    a. pset.addPrimitive(np.subtract, arity=2), BY THE WAY, arity is the number of arguments an operation will take.
    b. pset.renameArguments(ARG0='x')
    c. pset.addPrimitive()

* What else should we not forget in the setup process?
    - Next we will define our toolbox, individual, population, and compiler.
    - This time, we have an expr function: gp.genHaldandHalf returns a primitive tree based on a primitive set and a minimum and maximum tree depth.
    - In this case, the primitive set is the one we defined earlier, the minimum depth is 1, and the maximum depth is 2.     

* How to optimize the function we are generating?
   - by minimizing mean squared error.
   - the mean squared error between the function we compile and the actual function we are trying to generate
   - you could think of genetic programming as finding the best combination of primitives given objectives to minimize or maximize.
   - This means we care a lot less about data than machine learning and care more about objectives.

* How did I add a new mutation function?
   - went to GP mutations in the DEAP source code here: https://github.com/DEAP/deap/blob/master/deap/gp.py
   - picked:  gp.mutEphemeral
   - added: toolbox.register("mutate_2", gp.mutEphemeral, expr=toolbox.expr_mut, pset=pset)

* How to add tree height constraints?
   - toolbox.decorate("mate", gp.staticLimit(key=operator.attrgetter("height"), max_value=17))

* How are the generations printed differently from our evolutionary algorithm?
   - they are printed from the the structure of the tree, read left to right

==== Multiple Objective Genetic Programming ====

* Remember, multiobjective genetic programming has more than one:
   - Weights!
* Plotting class?
   - import matplotlib.pyplot as plt
* Where to visit for Pareto front/dominance?
   - https://github.com/lmarti/evolutionary-computation-course/blob/master/AEC.06%20-%20Evolutionary%20Multi-Objective%20Optimization.ipynb

==== Lab 2 conclusions and issues ====
* I still do not have access or full know-how of how to upload pictures to my Wiki
* My process included changing my git username and email address on my command prompt. When I try to clone the Wiki
* I get an error claiming my PC's space is too low for the wiki's
* When I try to commit the first time, it claims that it is ready to delete all the current pictures/wikis uploaded to EMADE, not good.

{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update notebook
|Completed
|August 27, 2021
|September 1, 2021
|August 27, 2021
|-
|Join Slack
|Completed
|August 25, 2021
|September 1, 2021
|August 27, 2021
|-
|Start "Lab 2 - Genetic Programming and Multi-Objective Optimization.ipynb" with JupyterLab
|Completed
|September 5, 2021
|September 1, 2021
|September 8, 2021
|}
== August 25, 2021 (Week 1) == 

===Lecture Notes:===
* Introduced to project requirements:  Rubric, Syllabus, JupyterLab, Python deap, 
* Shown emade's GitHub, Wiki, Personal Progress Notebooks, Python Jupyter Notebooks, Slack
* Intro to Genetic Algorithms:
    -  The evolution and DNA of the computing world.
    -  Multiple solutions to complex problems, AKA genomes, that can mutate with other solutions given evaluation/fitness.
    -  You can do mating/mutation -> next gen, we loop the process until we find the perfect specimen.
* "Individual"
    -  One candidate in the population
    -  A single organism
* "Population"
    -  Group of individuals to be experimented upon
* "Objective"
    -  Individual's performance measurement
    -  This is like a credit score
* "Fitness"
    -  How good individual is compared to others.
* "Evaluation"
    -  Takes individual and spits out objective.
* "Selection"
    -  Gives preference to better individuals to pass on their genes
    *  2 types:
        -  I. Fitness Proportionate: fitness value is the deciding factor, most fit from all moves on.
        -  II. Tournament: given group of n individuals, most fit is selected for mating. A bit more of a real life scenario.
* "Mating"/"Crossover"
    -  mating between individuals, DNA is combined from individuals.
    -  examples: single point splice, double point splice, ... represented as python list splicing and joining.
* "Mutation"
    -  Inserting change to an individual (changing a person's DNA)
    -  Why? Keep diversity as a factor.
* Algorithms
    -  Initialize population
    -  Consider population fitness (survival of fittest)
    -  Repeat and pick the chosen one:
        1. Select parents
        2. Mating actions
        3. Mutations
        4. Determine fitness
        5. (until the best individual is acceptable)

===Lab 1 walkthrough/personal progression Notes:===
* Downloaded and installed pip for Windows 10
* pip installed jupyterLab for Windows 10
* Added python to my environment variables
* I launched JupyterLab from cmd using 'jupyter-lab' command.
* downloaded DEAP Problem from the Calendar, under the week 1 Assignments column. Saved the file as .ipynb
* Imported Lab1 .ipynb into JupyterLab via the jupyterLab file explorer GUI.
* Opened a new command prompt and used 'pip install deap' to install deap

===Lab 1 Notes:===

===oneMax===
* we defined the name of the class, the inherited class, and the objectives.
    - creator.create("FitnessMax", base.Fitness, weights=(1.0,))
      weight is the objective, if we wanted multi-objective, maybe something like (1.0, -1.0)
* Deap's toolbox
    - DEAP's toolbox.register, we generate individuals with their attributes and how many attributes each individual container should have.
* evalOneMax()
    - simple algorithm to return the # of 1's in a list.
* Genetic Operations
    - Evaluate: evalOneMax()
    - Mate: a two-point crossover function (tools.cxTwoPoint)
    - Mutate: is defined as flipping a bit in our bitstring to either 1 or 0, independent probability of flipping each individual bit of 5%.
    - Select: tournament selection of 3 individuals
* Evaluating our population
    - mapped the evaluation function, then assigning fitness by zipping individuals and their fitness together:
       fitnesses = list(map(toolbox.evaluate, pop))
       for ind, fit in zip(pop, fitnesses):
           ind.fitness.values = fit 
* Evolution process
    - After the tournament selection, clone the offspring so they do not mix with the last loop.
    - next is crossover mutation, where we zip the 2 versions of the list, one being the odd skip, the other being the even skip.
    - in the chance we generate a random < 0.5, we will be mating the two and deleting their separate fitness values.
    - mutate individuals having <20% probabilities and deleted the mutated offspring's fitness values.
    - individuals with invalid fitness in offspring will have their fitness evaluated and then given fitness values, then we set the pop to offspring.
    - found max, min, avg, and standard deviation statistics for the new pop.

===N Queens===
* A conceptually simple problem:
    - knowing that a queen can move horizontally, vertically, and diagonally, how can we stack queens on an n x n board in each row, so that no one queen 
      can reach another queen?
* Make fitness and individual classes for sample 20 x 20 board. Fitness is negative weight, why? We want to minimize conflicting queen paths.
* Individual
    -  our individual (set of Queens) becomes the return value of toolbox_q.permutation, which happens to be a list of integers sampled from range(n) 
       without replacement.
    - If n = 10, then an individual could look like this: [7,0,4,6,5,1,9,2,8,3]. If the first integer in the list is 7, then the queen on the first row 
      will be in column 8.
* Diagonals:
    - Ledt/Right diagonals: https://media.geeksforgeeks.org/wp-content/cdn-uploads/20200510152131/TopLeftBD.jpg
    - Count queens on each diagonal for evalNQueens(individual), and sum the total number of conflicts on L/R diagonals.
* Partially matched crossover:
    - is specifically used in this problem because it represents swapping around pairs of queen positions between two-parent individuals. 
    - This should be more effective than swapping pieces of individuals around like in a one or two-point
    - If we swapped half of the chessboard we would not retain the information gained from either parent because the individual is formed row by row.
    - Chose two random crossover pts then swap the individuals' bits between their indices.
    -  Two Point crossover is also available.
    - x = / next line code is just a way to continue writing value assignment on the next line.
* My mutation function that includes the equivalently counted index from swap_indx, from the opposite end of the list where swap_indx resides.
    def myMutation(individual, indpb):
    size = len(individual)
    
    for i in range(size):
        if random.random() < indpb:
            swap_idx = random.randint(0, size - 2)
            if swap_idx >= i:
                swap_idx += 1
            # swap_opp(opposite) should be at the opposite side of swap_idx
            swap_opp = size - 1 - swap_idx
            if swap_idx != swap_opp:
                individual[i], individual[swap_opp], individual[swap_idx] = \
                    individual[swap_opp], individual[swap_idx], individual[i]
            else:
                 individual[i], individual[swap_idx] = \
                individual[swap_idx], individual[i]
            
    return individual, 
* functions for evaluate -> evalNQueens(), mating -> cxPartiallyMatched, mutate -> indpb = 2.0/n, selection -> tournament with 3 in an arena.
* evolutionary cycle, as shown in lecture.
* pip installed matplotlib

* my mutation (myMutation()) function results:
    - 0 min fitness on gen. 24
    - 0 min fitness on gen. 52
    - 0 min fitness not obtained in first 100 generations
    - 0 min fitness on gen. 31

* mutShuffleIndexes() function results:
    - 0 min fitness on gen. 91
    - 0 min fitness not obtained in first 100 generations
    - 0 min fitness on gen. 11
    - 0 min fitness not obtained in first 100 generations

===Action Items:===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Set up personal notebook page
|Completed
|August 27, 2021
|September 1, 2021
|August 27, 2021
|-
|Join Slack
|Completed
|August 25, 2021
|September 1, 2021
|August 27, 2021
|-
|Complete "Lab 1 - Genetic Algorithms with DEAP.ipynb" with JupyterLab
|Completed
|August 25, 2021
|September 1, 2021
|August 30, 2021
|}
