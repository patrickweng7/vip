== Team Member ==

Team Member: Leul Wubete

Email: wubete3@gatech.edu
Cell Phone: +1 4047897798

Interests: Soccer, Walking, Eating, Breathing

== Oct. 6, 2021 ==

=== Takeaway Notes: ===
* Git-lfs installed through homebrew, Emade repo is being cloned and SQL is currently installing
* Met with my new team, discussed MySQL, installed EMADE
* Decided to ask a few questions for next class: Possible conda and package dependency issues? How to move forward after installing MySQL?
* Installed MySQL Workbench

* What is EMADE?
  - Evolutionary Multiobjective Algorithm Design Engine
  - Primitives are ML functions
  - involves data optimizing / selection
*TODO:
  - Install Emade and MySQL
  - download and install git-lfs
  - Clone emade repo (readme.txt)
  - Run python setup.py install
* Emade necessities
  - Navigate to top-level directory Run “python src/GPFramework/launchGTMOEP.py templates/input_titanic.xml"
* Input (files):
  - .xml file to configure emade
  - first block is for python configuration where it says "<localPythonCommand> python3 </localpythoncommand>"
  - block 2 configures MySQL "<server> 127.0.0.1 </server>" for localhost
  - Set up user/pass
  - We will make our own database but tables are provided
  - Reuse = 1 for master if it's not our first time accessing EMADE
  - May not be a good choice to always use 1 because it may not rerun all the generations
* Datasets
  - Five folds of the same datasets, shuffling used here, which 20% is test set, and then averaging results
  - In Datasets/titanic, sample file titanic_data_splitter.py
  - Produces .csv.gz files with test and train data partitioned from input
  - Can replace preprocessing code with ours, k number splits
  - .gz files need GVIM to open, numpy.loadText also works
  - Emade reserves the last column: fitting models, using train data, and scoring for test data. Last column is truth data.
*  Objectives
  - Minimize it (-1.0 weight)
  - Names will be used as columns in DB.
  - <evaluationFunction> in python src/GPFramework/evalFunctions.py, it specifies method name
*  Params:
  - Evaluation specifies where eval functions in Objectives live and how much memory each worker is allowed to use before marking an 
    individual as “fatal"
  - <workersPerHost> specifies how many evaluations to run in parallel, eval > 2 is tasking for a normal device
  - Evolution parameters:
            ~ Hyperparameters, “magic constants” that affect the evolutionary process
            ~  Initial pop size, launchSize, inQueueSize, etc.
            ~  includes Mating probabilities
            ~ Check out headless chicken crossover
* Connecting a work process to a peer
  - "python src/GPFramework/launchGTMOEP.py templates/input_titanic.xml -w"
* EMADE output formats
  -  Mysql -h hostname -u username -p, asks for a password
        ~ mysql -u root -p
        ~  Selected database command: “use database_name”
        ~  Queries:
           - Select * from individuals join paretofront on individuals.hash=paretofront.hash where paretofront.generation=(select 
             max(generation) from paretofront);
* Structure:
  - Src/GPFramework is the main body of code
  - gtMOEP.py has the main emade engine (genetic loop, including evaluation function)
  - gr_framwork_helper.py is where the primitive set is built for Emade, points to where primitives live:
    ~  methods.py
    ~  signal_methods.py
    ~  spatial_methods.py
  -  data.py provisions DataPair object passed between primitives
  -  input files are in templates/

*  Assignment:
        -  Run Emade together. 1 person has an SQL server set up and 1 acts as a master process, the rest connects as workers.
        -  Run for many generations (like last project; maybe 30, 40)
        -  Learn some SQL, try to mine some information from the database
        -  Plot non-dominated frontier at the end of the run, compared with ML and MOGP assignments
            ~  Going to want to put in own preprocessed data
            ~  Try to get all on the same graph
        -  Make any other plots + figures to show analysis of Emade, try to find some successful trees
            ~  Average evaluation time of a generation, etc.
        -  Presentation on Monday, 25th October

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook
|Done
|October 6, 2021
|October 13, 2021
|October 10, 2021
|-
|Run/Setup emade
|Done
|October 6, 2021
|October 13, 2021
|October 10, 2021
|}


== Sept. 29, 2021 ==

=== Lecture ===
* Presented Titanic MOGP v. ML findings, received feedback, learned from other groups findings
* NSGAII is not supposed to be used in default settings because it doesn't do the optimal selection that we want it to for multiobjective, need to mess around with parameters..
* Slides: https://docs.google.com/presentation/d/1wyaq1Y04CNTXB_JWdlfzPPz3gGLgqZepK5NC_Olhn2U/edit#slide=id.p1
* Had my assumptions of One-Hot encoding clarified by zutty, since we used it for columns like Embarked, Fare, Passenger... to stop ML from creating non-existent links between non-binary int values. For example, ML sometimes assumes in a pair set such as {A : 1, B : 2, C : 3, D : 4, E : 5}, it will sometimes make assumptions that D is closer to E based on the numeric value, but that may not always be the case.
* Still a little confused about One - Hot encoding, so I found a cool site for it: https://www.youtube.com/watch?v=9yl6-HEY7_s

My group's GP vs ML results below
[[files/leul-files/GPvMOGP.png|thumb|123x123px]]

== Sept. 22, 2021 == 

=== Individual Updates: ===
* I'm too awesome
* I have been working on the group slides as well as communicating with my team members on Slack. Team names, slide numbers added.
* Research findings:
    - cool white paper on strongly typed GP: https://direct.mit.edu/evco/article/3/2/199/731/Strongly-Typed-Genetic-Programming
    - NSGA-2 could be a great alternative to selTournament
* I updated my team's subgroup wiki last week and will do so again today.
* We discussed the algorithm for our evaluation, we still have not made a decision but have found a better algorithm for smaller AUC compared to EMADE

=== Lecture: ===
*  Titanic, how to present:
    - use multiple objective genetic programming to find set of, you will evolve that dataset to use those features of your programming.
    - You are used to allowing logical and mathematical operators, simple primitives, strongly or loosely typed genetic programming.
    - Write an algorithm, do not use the default algorithm in DEAP.
    - Use selective, crossover, mutation algorithms, but cannot use algo from there
    - FP, FN, evaluation function. You can add on additional objectives. FP, FN
    - DO NOT USE SELTOURNAMENT, IT IS ONLY FOR SINGLE OBJECTIVE NOT MULTIPLE OBJECTIVE (for titanic project)
    - Do a comparison of the Pareto front that your GP
*   Graphs:
    - Title
    - Labels
    - font size
    - Pareto lines go in the appropriate directions

*  Titanic TODO:
    *  Compare pareto front of ML and GP frontiers
    *  Strong AND loosely typed GP for the project
    *  Multiple objective genetic programming to find a set of pareto optimal algorithms for the same titanic data set
    *  use only simple primitives
    *  Minimize False Negatives and False Positives for small AUC.
    *  Compare pareto front of ML and GP frontiers
    *  Submit CSV, Columns: {PassangerID, {Survived: 0, Not survived: 1}}
    *  Start on PowerPoint
    *  Have LABELS ON YOUR GRAPHS, list group members, do not read-only off the slides. Have a takeaway.       

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
| Finish "Titanic - Machine Learning From Disaster" presentation
|In-progress
|September 26, 2021
|September 30, 2021
|September 26, 2021
|-
|Group work on "Titanic - Machine Learning From Disaster" GP model
|Completed
|September 26, 2021
|September 30, 2021
|September 26, 2021
|-
|Update Weekly Notebook
|Completed
|September 26, 2021
|September 30, 2021
|September 26, 2021
|}

=== Sept.11 - Sept.21 Notes: ===
==== Kaggle: Titanic ====
*  We will be working on: Kaggle Titanic project (GROUP 1 BABY)
* set random_state value to the same thing, you will get the same random numbers, resulting in the same partitions. This is to be CODOMINANT with your group.
*  Libraries to use: Scikit for predictors and models, pandas, support vector machines, DataFrames.
*  Results are scored by: false positive, false negative.
*  Using: train.csv, test.csv, predictions.csv, and the python notebook to structure the project.
===== Libraries Notes: =====
* Pandas is a data analysis library that lets us read and work with different types of data, usually Excel files.
* Some of the datasets aren't perfect, some null cells, so cleaning is required.
* Encode your strings to ints and replace them in their columns (more useful in ML).
* The "survived" column is what we are trying to predict, but things like Age, family members, which class the person was in, etc are the Features.
* Feature: something that describes the data at hand.
*  Allocate training data for training and testing: (not to be confused with test.csv data)
    - X_train = randomized x rows from trains.csv without survived column included
    - y_train = survived x rows of train.csv
    - X_test = remaining (n - x) rows of train.csv
    - y_test = survived (n - x) rows of train.csv
* Use Scikit score function to evaluate predictions
* individually submit our final predictions file on the ZZZ course with results codominant with our team.

==== Personal Notes: ====
* Link for train_test_split: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split
* Pandas .loc: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html
=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook
|Completed
|September 18, 2021
|September 22, 2021
|September 18, 2021
|-
|Meet Group 1 (the best that ever lived) and start "Titanic - Machine Learning From Disaster" 
|Completed
|September 15, 2021
|September 22, 2021
|September 19, 2021
|}
== Self-Assessment Sept. 12, 2021 ==

https://drive.google.com/file/d/1vIVbjxiLl1OnBc4eH0AITw4Mx9kTa2xh/view?usp=sharing
*  Student: Leul Wubete
*  Team: N/A
*  Semester: 1

*  Notebook Maintenance:
    *  Name and contact info: 5
    *  Teammate names and contact are easy to find: 5
    *  Organization: 5
    *  Updated at least weekly: 5
*  Meeting Notes:
    *  Main meeting notes: 5
    *  Sub-teams' efforts: 5
*  Personal Work and Accomplishments:
    *  To-do items: clarity, easy to find: 5
    *  To-do list consistency (weekly or more): 5
    *  To-dos and cancellations are checked and dated: 5
    *  Level of detail: personal work and accomplishments: 15
*  Useful Resource:
    *  References: 10
    *  Useful resource for the team: 15
*  Total: 100/100

== Sept. 8, 2021 (Week 3) == 

=== Lecture Notes: ===

* Pareto optimality: https://www.youtube.com/watch?v=cT3DcuZnsGs
* Multi-objective problems: https://www.youtube.com/watch?v=56JOMkPvoKs
* Euclidian distance: https://www.youtube.com/watch?v=1jcnOEDnwLI
* Pareto frontier: https://www.youtube.com/watch?v=9sXEBzI1R5Q

==== MultiObjective Optimization ====
*  Multiple metrics together, like finding a mate in nature
* you look for many things in a person, the personality, attractiveness...
*  Algorithms: reliability, memory usage, consistency, accuracy, speed
*  Genome = description of an individual's algorithm
    *  DNA
    *  GA = set of values
    *  GP = input for functions (tree structure, string)
    *  Drive selection by favoring Pareto optimal individuals (But also want to maintain diversity by fiving all individuals some possibility of mating)
* Classification measures:
    - positive and negative for now {0, 1}
    - multiclass: it can be in this set of things, e.g. {0, .. , 9}
    - look at the confusion matrix
* Maximization measurements:
    - to work on maximizing, focus on true positives and true negatives.
    - True positive rate = # of true positives / total positives (true positive + False Negative)
    - Going to try to put our Pareto frontier (1, 1)
* Minimization measure:
    - pareto frontier to (0, 0) 
* Accuracy:
    - given you have a positive given from algorithm, what percent of the time is it accurate?
* nondominated:
    - best"Pareto optimal" individual you have found so far.
*  (NSGA II) Nondominated sorting genetic algorithm II 
    * If we remove the pareto frontier, then the next set of points becomes the next rank, and then loop doing that.
    *  Lower ranked individuals beat higher ranked individuals
    *  Ties are broken by “crowding distance” (summation of normalized Euclidian distances to all other points within the front)
    *  Higher crowding distance wins
*  (SPEA2) Strength Pareto evoluationary algorithm 2   
    *  Each individual has strength S (number of others in the population it dominates)
    *  Each individual has rank R (sum of the S’s of individuals that dominate it)
    *  Paretos are nondominated and have rank 0
    *  Fitness = R + 1/(dk + 2), where dk is the distance to the kth nearest neighbour

=== My Status/Notes: ===
*  Finished Lab 2:  "Multi-Objective Genetic Programming"
*  Created fitness/individual classes for the multi-objective question - aim to minimize objectives: 'mean squared error', 'tree size'.
*  sin, cos, tan, add, multiply, subtract primitives added to the upset including with parity 1.
*  evaluation function's objectives were added, by combining primitive functions with 'points' in mean squared term.
*  pareto_dominance(ind1, ind2) function initialized to visualize objective space. 
*  Initialized population of 300 with an additional individual for comparison.
*  With respect to the comparison individual, Sorted population into dominated and dominators.
*  Plotted the resulting sorted population in objective space.
*  After running the original main evolutionary algorithm.
    *  Best individual is: negative(cos(multiply(add(cos(sin(cos(sin(cos(tan(x)))))), cos(x)), tan(x)))) with fitness: (0.2786133308027132, 15.0)
    *  Area Under Curve: 2.3841416372199005
*  Objective: To reduce the area under the graph by 25%
    *  I first tried to make everything arity 2 from my pset, but I got an error telling me I was missing ARG1.
    * This error occurred because I gave main an arity of 2 with only ARG0 provided. I did not realize this at the time.

      random.seed(25)
      pset = gp.PrimitiveSet("MAIN", arity=2)
      pset.addPrimitive(np.add, arity=2)
      pset.addPrimitive(np.subtract, arity=2)
      pset.addPrimitive(np.multiply, arity=2)
      pset.addPrimitive(np.negative, arity=2)
      pset.addPrimitive(np.sin, arity=2)
      pset.addPrimitive(np.cos, arity=2) 
      pset.addPrimitive(np.tan, arity=2)
      pset.renameArguments(ARG0='x')


     --> 3     sqerrors = (func(points)-(np.negative(points) + np.sin(points**2) + np.tan(points**3) - np.cos(points)))**2
      4 
      5     return (np.sqrt(np.sum(sqerrors) / len(points)), len(individual))
   * I then immediately turned Main's arity to arity = 1 and left everything the same. The results were too hot to handle.
      - Best individual is: negative(x, negative(multiply(x, x), multiply(x, x))) with fitness: (0.0007884709018408653, 9.0)
   * Area Under Curve: 0.35362638208500674 Vs. 2.3841416372199005
   * Percent decline: ~ 85.17%

TypeError: <lambda>() missing 1 required positional argument: 'ARG1'
  

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Self-Grade Rubric
|Complete
|September 8, 2021
|September 15, 2021
|September 12, 2021
|-
|Update Weekly Notebook
|Complete
|September 9, 2021
|September 15, 2021
|September 12, 2021
|-
|Complete "Lab 2 - Genetic Programming and Multi-Objective Optimization.ipynb" with JupyterLab
|Complete
|September 8, 2021
|September 15, 2021
|September 12, 2021
|}

== September 1, 2021 (Week 2) == 
===Lab 2 Notes:===
* Genetic Programming:
    - Tool used for automated algorithm design. Just like genetic algorithms, we still need fitness and individual classes.

* Instead of lists that we use for genetic algorithms, we use what data structure?
    - gp.PrimitiveTree, individuals represented as a tree structure

* Trees are made of?
    - functions and variables are called primitives AKA the normal nodes.
    - Terminals are the leaf nodes.
    - Root node is considered primitive.

* How to add math operations and rename default arguments? How to add primitives?
    a. pset.addPrimitive(np.subtract, arity=2), BY THE WAY, arity is the number of arguments an operation will take.
    b. pset.renameArguments(ARG0='x')
    c. pset.addPrimitive()

* What else should we not forget in the setup process?
    - Next we will define our toolbox, individual, population, and compiler.
    - This time, we have an expr function: gp.genHaldandHalf returns a primitive tree based on a primitive set and a minimum and maximum tree depth.
    - In this case, the primitive set is the one we defined earlier, the minimum depth is 1, and the maximum depth is 2.     

* How to optimize the function we are generating?
   - by minimizing mean squared error.
   - the mean squared error between the function we compile and the actual function we are trying to generate
   - you could think of genetic programming as finding the best combination of primitives given objectives to minimize or maximize.
   - This means we care a lot less about data than machine learning and care more about objectives.

* How did I add a new mutation function?
   - went to GP mutations in the DEAP source code here: https://github.com/DEAP/deap/blob/master/deap/gp.py
   - picked:  gp.mutEphemeral
   - added: toolbox.register("mutate_2", gp.mutEphemeral, expr=toolbox.expr_mut, pset=pset)

* How to add tree height constraints?
   - toolbox.decorate("mate", gp.staticLimit(key=operator.attrgetter("height"), max_value=17))

* How are the generations printed differently from our evolutionary algorithm?
   - they are printed from the the structure of the tree, read left to right

==== Multiple Objective Genetic Programming ====

* Remember, multiobjective genetic programming has more than one:
   - Weights!
* Plotting class?
   - import matplotlib.pyplot as plt
* Where to visit for Pareto front/dominance?
   - https://github.com/lmarti/evolutionary-computation-course/blob/master/AEC.06%20-%20Evolutionary%20Multi-Objective%20Optimization.ipynb

==== Lab 2 conclusions and issues ====
* I still do not have access or full know-how of how to upload pictures to my Wiki
* My process included changing my git username and email address on my command prompt. When I try to clone the Wiki
* I get an error claiming my PC's space is too low for the wiki's
* When I try to commit the first time, it claims that it is ready to delete all the current pictures/wikis uploaded to EMADE, not good.

{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update notebook
|Completed
|August 27, 2021
|September 1, 2021
|August 27, 2021
|-
|Join Slack
|Completed
|August 25, 2021
|September 1, 2021
|August 27, 2021
|-
|Start "Lab 2 - Genetic Programming and Multi-Objective Optimization.ipynb" with JupyterLab
|Completed
|September 5, 2021
|September 1, 2021
|September 8, 2021
|}
== August 25, 2021 (Week 1) == 

===Lecture Notes:===
* Introduced to project requirements:  Rubric, Syllabus, JupyterLab, Python deap, 
* Shown emade's GitHub, Wiki, Personal Progress Notebooks, Python Jupyter Notebooks, Slack
* Intro to Genetic Algorithms:
    -  The evolution and DNA of the computing world.
    -  Multiple solutions to complex problems, AKA genomes, that can mutate with other solutions given evaluation/fitness.
    -  You can do mating/mutation -> next gen, we loop the process until we find the perfect specimen.
* "Individual"
    -  One candidate in the population
    -  A single organism
* "Population"
    -  Group of individuals to be experimented upon
* "Objective"
    -  Individual's performance measurement
    -  This is like a credit score
* "Fitness"
    -  How good individual is compared to others.
* "Evaluation"
    -  Takes individual and spits out objective.
* "Selection"
    -  Gives preference to better individuals to pass on their genes
    *  2 types:
        -  I. Fitness Proportionate: fitness value is the deciding factor, most fit from all moves on.
        -  II. Tournament: given group of n individuals, most fit is selected for mating. A bit more of a real life scenario.
* "Mating"/"Crossover"
    -  mating between individuals, DNA is combined from individuals.
    -  examples: single point splice, double point splice, ... represented as python list splicing and joining.
* "Mutation"
    -  Inserting change to an individual (changing a person's DNA)
    -  Why? Keep diversity as a factor.
* Algorithms
    -  Initialize population
    -  Consider population fitness (survival of fittest)
    -  Repeat and pick the chosen one:
        1. Select parents
        2. Mating actions
        3. Mutations
        4. Determine fitness
        5. (until the best individual is acceptable)

===Lab 1 walkthrough/personal progression Notes:===
* Downloaded and installed pip for Windows 10
* pip installed jupyterLab for Windows 10
* Added python to my environment variables
* I launched JupyterLab from cmd using 'jupyter-lab' command.
* downloaded DEAP Problem from the Calendar, under the week 1 Assignments column. Saved the file as .ipynb
* Imported Lab1 .ipynb into JupyterLab via the jupyterLab file explorer GUI.
* Opened a new command prompt and used 'pip install deap' to install deap

===Lab 1 Notes:===

===oneMax===
* we defined the name of the class, the inherited class, and the objectives.
    - creator.create("FitnessMax", base.Fitness, weights=(1.0,))
      weight is the objective, if we wanted multi-objective, maybe something like (1.0, -1.0)
* Deap's toolbox
    - DEAP's toolbox.register, we generate individuals with their attributes and how many attributes each individual container should have.
* evalOneMax()
    - simple algorithm to return the # of 1's in a list.
* Genetic Operations
    - Evaluate: evalOneMax()
    - Mate: a two-point crossover function (tools.cxTwoPoint)
    - Mutate: is defined as flipping a bit in our bitstring to either 1 or 0, independent probability of flipping each individual bit of 5%.
    - Select: tournament selection of 3 individuals
* Evaluating our population
    - mapped the evaluation function, then assigning fitness by zipping individuals and their fitness together:
       fitnesses = list(map(toolbox.evaluate, pop))
       for ind, fit in zip(pop, fitnesses):
           ind.fitness.values = fit 
* Evolution process
    - After the tournament selection, clone the offspring so they do not mix with the last loop.
    - next is crossover mutation, where we zip the 2 versions of the list, one being the odd skip, the other being the even skip.
    - in the chance we generate a random < 0.5, we will be mating the two and deleting their separate fitness values.
    - mutate individuals having <20% probabilities and deleted the mutated offspring's fitness values.
    - individuals with invalid fitness in offspring will have their fitness evaluated and then given fitness values, then we set the pop to offspring.
    - found max, min, avg, and standard deviation statistics for the new pop.

===N Queens===
* A conceptually simple problem:
    - knowing that a queen can move horizontally, vertically, and diagonally, how can we stack queens on an n x n board in each row, so that no one queen 
      can reach another queen?
* Make fitness and individual classes for sample 20 x 20 board. Fitness is negative weight, why? We want to minimize conflicting queen paths.
* Individual
    -  our individual (set of Queens) becomes the return value of toolbox_q.permutation, which happens to be a list of integers sampled from range(n) 
       without replacement.
    - If n = 10, then an individual could look like this: [7,0,4,6,5,1,9,2,8,3]. If the first integer in the list is 7, then the queen on the first row 
      will be in column 8.
* Diagonals:
    - Ledt/Right diagonals: https://media.geeksforgeeks.org/wp-content/cdn-uploads/20200510152131/TopLeftBD.jpg
    - Count queens on each diagonal for evalNQueens(individual), and sum the total number of conflicts on L/R diagonals.
* Partially matched crossover:
    - is specifically used in this problem because it represents swapping around pairs of queen positions between two-parent individuals. 
    - This should be more effective than swapping pieces of individuals around like in a one or two-point
    - If we swapped half of the chessboard we would not retain the information gained from either parent because the individual is formed row by row.
    - Chose two random crossover pts then swap the individuals' bits between their indices.
    -  Two Point crossover is also available.
    - x = / next line code is just a way to continue writing value assignment on the next line.
* My mutation function that includes the equivalently counted index from swap_indx, from the opposite end of the list where swap_indx resides.
    def myMutation(individual, indpb):
    size = len(individual)
    
    for i in range(size):
        if random.random() < indpb:
            swap_idx = random.randint(0, size - 2)
            if swap_idx >= i:
                swap_idx += 1
            # swap_opp(opposite) should be at the opposite side of swap_idx
            swap_opp = size - 1 - swap_idx
            if swap_idx != swap_opp:
                individual[i], individual[swap_opp], individual[swap_idx] = \
                    individual[swap_opp], individual[swap_idx], individual[i]
            else:
                 individual[i], individual[swap_idx] = \
                individual[swap_idx], individual[i]
            
    return individual, 
* functions for evaluate -> evalNQueens(), mating -> cxPartiallyMatched, mutate -> indpb = 2.0/n, selection -> tournament with 3 in an arena.
* evolutionary cycle, as shown in lecture.
* pip installed matplotlib

* my mutation (myMutation()) function results:
    - 0 min fitness on gen. 24
    - 0 min fitness on gen. 52
    - 0 min fitness not obtained in first 100 generations
    - 0 min fitness on gen. 31

* mutShuffleIndexes() function results:
    - 0 min fitness on gen. 91
    - 0 min fitness not obtained in first 100 generations
    - 0 min fitness on gen. 11
    - 0 min fitness not obtained in first 100 generations

===Action Items:===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Set up personal notebook page
|Completed
|August 27, 2021
|September 1, 2021
|August 27, 2021
|-
|Join Slack
|Completed
|August 25, 2021
|September 1, 2021
|August 27, 2021
|-
|Complete "Lab 1 - Genetic Algorithms with DEAP.ipynb" with JupyterLab
|Completed
|August 25, 2021
|September 1, 2021
|August 30, 2021
|}
