==Team Member==
[[files/GeorgiaTechBuzz.jpg|thumb|123x123px]]

Team Member: Lucas Zhang

Email: lzhag462@gatech.edu 

Cell Phone; 912-257-6740

Classes Taking: Deeping Learning, Digital Design Lab, Computer Networking I, Robotics and Perception, Ethics

Interests: Machine Learning, Python, Web Development, Healthcare
== Fall 2021 Semester ==
== Neural Architecture Search Members (Fall 2021): ==

[[Notebook Lucas Zhang|Lucas Zhang]]

[[Notebook Cameron D Bennett|Cameron D Bennett]]

[[Notebook Cameron Whaley|Cameron Whaley]]

[[Notebook Devesh Kakkar|Devesh Kakkar]]

[[Notebook Conner Jackson Yurkon|Conner Jackson Yurkon]]

[[Notebook Justin Hsu Hinckley|Justin Hsu Hinckley]]



== AAD General Meeting: Monday, August 23, 2021 ==
*First day of class
*Talked about plan for the semester
* We had a brainstorming session to decide on which teams to have for the semester.
* 

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Access VIP notebook
|Completed
|8/23/21
|8/23/21
|8/23/21
|-
|Brainstorm for subteams
|Completed
|8/23/21
|8/30/21
|8/30/21
|-
|Submit sub-team preferences
|Completed
|8/23/21
|8/31/21
|8/30/21
|}


== AAD General Meeting: August 30, 2021 ==
* We discussed the subteam ideas from the last general AAD meeting.
* I was assigned to be on the Neural Architecture Search (NAS) subteam.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Fill out the LettuceMeet for NAS meeting time
|Completed
|8/30/21
|9/6/21
|9/1/21
|-
|Read the 2 papers assigned
|Completed
|8/30/21
|9/10/21
|9/9/21
|}


== AAD General Meeting: Monday, September 6, 2021 ==
No Meeting due to Labor Day

== Neural Architecture Search Meeting: Friday, September 10, 2021 ==

*Met with the other NAS subteam members for a little over an hour.
*We went over the brainstorming ideas, todos etc. on the  [https://trello.com/b/RbwUW89F/nas-brainstorm our Trello board]. Access may only limited to NAS subteam members. 

*Brainstorming ideas on [https://trello.com/b/RbwUW89F/nas-brainstorm Trello board]
**Speeding up EMADE
*** Goal is to generate a tokenization process which only needs to occur once. The results of this tokenization process will be made accessible by all future individuals generated rather than forcing individuals/EmadeDataPairs to undergo their own expensive tokenization process.

**Novelty detection
*** Goal is to incorporate some reward into made which encourages individuals to use components/layers which have not been used by other individuals prior. This would help diversify the number of individuals per generation allowing for the discovery of ideal individuals fast.

**Triviality
*** Goal is to set up some sort of penalization within made for individuals that simply guess the same clarifications constantly without any effective algorithmic considerations.

**Add some test scripts for debugging
*** Goal is to create a test file as a starting point for creating some test cases that quickly reproduce undesirable individuals. This test file will be created by using a simple dataset such as MNIST or CIFAR-10 and add a template file that is small enough to generate around 5 generations for a local run.

* We decided that our weekly meeting times are going to be Fridays from 2 pm to 3pm.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Look over the trello board and get more familiar with emade
|Completed
|9/10/2021
|9/20/21
|9/15/21
|}



== AAD General Meeting: Monday, September 13, 2021 ==

* We went over general announcements
* Scrum meeting in which each team spoke about what they are working on and where they are stuck.
* After the scrum meeting, the NAS subteam met for about 10 minutes to discuss our action points. Based on Dr. Zutty's feedback, our team modified some of our objectives. One of which was modifying EMADE's DataPair.
*

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read both assigned papers and the EMADE/nn-vip Crash Course slides
|Completed
|9/13/21
|9/17/21
|9/17/21
|-
|Fill out Self-evaluation form
|Completed
|9/13/21
|9/13/21
|9/13/21
|}

== Self-Evaluation Form Fall 2021 ==
* Notebook Maintenance  
** Name & contact info. '''5/5'''
** Teammate names and contact info easy to find. '''5/5'''
** Organization. '''5/5'''
** Updated at least weekly. '''2/10'''
* Meeting Notes
** Main meeting notes. '''1/5'''
** Sub-teams’ efforts. '''5/10'''
* Personal work & accomplishments
** To-do items: clarity, easy to find. '''2/5'''
** To-do list consistency (weekly or more). '''2/10'''
** To-dos & cancellations checked & dated. '''2/5'''
** Level of detail: personal work & accomplishments. ''2/15'''
* Useful resource
** References (internal, external). '''2/10'''
** Useful resource for the team. '''10/15'''

Total Out of 100: '''43/100'''
*Reflection:
**I think the biggest thing that I can improve upon is to update my notebook more regularly.

== Neural Architecture Search Meeting: Friday, September 17, 2021 ==
* Met with my sub-team for an hour to make sure that everyone on our subteam had EMADE setup
* Thr meeting started off with information regarding setting up EMADE on everyone's computers as well as having everyone sign into the team trello board.
* Cameron Whaley then gave an introduction regarding the NAS subteam and about neuroevolution. 

== AAD General Meeting: Monday, September 20, 2021 ==
*Each team shared their updates.
* Our team presented our current tasks, including CIFAR-10 templating and novelty detection.
* After the scrum meeting, my sub-team met and I listened to Cameron  showing us to analyze results with his analysis library and how to make training faster. This is done by adjusting the num_instances in the dataset input .XML files).
* Studied [https://docs.pace.gatech.edu/interactiveJobs/jupyterInt/ PACE Guide]  to learn how to setup and use PACE.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Study PACE Guide
|In Progress
|9/17/21
|9/27/21
|
|}



== Neural Architecture Search Meeting: Friday, September 24, 2021 ==
*For an hour, our sub-team met for each sub-team member to update the sub-team on their progress and to talk about plans for what the sub-team will do next.
* We talked about setting up a team meeting to learn more about EMADE and the portions relevant to our sub-team.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Continue studying PACE Guide and EMADE
|In Progress
|9/17/21
|9/27/21
|
|}


== AAD General Meeting: Monday, September 27, 2021 ==
*Each team shared their updates.
* Our NAS sub-team scrum meeting presentation was mainly about our discussion of Supernet and the types of methods we can implement. The idea of weight sharing was mentioned.
* After the scrum meeting, our sub-team met to check-in with each member.
* We confirmed that the CIFAR-10 dataset was added into our branch and we talked about the layer list is stored for each individual.
* I was assigned the task of "Debugging /Reproducing issue with test_swap line300 EMADE.py"

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Work on setting up PACE
|In Progress
|9/27/21
|10/8/21
|
|Work on "Debugging /Reproducing issue with test_swap line300 EMADE.py"
|In Progress
|9/27/21
|10/8/21
|
|}


== Neural Architecture Search Meeting: Friday, October, 1, 2021 ==
*Justin Hsu Hinckley joined the NAS team from the stocks team
*On 9/29/2021, I met with Cameron Bennett and Cameron Whaley to discuss setting up PACE and the task regarding "Debugging /Reproducing issue with test_swap line300 EMADE.py".

*I wasn't able to attend Cameron Bennett and Cameron Whaley's presentation, "Guide to EMADE.py" live due to a time conflict so I watched a recording of it.
Guide to EMADE.py Presentation Notes:
*Agenda
**EMADE Object
**Helper Functions
**Mating/Mutation Functions
**Master Algorithm
**Worker Algorithm
*EMADE Object
**Contains methods to feed input XML arguments into deap
**On init: creates empty toolbox
*create_representation(self, adfs=0, regression= False)
**Does a few important things: self.pset = gp.PrimitiveSetTyped('MAIN', [EmadeDataPair], EmadeDataPair)
** Functionality to create Automatically Defined Functions (ADFs) added to toolbox
*** Creates self.pset to store primitives/ADFs
****Initialized by adding MAIN primitive to self.pset
*setObjective(self, objectivesDict) and setDatasets(self, datasetDict)
**Both assign their one argument as a class attribute
**setObjectives uses objective bounds to define area for hypervolume (AUC) calculations
**setDatasets creates constructs a deap creator,Individual, adds its fitness attributes, and adds it to the toolbox
***Also registers the following to the toolbox: population (list of inds), selection algorithm, tournament algorithm, mating/mutation functions, evaluation functions, and misc function used to modify individuals.

* buildClassifier(self)
**Actually loads datasets using arguments from self.datasetDict()
**Uses different loading function based on type of data
**Loads datasets and metadata into EmadeDataPair object, which is assigned to self.datasetDict[dataset name]['dataPairArray']

**Target data for test set is assigned to self.datasetDict[dataSet name]['truthDataArray'] + "truth data" datapair attribute 
**Test set's target data is overwritten in the datapairs(s)

*Helper Functions Used in EMADE.py
** handleWorker(func, dataPair, return_dict, my_queue, ind_hash)
***Purpose: Execute evaluation method in separate process and store within return_dict
***Used By: evaluate_individual
***Nested method: sigterm_handler_sub(signal, frame)
***Terminates the evaluation process upon completion of evaluation

**setObjectives(self, objectivesDict)
***Purpose: Construct 3 tuples to define the space of our objective goals and achievability along with our weights for each
***Affects FitnessMin within toolbox
***Affected variables:
****LROI: a hypercube defining the minimum acceptable objective values
****SROI: a hypercube defining where solutions are known to be possible
***Args: objectives_dict <= defined in launchEMADE.py

**setDatasets(self, datasetDict)
***Purpose: Registers the majority of the toolbox methods to be used
***Args: datasetDict <- defined in launchEMADE.py
***Notable assignments
****self.toolbox.register("evaluate", evaluate)
****self.toolbox.register("mutateSwapLayer", emade_operators.swap_layer)
****self.toolbox.register("mutateAddLayer", emade_operators.add_layer)
****self.toolbox.register("fitnessScale", HCDScaleMin)
**my_str(individual)
***Useful header when developing
***Purpose: Return the string representation of an individual
***Args:
****Individual object
*Mating/Mutation Functions
**swap_layer(individual, upset)
***Purpose: Randomly replaces a non-IO layer from an NNLearner with another layer
**cx_ephemerals(ind1, ind2)
***Purpose: Randomly select in each individual and exchange each subtree with the point as root between each individual.
**swap_layer swaps a a single layer as opposed to cx_ephemerals swaps entire subtree.
**concat_healer(individual, pset, oldbranch)
***Purpose: Ensures newly concatenated layers are initialized within individual object
*Master Algorithm


'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Work on setting up PACE
|In Progress
|9/27/21
|10/8/21
|
|-
|Work on "Debugging /Reproducing issue with test_swap line300 EMADE.py"
|In Progress
|9/27/21
|10/8/21
|}






== AAD General Meeting: Monday, October, 4, 2021 ==
*Each team shared their updates during the scrum meeting
* Our sub-team presented about adding the CIFAR-10 dataset into made and our progress in novelty detection.
*After the scrum meeting, our subteam did a check-in with each team member.
* I had some help resolving some errors regarding setting up pace.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Work on setting up PACE
|In Progress
|9/27/21
|10/8/21
|-
|Work on "Debugging /Reproducing issue with test_swap line300 EMADE.py"
|In Progress
|9/27/21
|10/8/21
|}

== Neural Architecture Search Meeting: Friday, October, 8, 2021 ==
* Met from 2 pm to 3:15 pm to give the sub-team updates regarding our weekly progress.
* Cameron Whaley talked about an issue that he encountered regarding the latest merge onto the nn-vip branch. We then decided to work off of Cameron Whaley's fork while the issue was being resolved. Justin resolved this issue by reverting the previous three commits and merging [https://github.gatech.edu/emade/emade/pull/200 a PR] onto this branch.
* Justin, Conner, and both Camerons helped Justin and I resolve errors regarding setting up Pace. We found out that one of our errors were from being on the EZCGP team in that one of our folders on pace were pointing to Rodd's account.
* We scheduled an optional work meeting on Monday for us to meet up and help each other make progress.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Work on setting up PACE
|In Progress
|9/27/21
|10/8/21
|-
|-
|Work on "Debugging /Reproducing issue with test_swap line300 EMADE.py"
|In Progress
|9/27/21
|10/8/21
|-
|}





== Spring 2021 Semester ==

== Bootcamp Group #1 Members (Spring 2021): ==
[[Notebook Lucas Zhang|Lucas Zhang]]

[[Notebook Vishesh Gupta|Vishesh Gupta]]

[[Notebook Andrew Tyler Weatherly|Andrew Weatherly]]

[[Notebook Kevin Zheng|Kevin Zheng]]

[[Notebook Diptendu Maity|Diptendu Maity (Dip) ]]

[[Notebook Sriram Mudireddy|Sriram Mudireddy]]

[[Notebook Shiyi Wang|Shiyi Wang (Scott) ]]

[[Notebook Heidi Mae Yap|Heidi Mae Yap]]


== ezCGP Members (Spring 2021): ==
[[Notebook Lucas Zhang|Lucas Zhang]]

[[Notebook Vishesh Gupta|Vishesh Gupta]]

[[Notebook Hemang Rajvanshy|Hemang Rajvanshy]]

[[Notebook Daniel Ignacio Martin|Daniel Ignacio Martin]]

[[Notebook Kevin Zheng|Kevin Zheng]]

[[Notebook Justin Hsu Hinckley|Justin Hsu Hinckley]]

[[Notebook Parshva Shah|Parshva Shah]]

[[Notebook Monil Manish Kaneria|Monil Manish Kaneria]]

[[Notebook Conner Jackson Yurkon|Conner Jackson Yurkon]]

== Bootcamp Meeting 1: January 20, 2021 ==
'''Team Meeting Notes:'''
** Syllabus Overview: [[Syllabus-Spring-2021|Syllabus]], Semester schedule: [[Calendar-Spring-2021|Calendar]]
** Bootcamp meetings: Wednesdays 5:00 - 5:50 pm
** Transition Meeting: Monday, March 22, 5-8 pm
** Main Meetings post transition: Mondays 5-6 pm
* '''Lecture Content'''
'''''Genetic Algorithm''''' 
*Evaluate each individual in a population of solutions. 
*If stopping criteria are not met, a new generation is created through mating/mutation and the evaluation step is performed again.
** Terms:
*** Individual: one specific candidate in the population (with properties such as DNA)
*** Population/Generation: a group of individuals whose properties will be altered to obtain a new generation
*** Objective: a value used to characterize individuals that you are trying to maximize or minimize (usually the goal is to increase objective through the evolutionary algorithm)
*** Fitness: Relative comparison to other individuals; how well does the individual accomplish a task relative to the rest of the population?
*** Evaluation: a function that computes the objective of an individual
** Selection: represents ‘survival of the fittest’; gives preference to better individuals, therefore allowing them to pass on their genes.
* Selection methods:
*** Fitness Proportionate: the greater the fitness value, the higher the probability of being selected for mating
*** Tournament: several tournaments among individuals (number of individuals in each tournament is dependent on tournament size); winners are selected for mating.
** Genetic Algorithms for creating a new generation:
*** Mating/Crossover: represents mating between individuals
*** Mutation: Introduces random modification; purpose is to maintain diversity
** Genetic Algorithm Steps:
**# Random initialization of population
**# Determine fitness of population
**#Repeat...
***# select parents from population
***# perform crossover on parents creating population
***# perform mutation of population
***# determine fitness of population
***Keep going until best individual is good enough
** One Max Problem:
*** The problem begins with individuals that contain a list of 100 values that are either zero or one
*** The goal is to eventually produce an individual that contains all ones Lab 1:
One Max Results:

[[files/1MaxLucas.jpg|504x504px]]

N Queens Results:

[[files/NQLucas1.jpg|643x643px]]

[[files/NQLucas2.jpg|655x655px]]

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install DEAP library
|Completed
|January 20th, 2021
|January 27th, 2021
|January 27th, 2021
|-
|Review Meeting 1 Slides and Notes
|Completed 
|January 20th, 2021
|January 27th, 2021
|January 27st, 2021
|-
|Install Jupyter Notebook and Anaconda
|Completed
|January 20th, 2021
|January 27th, 2021
|January 27st, 2021
|-
|Join the Slack and Piazza
|Completed
|January 20th, 2021
|January 27th, 2021
|January 27th, 2021
|-
|Review Syllabus
|Completed
|January 20th, 2021
|January 27th, 2021
|January 20th, 2021
|-
|Complete Lab 1
|Completed
|January 20th, 2021
|January 27th, 2021
|January 27th, 2021
|-
|}

== Bootcamp Meeting 2: January 27, 2021 ==
'''Team Meeting Notes:'''
* '''Lecture Content'''
'''''Last Week: Genetic Algorithms''''' 
* Population based solution
* Used concepts from natural selection to evolve individuals
* Used properties of DNA to exchange and change information between individuals
* Individuals represented as list
**[Gene_0, Gene_1, Gene_2, …, Gene_N-1]

'''''This Week: Genetic Programming''''' 
* Instead of taking an individual and having a function evaluator to obtain objective scores…
** The individual is the function itself

** Terms:
* '''genetic algorithms: '''a population-based solution to optimizing properties of algorithms.
* '''genotypic diversity: '''how similar is the structure of an algorithm.
* '''phenotypic diversity: '''how similar are the fitness levels and objective scores of 2 algorithms
* '''Lisp preordered parse tree:''' Operator followed by inputs list
* '''Leaves/terminals:''' tree abstractions to represent parameters.
* '''Nodes/primitives:''' tree abstractions to represent functions
* '''Cross in GP: ''' Cross over in tree-based GP is simply exchanging subtrees

*'''Tree Representation'''
* We can represent a program as a tree structure
** Nodes are called primitives and represent functions
** Leaves are called terminals and represent parameters
*** The input can be thought of as a particular type of terminal.
*** The output is produced at the root of the tree

**'''How is the Tree Stored?'''
* The tree is converted to a lisp preordered parse tree.
**Operator followed by inputs
* The tree for f(x) = 3*4+1 can be written as: [+,*,3,4,1]
* This comes from using the root first and then expanding:
[+, input1, input2]
[+,*, input3, input4, 1]

*'''Crossover in GP'''
** Crossover in tree-based GP is simply exchanging subtrees
** Start by randomly picking a point in each tree
** These points and everything below create subtrees
** The subtrees are then exchanged to produce children

'''''Mutation in GP''''' 
Mutation can involve...
** Inserting a node or subtree
** Deleting a node or subtree
** Changing a node 

*'''''Symbolic Regression''''' 
* Using simple primitives to evolve solutions

*'''''Symbolic Regression Example: Evolve a solution to y = sin(x)''''' 
Primitives: +, *, -, /
Terminals:  integers and a variable "x"
We can use the Taylor series to form a polynomial approximation to sin(x)

*'''''Evaluating a tree''''' 
* We can feed a number of input points into the function to get outputs
** X = [0..2pi]
* Run f(X)
* We can measure error between outputs and truth (e.g. the sum square error example)

*'''''What Primitives Could Make This Evolution Easier''''' 
* Power(0)
* Factorial()
* Sin()
* Cos()
* Tan()

'''Lab 2 Part 1:'''

[[files/Lab211.jpg]]

[[files/Lab212.jpg]]

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review Lecture 2 Slides
|Completed
|January 27th, 2021
|February 3, 2021
|January 27th, 2021
|-
|Complete Lab 2 Part 1
|Completed 
|January 27th, 2021
|February 3, 2021
|February 3, 2021
|}

== Bootcamp Meeting 3: February 3, 2021 ==
'''Self Evaluation'''
https://drive.google.com/file/d/1AwWIlX0HML0Q5Rks94kQtg25UXpJrPtP/view

'''Team Meeting Notes:'''
* '''Lecture Content'''
'''''Multiple Objectives- The MO in MOGA and MOGP''''' 
* Genetic Programming Life Cycle: New Gene Pool → Evaluation → Genes w/ scores → Fitness Computation → Genes w/ fitness → Selection → Parental Genes → Mating → Child Genes → Mutation → New Gene Pool
 
* '''New Gene Pool'''
* Gene pool is the set of genome to be evaluated during the current generation
** Genome
*** Genotypic description of an individuals
*** DNA
*** GA = set of values
*** GP tree structure, string
** Search Space
*** Set of all possible genome
*** For Automated Algorithm Design
**** Set of all possible algorithms
*** How big is the search space?
*** Why is this important for algorithm design

* '''Objective Space'''
* The Evaluation of a Genome associates a genome/individual (set of parameters for GA or string for GP) with a set of scores 
* What are these scores
** True Positive - TP
*** How often are we identifying the desired object
** False Positive - FP
*** How often are we identifying something else as the desired object
** More? - On board, next page
* Objectives
** Set of measurements each genome (or individual) is scored against
** Phenotype
* Objective Space - Set of objectives
* Evaluation - Maps an genome/Individual
** From a location in search space
*** Genotypic description
** To a location in objective space
*** Phenotype description

* '''Terms'''
True Positive (TP): an outcome where the model correctly predicts the positive class.
True Negative (TN): an outcome where the model correctly predicts the negative class.
False Positive (FP): an outcome where the model incorrectly predicts the positive class.
False Negative (FN): an outcome where the model incorrectly predicts the negative class.

* '''Stats Measures'''
** True Positive Rate (TPR): TP/P = TP/(TP+FN)
** True Negative Rate (TNR): TN/N = TN/(FP+TN)
** False Negative Rate (FNR): FN/P = FN/(TP+FN) = 1 - TPR
**False Positive Rate (FPR): FP/N = FP/(FP+TN) = 1 - TNR
**Positive Predictive Value (PPV): TP/(TP+FP)
**False Discovery Rate (FDR): FP/(TP+FP) = 1 - PPV
**Negative Predictive Value (NPV): TN/(TN+FN)
**Accuracy (ACC): (TP+TN)/(P+N) = (TP+TN)/(TP+FN+FP+TN)

* '''Objective Space'''
* Each individual is evaluated using objective functions
** Mean squared error
** Cost
** Complexity
** True positive rate
** False positive rate
** Etc…
* Objective scores give each individual a point in objective space
* This may be referred to as the phenotype of the individual

* '''Pareto Optimality'''
* An individual is Pareto optimal if there is no other individual in the population that outperforms the individual on all objectives
* The set of all Pareto individuals is known as the Pareto frontier
* These individuals represent unique contributions
* We want to drive selection by favoring Pareto individuals
** But maintain diversity by giving all individuals some probability of mating

* '''Nondominated Sorting Genetic Algorithm II (NSGA II'''
* Population is separated into nondomination ranks
* Individuals are selected using a binary tournament
* Lower Pareto ranks beat higher Pareto raks
* Ties on the same front are broken by crowing distances
** Summation of normalized Euclidian distances to all points within the front
** Higher crowding distance wins

* '''Strength Pareto Evolutionary Algorithm 2 (SPEA2)'''
* Each individual is given a strength S
** S is how many others in the population it dominates
* Each individual receives a rank R
** R is the sum of S’s of the individuals that dominate it
** Pareto individuals are nondominated and receive an R of 0
* A distance to the Kth nearest neighbor (σ^k) is calculated and a fitness of R + 1/((σ^k)+ 2) is obtained

'''Lab 2 Part 2 Results:'''

[[files/Lab221.jpg]]

[[files/Lab222.jpg|424x424px]]

[[files/Lab223.jpg]]

[[files/Lab224.jpg]]
===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|E-mail 'Rate Yourself' to Dr. Greg
|Completed
|February 3, 2021
|February 10, 2021
|February 3, 2021
|-
|Complete Lab 2 Part 2
|Completed
|February 3, 2021
|February 10, 2021
|February 10, 2021
|-
|Complete Self-Evaluation
|Completed
|February 3, 2021
|February 10, 2021
|February 10, 2021
|-
|}

== Bootcamp Meeting 4: February 10, 2021 ==
'''Team Meeting Notes:'''
* We were assigned to groups today using Pareto ranks.
* I have been assigned to Group 1 and my team leader is Vishesh Gupta.
* We were introduced to the Titanic Dataset Challenge on Kaggle. Our goal is to create Pareto codominant machine learning models.
* '''Codominant Algorithms: ''' Algorithms in which one does not dominate another on every objective. For the Titanic challenge, we are supposed to classify survivors and minimize false positives and false negatives.

'''Group 1 Meeting Notes'''

'''Feb 13, 2021:'''
* Familiarized with the Kaggle Titanic Challenge
* Chosen three feature selection techniques for data preprocessing: Univariate Selection, Feature Importance, and Correlation Matrix with Heatmap.
* Modified the test split size proportion from 0.30 to 0.25
* Decided next meeting date and time
Action Items
* Complete feature selection using the univariate selection - Completed 2/15/2021
* Continue to explore different selection models on Scikit learn - Completed 2/15/2021
* Notify the team of model selection choice - Completed 2/15/2021
* Complete model selection on Jupyter Notebook - Completed 2/15/2021
* Complete Team Meeting Notes - Completed 2/15/2021<br> '''Feb 16, 2021:'''

* Clarified the term Pareto optimal.
* Decided to drop columns ‘embarked’, ‘SibSp’ based on the feature selection results from univariate selection and correlation matrix with heatmap.
* Decided to keep the 'Parch' column due to an accuracy drop in multiple models.
* Finalized the machine learning models for each member through CodeShare.
Action Items
* Record Confusion Matrix and model accuracy - Completed 2/16/2021
* Set up Google Sheet for Pareto optimal check for the subteam on CodeShare - Completed 2/16/2021
* Complete Team Meeting Notes - Completed 2/16/2021
* Submit Titanic ML assignment on Canvas - Completed 2/17/2021

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Attend Group 1 meetings
|Completed
|February 10, 2021
|February 17, 2021
|February 17, 2021
|-
|Complete Titanic ML Assignment
|Completed
|February 10, 2021
|February 17, 2021
|February 17, 2021
|}

== Bootcamp Meeting 5: February 17, 2021 ==
'''Team Meeting Notes:'''
* We discussed a variety of techniques that each group was doing. One of those was one-hot encoding.
* For the upcoming assignment, we are supposed to use a multi-objective genetic programming front using the same preprocessed data for the Titanic Dataset from the previous group assignment. We are allowed to use DEAP but not its evolutionary algorithm.
'''Group 1 Meeting Notes'''

'''Feb 20, 2021:'''
* Introduced new member.
* Familiarized with the genetic programming process.
* Decided to finalize the genetic programming version Titanic project by Sunday.
Action Items
* Begin to work on the GP version Titantic project. - Completed 2/20/2021
* Complete Team Meeting Notes - Completed 2/20/2021

'''Feb 21, 2021:'''
* Discussed the guideline and inspirations for the GP version of the Titanic project.
* Discussed the idea for creating the presentation slides and possible task-assignment.
* Decided to work on the presentation slides, merge the final CSV file submission, and update the wiki webpage on Tuesday.
Action Items
* Set up and Fill in the LettuceMeet for Tuesday’s (2 to 3 hrs) meeting availability. - Completed 2/21/2021
* Continue to work on the GP version Titantic project. - Completed 2/21/2021
* Update false-negative and positive values in the Pareto Optimal Google Sheet to reach Pareto optimal. - Completed 2/21/2021
* Upload the GP version Titanic project on the Team Github page. - Completed 2/21/2021
* Complete Team Meeting Notes - Completed 2/21/2021

'''Feb 23, 2021:'''
* Clarified the meeting goals and presentation requirements.
* Walked through Kevin's MOGP methodology in Jupyter Notebook.
* Collected the Titanic project CSV files from each team member.
* Assigned tasks for the presentation to each team member.
* Created the slides for the Presentation on "Predictions on Titanic Survivors with ML and MOGP"
Action Items
* Complete the assigned presentation section - Completed 2/23/2021
* Submit the Titanic project code for MOGP on Github - Completed 2/23/2021

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Attend Group 1 Meetings
|Completed
|February 17rd, 2021
|February 24th, 2021
|February 24th, 2021
|-
|Complete MOGP Assignment
|Completed
|February 17rd, 2021
|February 24th, 2021
|February 24th, 2021
|-
|}

== Bootcamp Meeting 6: February 24, 2021 ==
'''Team Meeting Notes:'''
* The first 3 groups presented their machine learning and genetic programming work
'''Group 1 Meeting Notes:'''

'''Feb 24, 2021:'''
* Reviewed our presentation slides and reformated them to Georgia Tech style.
* Rehearsal on our presentation through the bluejeans meeting before the class meeting time.
* Updated our presentation slides on the [[Group 1|subteam #1 Wiki page]].
Action Items
* Update subteam wiki page - Completed 2/24/2021
* Everyone good luck with the presentation - Completed 2/24/2021

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install Emade
|Completed
|February 24, 2021
|March 3, 2021
|March 3, 2021
|-
|Complete Peer Evaluations
|Completed
|February 24, 2021
|March 5, 2021
|March 2, 2021
|-
|Complete Notebook
|Completed
|February 24, 2021
|March 3, 2021
|March 3, 2021
|}

== Bootcamp Meeting 7: March 3, 2021 ==
'''Team Meeting Notes:'''
* We watched the other three groups present their ML and GP Titanic work.
* Dr. Zutty gave an introduction to the Evolutionary Multi-Objective Algorithm Design Engine (EMADE).

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Familiarize with EMADE library
|Done
|March 3, 2021
|March 9, 2021
|March 9, 2021
|-
|}

== Bootcamp Meeting 8: March 10, 2021 ==
'''Team Meeting Notes:'''
* Today we spend the whole class time trying to install emade and debug errors.

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish installing emade
|Done
|March 8, 2021
|March 8, 2021
|March 8, 2021
|-
|Set up the SQL server
|Done
|March 8, 2021
|March 17, 2021
|March 10, 2021
|-
|}

== Bootcamp Meeting 9: March 17, 2021 ==
'''Team Meeting Notes:'''
* We continued going over setting up EMADE
* We also went over debugging techniques such as using the GT VPN to connect to database and setting DEAP to version 1.2.2

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Meet with Group 1 to help me connect to the SQL server
|Completed
|March 17, 2021
|March 24, 2021
|March 24, 2021
|-
|}

== Week of March 29-April 5 ==
'''AAD Main Meeting: Monday 3/29/2021 Notes:'''
*I was assigned to the ezCGP team. I attended a breakout session with my ezCGP team. We all introduced ourselves to each other and told each other how much ML experience we have.


'''ezCGP Meeting: Thursday 4/1/2021 Notes:'''
* The team went over this presentation called "Intro to CGP"
** Visual Representation of Genome
***Tree
***LISP
***Cartesian
*Rodd showed us the ezCGP [https://github.com/ezCGP/ezCGP code base]
** [https://github.com/ezCGP/ezCGP/blob/master/main.py Main.py]
**[https://github.com/ezCGP/ezCGP/blob/master/problems/problem_multiGaussian.py problem_multiGaussian.py]
* All members in the ezCGP team were assigned specific tasks.
**Mating
**Visualization
**Seeding
* I choose to be assigned a task related to the mating algorithms because someone said that it was an opportunity to make a big impact.
*'''I met with Rodd and I was able to successfully set up my SSH and install and run ezCGP'''

*[[files/CreatingSSHkeys.JPG]]


*[[files/Install1.JPG]]


*[[files/SSHkeysGithub.JPG]]

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install/Run ezCGP on local machine and on PACE
|Completed
|March 29, 2021
|April 1, 2021
|March 29, 2021
|-
|Study the ezCGP design document
|Completed
|March 29, 2021
|April 1, 2021
|March 31, 2021
|-
|Study ezCGP code base
|Completed
|March 29, 2021
|April 5, 2021
|April 2, 2021

|}

== Week of April 5-April 12 ==
'''AAD Main Meeting: Monday 4/5/2021 Notes:'''
*Dr. Zutty gave us a lecture on statistics. We learned about hypothesis testing and techniques such as the 1 tail test, 2 tail test, and the chi-squared test.


'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read paper with mating team
|Completed
|April 5, 2021
|April 8, 2021
|April 8, 2021
|-
|Individually read the research paper and take notes
|Completed
|April 5, 2021
|April 8, 2021
|April 8, 2021

|}


'''ezCGP Meeting: Thursday 4/8/2021:'''
* In the mating group we read a research paper together: https://link.springer.com/chapter/10.1007/978-3-319-77553-1_13 
**The paper was a comparative study of crossover in CGP
**In the paper, the experiment involved selecting parent genomes for the next generation by using 2 separate tournaments. This makes it so that the sample individual can be picked multiple times.

'''Research paper notes:'''
 - CGP is often used with mutation as the sole operator.
 - This paper is on a comparative study of previously proposed crossover techniques for CGP.
 - The results of the experiment shows that it is possible for a crossover operator to outperform the standard (1 + lambda) strategy on a limited number of tasks.
 - A universal operator in CGP still remains open to find

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish reading research paper
|Completed
|April 5, 2021
|April 8, 2021
|April 8, 2021
|}

== Week of April 12-April 19 ==
'''AAD Main Meeting: Monday 4/12/2021 Notes:'''
* Jason checked in with each team to each where each team was at.



'''ezCGP Breakout Monday 4/12/2021 Notes:'''
* The mating team finished reading the research paper
*Rodd assigned the problems: Koza-3, Nguyen-4, Nguyen-7, Pagie-1 to each of us to run symbolic regression
**He assigned me Nguyen-4
***Objective function - x^6 + x^5 + x^4 + x^3 + x^2 + x
***Training set - U[-1, 1, 20]

[[files/Problems.JPG]]

'''Personal work'''
*I met with Rodd for about 40 minutes on 4/14/2021 to discuss the concepts and problems mentioned during the recent meetings
*I worked on implementing my code for the Nuguyen-4 problem.

'''My code for my Nguyen-4 problem task'''
*https://github.com/ezCGP/ezCGP/blob/feature/SymbolicRegression-Lucas/problems/problem_symbolicRegression_Nguyen-4.py

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read the Crossover research paper again to better understand Nguyen-4
|Completed
|April 12, 2021
|April 15, 2021
|April 14, 2021
|-
|Work on the Nguyen 4 problem
|Completed
|April 12, 2021
|April 19, 2021
|April 14, 2021
|}

== Week of April 19-April 26 ==
'''AAD Main Meeting: Monday 4/19/2021 Notes:'''
*Each team showed their progress.
* Jason reminded us of our final presentation date


'''ezCGP Breakout:'''
*Rodd assigned Monil and I to parameter search.
*Mating methods - Vishesh
*Parameter Search/Meta evolution - Lucas and Monil
*1+lambda Evol strategy - Parshva and Justin

'''ezCGP Meeting: Thursday 4/22/2021 Notes:'''
*We began working on final presentation slides.
*The team made a slide that outlined our presentation. It showed the order of topics that we were going to present in and who was presenting each topic.
'''Personal Work'''
*I met with Monil and Rodd to talk through our tasks and I was able to complete some to-dos on the parameter search problem file.
*The 2 main tasks that we were given for parameter search:
** 1.  Create a new output file structure that would save the generations in an a way that is organized, so that each different combination of population size and genome size are saved in a separate directory.
** 2.  implementing a way to get the best fitness values of each combination and outputting the best parameter combination according to the fitness values.

'''Link to my 4/26/2021 commits for Parameter Search'''
*https://github.com/ezCGP/ezCGP/commit/b7355d541c67e75192f4882a73dcea6f73a7ffb8
*https://github.com/ezCGP/ezCGP/commit/1c8ffb099a7a4a11d7a91f6ab3fcd2b328ef54aa


'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Work on the parameter search problem
|Complete
|April 19, 2021
|April 26, 2021
|April 25, 2021
|-
|Make the assigned slides for the final presentation
|Complete
|April 22, 2021
|April 26, 2021
|April 25, 2021
|-
|Complete the final peer evaluation
|Completed
|April 19, 2021
|April 22, 2021
|April 22, 2021
|}

== Week of April 26-April 30 ==
'''AAD Main Meeting: Monday 4/26/2021 Notes:'''
*Jason checked the progress of each team
*The final presentation is on April 30th at 6pm


'''ezCGP Meeting: Thursday 4/29/2021'''
* Everyone on the ezCGP team did a final review of the presentation slides that we all made to make sure that everything needed is included and that our information is accurate.
* Presentation: https://docs.google.com/presentation/d/1eMU46VktpHKwrQK5wQQ_oSM8ZK6Zzxky1rn5YFm27iw/edit?usp=sharing

'''Personal Work'''
'''I did the slide on the meta-parameter search'''
*[[files/MetaparamSlide.JPG]]
*'''My script for the presentation:'''
Lucas -  Meta-evolution can be very expensive in terms of the computational effort required to find an optimal parameter setting. Since the GP benchmark problems can be very noisy in terms of finding the ideal solution, the evolution of the evolved individual is repeated multiple times, with the fitness defined as the mean result. So what Meta-Parameter Search, is about, is it is implementing a new way to run ezCGP so that we can easily run different iterations of the same problems while making small edits before each run. For the first round of meta-evolution, all problems use the same setting. During the second round , the granularity and range were modified to better fit each individual problem. Since, the (1+lambda) scheme doesnt use tournament selection nor elitism, the 2 parameters have been ignored during its meta-evolution. Because the computational effort that is required to perform a parameter sweep grows exponentially with the number of parameters, only the two most important parameters, mutation rate and population size, were included in the sweep. Elitism rate: The ideal elitism rate was similar across all problems and types of crossover. The ideal elitism rate was similar across all problems and types of crossover. The ideal genotype length was highly variable and largely depended on the problem, rather than the type of crossover used. For the sweep, the genotype length was set up individually for each problem.





'''AAD Main Meeting: Friday 4/30/2021 Notes:'''
Each team is giving their final presentation today.

'''Stocks:'''
*Had 2 notable individuals. Used monte carlo simulations. They calculated profits on stock with random buy and sell trades and found the mean and standard deviation of profits to create a gaussian.
*Showed visualize of individuals compared to randomness.
* Did a buy/hold comparison
**Compare profit to a buy hold strategy.
* Buy/sell lag
**Calculate distance of buy/sell decision to extrema
** Compute the average lag
**Benefits
***Minimal impact from overall stock pattern
***Provides a price independent measurement
**Downfalls:
Primitives Analysis
* Determine which TI's and which ML learners have the best performance
** Used 1917 valid individuals as the sample space
Issues and Future Work
*Compare levels of generalization of optimal models
*Statistical analysis of seeding/types of sees on AUC
*Creating bounded objective functions
*Applying Fundamental analysis in addition to Technical Analysis
* Effectiveness of EMADE on hourly/intraday

Becoming more research heavy:
*VIP is supposed to function as a research group
*Demonstrate something new, something new to the world and contribute that.
*A certain amount of control and experimentation is needed
*Jason wants us to become a little more rigorous with our research.


'''NLP'''
*NNLearner Refresher

*LayerListL Refresher
**LayerList - Python list of layer primitives
*Last Semester Woes
**Had trivial solutions
**Dealt with difficult datasets
*Semester Goals
*First Half
**Choose a simpler dataset
**Streamline how we run EMADE
*Second Half:
**Run EMADE, examine the shortcomings of our implementations of NAS
**Look for improvements in increasing order
*Using PACE-ICE
**At start of semester, no one could reliably run our branch of EMADE
*Problems we solved
**PACE-specific
***Didn't have an up-to-date conda environment but now they have a working .yml file in repo
***They had a ton of MySQL errors
***They added support for multiple worker nodes

*Showed MySQL issues and solutions
*Pretrained Embedding Layers
**Word embedding-vector representation of words learned by a predefined vocabulary 
**Embedding Layer - neural network layer that takes in word embedding
***Input_dim: size of vocabulary
*Documentation and Resources
**Primitives Documentation
***Ported Notion documents to wiki that details 
*New DataSet

**Amazon Product Review Dataset
***Binary Classification

*Promising Non-trivial Solutions

*Configurations for FPR/FNR Run
**Accuracy Score 
*Run with Pareto Optimal Individuals
*Run 1 Pareto Front
*Run 2 Pareto Optimal Individuals
*Run 2 - Pareto Front
*Run 2 - Individual
*See how much EMADE improves over seeds?

'''Modularity'''
* Exploring ways to abstract parts of individuals
* This allows for us to create "building blocks" that can help with the genetic process
* EMADE already uses machine learning models as a form of abstraction
**Primitives can be models instead of simple operations found in GP
*Current implementation is based on Adaptive Representation through Learning (ARLS)
*ARL Complexity Summary
** Edited multiple other methods to deal with the increased depth of ARLs
**These methods contract places where arl subtrees are found in the population into just the single arl primitive node creat the lambda function that composes the arl node, pass data into made
**Originally, these methods passed in the children directly, but now these methods search for the arl subtree because of the arbitrary depth they could be.
*Future Work
**New Models
***Deep Ensembles with a diversity term
***A CNN architecture with decaying learning rate
**Selection Method
**Selection Method
***Modifying the evolutionary selection method to help encourage the spread of ARLs throughout the population and complexity.
**New Dataset Training
***Look at other datasets to expand ARL training to see which ARLs stored in the database are the most used and why.
***Practice on more image datasets and multi-class classification datasets.
**Diversity measure
***Create some quantifiable way to measure diversity, generalizable for EMADE. Made use a diversity measure as a heuristic when finding ARLs.
**ARL Database Storage
***IMprove the way ARLs are stored in the database to keep any information from being lost
**EMADE Integration
***Integrate ARLs with EMADE's original architecture and other modularity techniques
**More Runs

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Notebook
|Completed
|April 30, 2021
|May 1, 2021
|May 1, 2021
|-
|Final Presentation
|Completed
|April 30, 2021
|April 30, 2021
|April 30, 2021
|}