= Team Member =

'''Name:''' Manas Harbola

'''Email:''' [mailto:mharbola3@gatech.edu]

'''Cell Phone:''' 732-983-2028

'''VIP:''' Automated Algorithm Design

'''Interests:''' Artificial Intelligence, Machine Learning, Tennis, Basketball

= Fall 2021 =

== Week 12: November 8th ==
=== Class Summary ===
*NLP Scrum Notes:
**Onboarded new members
**Working on intergrating new primitives finished this week
*Had a class discussion on whether neural networks should be covered in Bootcamp
**Voted in favor of idea because it would make onboarding to subteams easier
**Tradeoffs are that students would have less time to begin contributing to subteam
*Subteam Discussion Notes:
**4 task teams created for the following tasks:
***NNLearner for 2 Data Pairs
***Experiment with Word Embeddings, include issue with pretrained embeddings
***Integrate team - Ensure standalone tree evaluator works for new primitives (my chsoen team)
***Solve output layer probability vector to words problem 
*NLP Team meeting notes for 11/10:
**Successfully was able to run EMADE with the amazon dataset using the input_amazon.xml file
***Solution involved replacing my XML file with Steven's and reconfiguring for my use
**Integration team was blocked by an issue that Steven was able to fix on Saturday after the Wednesday meeting - standalone tree evaluator is now able to work on input_amazon_local.xml with 80% accuracy
=== Individual Notes ===
*Finished setting up EMADE on PACE-ICE and looking forward to begin developing for the NLP subteam
=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook
|Completed
|November 8th, 2021
|November 15th, 2021
|November 15th, 2021
|-
|Setup EMADE on PACE ICE
|Completed
|November 8th, 2021
|November 10th, 2021
|November 10th, 2021
|-
|}

== Week 11: November 1st ==
=== Class Summary ===
*Was assigned to NLP Subteam
*NLP Scrum Notes:
**Determined necessary primitives to develop
**Completing BiDAF
**Modeling layer complete, output layer nearly complete
*NLP Subteam Meeting Notes:
**Joined NLP Slack and was introduced to the team
**Given a quick rundown of what is going to be presented on Wednesday's meeting
**NLP subteam is currently trying to solve QA (Question/Answer) problems with EMADE with the goal of outperforming modern NLP frameworks
**QA format: Given question and context paragraph where the answer can be found, return the answer from the context
**The primitives here are the different layers (BiDAF, Modeling, Output, etc.)
**Layers are connecting sequentially
**Team meets on Wednesdays @ 2pm
*NLP Subteam Meeting for 11/3 Notes:
**Received presentation on intro to QA
**Current model structure from top to bottom: character embedding layer, word embedding layer, contextual embedding layer, attention flow layer, modeling layer, and output layer
*Resources:
**Paper on BiDAF: https://arxiv.org/pdf/1611.01603.pdf
**Pace Setup Tutorial: https://www.youtube.com/watch?v=LashYCCJF3E

=== Individual Notes ===
*Currently working on setting up EMADE on PACE ICE with amazon dataset
*NLP subteam meets on Wednesdays at 2pm
*PACE ICE setup video was really useful and quite detailed, but I hope it also covered the EMADE installation step on PACE ICE, because I ran into some issues running the "reinstall.sh" script on PACE, so I had to manually run the commands
*90% completed with PACE ICE setup, but I keep getting error "Element 'slurmPythonPathMaster': This element is not expected., line 7" in my emade-amazon.out file
*I've been experiencing a lag issue where running "conda install ..." simply hangs and does nothing in PACE. Perhaps it's on purpose and conda works differently on PACE.
*Planning to discuss issues with team during Monday VIP meeting

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook
|Completed
|November 1st, 2021
|November 8th, 2021
|November 8th, 2021
|-
|Attend Wednesday Intro Presentation
|Completed
|November 1st, 2021
|November 3rd, 2021
|November 3rd, 2021
|-
|Setup EMADE on PACE ICE
|In Progress (fixing runtime issue)
|November 1st, 2021
|November 8th, 2021
|
|-
|}

== Week 10: October 25th ==
=== Class Summary ===
*Final Presentation for Bootcamp
=== Lecture Notes ===
*Watched presentations from the different subteams in AAD:
**NLP
**NAS
**Image processing
**Modularity
*My team and I presented our work on the applying ML, MOGP, and EMADE on the Titanic dataset to not just our bootcamp, but also the returning VIP members
**We answered questions the issues we faced, including why we ran only so few generations
**We also explained how we could have improved our EMADE run by using a normalized fitness objective to better compare the AUC to ML and MOGP results.
**Discussed issues with our graphs and presentation
*'''Presentation Link:''' https://docs.google.com/presentation/d/1ShDz-7hPoor3ExWA9BKqiSzqn-G4ufgBYWor-mtlzdU/edit?usp=sharing
=== Individual Notes ===
*NLP team:
**Meets on Wednesdays at 2pm
**Goal is to make machines interpret and act upon natural langauge
**Applying BiDAF (bidirectional attention flow) and SQUAD dataset for their work
**Apply NAS to solve their problems
*NAS team:
**Meets Fridays at 2pm
**Goal is to improve EMADE's overall performance
**Working on improving training time for neural nets and changing EMADE primitives for valid connections
**Creating more tutorials/documentation for EMADE setup
*I had to leave early for a night class, so I wasn't able to watch the other VIP subteams present.

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook
|Completed
|October 25th, 2021
|November 1st, 2021
|November 1st, 2021
|-
|Present EMADE final presentation
|Completed
|October 25th, 2021
|October 25th, 2021
|October 25th, 2021
|-
|Rank subteam preference
|Completed
|October 25th, 2021
|November 1st, 2021
|October 31th, 2021
|-
|}


== Week 9: October 20th ==
=== Class Summary ===
*Working session with VIP AAD alumni to use EMADE on Titanic dataset
*VIP Alumni were able to able to help us resolve our issues with running EMADE locally and helped us shift our focus to running EMADE worker processes

=== Team Meeting Notes ===
*Team was able to successfully run worker processes on seperate computers while connected to MySQL database.
*Team struggled to understand why EMADE is running slow across master processes and worker processes
**Team was unable to get past 11 generations, after over 3 days of uptime on EMADE
*Team worked on creating final presentation on 10/25.

=== Individual Notes ===
*Before team meeting, I was successfully able to get EMADE running as a master process on my computer after switching from Python 3.9 to 3.8 to Conda 3.7
*During team meeting, I fixed my issue with connecting to the remote MySQL database after realizing the following:
**GT ethernet is NOT on the same network as eduroam - you MUST be on the same network as the MySQL database is on
**MySQL database must allow any type of host to connect to it, specified by a wildcard flag '%'

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook
|Completed
|October 20th, 2021
|October 25th, 2021
|October 25th, 2021
|-
|Team Meeting #1
|Completed
|October 20th, 2021
|October 24th, 2021
|October 24th, 2021
|-
|Run EMADE on Titanic Dataset
|Completed
|October 20th, 2021
|October 24th, 2021
|October 24th, 2021
|-
|Create EMADE final presentation
|Completed
|October 20th, 2021
|October 25th, 2021
|October 24th, 2021
|-
|}

== Week 8: October 13th ==
=== Class Summary ===
*Working session to get EMADE running on the Titanic dataset.
*Dr. Zutty was answering questions students were having regarding setting up MySQL and EMADE

=== Team Meeting Notes ===
*Team was successfully able to get EMADE to recognize/write to our MySQL database.
*Team is experiencing an issue where our fitness values for individuals are (inf, inf, inf)
*Team is also experiencing EMADE error stating "Tree missing valid primitive for data type"
*Discovered problem might have to do with the false positive and false negative evaluation functions defined in evalFunctions.py

=== Individual Notes ===
*Helped team create custom evaluation functions to find FPR and FNR.
*Discovered that splitting test CSV data shuffles columns in alphabetical order.
*Trying to figure out how to resolve issue with primitives in EMADE through Slack and team help.


=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook
|Completed
|October 13th, 2021
|October 20th, 2021
|October 20th, 2021
|-
|Team Meeting #1
|Completed
|October 13th, 2021
|October 16th, 2021
|October 16th, 2021
|-
|Run EMADE on Titanic Dataset
|In Progress
|October 13th, 2021
|October 20th, 2021
|N/A
|-
|}

== Week 7: October 6th == 

=== Class Summary ===
*Discussed preparing notebooks for midterm grading on 10/8
*Received introduction to EMADE and MySQL
*Notified of final presentation deadline October 25th

=== Lecture Notes ===
*Received introductory presentation to EMADE (Evolutionary Multi-Objective Algorithm Design Engine)
*EMADE "combines a multi-objective evolutionary search with high-level primitives to automate the process of designing machine learning algorithms"
*On startup, EMADE requires an input XML file to configure the following:
**Python application path
**MySQL Connection Information/Credentials
**Dataset paths
**Objective functions (available objectives can be found in "src/GPFramework/evalFunctions.py"
**Evaluation functions and workers per host
**Evolution Parameters
*Connecting worker process to peer can be specified using "python src/GPFramework/launchGTMOEP.py templates/input_titanic.xml -w"
*EMADE Output can be viewed on MySQL databases
*EMADE structure info:
**src/GPFramework is the core:
***gtMOEP.py is the main EMADE engine
***gp_framework_helper.py is where primitive set is built
**"datasets/" is where test datasets live
**"templates/" is where input files live

=== Team Meeting Notes ===
*Team members were all able to successfully install EMADE and MySQL on their laptops
*Configured input XML file for EMADE to run Titanic dataset
*Modified data splitter script to one-hot encode "Embarked" feature in dataset and to integrate team preprocessing steps used for MOGP assignment
*Currently experiencing issue where EMADE is unable to evaluate individuals in queue - keep getting "508 individuals left on queue" error. This is blocking our team from being able to run the evolutionary loop of EMADE.
=== Individual Notes ===
*Installed Anaconda and installed necessary dependencies for EMADE
*Successfully cloned and installed EMADE from GitHub
*Installed and setup MySQL on laptop
*Currently trying to find a fix issue with running EMADE and looking to ask Dr. Zutty for advice during 10/13 meeting.
**Personal suspicions are the we haven't properly configured the XML file with our python environment, but reading the output logs more carefully might point to the problem

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook
|Completed
|October 6th, 2021
|October 13th, 2021
|October 13th, 2021
|-
|Add Photos to Notebook for Midterm
|Completed
|October 6th, 2021
|October 8th, 2021
|October 8th, 2021
|-
|Review Lecture Notes
|Completed
|October 6th, 2021
|October 13th, 2021
|October 12th, 2021
|-
|Install EMADE and MySQL
|Completed
|October 6th, 2021
|October 13th, 2021
|October 12th, 2021
|-
|Team Meeting #1
|Completed
|October 6th, 2021
|October 12th, 2021
|October 12th, 2021
|-
|Run EMADE on Titanic Dataset
|In Progress
|October 6th, 2021
|October 13th, 2021
|N/A
|-
|}

== Week 6: September 29th ==
=== Class Summary === 
*Listened to team presentations on Titanic MOGP/ML project
*Presented Team 2's finding for MOGP/ML project
**Discussed the difference in ML models and GP individual results
**Discussed how we could have improved our models, including where models outperformed each other in certain fitness objectives
*Subteam #2 Presentation: https://docs.google.com/presentation/d/1E5DIPJOt7uBeqUeYklg6TE7X7PTdOsaFdUjTDCrttkU/edit?usp=sharing
*Our subteam realized that we could have implemented one-hot encoding for the 'Embarked' feature in our dataset, because mapping embarked locations to specific can cause undesired predictions within the model, reducing accuracy.

=== Lecture Notes ===
*It was interesting to see how other teams tried to "reward" individuals in their MOGP algorithm that didn't predict false/true in earlier generations. For instance, Austin's subteam squared their fitness values for their objective values to discourage a 1.0 fpr/fnr predictions from their individuals
*Some teams chose to use one-hot encoding for particular features in the dataset, which I think would have helped our team with the 'Embarked' feature

=== Individual Notes ===
*Completed VIP Peer Evaluation report due on Friday, October 8 @ 4pm
*Took notes on how to better select primitives and MOGP objectives for future projects

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook
|Completed
|September 29th, 2021
|October 6th, 2021
|October 6th, 2021
|-
|Peer Evaluations
|Completed
|September 29th, 2021
|October 8th, 2021
|October 6th, 2021
|-
|Review Lecture Notes
|Completed
|September 29th, 2021
|October 6th, 2021
|October 4th, 2021
|-
|}

== Week 5: September 22th ==
=== Class Summary ===
*Discussed last week's Titanic ML project and findings
*Given overview of Titanic MOGP task due next week
*Received presentation on how to give a presentation by Dr. Rohling
*Met with subteam members to schedule meetings for completing Titanic MOGP

===Lecture Notes===
*Learned how changing hyperparameters in ML models was crucial for creating the 5 co-dominant models for last week's assignment
**'''Important''': Changing model hyperparameters will affect the pareto optimality and fitness of an individual/solution
*Several teams noted having to fine-tune hyperparameters by trial-and-error in order to achieve co-dominance
*Dr. Zutty assigned every team to apply GP on the Titanic dataset problem for next class using the Lab 2 MOGP notebook as a template.
*Objective of using MOGP for Titanic was to see how objective results and AUC would compare to ML model results
*Constraints for the MOGP assignment included the following:
**Only basic primitives (add, subtract, multiply, etc.) and mathematical (sin, cos, tan, etc.) could be used
**Do not use tournament selection, instead research other selection methods such as SPEA2.
*Dr. Rohling gave a talk on how to present findings. Here were some takeaways:
**Make sure graphs are properly labeled, readable, and have relevant info
**Use page numbers in presentation so audience can ask questions
**Technical presentations are often stand-alone
**It is good practice to have take-away slides in presentation

===Team Meeting Notes===
*Organized times to meetup on Discord
*Meeting #1, Sept 25:
**Discussed and concluded that preprocessing step for MOGP would remain the same, as we were satisfied with our current features
**Discussed which primitives we would use - agreed on using subtract, add, multiply, sin, cos, and tan
**Researched different selection algorithms as a group and decided to use SPEA2
**Repurposed evaluation function from Lab 2 for evaluating both FPR and FNR objectives
**Learned about activation functions in order map any real number to either 0 or 1. Our team chose f(x) = arctan(x) / (pi / 2) as our function. We decided that if f(x) < 0.5 we would map the result to a 0, otherwise a 1.
*Meeting #2, Sept 26:
**Designed and wrote genetic loop for our MOGP algorithm
**Best individual is multiply(cos(add(subtract(Sex, Age), add(add(Sex, Sex), Parch))), Sex) with fitness (fpr, fnr) = (0.0, 0.37966101694915255) and pareto front AUC of about 0.125653
**Created presentation slides for our findings and results

[[files/mharbola3/titanic_mogp_fitness_graph.png|center|height=300px]]
[[files/mharbola3/titanic_mogp_pareto_front.png|center|height=300px]]

===Individual Notes===
*Wrote majority of genetic loop with help from team members on selection, mutation, and evaluation functions
*Originally our evaluation function was causing our best individual to always have fitness (0, 1.0). I discovered that even though fpr = fp / N and fnr = fn / P, our evaluation function was somehow not counting P and N properly. Therefore, I rewrote the evaluation function to calculate tp, tn, fp, and fn. We also decided to make fnr and/or fpr = 1 whenever the divisor was 0 to handle divide by 0 errors.
*Cleaned up genetic loop and refactored notebook cells after achieving satisfying individuals
*If I had more time, I would have repurposed the metrics calculations from Lab 2 to better visualize each generation in our genetic loop. Also, I would want to experiment with the mating and mutation rates in the notebook as well.

[[files/mharbola3/titanic_mogp_genetic_loop_1.png|center|height=300px]]
[[files/mharbola3/titanic_mogp_genetic_loop_2.png|center|height=300px]]

'''Team Presentation''': https://docs.google.com/presentation/d/1E5DIPJOt7uBeqUeYklg6TE7X7PTdOsaFdUjTDCrttkU/edit?usp=sharing
'''Team Prediction CSV''': https://drive.google.com/file/d/1KALnPrR3gzMZsj1A-MwHfa7Doa3NMw_l/view?usp=sharing

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook
|Completed
|September 22th, 2021
|September 29th, 2021
|September 29th, 2021
|-
|Review lecture slides
|Completed
|September 22th, 2021
|September 29th, 2021
|September 25th, 2021
|-
|Team Meeting #1
|Completed
|September 22th, 2021
|September 25th, 2021
|September 25th, 2021
|-
|Team Meeting #2
|Completed
|September 22th, 2021
|September 26th, 2021
|September 26th, 2021
|-
|Complete Titanic MOGP Notebook
|Completed
|September 22th, 2021
|September 29th, 2021
|September 29th, 2021
|-
|}

== Week 4: September 15th ==
===Class Summary===
*Assigned to Sub-teams
*Overview of Sci-kit learn and other ML-related libraries
*Titanic dataset discussion

===Lecture Notes===
*Received sub-team assignment based on GA
**Assigned to sub-team #2
*Introduced to Titanic Dataset on Kaggle
**Problem: Implement a model predicting if a passenger on the Titanic either survived or died. Create and document 5 separate co-dominant models in your subteam and generate a prediction csv file for each model.
**Codominance: Two algorithms are said to be codominance when neither dominates the other on every objective.
**Objectives for Titanic Dataset: False Positive Rate (FPR) and False Negative Rate (FNR)
*Reviewed preprocessing data notebook in Jupyter and learned how to adapt it for our training models
*Breakout into sub-teams for introductions and setting up team meetings.

===Team Meeting Notes===
*Organized Discord chat for communication, ideas, and meetings
*First meeting on Saturday, 9/18
*Repurposed preprocessing data notebook for assignment
*Selected features in training data relevant and correlated to survival
**Excluded following features: Name, PassengerID, Ticket Number, Fare
**Embarked feature was kept because we noticed a strong visual correlation between embarked location and male and female passengers' survival in training data. This makes sense as passengers who embarked earlier would have more cabin choices.
*Used average age and embarked values to fill in NaN age and embarked data
*Experimented with different classifier models to minimize FPR and FNR.
*Used the following different models:
**RandomForestClassifier (Manas) - Parameters: n_estimators=100, max_depth=5, min_samples_leaf=5, criterion=entropy, random_state=2; FP=18, FN=29
**DecisionTreeClassifier (Rohan) - Parameters: min_samples_leaf=30; FP=9, FN=45
**MLP Classifier (Adithya) - Parameters: default args; FP=26, FN=26
**SVM (Yisu) - Parameters: kernel = sigmoid; FP=0, FN=104
**AdaBoostClassifier (Aditya) - Parameters: default; FP=32, FN=21
*'''Important Observation:''' In order to achieve co-dominance, hyperparameters for certain models had to be purposefully manipulate to either lower FNR/raise FPR or vice versa.
===Individual Notes===
*Researched common models used for classification and chose RandomForestClassifier
*Researched on SciKit-learn, StackOverflow and Medium articles how to select appropriate parameter values for model
*Achieved approx. 84% accuracy with model with relatively low FPR and FNR
*Added code to generate prediction CSVs for everybody's model
*Added cells for plotting model performance on FPR/FNR axis to demonstrate co-dominance.

[[files/mharbola3/titanic_ml_pareto_front.png|center|height=300px]]

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook
|Completed
|September 15th, 2021
|September 22th, 2021
|September 22th, 2021
|-
|Review lecture slides
|Completed
|September 15th, 2021
|September 22th, 2021
|September 18th, 2021
|-
|Team Meeting #1
|Completed
|September 15th, 2021
|September 22th, 2021
|September 18th, 2021
|-
|Team Meeting #2
|Completed
|September 15th, 2021
|September 22th, 2021
|September 19th, 2021
|-
|Complete Notebook and Submit prediction csv
|Completed
|September 15th, 2021
|September 22th, 2021
|September 19th, 2021
|-
|}

== Week 3: September 8th ==
=== Self-Evaluation Rubric ===
https://drive.google.com/file/d/1Pf-QiG10gAFf0VANSVCnFhZwgSxYGQd5/view?usp=sharing

===Class Summary===
* Intro to Multiple Objectives (MO) in Genetic Algorithms/Programming
* Intro to Pareto Optimality

===Team Meeting Notes===
*What to look for in algorithms:
**Scalability, Reliability, Accuracy, Efficiency, Consistency
*How are Genome evaluated?
**Evaluation of a genome associates a genome/individual (set of parameters for GA or string for GP) with a set of scores.
*What are the possible scores?
**True Positive (TP): How often we are identifying the desired object
**False Positive (FP): How often are we identifying something else as the desired object
*What are Objectives?
**Set of measurements each genome (or individual) is scored against
**Phenotype
*Objective Space: Set of objectives
*Evaluation: Maps an genome/individual
**From a location in search
*** Genotypic description
**To a location in objective space
*** Phenotype description
*Classification Measures
**Data Set (Positive (P) and Negative (N) samples) -> Classifier -> Confusion Matrix

{| class="wikitable"
|+Confusion Matrix
|-
|
|Predicted: Positive
|Predicted: Negative
|-
|Actual Positive (P)
|True Positive (TP)
|False Negative (FN), type II error
|-
|Actual Negative (N)
|False Positive (FP), type I error
|True Negative (TN)
|}

*'''Maximization Measures'''
**Sensitivity or True Positive Rate (TPR):
***AKA hit rate or recall
***TPR = TP/P = TP/(TP + FN)
**Specificity (SPC) or True Negative Rate (TNR):
***TNR = TN/N = TN/(TN + FP)
**We want both TPR and TNR to be as close to 1 as possible

*'''Minimization Measures'''
**False Negative Rate (FNR)
***FNR = FN/P = FN/(TP + FN)
***FNR = 1 - TPR
**Fallout or False Positive Rate
***FPR = FP/N = TN/(FP + TN)
***FPR = 1 - TNR = 1 - SPC

*'''Other Important Measures'''
**Precision or Positive Predictive Value (PPV)
***PPV = TP / (TP + FP)
***Bigger is better
**False Discovery Rate
***FDR = FP/(TP + FP)
***FDR = 1 - PPV
***Smaller is better
**Negative Predictive Value (NPV)
***NPV = TN/(TN + FN)
***Bigger is better
**Accuracy (ACC)
***ACC = (TP + TN)/(P + N)
***ACC = (TP + TN)/(TP + FP + FN + TN)
***Bigger is better

*'''Objective Space'''
**Individuals are evaluated using objective functions
***Mean Squared Error
***Cost
***Complexity
***True positive rate
***False positive rate
***Etc...
**'''Objective scores''' give each individual a point in '''objective space'''
**This may be referred to as the '''phenotype''' of the individual

*'''Pareto Optimality'''
**An individual is '''Pareto Optimal''' if there is no other individual in the population that outperforms the individual on all objectives
**'''Pareto frontier''': set of all Pareto individuals
**Pareto optimal individuals represent unique contributions
**We drive selection by favoring Pareto individuals, but main diversity by giving all individuals some probability of mating

*'''Nondominated Sorting Genetic Algorithm II (NSGA II)'''
**Population is separated into nondomination ranks
**Individuals are selected using a binary tournament
**Lower Pareto ranks beat high Pareto ranks
**Ties on the same front are broken by '''crowding distance''', the summation of normalized Euclidean distances to all points within the front
***Higher crowding distance wins

*'''Strength Pareto Evolutionary Algorithm 2 (SPEA2)'''
**Each individual is given a strength '''S''', how many others it dominates in the population
**Each individual receives rank '''R''', sum of S's of the individuals that dominate it
***Pareto individuals are nondominated and receive an R of 0
**Distance to the kth nearest neighbor (omega^k) is calculated and a fitness of R + 1/(omega^k + 2) is obtained

===Lab 2: Symbolic Regression (Part 2)===
*I followed the instructions in the notebook and plotted the Pareto frontier
*Our goal is to minimize the AUC because we want to minimize the tree size of the Pareto individuals and as well as their mean squared error.
*'''AUC with original configuration''': 2.3841416372199005
*Best individual was negative(cos(multiply(add(cos(sin(cos(sin(cos(tan(x)))))), cos(x)), tan(x)))), with fitness (0.2786133308027132, 15.0)
*Experiments conducted to reduce AUC by at least 25%:
**Remove sin and cos from primitives:
***AUC: 1.0884023352769998 (approx. 54% reduction)
***Best individual: subtract(multiply(x, tan(multiply(x, x))), x), with fitness (0.6669255057183378, 8.0)
**Remove sin, cos, and tan from primitives:
***AUC: 0.6912744703006891 (approx. 71.01% reduction)
***Best Individual: subtract(x, x), with fitness (0.7223441838209306, 3.0)

[[files/mharbola3/lab2_mogp_objective_space.png|center|height=300px]]
[[files/mharbola3/lab2_mogp_fitness_graph.png|center|height=300px]]
[[files/mharbola3/lab2_mogp_pareto_front.png|center|height=300px]]

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook
|Completed
|September 8th, 2021
|September 15th, 2021
|September 14th, 2021
|- 
|Complete Self-Evaluation rubric
|Completed
|September 8th, 2021
|September 15th, 2021
|September 13th, 2021
|-
|Review lecture slides
|Completed
|September 8th, 2021
|September 15th, 2021
|September 14th, 2021
|-
|Finish Lab 2, Part 2
|Completed
|September 8th, 2021
|September 15th, 2021
|September 14th, 2021
|}

== Week 2: September 1st ==

=== Class Summary===

* Intro/Overview of Genetic Programming
* Representing programs as Tree Structures
* Crossover/Mutation in Genetic Programming
* Symbolic Regression

=== Team Meeting Notes ===
* Conducted brief review of last week's lecture on Genetic Algorithms
* Genetic Algorithms are a population-based solution, using concepts such as natural selection and properties of DNA to exchange/modify information between individuals
* '''Genetic Algorithms''' have an evaluator function to obtain objective scores on individuals, whereas in '''Genetic Programming''', the individuals are the function themselves.

* A way to represent program structure in Genetic Programming is to use a '''Tree Representation'''.
** '''Nodes''' are called '''primitives''' represent functions
** '''Leaves''' are called '''terminals''' and represent parameters
*** Input can be thought as a particular type of terminal
*** Output is produced at root of tree

* Trees are stored by converting them to a '''lisp preordered parse tree'''.
** Operators are followed by inputs
** For example, the tree for '''f(x) = 3*4+1''' can be written as '''[+,*,3,4,1,]'''
** Parse tree of '''f(x) = 2-(0+1)''' is '''[-,2,+,0,1]'''

[[files/TreeRepresentation1.png]]

* Crossovers in GP are handled by simply exchanging subtrees
** Start by randomly picking a point in each tree
** These points and everything below create subtrees
** Subtrees are exchanged to produce children

* Mutations in GP can involve:
** Inserting a node or subtree
** Deleting a node or subtree
** Changing a node

* Symbolic Regression
** Using simple primitives, we can use GP to evolve a solution to '''y=sin(x)'''
** Primitives include: '''+, *, -, /'''
** Terminals include integers and variable input '''X'''
** Calculus uses Taylor Series to approach this problem

* Evaluating a Tree
** Feed inputs into function to get outputs
** Run '''f(x)''' to get result
** Measure error between output of '''f(x)''' and expected output - for instance, we can use sum square error for the y=sin(x) situation

* Primitives that could make evolution easier:
** Power(), Factorial(), Sin(), Cos(), Tan()
** '''Main Idea behind EMADE'''

===Lab 2: Symbolic Regression (Part 1)===
In this lab, I ran the evolutionary algorithm several times to observe the improves in best fit individuals. Here are the following results

'''First try, no modifications:'''
*Best individual was add(add(multiply(x, add(x, subtract(x, x))), multiply(x, multiply(add(x, multiply(x, x)), x))), x), (1.0195405384704813e-16,)

[[files/mharbola3/lab2_sogp_first_try.png|center|height=300px]]

'''Second try, add primitives:'''
*Added primitives were ''np.square'' and ''np.absolute''
*Best individual was add(add(multiply(absolute(absolute(absolute(add(multiply(square(x), x), square(x))))), x), square(absolute(x))), x), (8.620776339403237e-17,)

[[files/mharbola3/lab2_sogp_second_try.png|center|height=300px]]

'''Third try, add mutations, no primitives:'''
*Added mutation was ''mutShrink''
*Best individual is add(x, multiply(x, add(multiply(x, x), add(multiply(multiply(x, x), x), x)))), (1.1608501979530989e-16,)

[[files/mharbola3/lab2_sogp_third_try.png|center|height=300px]]

'''Fourth try, added primitives and mutation:'''
*Best individual is Best individual is add(add(multiply(add(x, multiply(x, x)), x), multiply(x, multiply(multiply(x, x), x))), x), (9.846703645016068e-17,)

[[files/mharbola3/lab2_sogp_fourth_try.png|center|height=300px]]

===Actions Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebook
|Completed
|September 1st, 2021
|September 8th, 2021
|September 8th, 2021
|- 
|Review Genetic Programming Slides
|Completed
|September 1st, 2021
|September 8th, 2021
|September 3rd, 2021
|-
|Finish Lab 2, Part 1
|Completed
|September 1st, 2021
|September 8th, 2021
|September 7th, 2021
|}

== Week 1: August 25th ==

=== Class Summary ===

* Intro to Automated Algorithm Design, Wiki, Syllabus, Notebooks
* Introductory lecture to Genetic Algorithms
* One Max Problem discussion

=== Team Meeting Notes ===

* Genetic Algorithms
** With '''genetic algorithms''', each new generation is created through '''mating/mutation''' of '''individuals''' in the previous population  
** Fitness evaluation is done through the Fitness Proportionate (randomization) or Tournament
** Fitness evaluation occurs before mating/mutation
** Goal is to produce individual best fit for selected task after several generations

* Important Keywords
** '''Individual:''' One specific candidate in the population (with properties such as DNA). The individual is usually intended as a solution to a problem
** '''Population:''' Group of individuals/solutions whose properties will be altered
** '''Objective:''' Value used to characterize individuals that you are trying to maximize or minimize (usually the goal is to increase objective through the evolutionary algorithm)
** '''Fitness:''' Relative comparison to other individuals of the population; how well does the individual accomplish a task relative to rest of population?
** '''Evaluation:''' Function that computes the objective of an individual
** '''Selection:''' Represents â€˜survival of the fittest'; gives preference to better individuals, therefore allowing them to pass on their genes
*** '''Fitness Proportionate:''' Higher the fitness value, the higher the probability of being selected for mating.
*** '''Tournament:''' Several tournament style (number of individuals in each tournament is dependent on tournament size); Winners are selected for mating
** '''Mate/Crossover:''' Represents mating between individuals.
** '''Mutate:''' Introduce random modification; purpose is to maintain diversity

===Lab 1: Genetic Algorithms with DEAP===

'''One Max problem:''' Simple genetic algorithm problem with the objective of finding a bit string containing all 1s with a set length. The following steps were followed for this lab:
* Import base, creator, tools from DEAP module and python random module
* Define fitness objective and individual classes using DEAP's creator
* Define individuals in population as booleans represented as 1s and 0s
* Define evaluation function for fitness objective as sum of all 1s in bit string
* For 40 generations, select the offspring for next generation, perform tournament selection, mate, and mutate
* '''Observations:''' Maximum fitness score was almost always achieved after 40 generations, although it wasn't guaranteed. However, the maximum fitness score by the 40th generation was always between 97.0-100.0.

[[files/mharbola3/lab1_onemax_fitness_graph.png|center|height=300px]]

'''N Queens Problem:''' Objective is to determine a configuration of n queens on a nxn chessboard such that no queen can be taken by another. For this version, each queen is assigned to one column and only one queen can be on each line. The following steps were followed for this lab:
* Import necessary DEAP modules
* Define fitness and individual classes as well as fitness objective and evaluation function
* Fitness objective is to minimize the number of conflicts between two queens on nxn chessboard
* Individual is defined as a list of n numbers denoting the column location of n queens in nxn chessboard
* Evaluation function returns number of conflicts between queens along diagonal of chessboard
* Define partially matched crossover function and mutate function to shuffle indices
* Run main evolutionary loop for 100 generations
* Algorithm doesn't consistently achieve minimum of 0.0 but gets consistently close to it

[[files/mharbola3/lab1_n_queens_fitness_graph.png|center|height=300px]]

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|DEAP library setup/installation on Python
|Completed
|August 25th, 2021
|September 1st, 2021
|August 25th, 2021
|-
|Start Notebook
|Completed
|August 25th, 2021
|September 1st, 2021
|September 1th, 2021
|- 
|Review Genetic Algorithms Slides
|Completed
|August 25th, 2021
|September 1st, 2021
|August 31th, 2021
|-
|Finish Lab 1
|Completed
|August 25th, 2021
|September 1st, 2021
|August 31th, 2021
|}