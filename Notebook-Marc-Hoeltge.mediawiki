== About Me ==
Name: Marc Hoeltge

Email: marc.hoeltge@gatech.edu

Phone: (973) 615-2330

Major: Computer Science, Intel/Info, Graduating in 2022

== December 2, 2019 ==

=== Team Meeting Notes ===
* Did our final presentation
* Ran EMADE for several hours across different computers 
*I ran the normal installation of EMADE because I couldn't get the preprocessing branch working; there was still a python error that I wasn't able to debug
*I made the pareto front visualization code, included below, in order to compare the performance of the preprocessing branch and the normal EMADE
<blockquote>plt.scatter(fp, fn, color='b')</blockquote><blockquote>plt.scatter(fp, fn, color='r')</blockquote><blockquote>plt.plot(fitness_1, fitness_2, color='r', drawstyle='steps-pre')</blockquote><blockquote>plt.xlabel("false positives")</blockquote><blockquote>plt.ylabel("false negatives")</blockquote><blockquote>plt.title("Pareto Front")</blockquote><blockquote>plt.show()</blockquote><blockquote>f1 = np.array(fp)</blockquote><blockquote>f2 = np.array(fn)</blockquote><blockquote>"""Calculate area under curve with least squares method"""</blockquote><blockquote>print("Area Under Curve: %s" % (np.sum(np.abs(np.diff(f1))*f2[:-1])))```</blockquote>

(This code was mostly adapted from the Lab 2 on the EMADE github page.)

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Final Presentation
|In Progress
|Nov 4, 2019
|Dec 2, 2019
|Dec 2, 2019
|-
|Peer Evals
|In Progress
|Nov 25, 2019
|Dec 4, 2019
|Dec 2, 2019
|}

== November 25, 2019 ==

=== Team Meeting Notes ===
* Unfortunately,some of how we approached getting image data and working with it were incorrect
** We were planning on using the Keras function as a primitive in order to manipulate data, but turns out that that will be run on ever generation with EMADE possibly, so data will bloat in size immensely
** Have to instead do preprocessing as a function before EMADE in order to expand the dataset just 1 time
** Our primitive probably will not work due to this
* Finally got EMADE working on my own computer
** Problem in the past was that I didn't have a root account in mySQL with a password, and I couldn't find a way to set no password with EMADE
** Solution: I flushed all privileges in MariaDB, (what I have for mySQL) and then set up the root account with a password of password
*** Now EMADE finally works, at least the main branch
*** Still some issues with getting the subteam branch working related to Python imports it seems.

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Final Presentation
|In Progress
|Nov 4, 2019
|Dec 2, 2019
|
|-
|Peer Evals
|In Progress
|Nov 25, 2019
|Dec 4, 2019
|
|-
|Get EMADE main branch working
|Completed
|Nov 18, 2019
|Nov 25, 2019
|Nov 23, 2019
|-
|Get EMADE subbranch working 
|In Progress
|Oct 2, 2019
|Oct 9, 2019
|Oct 7, 2019
|}

== November 18, 2019 ==

=== Team Meeting Notes ===
* Met with Austin to see how image data can be used in EMADE
** From the source tree, most of what we want to implement will be done using the functions found inside of spatial_methods.py
** Some other things can be found in signal_methods.py, but probably not as relevant
** Austin himself worked on many of the methods relating to image data
** He talked to us about image data, and spoke more about the EMADE datapair that we were looking at
*** We have several options for how to deal with it, can do things like load images as one list and truth data as another
* Created a primitive using Keras in order to do many of the image preprocessing commonly done and expand the dataset. (Code is below)
** Based most of the code on the unit tests already present in src/UnitTests/spatial_methods_unit_test.py
** cannot test the code yet until we create the working primitive in the spatial_methods.py file 
** The preprocessing primitive is based on the Keras function, [https://keras.io/preprocessing/image/]
Code for the primitive: <blockquote>def test_keras_preprocessing(self):</blockquote><blockquote>print("keras_preprocessing")</blockquote><blockquote>result = sp.keras_preprocessing(self.image_data, STREAM_TO_STREAM)</blockquote><blockquote>self.assertIsInstance(result, data.EmadeDataPair)</blockquote>

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Learn more about image data in EMADE
|In Progress
|Nov 4, 2019
|Nov 18, 2019
|
|-
|Create a primitive 
|Completed
|Nov 11, 2019
|Nov 18, 2019
|Nov 15, 2019
|}

== November 11, 2019 ==

=== Team Meeting Notes ===
* Have to learn what image data in EMADE is loaded as, and how it is used.
* Based on looking through the EMADE source code, it looks like image data is loaded as an EMADE datapair, with one part being the images and the other part being the truth data
* looked into what Anika did last semester to see how some data preprocessing works for feature data and try and figure out how to translate it to image data
** Anika used a lot of unit tests in order to get her code working and see that it was functioning before running in EMADE, so that should be our goal as well

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Learn more about image data in EMADE
|In Progress
|Nov 4, 2019
|Nov 18, 2019
|
|-
|Git clone subteam branch and checkout into it
|Completed
|Nov 8, 2019
|Nov 11, 2019
|Nov 9, 2019
|}

== November 4, 2019 ==

=== Team Meeting Notes ===
* Discussed what the goals are for the rest of the semester
** Anika has previously done work with feature data, but we want to branch into image data or stream data
** Decided to go with image data because I at least have some experience with it, and me and Ford don't know what stream data entails
** Unfortunately our group doesn't have much Python experience so we will have to learn many of the good practices

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Join subteam GroupMe
|Completed
|Oct 28, 2019
|Nov 4, 2019
|Nov 4, 2019
|-
|Decide on a type of data to tackle
|Completed
|Oct 28, 2019
|Nov 4, 2019
|Nov 1, 2019
|}

== October 28, 2019 ==

=== Team Meeting Notes ===
* Joined subteams, talked to some of the members to find out more about what they do and what we will be tackling for the rest of the semester.
* Chose to join the data preprocessing group because I have worked in a lot of data manipulation in the past, so I have experience with libraries like Pillow

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Join a subteam
|Completed
|Oct 28, 2019
|Oct 28, 2019
|Oct 28, 2019
|}

== October 21, 2019 ==

=== Team Meeting Notes ===
* Finished presentation for the Titanic dataset in EMADE
* Managed to get EMADE working on my computer. Got around the issue of fixing mySQL on my computer because I can just use Hemang's credentials since he is the master
* Got Amazon AWS credit via the VIP link and used to create another server with EMADE installed and able to be used as a worker computer

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get EMADE running and have someone designated as the master
|Completed
|Oct 9, 2019
|Oct 21, 2019
|Oct 18, 2019
|-
|Create an AWS instance and install EMADE on it
|Completed
|Oct 16, 2019
|Oct 21, 2019
|Oct 18, 2019
|}

== October 16, 2019 ==

=== Team Meeting Notes ===
* Worked in groups because presentation will be next week over our findings of the Titanic dataset with EMADE
* Couldn't get a master computer working on the cloud, so instead we will just host it from one of our laptops
* I couldn't get EMADE running due to issues with the mySQL installation on my computer
* We can possibly use an AWS server as a worker so we can get more generations

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get EMADE running and have someone designated as the master
|In Progress
|Oct 9, 2019
|Oct 21, 2019
|
|-
|Install emade and git LFS
|Completed
|Oct 2, 2019
|Oct 9, 2019
|Oct 7, 2019
|}

== October 9, 2019 ==

=== Team Meeting Notes ===
* Had Austin go over the basics of EMADE and show us some of the things we need to get it running, like the xml file.
* EMADE already has a Titanic dataset, so we are tasked with loading that on our own computers and attempting to get results for it.
* have to get mySQL working and decide as a group who is going to have the master and who will just be workers.

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get EMADE running and have someone designated as the master
|In Progress
|Oct 9, 2019
|Oct 21, 2019
|
|-
|Install emade and git LFS
|Completed
|Oct 2, 2019
|Oct 9, 2019
|Oct 7, 2019
|}

== October 2, 2019 ==

=== Team Meeting Notes ===
* Presented our findings on the Titanic Problem using MOGP.
** Many groups (ours included) created our solutions to the problems through the use of MuPlusLamda, but it would have been beneficial to try making our own GP algorithm
** Just like our group, many groups did not try using strongly typed GP nor use things like AND, OR, and NOT.
* My mutation function testing from the previous week would have benefitted from not using MuPlusLambda 
** For my testing, I was only able to test using 1 mutation function at a time. Had we created our own GP algorithm, then I would have been able to try using more than 1 mutation function, and even give them different weights.

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update notebook for Oct 2 (evals on Friday!)
|Completed
|Oct 2, 2019
|Oct 9, 2019
|Oct 3, 2019
|-
|Peer Evals
|Completed 
|Sep 30, 2019
|Oct 4, 2019
|Oct 2, 2019
|-
|Install emade and git LFS
|In Progress 
|Oct 2, 2019
|Oct 9, 2019
|
|}

== September 25, 2019 ==

=== Team Meeting Notes ===
* Got assigned as groups to make a genetic programming solution to the Titanic problem from 2 weeks ago
* Have to present the pareto front and turn in a CSV for 100 individuals

=== Titanic Problem (This time with MOGP) ===
* Found that the NSGA2 method was the best for a selection format
** The tournament selection mode performed with about .2 greater area under the curve than NSGA2
* I personally tested out many of the different mutation functions provided under deap.gp()
** see the slide below for my findings 
** tests were done with the same random seed (25) and 100 children, of which 50 were selected
** tests were just to determine the best overall mutation method which we would then combine with the rest of our findings to produce a final result
* I also created the code to export the project as a CSV:
[[files/Titanic MOGP Mutations findings.png|thumb|Results of my tests from trying out many of the mutation functions DEAP has to provide.]]
<blockquote><code>survival_df = pd.DataFrame(index=X_test.index)</code></blockquote><blockquote><code>for num, ind in enumerate(pop):</code></blockquote><blockquote>    <code>func = gp.compile(expr=ind, pset=pset)</code></blockquote><blockquote>    <code>y_pred = []</code></blockquote><blockquote>    <code>for i, x in X_test.iterrows():</code></blockquote><blockquote>        <code>res = func(*x.values.tolist())</code></blockquote><blockquote>        <code>if res > 0:</code></blockquote><blockquote>            <code>y_pred += [1]</code></blockquote><blockquote>        <code>else:</code></blockquote><blockquote>            <code>y_pred += [0]</code></blockquote><blockquote>            </blockquote><blockquote>    <code>sn = 'S' + str(num + 1)</code></blockquote><blockquote>    <code>#print(y_pred)</code></blockquote><blockquote>    <code>survival_df[sn] = y_pred</code></blockquote><blockquote>    <code>num += 1</code></blockquote><blockquote>    </blockquote><blockquote><code>print(survival_df)</code></blockquote><blockquote><code>survival_df.to_csv('GP Titanic Survival.csv', header=True, sep=',')</code></blockquote>

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update notebook for Sep 25 (evals this week!)
|Completed
|Sep 25, 2019
|Oct 2, 2019
|Oct 2, 2019
|-
|Complete MOGP for the Titanic problem
|Completed 
|Sep 25, 2019
|Oct 2, 2019
|Oct 1, 2019
|-
|Help complete the presentation for our group
|Completed
|Sep 25, 2019
|Oct 2, 2019
|Oct 2, 2019
|-
|Complete peer evals
|In Progress
|Sep 30, 2019
|Oct 4, 2019
| 
|}

== September 18, 2019 ==

=== Team Meeting Notes ===
* Did presentations on our findings from the previous week
* Whitening and Vectorization are methods to improve a dataset before use in a ML algorithm
* no work to be done this week; we get a break

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update notebook for Sep 18
|Completed
|Sep 18, 2019
|Sep 25, 2019
|Oct 2, 2019
|-
|Submit predictions to canvas
|Completed 
|Sep 18, 2019
|Sep 25, 2019
|Sep 25, 2019
|}

== September 11, 2019 ==

=== Team Meeting Notes ===
* Did an introduction to actual machine learning using SKLearn and Pandas
* Broke up into groups and got assigned the Titanic problem at Kaggle
[[files/Ada Boost Confusion Matrix.png|thumb|The confusion matrix from the Ada Boost Classifier I fit to the Titanic dataset.]]

=== Titanic Problem ===
* Explored fitting models onto data using sklearn
* also learned to extract relevant data from a large dataset
** the Titanic dataset had many irrelevant parts like name, and a lot of data was more relevant than others
* I personally fitted a model to the data using the Ada Boost Classifier from sklearn. [https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html]
** I found it to be codominant with the Random Forest Classifier 
*** It performed better because it had less false negatives, but it ended up having more false positives
** Commit from my changes: [https://github.com/HemangRajvanshy/Bootcamp_team5/commit/17f7ec3ddf8fac3bf58669b70d6c84e652fb897d]

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update notebook for Sep 11
|Completed
|Sep 11, 2019
|Sep 19, 2019
|Sep 18, 2019
|-
|Find a codominant classifier for the Titanic problem
|Completed 
|Sep 11, 2019
|Sep 19, 2019
|Sep 18, 2019
|-
|Help complete the presentation for our group
|Completed
|Sep 11, 2019
|Sep 19, 2019
|Sep 18, 2019
|}

== September 4, 2019 ==

=== Team Meeting Notes ===
* Discussed many of the things that you want to optimize using genetic programming
** Space efficiency
** Minimizing misclassificiation
*** more true positives
*** less false positives
** Time efficiency
** Security
** Usability
** Cost-effectiveness
** Power consumption
* Pareto optimal individuals are ones that are the most fit in a certain category that you are optimizing for.
* Took notes on the "Confusion Matrix" 
** provides a way to score individuals based on their positives and negative classifications
** see picture
[[files/Confusion Matrix Marc Hoeltge.png|none|thumb|Notes from the lecture about the confusion matrix, sensitivity, specificity, and accuracy]]

=== Multi-Objective Genetic Programming (Second half of lab 2) ===
* Now, we are optimizing for multiple variables in our genetic programming.
* We want both a low squared error, as well as a low length for the functions so they don't get out of control.
* also made the function much harder to optimize for, in order to increase the length of time that it will take to get it using evolution
[[files/New function lab 2 marc hoeltge.png|thumb|The new function that we are optimizing for. This also takes into account the length so we can optimize for two things at once.]]
* used the pareto-optimal individuals in order to show the best individuals and see how the function improves with each generation
[[files/Lab 2 pareto optimal marc hoeltge.png|none|thumb|A graph showing the pareto optimal individuals in lab 2.]]

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update notebook for Sep 4
|Completed
|Sep 4, 2019
|Sep 11, 2019
|Sep 10, 2019
|-
|Fix notebook formatting (images)
|Completed
|Sep 4, 2019
|Sep 11, 2019
|Sep 10, 2019
|-
|Complete the second half of lab 2
|Completed* 
|Sep 4, 2019
|Sep 11, 2019
|Sep 10, 2019
|}
<nowiki>*</nowiki> didn't figure out how to make a more optimal function. Will continue later.

== August 28, 2019 ==

=== Team Meeting Notes ===
* Learned about a new type of genetic algorithm - genetic programming with functions
** In this, you attempt to use primitives to model a function
** the computer will use error approximations to determine how close it is to the correct answer, and continually produce new generations of functions that get closer and closer
* the nodes are called primitives and represent the functions. Leaves of the tree are called the terminals, or outputs
* When listing out the tree, parse it using a preordered method
* Possible mutations to a tree include inserting a node or subtree, deleting a node or subtree, and changing terminals in it
* To evaluate a tree, test it on multiple inputs and measure the error between the outputs and the known true answer. 
** For example, you can measure the fitness of a tree set to model the sin() function by measuring the error and comparing it to other individuals
[[files/Marc hoeltge crossover in genetic programming.png|thumb|Notes from the team meeting on how crossovers work in genetic programming with functions|none]]

=== Symbolic Regression (First half of Lab 2): ===
* Followed the Jupyter Notebook for lab 2 in order to experiment with genetic programming in relation to functions[[files/Marc hoeltge lab 2 part 1 added primitives.png|thumb|The two primitives that I used in my function in addition to the ones already there. They were initially pow() and mod(), but those presented problems.]]Unlike the first lab, here we are trying out different functions against each other and attempting to find the one that fits the best and gets the least error
* Implemented my own functions, as well as a mutation function
** Initially, when testing out using the mod() and pow() functions from numpy, the function came across a divide by 0 error, and many individuals were not being measured correctly. I changed it to use the sin() and floor() functions instead to avoid this issue.
** Using the source code at https://github.com/DEAP/deap/blob/master/deap/gp.py, I chose to include the mutInsert() function as an additional way to mutate individuals 20 percent of the time in order to add more randomness and possibly better results, as well as to get practice with using the functions already existing in DEAP
[[files/Marc hoeltge lab 2 part 1 results.png|thumb|The results from running the symbolic regression in lab 2 while using my primitives as well as mutInsert(). Since the fitness is measured by the error between the function and the true answer, it is a good thing that it approaches 0 as there are more and more generations.|none]]

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update notebook for Aug 28
|Completed
|Aug 28, 2019
|Sep 4, 2019
|Sep 4, 2019
|-
|Complete the first half of lab 2
|Completed 
|Aug 21, 2019
|Sep 4, 2019
|Sep 2, 2019
|}
== August 22, 2019 ==
=== Team Meeting Notes ===
==== Some Genetic Algorithm Keywords ====

* Individual
:- One specific candidate with DNA

* Population
:- Group of individuals whose properties will be altered

* Objective
:- Goal to maximize

* Fitness
:- Performance relative to other individuals

* Ways of selection
:- Fitness Proportionate: the greater the fitness, the higher the chance of passing on traits
:- Tournament: winners in a tournament get to mate

* Crossover 
:- mating between individuals, can either be single or multi-point

* Mutate
:- use random changes to introduce variability

==== One Max Problem ====
* Begin with individuals, each with 100 binary values
* The goal is to get the maximum sum
:- The minimum value is 0
:- The maximum value is 100
* Over time and generations, you approach the goal through breeding between individuals

==== N-Queens Problem (Lab 1): ====
* Followed the steps in the Jupyter Notebook for lab 1 in order to produce a genetic algorithm to determine solutions to the N-Queens problem. 
* Implemented a simple mutation function of my own that randomly swapped 2 of the places of the queens, 20 percent of the time. Code is pictured on the right.
[[files/Marc hoeltge n queens.png|thumb|The results of the N-Queens problem in Lab 2 with my mutation function.|none]]

[[files/Marc hoeltge lab 1 mutations.png|thumb|my mutation function for lab 1 to swap 2 indices of queens in a mutant 20 percent of the time.]]

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Start notebook
|Completed
|Aug 21, 2019
|Aug 28, 2019
|Aug 27, 2019
|-
|Join Slack
|Completed 
|Aug 21, 2019
|Aug 27, 2019
|Aug 24, 2019
|-
|Install Anaconda and Other ML Libraries 
|Completed
|Aug 21, 2019
|Aug 27, 2019
|Aug 25, 2019
|-
|Setup [https://jupyter.org/install Jupyter Notebook] and [https://deap.readthedocs.io/en/master/installation.html DEAP]
|Completed
|Aug 21, 2019
|Aug 28, 2019
|Aug 28, 2019
|-
|Complete Lab 1 
|Completed
|Aug 21, 2019
|Aug 28, 2019
|Aug 28, 2019
|}