== General Information ==
Team member: Nesha Prabahar

Year: Sophomore

Major: Computer Science

Email: neshaprabahar@gatech.edu

== Last Presentation Day: 2 December 2019 ==
Github:  https://github.gatech.edu/emade/emade

Presentation: https://docs.google.com/presentation/d/1KPcNsmbxPipkDncRDKeScHZCRR71gXoDNyumCGimTVc/edit?usp=sharing
* Text Classification Progress: 
** Stemming
** Lemmatisation 
* Text Summarisation
** Integrating into EMADE.
** Padding - 255 sentences each
** Created three new primitives to help in classification - first semesters
*** Tsisf - determining how often a term appears in context to the sentence 
*** text_rank
*** number of named entities
** Result: didn't finish running / timeout 
* Personal Contribution post midterm
** Wrote a primitive to help analyse the importance of sentences 
*** Read several articles to understand the functions (important ones linked in the weeks)
** Presented the primitive and how it works and assigns values to sentences  [[files/Screenshot 2019-12-04 at 4.05.07 AM.png|center|thumb|400x400px|Presentation Slides]][[files/Screenshot 2019-12-04 at 4.05.14 AM.png|center|thumb|401x401px|Presentation Slides]]

== Week 15: 25 November - 1 December 2019 ==

=== Team Meeting: ===
* Start adding slides to the presentation 
* Push the changes to github

=== Sub Team Personal Notes ===
* I finished up the primitive on Monday 
* Tushna had access to the repo and pushed the final primitve
* Changes were made to the loop later 
* Get started on slides 

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish the primitive
|Completed
|November 4, 2019
|November 26, 2019
|November 24, 2019
|-
|Push the code 
|Completed
|November 25, 2019
|November 25, 2019
|November 25, 2019
|-
|Finish the slides for the presentation
|Completed
|November 25, 2019
|December 2, 2019
|December 1, 2019
|-
|Finish Peer Evals
|Completed
|November 14, 2019
|December 4, 2019 
|December 1, 2019
|}
[[files/Screenshot 2019-12-04 at 3.52.09 AM.png|center|thumb|Final Primitive Pushed]]
[[files/Screenshot 2019-12-04 at 3.52.31 AM.png|center|thumb|Final Primitive Pushed]]
[[files/Screenshot 2019-12-04 at 3.52.43 AM.png|center|thumb|Final Primitive Pushed]]

== Week 14: 18 November - 24 November 2019 ==

=== Team Meeting: ===
* Hackathon for this weekend
* Prepare for the presentation 
* Finish up primitives 

=== Sub Team Personal Notes ===
* Continue writing the primitive
* Almost wrapped up during the hackathon
** Found a way to iterate through the array np.nditer() - later changed 
** Used pandas DataFrame to access the values created by the TfIdfVectorizer 
** Three nested loops - probably not too efficient 

=== Article / Website used ===
* https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/#.Xedu2JNKjoB
** Helped me understand how the vectorizer worked and tranformed the data 
** Introduced to pandas DataFrame which was helpful for visualising and accessing the data later on 
* https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html
** Used the documentation to understand the functions using the examples given 

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Continue working on the primitive
|In Progress
|November 4, 2019
|November 26, 2019
|November 24, 2019
|}

== Week 13: 11 November - 17 November 2019 ==

=== Team Meeting: ===
* Making sure columns were labeled correctly
* First semesters working on primitives

=== Sub Team Personal Notes ===
* Continue writing the primitve
* Ran into road blocks 
** Right way to iterate through the array - errors in notebook
** How does the tfidfvectorizer assign values 
** How to store and access that data while looking at each sentence

=== Article / Website used ===
* https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/#.Xedu2JNKjoB
** Helped me understand how the vectorizer worked and tranformed the data 
** Introduced to pandas DataFrame which was helpful for visualising and accessing the data later on 
* https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html
** Used the documentation to understand the functions using the examples given 

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Continue working on the primitive
|In Progress
|November 4, 2019
|November 26, 2019
|November 24, 2019
|}
[[files/Screenshot 2019-12-04 at 3.35.18 AM.png|center|thumb|461x461px|Used sample data to understand where we were going wrong but still wasn't accurate]]

== Week 12: 4 November - 10 November 2019 ==

=== Team Meeting: ===
* Working on padding the data 
* Equal number of sentences

=== Sub Team Personal Notes ===
* Start writing the primitive 
* Follow the count vectorizer function
* Helped to follow tfidf function - similar to what we were doing 
* Add up tfidf scores for each term in the sentence, scale b ythe size of the sentence 
* Prevents longer sentences having arbitrarily longer scores

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Branch to nlp-app 
|Completed
|November 4, 2019
|November 11, 2019
|November 5, 2019
|-
|Update text_processing_methods.py with the primitive
|In Progress
|November 4, 2019
|November 26, 2019
|November 24, 2019
|}

== Week 11: 28 October - 3 November 2019 ==
Team selection: NLP

=== Team Meeting ===
* NLP
** Adding new primitives (first years)

* Updates from the other sub teams

=== Sub Team Personal Notes ===
* Updated on the team's work so far
* Based on research paper: https://www.sciencedirect.com/science/article/pii/S1877050915006869 
* Tf-idf: term frequency inter document frequency (the lesser a term appears in a document the more important it would be)  
* a way to quantify the importance of words (or terms) in a document 
* final personal goal: creating a way to implement ts-isf (term frequency inter sentence frequency)  
* This week's goal: Implement a basic tf-idf function 

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Join nlp channel 
|Completed
|October 28, 2019
|November 4, 2019
|November 1, 2019
|-
|Jupyter notebook tf-idf function
|Completed
|October 28, 2019
|November 4, 2019
|November 1, 2019
|}

=== Article used ===
* https://towardsdatascience.com/tfidf-for-piece-of-text-in-python-43feccaa74f8
** Processing text using tf-idf
** I mainly used this to understand how tf-idf can be implemented in functions, understand how to improve the accuracy of its representation

=== Screenshots ===
[[files/Screenshot 2019-12-04 at 2.58.38 AM.png|center|thumb|537x537px|Term Frequency Calculation]]
[[files/Screenshot 2019-12-04 at 2.58.52 AM.png|center|thumb|536x536px|Document Frequency Calculation]]

== Week 10: 21 October - 27 October 2019 ==

=== Presentation day ===
* Presentations from the subteams with the comparison of single objective, multi-objective, and EMADE results
* Other subteam presentations
* Team presentation:  https://docs.google.com/presentation/d/1s0Jzx6FY2tZJA3XuXwQ89gayCjDl8HlSzuksCfltXd4/edit#slide=id.g6408953ec7_1_0
* Github repository:  https://github.gatech.edu/bsu32/emadeGroup

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Present the results
|Completed
|October 21, 2019
|October 21, 2019
|October 21, 2019
|-
|Choose the subteam to join (NLP)
|Completed
|October 21, 2019
|October 21, 2019
|October 21, 2019
|}
[[files/Screenshot 2019-12-04 at 4.08.05 AM.png|center|thumb|Pareto Front]]
[[files/Screenshot 2019-12-04 at 4.08.15 AM.png|center|thumb|Individual]]
[[files/Screenshot 2019-12-04 at 4.07.55 AM.png|center|thumb|Comparison of three approaches]]  

== Week 9: 16 October - 20 October 2019 ==

=== Lecture Notes ===
* Working in class to develop a solution for the titanic problem
* Using MySQL and EMADE

=== Sub-team 2 ===
* Work to connect the master and workers on the MySQL server

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Set up master and worker on the server
|Completed
|October 16, 2019
|October 21, 2019
|October 19, 2019
|-
|Set up database and input_titanic.xml file
|Completed
|October 16, 2019
|October 21, 2019
|October 19, 2019
|-
|Presentation for the next week
|Completed
|October 16, 2019
|October 21, 2019
|October 19, 2019
|-
|Use EMADE on the titanic dataset
|Completed
|October 16, 2019
|October 21, 2019
|October 19, 2019
|}

== Week 8: 9 October - 15 October 2019 ==

=== Lecture Notes ===
* ML concept building continued
* Begin to learn how to use EMADE and MySQL 
* EMADE - Evolutionary Multi Objective Algorithm Design Engine

=== Team Meeting Notes ===
* To run EMADE: 
** Navigate to top level directory
** python src/GRFramework/launchGTMOEP.py templates/input_titanic.xml
* Input file
** Configures all the moving parts in EMADE
* MySQL servers
** Configure the MySQL server - add the host and workers
** Username and Password required for each worker - do not forget
* Input file datasets
** Data: preprocessed into gzipped csv files
** Cross-folded using 5 Monte-Carlo Trials 
** Every train and test dataset creates a "DataPair" object in EMADE
* Titanic Dataset Data Setup
** Each row corresponds to an instance (person), each column is a feature, the final column is the truth data.
* Objectives
** Minimised weights (-1.0) and Maximized weights (1.0)
** The evaluation function specifies the name of a method in src/GPFramework/evalFunctions.py (-w - worker tag)
** <workersPerHost>  - how many evaluations run together or in parallel

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Configure MySQL Server
|Completed
|October 9, 2019
|October 16, 2019
|October 15, 2019
|-
|Explore EMADE 
|Completed
|October 9, 2019
|October 16, 2019
|October 14, 2019
|}

== Week 7: 2 October -  8 October 2019 ==
Presentation link: https://docs.google.com/presentation/d/e/2PACX-1vQKLpnDdAeP3WDqky0OND8uzZ0FC1F1v6e4UnxV6tYPKySzyYRBEtKXQuJ6MH6wnWxYWCphIKWgivXk/pub?start=false&loop=false&delayms=3000

GitHub Repository Link: https://github.gatech.edu/bsu32/emadeGroup

=== Lecture Notes ===
* Sub Team Presentations

=== Sub- Team 2 ===
* Presented Solution - Multi Objective GP 
* Presented AUC Graph

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install EMADE
|In Progress
|October 2, 2019
|October 9 2019 
|In Progress
|-
|Install MySQL
|In Progress
|October 2 2019
|October 9 2019 
|In Progress
|-
|Explore External Knowledge
|In Progress
|October 2 2019
|October 9 2019 
|In Progress
|}

=== Recommendations ===
* Simulation of the AUC as the generations passed by.
* Use other logical operators
* What the tree looks like with the individuals

== Week 6: 25 September - 1 October 2019 ==
Presentation link: https://docs.google.com/presentation/d/e/2PACX-1vQKLpnDdAeP3WDqky0OND8uzZ0FC1F1v6e4UnxV6tYPKySzyYRBEtKXQuJ6MH6wnWxYWCphIKWgivXk/pub?start=false&loop=false&delayms=3000

GitHub Repository Link: https://github.gatech.edu/bsu32/emadeGroup
[[files/Defining Func.png|thumb|Tushna and I changed the dominance function to frontier to better solve the problem]]

=== Team Meeting Notes ===
* Use Multiple objective genetic programming algorithm on the Titanic data set.
** Use simple primitives - and, or, not, +, -, /, %
** Create the evolutionary loop for the genetic algorithm.
** Get a non-dominating frontier.
* Create non-dominating graph.
* Area Under Curve
** Use Reimann's Sum 
** AUC vs Gen Graph 
[[files/Pareto Front 2.png|thumb|Pareto Front ]]

=== Sub-Team 2 ===
* Team Meeting 09/30/2019 - Titanic ML Multiple Objective GP Assignment.
* Initial Drafted Team Responsibilities:
** Sanket: Working on redoing our feature set with vectorization and presentation.
** Tusheet and Brandon: Genetic Programming and Evolutionary Algorithm.
** Tushna and Nesha: Working on AUC graph and Riemann sums.
* Resulted Team contribution: 
** Sanket: Features +  Part of presentation 
** Tusheet + Brandon: Single Objective GP with SelBest (Changed in later iterations of code) 
** Nesha + Tushna: MultiObjective GP with selNSGA2, corresponding AUC curve

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Solve the Titanic Example problem using multiple objective genetic programming
|Completed
|September 25, 2019
|October 2, 2019
|October 2 2019
|-
|Create non-dominating graph
|Completed
|September 25, 2019
|October 2, 2019
|October 2 2019
|-
|Create area under graph
|Completed
|September 25, 2019
|October 2, 2019
|October 2 2019
|-
|Peer Evaluation Survey 
|Completed
|September 25, 2019
|October 4, 2019
|October 4 2019
|}

=== Results: ===
Area Under Curve: 0.12988087232811915
[[files/AUC 1.png|left|thumb|339x339px|Final results ]]

[[files/AUC graph desmos.png|thumb|AUC v Generation |center|345x345px]]

== Week 5: 18<sup>th</sup> September - 24<sup>th</sup> September 2019 ==
* GitHub Repository Link: https://github.gatech.edu/bsu32/emadeGroup
* Our team presentation link: https://docs.google.com/presentation/d/e/2PACX-1vSL90uzHtPocLyegASRUGtKyhA5YwrN4W7gR06LEOOYAToNM1FjToTjF0ywVq-2xuU6sJTzKeFalIC3/pub?start=false&loop=false&delayms=3000

=== Lecture Notes ===
* Sub Team Presentations

=== Sub- Team 2 ===
* Presented Codominant Solution 
* Do not use external sources 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Make edits to Titanic Problem
|Completed
|September 18, 2019
|September 25, 2019
|September 24, 2019
|-
|Vectorisation + Concept read up
|Completed
|September 18, 2019
|September 25, 2019
|September 19, 2019
|}

== Week 4: 11<sup>th</sup> September - 17<sup>th</sup> September 2019 ==
GitHub Repository Link: https://github.gatech.edu/bsu32/emadeGroup

=== Lecture Notes ===
* Machine Learning crash course.
* Kaggle for data sets to work on.
* Scikit learn to check out various machine learning algorithms.
* Formed bootcamp subteam - Team 2

=== Subteam Creation ===
* Brandon, Tushna, Tusheet, Nesha, Sanket
* Titanic Dataset from Kaggle 
* Select 5 algorithms to get codominant solution

=== Team Meeting Notes ===
* Titanic Example Data Set:
** One algorithm selected by each group member
** All the algorithms together should provide a codominant solution 
** Scikit learn and train, test, split function for the prediction 
** FPR vs FNR plot

=== Sub-Team Notes ===
* Team Meeting 12th September 2019 Thursday Meeting
** Choosing the feature set
*** https://www.anesi.com/titanic.htm
*** https://www.washingtonpost.com/opinions/women-and-children-did-go-first-on-titanic/2012/04/19/gIQAgSaugT_story.html?noredirect=on
**** “Heroism was exhibited by the men on board across all classes and crew.”
**** “First-class men survived at a higher rate than the third-class children”
**** “Men in first class survived at a lower rate, 32 percent, than did third-class women and children (42 percent)”
**** “The Titanic sank at night, and most third-class passengers were far below in the ship, making such access difficult”
**** “Altogether, survival percentage for all women and children on board was 70 percent, for men it was 19 percent”
**** “third class women were 41% more likely to survive than first class men.”
*** Update note: Do not use external sources to determine the feature set - affects results
*** Presentation Link: https://docs.google.com/presentation/d/e/2PACX-1vSL90uzHtPocLyegASRUGtKyhA5YwrN4W7gR06LEOOYAToNM1FjToTjF0ywVq-2xuU6sJTzKeFalIC3/pub?start=false&loop=false&delayms=3000
'''Manipulated Features:''' PClass (1) was given a higher value than PClass 

We added a new feature set by changing the Pclass to give class 1 a higher number and class 3 a lower one. We also combined this edited Pclass with the Sex class, giving women a higher numeric value then men from historic examples.

'''Dropped features:'''  Embarked, Fare, Name, Ticket, Cabin, Parch

'''Personal Contribution:''' Choosing the features, determining the importance and how it affects accuracy of results, redoing the presentation for readabilty

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Kaggle and Scikit-learn
|Completed
|September 11, 2019
|September 18, 2019
|September 13, 2019
|-
|Sub Team Meeting @ Crosland
|Completed
|September 11, 2019
|September 12, 2019
|September 12, 2019
|-
|Come up with a codominant solution
|Completed
|September 11, 2019
|September 18, 2019
|September 13, 2019
|-
|Prepare Presentation 
|Completed
|September 11, 2019
|September 18, 2019
|September 17, 2019
|}
[[files/FNR vs FPR.png|thumb|The codominant model ]]

=== Conclusions ===
[[files/Feature Set Titanic.png|thumb|Feature Set Used - with dropped and created features]]
* General Procedure:
*# Import Necessary Libraries
*# Read In and Explore the Data - Research
*# Data Analysis
*# Cleaning Data
*# Choosing the Algorithm
*# Plotting the fpr vs fnr
* Feature Set Used:
** Age (Further classified)
** Pclass
** SibSp + Parch
** Sex (Further classified)
* Machine Learning Algorithms Used:
** Decision Tree
** K Neighbors
** Neural Networks
** Random Forest
** Linear Regression
** Gaussian NB

== Week 3: 4<sup>th</sup> September - 10<sup>th</sup> September 2019 ==
[[files/Visualisation of objective space and pareto front.png|thumb|Visualisation of objective space and pareto front]]

=== Lecture Notes ===
* Introduction to multiple objectives
* Translation of the vector of scores into a fitness value 
* Gene pool: Set of genomes to be evaluated during the current generation 
* Genotype: Individual 
* Phenotype: the function 
* Objective Space: Set of objectives 
* Evaluation: Association with a set of scores
* True Positive: Actually identifies the object
* False Positive: Identifies something else as the object 
* True Negative: Type II Error
* False Negative: Type I Error
* Maximization Measures
**True Positive Rate(TRP)
*** TRP = TP/(TP + FN)
** Specificity (SPC) or True Negative Rate(TNR)
*** TNR = TN/(TN + FP)
* Minimization Measures 
** False Negative Rate (FNR)
*** FNR = FN/P = FN/(TP + FN) = 1 - TPR
** Fallout or False Positive Rate (FPR)
*** FPR = FP/N = FP/(TN + FP) = 1 - TN

=== Objectives for Assignment ===
* minimise two objectives 
* minimise tree size
* minimise mean squared error 

=== Steps - How to go about Lab 2 Part 2 ===
* Import libraries for Multi Objective Genetic Programming 
* Create our fitness, individuals, population, complier, toolbox. 
* Define our evaluation function . 
* Use SelBest for the evolutionary algo
* Using plots to represent findings

=== Action Items ===
{| class="wikitable"
!Task 
!Current Status
!Date Assigned
!Suspense Date 
!Date Resolved
|-
|Go over Lecture Material 
|Completed
|4 Sep 2019
|11 Sep 2019
|7 Sep 2019
|-
|Finish Lab2 Part 2; Add the required code 
|Completed
|4 Sep 2019
|11 Sep 2019
|10 Sep 2019
|-
|Update VIP notebook 
|Completed
|4 Sep 2019
|11 Sep 2019
|16 Sep 2019
|}   

== Week 2: 28<sup>th</sup> August - 3r<sup>d</sup> September  2019 ==

=== Lecture Notes ===
* Shift from Genetic Algorithms to Genetic Programming 

* Recap: GA 
** Population based solution  
** Individuals represented as lists 
* Genetic Programming: 
** Individual turns into the function instead of being evaluated upon 
* Tree Representation: 
** Nodes: Operators  
** Terminals: Parameters  
** Input: At terminal  
** Output: At Root  

* Lisp Preordered Parse Tree
**f(x) = 3 * 4 + 1 =>  [+, *, 3, 4, 1]
**Root first, then expand 
*Crossover: 
**Exchanging subtrees 
*Mutation 
**Inserting a node / subtree
**Deleting a node / subtree
**Changing a node

=== Action Items ===
{| class="wikitable"
!Task 
!Current Status
!Date Assigned
!Suspense Date 
!Date Resolved
|-
|Go over Lecture Material 
|Completed
|28 Aug 2019
|2 Sep 2019
|5 Sep 2019
|-
|Download Lab 2 file from github repo
|Completed
|28 Aug 2019
|2 Sep 2019
|5 Sep 2019
|-
|Run the code from Lab 2; Add the required code 
|Completed
|28 Aug 2019
|2 Sep 2019
|5 Sep 2019
|-
|Update VIP notebook 
|Completed
|28 Aug 2019
|2 Sep 2019
|11 Sep 2019
|}
== Week 1: 21<sup>st</sup> - 27<sup>th</sup> August 2019  ==

=== General Information ===
* Wednesday, 4:30-5:20 pm - Bootcamp 
* Update Notebooks every single week 
* Grades - Evenly Distributed Between: 
** Documentation and records
** Personal accomplishments and contributions to your team’s goals 
** Teamwork and interaction 

=== Lecture Notes ===
* First lecture of the semester 
* Introduction to the team and the crux of the project 
* Introduction to Genetic Algorithms and Programming
* Definitions
** Genetic Algorithm: To produce the individual with the best fitness using mutation and mating of individuals in a population with a function that determine the best individual
** Objective: Value used to characterise the individuals in the population 
** Fitness: Used to compare individuals in the population, determined the best individual
** Selection: Higher fitness, higher chances to pass on their genes
*** Tournament: "Tournament" between certain number of individuals to select the winners for mating 
*** Fitness Proportionate: Higher the fitness, Higher chances of mating 
** Mutation and Mating to change population
* Introduction of One Max Problem (Lab 1)
** Goal: Create an individual whose list contains only 1's and no 0's
* Moved on to explanation of jupyter and anaconda and how to complete Lab 1
* Reviewed the code in relation to material taught

=== Action Items ===
{| class="wikitable"
!Task 
!Current Status
!Date Assigned
!Suspense Date 
!Date Resolved
|-
|Go over Lecture Material 
|Completed
|21 Aug 2019
|28 Aug 2019
|27 Aug 2019
|-
|Configure and Set up Jupyter, Anaconda, GitHub
|Completed
|21 Aug 2019
|28 Aug 2019
|27 Aug 2019
|-
|Join the AAD Slack
|Completed
|21 Aug 2019
|28 Aug 2019
|27 Aug 2019
|-
|Download Lab 1 file from github repo
|Completed
|21 Aug 2019
|28 Aug 2019 
|27 Aug 2019
|-
|Run the code from Lab 1; Read through 
|Completed
|21 Aug 2019
|28 Aug 2019
|27 Aug 2019
|-
|Make a personal vip notebook 
|Completed
|21 Aug 2019
|28 Aug 2019
|27 Aug 2019
|}

=== Conclusions ===
* Lab 1 - One max Problem & N Queens - Single Objective
# Define Individual and gave a random generated initializer for the individual. Create 300 individuals
# Algorithm runs for 40 generations (0 - 39) to observe the population evolution to make progress towards the objective.
# Selection (tournament) - Mate (50%) - Mutate (20%) - replace population.
# Plot Data