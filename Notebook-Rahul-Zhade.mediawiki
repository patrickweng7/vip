
== Team Member ==

'''Team Member:''' Rahul Zhade

'''Email:''' rzhade@gatech.edu

'''Phone Number:''' 425 628 4917

'''Interests:''' Programming, basketball, video games

= 7- 13 January 2019 =

=== '''Team Notes''' ===

===== 7 February 2019 =====
* First day of class
* Have class conflict, so could not attend general team meeting
** Emailed Professor Zutty and Scott + team

=== Sub Team Notes ===
===== 11 January 2019 =====
* Read through abstract that Scott shared on Slack
* All techniques that were discussed last semester
* Critiques
** Well written, clear if a bit technical
** Methodology is clearly discussed, nothing that should be changed before being sent over

=== '''Action Items''' ===
{| class="wikitable"
!Task Description
!Current Status
!Data Assigned
!Suspense Date
!Data Completed
|-
|Resolve Class Conflict
|Completed
|7 January 2019
|14 January 2019
|10 January 2019
|-
|Read Shared Abstract on Team Slack
|Completed
|7 January 2019
|11 January 2019
|11 January 2019
|-
|Share Feedback about Summary
|Completed
|7 January 2019
|11 January 2019
|11 January 2019
|}

= 14- 20 January 2019 =

=== Team Notes  ===
===== 14 February 2019 =====
* Second general meeting
* Finalized two subteam meeting times
* Presented a quick Scrum stand up on current progress
** Progress from last semester
*** Talk about progress with GCP and Emory laboratory  
** Discussed actionable items

=== Sub Team Notes ===

===== 19 February 2019 =====
* Couldn't make the team meeting so contacted Scott
** Rest of team was assigned sub- projects
*** Sub projects are in Slack
** Will choose my subproject next week
* Assigned to read Chapter 3 of Analyzing Neural Time Series Data: Theory and Practice

=== 23 February 2019 ===
* Read Chapter 3 of Analyzing Neural Time Series Data textbook
* '''Notes'''
** EEG Oscillations are measured in: Frequency, Power and Phase
*** Power is amount of energy in frequency band, given by squared amplitude of oscillation (measured in mV)
*** Phase is position along sine wave at any given point (measured in Radians)
** Brain rhythms are grouped into bands:
*** Delta, Theta, Alpha, Beta, Lower Gamma, Upper Gamma
*** Not precise bands, limits can be different depending on text
*** Logarithmically increasing bands
** Since EEG data is ''at least'' three dimensional, to view it, we must take slices, in either time/ space/ power frequency

=== '''Action Items''' ===
{| class="wikitable"
!Task Description
!Current Status
!Data Assigned
!Suspense Date
!Data Completed
|-
|Read Chapter 3 of Analyzing Neural Time Series Data
|Completed
|18 January 2019
|25 January 2019
|23 January 2019
|}

= 21- 27 January 2019 =

=== Team Notes ===
* No general meeting this week because of MLK

=== Sub Team Notes ===
===== 25 February 2019 =====
* Filled in from last meeting since I didn't attend
** Sub sub teams have been assigned
*** Am in sub sub team with Joel and James
*** Responsible for implementing Alpha Channel and frequency cropping for EEG signals
* Ali went over his work implementing average waveforms
* Subteam, Joel is responsible for writing script to preprocess data, and I am to create a simple neural network learner to validate results

=== Action Items ===
{| class="wikitable"
!Task Description
!Current Status
!Date Assigned
!Suspense Date
!Date Completed
|-
|Create learner for cropped frequency domain
|Completed
|25 January 2019
|1 February 2019
|1 February 2019
|}
= 28 January- 3 February 2019 =

=== Meeting Notes ===

===== 28 January 2019 =====
* Dr. Zutty said notebooks are not up to par
** Go back through and update existing notebook entries
* Announced Scott securing the FORCE cluster
* Zretty Forecasting as a primitive
* Talked with Dr. Zutty regarding the memory leakage problem
** Should be an easy fix? Follow up with Austin about this

=== Sub Team Notes ===
=====  1 February 2019 =====
* Implemented arbitrary neural network learner in preparation for learner
* Joel's script to parse data is returning 3 dimensional array?
** Flatten time domain, network can figure this out
* Learner is achieving ~73% accuracy on test
** Debugging, learner is outputting trivial results, all positive
** Tried out SVM, kNN, and Decision Tree
*** Marginal improvements, Decision Tree is slightly better than trivial, however, result is still not correct 

=== Action Items ===
{| class="wikitable"
!Task Description
!Current Status
!Date Assigned
!Suspense Date
!Date Completed
|-
|Update old notebook entries to reflect specific dates, rather than week 
|Completed
|28 January 2019
|25 February 2019
|17 February 2019
|-
|Follow up with Scott regarding trivial learner
|Completed
|1 February 2019
|2 February 2019
|2 February 2019 
|}

= 4-10 February 2019 =

=== Team Notes ===

===== 4 February 2019 =====
* Scrum meeting
** Discussed cropped frequency domain
** No information about our dataset (blocked on metadata about dataset)
** Success with Ali's technique of averaging data?
*** Still don't understand how cross contamination of data does not occur
*Ali wants to unpickle `.dat` file from `eegmade` last semester, apparently we have some data in there
**Is there a script to go from Emade dataset to numpy dataset?

=== Sub Team Notes ===

===== 8 February 2019 =====
* Discussed main analysis techniques
** Apparently for analyzing EEG data, using a image classifier is a good technique?
*** Joel, looking into using a spectrogram  
*** Spectogram data not making sense except when running through logarithm first?
**** Look into this, currently this preprocessing is mostly arbitrary, running through Emade will find a more optimal preprocessing technique 

=== Action Items ===
{| class="wikitable"
!Task Description
!Current Status
!Date Assigned
!Suspense Date
!Date Completed
|-
|Update old notebook entries to reflect specific dates, rather than week 
|Completed
|28 January 2019
|25 February 2019
|17 February 2019
|-
|Follow up with Scott regarding trivial learner
|Completed
|1 February 2019
|2 February 2019
|2 February 2019 
|}  

= 11- 17 February 2019 =

=== Team Notes ===

===== 11 February 2019 =====
* Scrum meeting
** Announced Ali and Jas new technique of finding seeds, concatenating samples together 
** Got the metadata, so unblocked regarding analyzing the healthy data 
** New study scheduled for March, getting new dataset then, need to have a run of Emade by then 

=== Sub Team Notes ===

===== 15 February 2019 =====
* Asked Scott about preprocessing techniques, are we splitting on instance/ individual or by class?
* Since lagging behind, plan on hackathon style workathon on Sunday, 2/17

===== 17 February 2019 =====
* Need to implement Morlet wavelet as a primitive into EEGMADE
** https://www.youtube.com/watch?v=wgRgodvU_Ms
** Implementation from Scipy, https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.morlet.html
** Task reassigned to just Austin and James
* Scott asked me to write config files for [http://www.pace.gatech.edu/getting-started-pace-clusters FORCE cluster]
** Scheduler for FORCE cluster uses PBS scheduler
** Currently EMADE has support for slurm scheduler, not for PBS
*** Extend Scott's code for Slurm to work for PBS

=== Action Items ===
{| class="wikitable"
!Task Description
!Current Status
!Date Assigned
!Suspense Date
!Date Completed
|-
|Implement required primitives into Emade
|In Progress
|15 February 2019
|22 February 2019
|Reassigned to James
|-
|Do one evolutionary run of Emade on dataset
|Blocked
|15 February 2019
|22 February 2019
| -
|-
|Write config files to run Emade on PACE cluster  
|Completed
|17 February 2019
|22 February 2019
|17 February 2019
|}

= 18-24 February 2019 =

=== Team Notes ===

===== 18 February 2019 =====
* Scrum meeting, discussed Sunday's workathon and progress made 
*  Dr. Zutty asked to see the PBS config files, need to send them to him or show him on Friday with Scott
*  Some confusion with Dr. Roehling regarding the way that Morlet transform will be implemented?
**  Creating a wrapper for the Morlet transform in Scipy
**  Dr. Roehling suggested looking into PyWavelets module
***  James has already looked into this, trying to minimize dependencies imported into Emade, so settled on Scipy implementation
*Discussion with Dr. Roehling regarding how to implement Morlet transform
**Transform has a prerequisite for FFT, do we run FFT in the primitive and risk running twice, or change tree structure?
**Dr. Roehling said to implement in primitive, and let Emade figure out proper way to construct model
*Ali and Jas working on flattening dataset to average better? Need to follow up on this preprocessing technique 

=== Sub Team Notes ===

===== 22 February 2019 =====
* Asked Scott about whether we are blocked on primitives in order to do an evolutionary run
** James needs help? Look into this
** Scott said to prioritize getting a run in, we can implement more specialized expert seed with custom primitives later
*Getting some expert seeds from Joel and/or Ali today
* Ali claims accuracy of 99% on eye open/ eye closed dataset?
** Joel was dubious about results, confirmed with Scott that results are *plausible*
** Ali's preprocessing was (a) contaminating train and test and (b) convoluting the data to pick points along a wave? 
*** Resulted in a trivial leader, basically a lookup table
*** Easy fix, need to hear back on results of learner with proper preprocessing
** Gave him a quick five step rundown of a typical machine learning pipeline
**# Join X and Y together into one dataframe
**# Randomly split X+Y dataframe into testing and training dataset
**# Preprocess X_train and X_test '''completely separately''', with no cross contamination
**# Feed X_train and Y_train into model
**# Validate results with X_test and Y_test

=== Action Items ===
{| class="wikitable"
!Task Description
!Current Status
!Date Assigned
!Suspense Date
!Date Completed
|-
|Implement required primitives into Emade
|In Progress
|15 February 2019
|22 February 2019
|Reassigned to Austin and James
|-
|Do one evolutionary run of Emade on dataset
|Blocked
|15 February 2019
|22 February 2019
|
|}

= 25 February - 3 March 2019 =

=== Team Notes ===

===== 25 February 2019 =====
* Scrum meeting
** Everyone is sick, delay because primitives have not been implemented yet 
** Main discussion regarding running Emade, Dr. Zutty said to stop wondering whether the problem is solvable, and just run it with Emade
*** Main concern: We need to figure out the way that we can feed the data in, 3D array are we keeping the individuals separate? Too little data this way, only 5000 data points per recording 

=== Sub Team Notes ===

===== 1 March 2019 =====
* Talked with Scott about gathering new data
** New dataset being collected tomorrow, 3/2
* Discussed techniques for feeding data into Emade
** Scott has been running Emade using 2D array of channel vs. time dataset, getting trivial results, blamed bad initial seeds
** Sklearn and other Emade primitives can only take vector arrays, perhaps bad performance is because many primitives cannot be used?
** Assigned to do a run of Emade with flattened array on time, and then channel to compare performance of each against 2D array
* Ali brought up that wavelet transforms might not be the best primitive to use for brain/ EEG data?
** Argument that brain waves aren't exactly cyclical?
** Emade should be able to find the correct primitive to use, so we'll move forward on this, and implement new primitives when needed

=== Action Items ===
{| class="wikitable"
!Task Description
!Current Status
!Date Assigned
!Suspense Date
!Date Completed
|-
|Run Emade with Flattened Data
|In Progress
|1 March 2019
|8 March 2019
|4 March 2019
|-
|Implement wavelet transform into Emade
|In Progress
|1 March 2019
|8 March 2019
|10 April 2019
|}

= 4-10 March 2019 =

=== Team Notes ===

===== 4 March 2019 =====
* Scrum meeting
** Announced PBS cluster support, for PACE
** Visit to Emory to gather new data
** Results from flattened dataset in Emade were trivial, updates from Ali about "weirdness" of the data
* Ali's updates about the dataset
** After running FFT on them, revealed quirky decompositions, no observable difference between True and False results
** Dr. Zutty suggested normalizing the data?

=== Sub Team Notes ===

===== 8 March 2019 =====
* Started recruiting slides for next week
** What kinds of first years are we trying to recruit?
*** Technical experience, some with exposure to EEG and others with CS
*** Also need to re-populate the group as at least 3-4 members are not going to return
* WRT Emade, new technique to try:
** Chunk samples of random sizes, to see if insights for smaller portions of the instance are different than total instance

=== Action Items ===
{| class="wikitable"
!Task Description
!Current Status
!Date Assigned
!Suspense Date
!Date Completed
|-
|Implement wavelet transform into Emade
|In Progress
|1 March 2019
|8 March 2019
|10 April 2019
|-
|Finish recruiting slides
|Complete
|8 March 2019
|11 March 2019
|10 March 2019
|}

= 11-17 March 2019 =

=== Team Notes ===

===== 11 March 2019 =====
Midterm presentation day, took notes with [[Notebook Jaswanth Sai Pyneni|Jas]] for this one:
*<u>Viz</u>
**Goal: visual interface to make training easier - View how individuals are performing during training
**Visualize: pareto front, evaluation times, tree structure, AUC graph, number of Pareto Individuals over time, evaluation times
**Current goals: add more visualizations (hereditary), improve usability (UI/UX), refactor code to be efficient
**User Study feedback: document progress, UI needs to handle failure better
***Segregate generational visualizations from aggregate visualizations
*<u>Group Four (1st Semester)</u>
**ML
***Dropped Name, Ticket and Cabin
***Replaced NaN with averages
***Logistic regression + DT ==> highest Kaggle score (.784)
**GP
***results : .79
***Better than ML
**EMADE
***39 generations over two weeks
***seeded with random forest individual
***maybe better if ran for longer but no time
***AUC: .9138
**Learned:
***EMADE makes building models so much easier
***ML - user needs to make many choices (data prep, future extraction)
***GP - requires more work
**Troubles:
***Installing Emade
***SQL Issues with EMADE
*<u>Group 2</u>
**ML
***Dropped non-numeric/ non-categorical cols
***Used GridSearch to find the best parameters
***Classifiers: DT, Random Forest, AdaBoost, C-SVM
***Best: Random Forest - 83.7%, Decision Tree - 84%
**GP
***Attempt 1: Best Individual fitness: (0, .983)
**EMADE
***Three objectives --> False positives, False negatives, Number of elements
***4 runs, 48 generations
***AUC: 1882.32 -- hypervolume
*<u>Group 5</u>
**Preprocessing
***Title Based NaN replacement
***Separate age groups for Mr. and Mrs.
***Banded age groups into 5 generations
***Embarked was one hotted, cabin was converted to # based on depth, fares was banded into groups
**ML
***Age: averaged based on subgroups split on other values
***DT, Gradient Boosting, KNN
***Hyperparameter selection using using trial and error
***Accuracy: 76%
**GP
***Mean square error for fitness
***Squash output between 0 and 1 with sigmoid
***Accuracy: 79%
**EMADE
***ASK AUSTIN
***Notes from Dr. Rohling: use proper graphs with units/ axis; otherwise hard to visually communicate what's going on
*<u>Caching</u>
**Shit ton of speed efficiency Instead of train subtrees over and over, cache previous generation instead of re-evaluating
***Just store result of previous Trees
**Built in parameter for EMADE
***Use_Cache a boolean variable now that can be flagged to make use of this
**Progress since last Semester
***Documentation web app for caching improvements/ API calls
***Updated all XML templates within caching to be compatible with branches
***Working on getting it to work with image data
****Currently works with stream/ strings
*****Can make running EMADE 500% faster
**Next Steps
***Get it to work on image data, currently there are errors

*<u>Bootcamp Group 3</u>
**Lab 1
***N Queens problem
**ML
***Best score: .78
***Score after parameter tuning: .77
***Three models had the same exact score (?)
**GP
***Added primitives, add subtract power max 2
***Used mutUniform for mutation
***AUC: .2310
**EMADE
***Ran for 30 generations
***AUC: .199
**Learned
***ML - least accurate, tended to overfit
***GP - more accurate because mutations
***EMADE - Best

*<u>Stock Team</u>
**Goal: use EMADE to predict stock price on next day based on previous few days
**Previously: simple binary classification problem: buy or sell
**Based on technical indicators
**Current focus: time series data
**Predict actual price value as regression problem
**Use signal processing on time series data for forecasting
***Auto regression
***Moving averages
***ARMA/ARIMA
***SARIMA
***VAR/VARMA
***SES
***HWES
**Future
**EMADE on Google Cloud
**Implement non-classical time series forecasting methods
*<u>Group One</u>
**Data Pre-processing
**ML
***MLP Classifier - Kaggle Highest Score .775
***Random Forest Classifier
***Gradient Booster Classifier
***Decision Tree Classifier
**GP
***Strongly typed operators
***Tournament selection did not work well
***^Used NGASII selection instead
***AUC = 30700
**EMADE
***Started with sql connection errors
***Ran for 14 generations
***Had 2 optimal individuals
***AUC: 647
***Used VIZ team data to produce EMADE Pareto front
**Conclusion
***AUC for EMADE far better than AUC for GP
***EMADE has best individual that is not overfitted with 4.6 fp and 35 fn

*<u>Group Six</u>
**Feature Engineering
**EMADE
***Best run - 21 generations
***EMADE > GP/Ml
**Used EMADE VIZ to generate visualizations
**Hypervolume calculation errors caused random jumps in graphs
**ML
**GP
***used selSPEA2 selection method

*<u>EEG</u>
**Our Presentation
**Feedback:
***Run EMADE
***Put things into EMADE
***Use EMADE
***Stop not using EMADE

*<u>Deep Learning</u>
**GP vs. CGP
**CGPs are represented by DAGs
**Not exactly a tree, its a directed acyclic graph
**Blocked primitives?
**Dataset: MNIST
**99+% accuracy
**Looking for:
***GCP experience
***ML + DL experience
***People with GPUs

=== Sub Team Notes ===

===== 15 March 2019 =====
* Mid semester reflections,
** What is our goal to do by the end of the semester?
** Get something running in Emade, with same dataset? Need updates on progress
* Reflection on feasibility of task, can we get real- time preprocessing?
** FFT can be run in 3 seconds, good

=== Action Items ===
{| class="wikitable"
!Task Description
!Current Status
!Date Assigned
!Suspense Date
!Date Completed
|-
|Run Emade with Flattened Data
|In Progress
|1 March 2019
|8 March 2019
|
|-
|Implement wavelet transform into Emade
|In Progress
|1 March 2019
|8 March 2019
|10 April 2019
|}

= 18-24 March 2019 =

=== Team Notes ===
Spring Break

=== Sub Team Notes ===
Spring Break

= 25-31 March 2019 =
=== Team Notes ===

===== 25 March 2019 =====
* Scrum Meeting
* New team members were added, idea to pair them up with a "big buddy" based on interests/ existing knowledge?
** List of members
*** Shlok Natarajan: 1st year Pre- med with CS minor --> work with James/ Austin
*** Michael Lee: 1st year ECE --> work with Scott/ Nick
*** Kang Shin: Masters student in CS, undergrad in bio --> work with Scott?
*** Shruti Sudhakar: 1st year CS, didn't show up to class --> Will have to assign
** Most of the above have conflicts with Friday meeting. How to accommodate?

=== Sub Team Notes ===

===== 27 March 2019 =====
* Since Kang and Sruthi have Friday conflicts, will have to set them up online, with weekly updates
** Use Scott's weekly update email
** Or have sub sub team meetings, like Ali and Jas's meetings
*Run this by Scott, see what to do about this

===== 29 March 2019 =====
* Scott wants to have a script to turn strings into seeds, wants to turn robust string parser from last semester into this?
** Turning string evaluations of trees into actual trees?
** Looks like Joel had already implemented this, https://github.gatech.edu/sheston3/eegmade/pull/7
*Helped Jas with SQL errors when running Emade locally, lots of debug issues
**Should follow up on existing PRs to emade/emade, get them merged in to prevent these kinds of problems from reoccurring

=== Action Items ===
{| class="wikitable"
!Task Description
!Current Status
!Date Assigned
!Suspense Date
!Date Completed
|-
|Figure out how to accommodate Friday meetings for first years
|Complete
|25 March 2019
|29 March 2019
|27 March 2019
|-
|Follow up on emade/emade PRs made last semester
|Complete
|29 March 2019
|29 March 2019
|29 March 2019
|}

= 1-7 April 2019 =

=== Team Notes ===

===== 1 April 2019 =====
* Scrum meeting
** Main goal has been to catch up first semesters, talked about the buddy system
** Since this week is hell week, pushing suspense dates all back by one week

=== Sub Team Notes ===

===== 5 April 2019 =====
* Scott created a Jupyter notebook to test out primitive methods
** Can now test out primitives to see if properly implemented
*** Should test out progress on Morlet transform to see if this is correct
** See if this should be merged into emade/emade? Might be helpful for other groups
* Scott explained to Jas the structure of a Datapair in Emade, useful notes:
** each of stream to stream, stream to features, feature to features describes different types of data
*** Since our data is time series, only need to focus on stream to stream and stream to features, last one is not for time series

=== Action Items ===
{| class="wikitable"
!Task Description
!Current Status
!Date Assigned
!Suspense Date
!Date Completed
|-
|Implement wavelet transform into Emade
|In Progress
|1 March 2019
|10 March 2019
|10 April 2019
|}  

= 8-14 April 2019 =

=== Team Notes ===

===== 8 April 2019 =====
* Scrum meeting
** Dataset has been confirmed to be corrupted by Ali and his professor
** New primitives are being implemented/ being tested
*** State variance + MSS
** Need to reconsider methods that we used already, since dataset was

=== Sub Team Notes ===

===== 10 April 2019 =====
* Looked for morlet transform online
** Found implementation of transform in [https://pywavelets.readthedocs.io/en/latest/ PyWavelets package], morlet transform and other wavelet transforms
*** Already imported n Emade, so it is OK to use
*** Seems to be everything I need
** Still don't understand wavelet transform vs FFT, 
*** https://www.youtube.com/watch?v=HSMwxBg7iq4&list=PLn0OLiymPak2G__qvavn3T8k7R8ssKxVr, have to watch this?
** James had tried previously, and ran into problem of not finding morlet that can take in arrays?
*** Run my implementation by him and see if I am doing this correctly
* For now, can just implement and worry about what I'm doing later
** Mostly copy paste from other primitives and pywt 

===== 12 April 2019 =====
* Couldn't make 12 PM meeting
* Went to 3 PM meeting instead, met with Scott, Joel, Nick
* Scott talked about changing dataset again, this time to emotion dataset? 
** http://www.eecs.qmul.ac.uk/mmv/datasets/deap/
** Trying to classify videos across four different features; arousal, valence, like/dislike, familiarity
** How to classify signals over multiple features?
*Dr. Zutty wanted a progress update on finishing in time
**Would changing the dataset affect our likelihood of finishing project in time?
**Get all primitives up by Monday for Dr. Zutty to be able to review in time
**Would using the same seeds for both datasets turn out fine?

=== Action Items ===
{| class="wikitable"
!Task Description
!Current Status
!Date Assigned
!Suspense Date
!Date Completed
|-
|Read through new dataset
|Complete
|12 April 2019
|14 April 2019
|12 April 2019
|-
|Get wavelet transform pushed up
|Complete
|12 April 2019
|15 April 2019
|15 April 2019
|}  

= 15-21 April 2019 =

=== Team Notes ===

===== 15 April 2019 =====
* Scrum standup
** Updates about new dataset, and new primitives implemented
*** From last week, using DEAP dataset for emotion prediction
** Talked about using same seeds for new problem set
** Dr. Zutty was not there for comments on new dataset/ approach for adapting existing solutions over
*** We've talked through this last Friday
* Filled in everybody about Friday meeting with Dr. Zutty, need to get all primitives pushed up by EoD

=== Sub Team Notes ===

===== 19 April 2019 =====
* First priority: Finish final presentation
** Kang and Sruthi did not have anything to do this week, so assigned them to do the presentation
*** Showed and explained last semester's presentation, and gave a list of updates
*** Showed all the PRs made this semester, and explained what each one of these does
* Scott has been running Emade on the DEAP dataset, asked for progress on my PR
** Haven't had time this week to work on it, so will work on this today/ tomorrow
** Need to look through seeds to see how to create an educated one

===== 20 April 2019 =====
* Dr Zutty reviewed my PR, and suggested making number of scales 
* What are scales? https://dsp.stackexchange.com/questions/41492/what-is-the-relationship-between-scales-and-frequency-in-a-morlet-wavelet-transf, seems to be inverse of frequency band?
* Implemented this change, scales function of length of dataset, now running takes forever
** Need to investigate how different distributions of scales affect runtime performance?
*** Currently scales are distributed linearly, with numpy.arange(), however online I see more complicated scale formulas online
*** Should scales be something that is passed in, or something that is hardcoded on a case by case basis?
**** Latter seems more reasonable, as the frequency bands that we want to transform over are on a case by case basis, need to talk about this

=== Action Items ===
{| class="wikitable"
!Task Description
!Current Status
!Date Assigned
!Suspense Date
!Date Completed
|-
|Make edits to wavelet transform to take in parameter from Emade
|In Progress
|15 April 2019
|22 April 2019
|
|-
|Finish final presentation
|Completed
|19 April 2019
|22 April 2019
|22 April 2019
|}  

= 22 April 2019 =

=== Team Notes ===

===== 22 April 2019 =====
* Last day of VIP, final presentations
* Took notes with Jas about presentations
**First group, Stocks
***Use EMADE to predict stock prices based on historical data
***Regression problem instead of classification (?)
***Implemented technical indicators as feature construction
***Since it's regression instead of classification, implemented completely different primitives (ex: MDP)
***Data used: Text file of GE stock data with some preprocessing
***Time series decomposed into multiple features (trend, seasonality, residuals)
***These preprocessing methods have been Implemented into primitives for emade to work with
***Statistical Models used: SARIMA (Seasonal AutoRegressive Integrated Moving Average), VARMA (Vector AutoRegressive Moving Average), HWES (Holt-Winters Exponential Soothing)
***Deep Learning Models used: MLP, RNN, LSTM
***Accuracy metrics used to evaluate models: sMAPE (symmetric Mean Absolute Percent Error), MASE (Mean Absolute Scaled Error)
***Results: Statistical models have lower error than DL models, likely due to Statistical models fitting directly on testing data
***DL methods also require much tuning
***Results don't produce accurate enough results to use in real life
***Problems
****Emade timeout errors, workflow of Emade, unfamiliarity with implementation
***Future work: run EMADE, more DL models, Sector market indicators

**Second group, Caching
***Divided into multiple sub-teams
****support all data types that EMADE supports
****Create APIs that give users options to use their own cache invalidation method for their own problem space
***Cache Maintenance - add documentation
****Dockerizing Cache - simplify, standardize process of running on all OS's - makes updates easier, less work for GCP setup
****Future updates: standardize outputs, build faster, fix conda version problems, test on other OS's
***Cache Validation
****Want more optimal system to maximize benefit of subtrees stored
****Solution: use the Dynamic Programming solution to the Knapsack Problem
****Problems with solution: time ineffective, time cost is large even when the number of subtrees in cache is very small
****Potential solutions to those problems: Scale weights, benchmarking, using buckets, etc
***Potential optimization of Knapsack
****Performance vs precision tradeoff
*****Sacrifice precision with approximation algorithm, greedy, scaling & rounding
****Parallelism
*****Hypercubes vs irregular mesh
***Scripts/ work done
****Wrote a script to run EMADE automatically

**Third group - EEG(us)
***https://docs.google.com/presentation/d/1UBfFPGBJ5NM3D_9h8j1SWma7n7bXaxWzh4zxxjiS9z8/edit?ts=5cbe4470

**Fourth group, Data Visualization
***Motivations
****Provide a visual interface to be able to interact with EMADE
***Recap Fall 2018
***Goals for 2019
****More visualizations
*****Visualizations of pareto front over time
****Improve usability
****Refactor Code
****Make app generalize
****Visualization of parents: concept
*****Want to have a visualization for where the parent of a dominated from comes from in a front.
***User Study Feedback
****documentation
*****Clearly state he separation between EMADE and EMADE-visualization
*****more detail on creating an environment
****UI Feedback
****Visualization
****XML Importing
*****Goal:
******Generalize visualizations for any type of problem and any kind of objective functions
***Pickling First Years
****Goal Reduce the number of times we make a call to the database in order to increase efficiency
*****Pickling
***Future
****Make EMADE log meta data in mysql table
****finish hierarchy visualizations
****add seed creation GUI
****GUI for executing sql queries

**Fifth group, DEEP
***Subteam B:
****Regression Problem Housing Prices
****Progress since Midterm
*****identified Kaggle Housing Price dataset
*****incorporated changes into ezCGP to support regression problems
*****Added Average Percent Change (APC) and Mean Absolute Error (MAE) as fitness functions for regression problem
*****used StandardScaler to split and normalize training/testing data and preprocessed the housing dataset
****Housing Price Dateset:
****Parameter Choices
*****restricted primitives to only dense layers, finding optimal number of dense layers
****Individual with Best APC:
*****uses about 7 dense layers, 6 hidden
*****predicted price is just 1 value, housing price
*****trained best individual for 35 epochs
****Results on Housing Dataset
*****compared to other kaggle results
*****regularized NN performed slightly better
***Subteam A:
****Improving structure of ezCGP
****Progress since Midterm
*****implemented argument/parameter mutation
*****changed the framework to deal with large datasets
****Dataset 1: MNIST
*****used because it is easy to evaluate and accessible, population size was 12, epoch set at 1, ran 35 generations
*****Results on MNIST
******best individual is 95.85% and 98.84%
******took the individual and trained on full training set
******got 99.85%
*****Compare to Midterm Results
******trained model further, about 42 epochs. best accuracy 99.43%
******assume since its continuously increasing, will keep going up
****Dataset 2- CIFAR-10
*****Parameters:
******pop size 9, epochs to 3, 25 generations
*****Results on CIFAR-10:
******best accuracy of 79.7%, ran for 100 epochs, increased in accuracy by 1.32%
****Dataset 3- CIFAR -100
*****Parameters:
******pop size 9, 5 epochs, 50 generations
*****Results:
******low accuracy but still improved
******best individual was bad - just a conv block->max pooling->average pooling
******trained over 200 epochs because accuracy plateaued
******cifar-100 model under performed when trained on whole dataset. why?
*******lack of genetic diversity
*******smaller models learn faster
*******larger models learn more defining features and therefore generalize better
******how to fix?
*******increase number of epochs
*******utilize first and second order gradient information to make better judgement whether its done learning
*******kill smaller individuals