== Team Member ==
[[files/Reagan Kan Photo.png|left|frameless|113x113px]]
[[files/GeorgiaTechBuzz.jpg|thumb|123x123px]]
Team Member: Reagan Kan

Email: rkan3@gatech.edu

Cell Phone; 858-213-5719

Major: CS [Intelligence/Theory]

Interests: AI/Machine Learning

= *Semester Three - Spring 2020 (recent on top)* =

== Monday April 27, 2020 ==
Upload stats script used to generate plots for final presentation.

== Monday April 20, 2020 Final Presentation ==
<u>Miscellaneous Notes</u>

200 seconds, not 500 seconds for eval time on a single individual, evaluated on subset of 2000 instances.

Plot Labels: 1 - ACC

<u>Link to commits</u>

https://github.gatech.edu/emade/emade/commits/nlp-nn/?author=rkan3

<u>Link to final presentation slide deck.</u>

https://docs.google.com/presentation/d/1sfyO-eB262HKiVnPvO8vDu_6n4wR-Q1RJrIfldWo810/edit?usp=sharing

== Sunday April 19, 2020 ==
'''Individual Work'''

Add in new April17 data Pulak sent in for nlp-app significance test.

Add pareto front info to slides.

'''Dry Run of Presentation'''

Unable to get in touch with DRGR.

Did a quick run through. Notice significant lag with my screenshare. Likely switch to someone else.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|New Primitives
|Complete.
|Mon-03-02-2020
|Sat-04-18-2020
|Sun-04-19-20
|}

==Saturday April 18, 2020 ==
'''Individual Work'''

<u>Downloading Pareto Front</u>

[[files/Seeding from file bug.png|thumb|seeding_from_file_bug *on pace*]]This command was altered from the original command from Feb 23.
* select `individuals`.* FROM `individuals` inner join `paretofront` on `individuals`.hash=`paretofront`.hash where 1 ORDER BY `individuals`.`evaluation_gen` DESC
* I was unable to export the query results.
* clicking the export button exported the most recent table I was viewing.
Solution

1. create table tmp_export select `individuals`.* FROM `individuals` inner join `paretofront` on `individuals`.hash=`paretofront`.hash where 1  ORDER BY `individuals`.`evaluation_gen`  DESC  

2..  create table pareto_export SELECT `hash`,`elapsed_time`,`retry_time`,`age`,`evaluation_status`,`evaluation_gen`,`evaluation_start_time`,`tree`,`error_string`,`FullDataSet RMS Error`,`FullDataSet Accuracy Score`,`FullDataSet Num Elements` FROM `tmp_export`

I was able to choose the columns I wanted from a dropdown menu on the right. I clicked on the columns you want to include from the list on the right, and phpadmin will add them to the sql query. But, you'll need to add commas yourself.

3. refresh schema and goto newly created pareto_export table.

4. Click on the export tab on the top, select csv for the format.

5. For export method select custom, a menu will pop up. scroll down and check the last box 'put column names in first row'. Then press go. 

6. A download should be initiated titled pareto_export.csv.

Step 2 was added to avoid downloading the pickle information, which became really messy and made it hard to parse for analysis.

<u>Final Slides</u>

Update with gif of pareto front AUCs and pareto front individual for baseline toxicity run.

<u>Launching Emade with New Primitives</u>
* Setup 1
** mkdir nlp-nn
** scp src/, datasets/toxicity, templates/, reinstall.sh, glove file.
** Failed with error.
*** Seeding was parsing individuals incorrectly and cut many trees short. --> Hash conflicts (many trees share common subtrees)
**** Tried removing whitespace/tabs
**** Could not find any bugs in gp_framework_helper. Primitives were all added to pset correctly.
*** Master Error: Objective Num Elements failed to be evaluated, returning the exception object of type 'MutableObject' has no len()  At least one objective returned inf. --NNLearner(ARG0, MultiLabelOutputLayer(ARG0, DropoutLayer(0.9, LSTMLayer(8, EmbeddingLayer(100, ARG0, falseBool)))))

* Setup 2
** use the copy of pace-emade from yesterday
** scp new files after moving old files to temporary directory.
** This fixed problems from setup 1
*** My guess is I was missing files related to reinstall in nlp-nn dir.
*** Future semesters should consider creating a pace-emade GitHub repo on their personal accounts, separate from Emade.
*** VCS would have been very helpful when trying different things specific to pace-ice
*** .git dir may be smaller with unnecessary files deleted.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|New Primitives
|In progress. Most new student primitives integrated and pass unittest. Waiting for full emade run.
|Mon-03-02-2020
|Sat-04-18-2020
|
|}

== Friday April 17, 2020 ==
'''Scrum'''

<u>Primitive Updates</u>

New Students had made pull requests/start their slides. Anish begins working on merging those.

Bek is working on BBox. He is hopeful of completion before the presentation.

<u>Running Emade</u>

Pace-ice runs made it past gen 100. 

Mohan and I work on finding a good number of instances for our runs. 

Evenutally fall back on 2000 instances. 

We also tried to raise the memory limit on colab. 
* attempts were unsuccessful since Colab consistently disconnects. 
* this sometimes requires restarting the entire setup, recloning emade, conda env, fix deap selDCD error, etc. 
* fall back to pace-ice. 
* binary search to find walltime with GPU settings. 8hrs max. 
* launched emade without new primitives. 
<u>PBS script</u> 

<nowiki>#</nowiki>PBS -N masterGPU-toxic 

<nowiki>#</nowiki>PBS -l nodes=1:ppn=2:nvidiagpu #main line for requesting GPU

<nowiki>#</nowiki>PBS -l pmem= 7gb #did not try raising this number

<nowiki>#</nowiki>PBS -l walltime=8:00:00 #lower walltime when asking for GPU

<nowiki>#</nowiki>PBS -q pace-ice-gpu #not sure if required.

<nowiki>#</nowiki>PBS -j oe

<nowiki>#</nowiki>PBS -o masterGPU3Apr16.out #errors and output are written here. Only appears after job ends.

<nowiki>#</nowiki>PBS -m abe

<nowiki>#</nowiki>PBS -M rkan3@gatech.edu  #email notification about job start/end time

cd ~/pace-emade

nvidia-smi > master_gpu3_info.txt.    #prints into about GPU used?

echo "Started on `/bin/hostname`"               # prints the name of the node job started on

module load java/1.8.0_25

module load openmpi/2.1.1

module load glib/2.40.0 

module load gcc/4.8.0

module load anaconda3/2019.03

conda activate envEMADE

echo 'running didLaunch'

python src/GPFramework/didLaunch.py myPickleFile18256.dat -ma -d mysql+pymysql://i25Ge3Mztx:0mGbcIIR3Q@remotemysql.com/i25Ge3Mztx -r

'''Individual Work'''

<u>Code Cleanup</u>

Cleanup: removed a method called InitLayerList, which simply returned an empty string. Some changes were made to gp_framework_helper to accomodate that deletion.

For whatever reason, the master process, during mutation, tried to add a terminalNode that uses LayerList class. Undoing the code cleanup fixed things. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|MultiLabel
|Complete. Dummy run ran smoothly.
|Sun-04-12-2020
|Fri-04-17-2020
|Fri-04-17-2020
|-
|New Primitives
|In progress. New students made pull requests. Anish is verifying them.
|Mon-03-02-2020
|Fri-04-17-2020
|
|-
|ChestXRay Integration
|On Hold.
|Mon-03-30-2020
|Sun-04-12-2020
|
|}

== Thursday April 16, 2020 ==
'''Bluejeans Call with Mohan/Anish'''

While I setup pace-ice, they try to get GPUs for pace jobs.

Eventually, they add the folllowing 3 lines to the pbs script.
* #PBS -l nodes=1:ppn=2:nvidiagpu #asks for GPU

* #PBS -q pace-ice-gpu #not sure if needed
* nvidia-smi > master_gpu3_info.txt #prints info about GPU
In hindsight, we did not fully verify if a GPU was used.

The runtime on 2000 instances <u>felt</u> slower than Colab.

Unfortunately, I did not check the elapsed time on Colab.

Pace-Ice: 200 seconds, without new student primitives.

'''Individual Work: Pace-Ice'''

Start up dummy pace ice with just 5 instances.

Observe that worker successfully evaluates all trees, but master does not update them.

Cancelling the jobs was the only way for pace-ice to generate the output/error files.

Master was not erring, but it kept printing GoodMorning/GoodNight.

Looking in the code, master will only do evolution if len(parents) < minQueueSize, which I had set to 0.

Changed minQueueSize to 6 and restarted. Emade was on gen 5 before I went to bed.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|MultiLabel
|Passes unittest and local run. Need to verify emade can run.
|Sun-04-12-2020
|Thu-04-16-2020
|
|-
|New Primitives
|In progress. Hand off to new students. Also renamed task.
|Mon-03-02-2020
|Mon-04-013-2020
|
|-
|ChestXRay Integration
|On Hold.
|Mon-03-30-2020
|Sun-04-12-2020
|
|}
== Wednesday April 15, 2020 ==
[[files/Colab Space.png|thumb|colab space usage spike]]
'''Individual Work: Multilabel'''

<u>Tensorflow 1.x -> 2.0</u>

Update some code to 2.0

<u>Multilabel Accuracy</u>

Hop on this since Mohan is busy.

Due to Emade Target issues from April 14, current accuracy score does not work with multilabel

Added new multilabel_accruacy eval method.

<u>Colab RAM/Disk Space</u>

1. RMS is erroring out when evaluating on the full dataset.
* "Objective RMS Error failed to be evaluated, returning the exception operands could not be broadcast together with shapes (0,) (63977,5) It was detected that the individual performed perfectly. At least one objective returned inf."
2. Colab crashes with memory alloc error when evaluating on the full dataset. Works with just 5 and 2000 instances.
* Observed that RAM usage was spiking right as predictions are loaded into the data_pair
3. EmadeData uses a python list to hold EmadeDatatInstances.

4. Conclusion: colab cannot handle so much data.

5. Possible solutions
* Pace-Ice with GPUs. (Tried CPUs yesterday. too slow)

* Refactor EmadeData to use numpy arrays.
* Run on subset of data.
* Pulak and Icehammer
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|MultiLabel
|In progress. Add Multilabel Acc Eval Method.
|Sun-04-12-2020
|Wed-04-15-2020
|
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1vGWQpaWf8FM4PDnd7EG04vEDL_XD7tkP4nuKf33Q3gY/edit list]..
|In progress. Hand off to new students.
|Mon-03-02-2020
|Mon-04-013-2020
|
|-
|ChestXRay Integration
|On Hold.
|Mon-03-30-2020
|Sun-04-12-2020
|
|}
== Tuesday April 14, 2020 ==
'''Individual Work: Multilabel'''

<u>Emade Target</u>

Normally, single label targets are stored in np.ndarray.
* Lots of places will only grab the first element in that array.
* Multilabel targets are the entrie array, not just the first element
* Make changes to account for this.
<u>Eval Methods: RMSE</u>
* Update unittest to cover eval methods. Testing RMSE.
* Fix shape error
<u>Note on testing setup</u>
* Running emade locally
* Restrict to 5 instances for quick unittests.
* Use remotemysql.
<u>Colab</u>
* Crashes. see point #2 under Colab in entry Wed April 15.
<u>PACE</u>
* Set up: Make a copy of pace-emade
** replace relevant files with scp -r SRC rkan3@pace-ice.pace.gatech.edu:/nv/pace-ice/rkan3/
** remotemysql
*** Server : remotemysql.com  Username:  i25Ge3Mztx  Password:  0mGbcIIR3Q  Database name:  i25Ge3Mztx
***Server : remotemysql.com:3306  Username:  tIrqYMOGdJ  Password:  oGP2HCoJnB  Database name:  tIrqYMOGdJ
***Server : remotemysql.com:3306  Username: pvGSBko1Wo  Password: tEWub8fqvl  Database name: pvGSBko1Wo
** terminate launchEMADE.py right after pickle file is created.
** copy the python command for running didLaunch.py into a pbs script.
*** this command was retrieved from a slurm script generated by launchEMADE a couple months ago.
*** use goodPickelFile.dat in this command
*** rename newly created pickle file to goodPickleFile.dat as needed.
*** qsub master.pbs first, then qsub worker.pbs.
*** *always seed beforehand.
* Results
** Seeding works.
** Master works(* later found out it does not work entirely).
** I know this since, the database was populated twice.
*** First, seeding script put in NNLearners.
*** Second, master put in randomly generated trees.
** Worker is too slow. All NNLearners are stuck in "In Progress" status.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|MultiLabel
|In progress. Account for how Emade stores targets. Fixed shape error.
|Sun-04-12-2020
|Tue-04-14-2020
|
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1vGWQpaWf8FM4PDnd7EG04vEDL_XD7tkP4nuKf33Q3gY/edit list]..
|In progress. Hand off to new students.
|Mon-03-02-2020
|Mon-04-013-2020
|
|-
|ChestXRay Integration
|On Hold.
|Mon-03-30-2020
|Sun-04-12-2020
|
|}
== Monday April 13, 2020 ==
'''Scrum'''

Decided to run emade with only toxicity dataset. 
* Most of the new students are working on NLP primitives anyway
Promised multilabel to be working by the end of the day.

'''Individual Work: Multilabel'''
* Create unittest for sanity check.

* add MultiLabelOutputLayer to primitive set and seeds.
* adjust inputSchema.xsd to accept multilabel info in template.xml
** fix various xml bugs
** <multilabel>
*** set to True, if dataset is multilabel
*** auto set to False, if nonexistent, so preexisting xml files will still work.
*** evaluate_individual() method in the EMADE.py file (line 1509) will check for MultiLabelOutputLayer before evaluating individuals, if this multilabel flag is raised.
** <LabelOrder> and <label>
*** optional, only needed if multilabel and targets need to be converted to bit vectors.
*** <LabelOrder> is the outer tag.
*** Specifiy as many <label> tags as necessary as inner tags.
*** Emade will look for the values of these <label> tags when converting the targets to bit vectors.
*** Relative ordering of labels should not matter, as long as all labels are specified.
* Realize toxicity is already encoded into bitvectors
** additional control logic in launchEMADE.py to deal with this.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|MultiLabel
|In progress.
|Sun-04-12-2020
|Mon-04-13-2020
|
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1vGWQpaWf8FM4PDnd7EG04vEDL_XD7tkP4nuKf33Q3gY/edit list]..
|In progress. Hand off to new students.
|Mon-03-02-2020
|Mon-04-013-2020
|
|-
|ChestXRay Integration
|On Hold.
|Mon-03-30-2020
|Sun-04-12-2020
|
|}
== Sunday April 12, 2020 ==
'''Individual Work'''

<u>MultiLabel</u>
* I found this out later, but Toxicity labels are not the same as ChestXRay. I worked assuming they were like ChestXRay.
* ChestXRay has targets as a concatenation of all labels. e.g. "pneumonia|cancer"
* Toxicity already has labels encoded as a bitvector.

* add method in data.py that converts multilabel target string to a bitmask. target_to_bitmask().
* MultiLabelOutputLayer, which is a Dense layer with the proper output dim.
** output dim is based on the number of labels. will need to grab from xml.
** uses sigmoid actiation to bound output to [0, 1].
** NNLearner already calls np.round on the final output, so no rounding happens in MultiLabelOutputLayer.
* add multilabel and labels tag in input.xml
** add int member in EmadeDataPair, to store the number of labels.
** adjust launchEMADE.py to call target_to_bitmask() and store the multilabel int value.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|MultiLabel
|In progress.
|Sun-04-12-2020
|Sun-04-12-2020
|
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1vGWQpaWf8FM4PDnd7EG04vEDL_XD7tkP4nuKf33Q3gY/edit list]..
|In progress.
|Mon-03-02-2020
|Mon-03-02-2020
|
|-
|ChestXRay Integration
|On Hold.
|Mon-03-30-2020
|Sun-04-12-2020
|
|}
== Saturday April 11, 2020 ==
'''Individual Work'''

<u>Spent the day downloading chestXray.</u> 
* 12 batches. each roughly 10K images. except for the 1st one, which is 5K images.

* The scripts I wrote work well.
** Ended up adding the first small batch of 5K to EMADE only.
** csv file with labels generated nicely.

* I had to free up storage. 

* Went to push and discovered the 2GB limit, even with git lfs.

* This means we cannot compare directly with NeuroAutoML paper results, assuming we store the data on github.
** Will have to train NeuroAutoML best individual train/test/val split that fits in EMADE.
** TODO: discuss with group on Monday.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1vGWQpaWf8FM4PDnd7EG04vEDL_XD7tkP4nuKf33Q3gY/edit list]..
|In progress.
|Mon-03-02-2020
|Mon-03-02-2020
|
|-
|ChestXRay Integration
|In progress. Add small subset of 5000 images. Will note be able to fit full dataset on GitHub.
|Mon-03-30-2020
|Mon-04-10-2020
|
|}

== Friday April 10, 2020 ==
'''Individual Work'''

<u>Miscellaneous Thoughts</u>
* think about how to split chestXray into folds and train test. Folds then split or split then folds?
# look at chestXray data. they already have train_val vs test. So I guess split then folds?
# But, we should use the same procedure as [https://arxiv.org/abs/1902.06827 (Evolutionary Neural AutoML for Deep Learning]). They do 70-20-10 train-val-test.
# How would that compare with EMADE? I only see train and test splits. Need to examine worker evaluation code, then ask DRJZ
* While looking at Evolutionary Neural AutoML for Deep Learning, discovered MTL(I thought meant multilabel, but is actually multitask learning) referencing [50]([https://arxiv.org/pdf/1705.02315.pdf ChestX-ray8: Hospital-scale Chest X-ray])

* Paper mentions 2 ideas which caught my eye.
# weakly-supervised object localization. we should consider this.
# R-CNN https://arxiv.org/pdf/1311.2524.pdf -- Bek was wondering where BBoxes are used in the NN architecture onMonday.
## Appendix A discusses 2 methods for warping bounding boxes to fixed size for CNN.
* List of additional papers I skimmed through
# https://arxiv.org/pdf/1807.05511.pdf  https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf  https://arxiv.org/abs/1408.5093  https://lilianweng.github.io/lil-log/2017/12/31/object-recognition-for-dummies-part-3.html#fast-r-cnn
* From DRJZ Thesis: Section 4.1 Feature Classification: Adult Dataset
** 48,842 points of data = 32,561 TRAINING instances and 16,281 VALIDATION(testing?)
** Take 32,561 data and CV it. "Next, we cross-fold the TRAINING data into 5 training/testing pairs. Each pair comprises 80% training data and 20% testing data."
** Note: tiered dataset happens! "A small sample of the the first fold forms our first tier dataset of 262 training samples and 69 testing samples"
** Takeaway, the train/test splits in the datasets folder comes from a KFOLD of the training data(32K samples)
** Then, to compare with SOTA, evaluate on testing data (16K samples).
*** Need to verify with DRJZ, he mentioned this with Micheal Jurado on Monday. [HINDSIGHT: during final presentation, DRJZ noted that we did benchmark comparison incorrectly.]
*** DRJZ made it clear NO TRANSFER LEARNING is supposed to happen, so I suppose, SOTA is also trained on the same folds as EMADE then, evaluations are done on the TEST(16K).
** Note: the EvoNeuroAutoML uses 70-20-10, meaning 90% training and 10% testing.
*** HOWEVER, this means they did not do KFOLD, since it is IMPOSSIBLE to have 2:7 ratio in KFold. ---> How did they do it? and can EMADE to it that way???
<u>New Todos</u>

verify in the code '''first''' then with DRJZ that my assumption of how EMADE datasets work is correct. KFOLD on Train in EMADE. Compare with SOTA later on TEST.

verify with DRJZ if comparison with SOTA/Benchmarks is on TEST.

figure out how EvoNeuralAutoML does training/testing. with 70-20-10.

<u>Specific Actions</u>

Generated 70-20-10 splits for entire chestXray dataset.

Wrote script to sort new chestXray images according to splits above.

'''SCRUM'''

<u>Cameron</u> error while setting up EMADE locally, has remotesql ready to go. (He has GPU so prefers to have EMADE locally)
* The error is the deap selection error that Eric fixed. .
<u>Anshul</u> jupyter notebook method for GLOVE is deprecated.
* Working on updated version of keras. gets 50% acc which means working ok?
<u>Rishi</u>, working on colab setup should be finished by Monday.

<u>Anish</u>. working on finishing colab documentation. 

<u>Pulak</u>, push multiple GPU and CPU nodes for faster computation.
* Icehammer stuck in queue for 5 days, then workers take 1-2 days to evolve "good" individuals.
* PACE database issues persist.
<u>Mohan</u>, 99% acc on toxicity is because they compare bitwise, not vector wise.
* E.g.: 000000 and 000001 has a 5/6 acc.
* Mohan will look into how to have a fair metric.
* Will also research better loss functions.
<u>Bek</u> is looking at BBox. I referred him to warping as described in R-CNN.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1vGWQpaWf8FM4PDnd7EG04vEDL_XD7tkP4nuKf33Q3gY/edit list]..
|In progress.
|Mon-03-02-2020
|Mon-03-02-2020
|
|-
|ChestXRay Integration
|In progress. Made 70-20-10 splits. Wrote script to sort new images according to those splits.
|Mon-03-30-2020
|Mon-04-10-2020
|
|}

== Monday April 6, 2020 ==
'''Individual Work'''

<u>Figured out how load_images() works</u>
* how it works: it loads image filenames from ith-fold(either train[i] or test[i]) and sorts them

* then reads in the corresponding labels from a labels_[fold[i]].csv file in the sorted order.

* what I did: write a script that takes in fold names and creates the csv file for labels. I can do this since Data_Entry_2017.csv contains labels for all images.
<u>Next: how to split the data?</u> 

foreseeable problems: 
* how to split? Are the splits in the paper tractable in EMADE (since the dataset is so big)? Or a K-FOLD?

* potential fix: do in batches, but may conflict with split method.

'''SCRUM'''

Report on progress with image loader.

Anish is working on Colab notebook for emade.

Bek has been looking into BBox info.
* Had a question about how BBox features would be used in the NN.
* I could only say that BBox patches would need to be extracted during the preprocessing/feature extraction part.
* There's also the question about variable size BBoxes. Feed forward nets take constant size input.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1vGWQpaWf8FM4PDnd7EG04vEDL_XD7tkP4nuKf33Q3gY/edit list]..
|In progress.
|Mon-03-02-2020
|Mon-03-02-2020
|
|-
|ChestXRay Integration
|In progress. Can reuse pre-existing image loader. Wrote script that generates csv with truth labels required by image loader. 
|Mon-03-30-2020
|Mon-04-06-2020
|
|}
== Friday, April 04, 2020 ==
'''NLP-NN Meeting'''

<u>Brought up problem with large dataset.</u>
* DRJZ suggests playing with a smaller set
* also make sure worker mem limits are turned on. Austin may have adjusted that code at some point.
'''Individual Work'''

<u>Dataloaders</u>
* Looked at Mohan's toxicity dataloader for reference.
There are already two loader for images.
* Update todo item: find out preconditions for image loaders.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1vGWQpaWf8FM4PDnd7EG04vEDL_XD7tkP4nuKf33Q3gY/edit list]..
|In progress.
|Mon-03-02-2020
|Mon-03-02-2020
|
|-
|ChestXRay Integration: find out preconditions for image loaders.
|In progress.
|Mon-03-30-2020
|Fri-04-04-2020
|
|}
== Monday, March 30, 2020 ==
'''Scrum'''

Released notebooks. Let new students pick which notebook to work on. They have a week.

'''Draft Rough Schedule for New Students'''

week 2 (Mar30 - Apr5): individual work on 2 notebooks. play with keras, explore CV primitives

week 3 (Apr6 - Apr12): read/understand neural_net.py. add any new primitives/features from notebook to neural_net.py

week 4 (Apr13 - Apr19): run Emade with new primitives and debug. Goal is just to see their code working in Emade, i.e. show some evolved/evaluated individuals that use their primitives.

Monday Apr 20: Final Presentation - talk about their primitive

'''Personal Progress'''

Self assigned task: chestXray dataset integration.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1vGWQpaWf8FM4PDnd7EG04vEDL_XD7tkP4nuKf33Q3gY/edit list]..
|In progress.
|Mon-03-02-2020
|Mon-03-02-2020
|
|-
|ChestXRay Integration
|In progress.
|Mon-03-30-2020
|Mon-03-30-2020
|
|}

== Friday, March 27, 2020 ==
'''NLP-NN Meeting'''

Not many new students were able to attend.

Bek sent some links to blog posts with notebook discussing Toxicity.
* I think they look good. Team agrees.
* We'll send out both notebooks when I wrap up the chestXray notebook.
Asked for help with the DiskSpace Issue.
* Anish points out that I am using a python list for the images.
'''Individual Work: Post Meeting'''
* I converted to numpy. This was quick enough for me, but still too slow for Anish's laptop.
* Decide to use just 50 images and generate the train/test split using the image file names only.
** All new students get the same splits. Easier to compare results.
** Operating on filenames is much faster.
** Small dataset is quick to load and faster to train.
* Notebook is ready to go!
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1vGWQpaWf8FM4PDnd7EG04vEDL_XD7tkP4nuKf33Q3gY/edit list].
|In progress.
|Mon-03-02-2020
|Mon-03-02-2020
|
|-
|ChestXRay Notebook
|Complete
|Mon-03-23-20
|Thu-03-26-20
|Fri-03-27-2020
|}

== Thursday, March 26, 2020 ==
'''Individual Work'''
* DictReader: the layout of the truth table seems to lend itself to the use of csv.dictreader.
* Getting the shapes of the network layers to match took some work.
* Odd OS/hardware compatibility error. see below for message.
** Encountered the error when trying to train the keras model.
** fix: add the following line
** if sys.platform == "darwin": os.environ['KMP_DUPLICATE_LIB_OK']='True'
Full Error Message

2020-03-26 18:15:46.852708: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA

To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.

2020-03-26 18:15:46.857022: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.

OMP: Error #15: Initializing libiomp5.dylib, but found libiomp5.dylib already initialized.

OMP: Hint: This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see <nowiki>http://www.intel.com/software/products/support/</nowiki>.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1vGWQpaWf8FM4PDnd7EG04vEDL_XD7tkP4nuKf33Q3gY/edit list].
|In progress.
|Mon-03-02-2020
|Mon-03-02-2020
|
|-
|ChestXRay Notebook
|In progress. Fixed OS error. Using DictReader. Now my disk is running out of memory.
|Mon-03-23-20
|Thu-03-26-20
|
|}

== Wednesday March 25, 2020 ==
'''Individual Work: Struggles with Notebook''' 

Many trials and tribulations with image types. RGBA(72~ish) vs Grayscale(rest). 

Planned to convert all images to grayscale, but wasted a lot of time trying to write converted RGBA back into file.
* plt.imsave did not seem to overwrite the file.

* np.save created a new file with .npy ending
** Any attempts to use os.rename messed up file metadata.
** So subsequent attempts to read the file get the following error.

...
 ValueError: invalid PNG header

Eventually decide to keep original files and only convert in the notebook. Do not write back.

Still need to get the truth labels, from Data_Entry_2017.csv.
* plan is to disregard other data included in the file as the focus is on the CV task.
* will potentially use info BBox_List_2017.csv, later on in emade, but exclude from notebook for now.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1vGWQpaWf8FM4PDnd7EG04vEDL_XD7tkP4nuKf33Q3gY/edit list].
|In progress. 
|Mon-03-02-2020
|Mon-03-02-2020
|
|-
|ChestXRay Notebook
|In progress. Solved conversion. Moving on to Truth Labels.
|Mon-03-23-20
|Wed-03-25-20
|
|}

== Tuesday March 24, 2020 ==
'''Group Work'''

Looked at Pulak's old notebook. He uses AG dataset. Some of the cells can be reworked for the toxicity dataset.

Bek and I decide to split up the task. I will handle chestXray; Bek gets toxicity.

'''Individual Work'''

ChestXRay is huge. 12 compressed files sum to 42GB.

Decide to use smallest file (4999) images. Need to work on getting into jupyter notebook.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1vGWQpaWf8FM4PDnd7EG04vEDL_XD7tkP4nuKf33Q3gY/edit?usp=sharing list].
|In progress. Updated the link.
|Mon-03-02-2020
|Mon-03-02-2020
|
|-
|ChestXRay Notebook
|In progress 
|Mon-03-23-20
|Tue-03-24-20
|
|}

== Monday March 23, 2020 First Online Meeting ==
'''Main Scrum'''

Mohan did his best as scrum representative

As always I was impressed by oragnizaition of other subteams.

'''Breakout'''

Kinda of disorganized.

Got through introductions/summariation of previous work

Decided focus to be on Neural Network. Pulak will work ongathering data for stats test. I need to polish stats scripts for future use.

Heavy Keras api usage results in decision to have first semesters train their own model on new Toxicity(NLP) and ChestXRay(CV) dadtasets. BOth datasets are multiclass. (I resolved misunderstanding of 'multiclass', they mean multilabel)

This serves 2 main purposes:
# new members gain familiarity with Keras. will be useful in neural network dev
# the flexibility for new members to design own model let's our subteam explore new functionality especially for CV primitives.
'''Personal Progress'''

MultiLabel
* Previously thought Anish/Mohan were referring to MultiClass (like AG news datasets).
* Mohan helped clear that up.
* I think 1 solution would be to convert the labels to a bitmask.
Merged Reagan/Anish todolists into one. Links to [https://docs.google.com/document/d/1vGWQpaWf8FM4PDnd7EG04vEDL_XD7tkP4nuKf33Q3gY/edit?usp=sharing new list] will be updated from this notebook entry and onwards. Previous entries will go to old list.

Self-assign new task, organized jupyter notebook to work with chestXRay/Toxicity dataset for first semester students to work on. 
* Work with Bek
* Goals for 1st Semester Students
** Understand vectorizers
** Get familiar with Keras
** Identify architectures new to nlp-nn branch.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1vGWQpaWf8FM4PDnd7EG04vEDL_XD7tkP4nuKf33Q3gY/edit?usp=sharing list].
|In progress. Updated the link.
|Mon-03-02-2020
|Mon-03-02-2020
|
|-
|ChestXRay/Toxicity Notebook
|In progress 
|Mon-03-23-20
|Mon-03-23-20
|
|}

== Friday March 13, 2020 Spring Break ==
No meeting, all members except Pulak are out of town.

== Monday March 9, 2020 Midterms ==
Impressed by the bootcampers. Their presentations include information I would not have known at the end of my bootcamp (unbalanced datasets, 3D hypervolume plots, etc). 

As expected, 3 obstacles were in the way of having good stats tests.
# Pulak's runs either barely finished gen 0 or never finished.
# data from last semester was not the correct pareto fronts, so the AUCs were very big.
# I scrambled to get past csv errors and misalignment of numpy arras caused by point #1.
Eventually, we discussed Pace issues, and showed a basic boxplot to demonstrate statistical capabilities.

Need to clean up the stats main method. Very clunky now. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1nLf5mz8uO83zDjIhmpoyhlt6ry8lDybdQX2ZoVgZVRM/edit?usp=sharing list].
|In progress
|Mon-03-02-2020
|Mon-03-02-2020
|
|-
|<s>Main method for stats script.</s> Received data from Pulak an 1hr before midterm, scrambled to put together. More work needed to clean up.
|<s>In progress</s> Complete, may revisit for cleanup.
|Sat-02-29-20
|Mon-03-09-2020
|
|-
|PACE-ICE. Consolidating pace-ice issues, and stats test data gathering into 1 item.
|In progress, merged into 1 item. Handoff to Pulak and icehammer.
|Mon-01-06-20
|Mon-03-09-2020
|Mon-03-09-2020
|}

== Sunday March 8, 2020 ==
'''Met on Culc rooftop.'''

<u>Chances of getting good data is very slim.</u>
* Pulak is running 2 runs on icehammer. Not evaluating. 

* Mohan manages to run EMADE locally. very slow.
* Tag up with timeconflictNLP, in hopes that they have pace capability. They are encountering many new problems after Pace maintenance.
<u>Misc</u>

Anish observes an odd looping behavior during individual evaluation.

<u>Try for hypothesis test with samples size of 2.</u>
* Stats scripts still require the main method. I suspect we will run into issues with csv and missing data that will complicate the main method. May need to do many adjustments on the fly before the presentation.

* Also, realize that it took 7 days to get to 30 generations last semester and Pulak can only spin up a run that is < 12 hrs.
** He could repeatedly launch the submitWorker.slurm files to add workers.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1nLf5mz8uO83zDjIhmpoyhlt6ry8lDybdQX2ZoVgZVRM/edit?usp=sharing list].
|In progress
|Mon-03-02-2020
|Mon-03-02-2020
|
|-
|Main method for stats script.
|In progress
|Sat-02-29-20
|Sat-02-29-20
|
|-
|PACE-ICE Seed individuals from Fall 2019.
|In progress
|Mon-01-06-20
|Fri-03-06-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Friday March 6, 2020 ==
'''Individual Work: More PACE'''

<u>Odd occurence</u>
* Tried to submit mysql.pbs on Mohan's pace. Mohan's mysql.pbs, like Bek's from a couple weeks back cancels, before running.
* Is this due to pace maintenance?
<u>Toils with MySQL</u>

On the login node, I can connect to some variants of the rich* host, using my 'password'. 
* (envEMADE) [rkan3@pace-ice pace-emade]$ mysql -h '''rich133-c32-10-r''' -u root -p 
** success 

* (envEMADE) [rkan3@pace-ice pace-emade]$ mysql -h '''rich133-c32-10-r.pace.gatech.edu -u root -p'''
** fail: ERROR 1045 (28000): Access denied for user 'root'@'''<nowiki/>'pace-ice.pace.gatech.edu'''<nowiki/>' (using password: YES)
Submit job. i.e. run: qsub launchEmade.pbs, which runs launchEMADE.py
* '''<nowiki/>'''<nowiki/> launchEmade creates and launches a pbs script 
** <server> some variant of rich </server> #in input.xml.
*** variants: pace, pace-ice, rich133-c32-10-r.pace.gatech.edu, rich133-c32-10-r, etc.
**** fail: sqlalchemy.exc.OperationalError: (pymysql.err.OperationalError) (1045, "Access denied for user 'root'@'rich133-c32-10-r.pace.gatech.edu' (using password: YES)")
*** variant: pace-ice.pace.gatech.edu
**** fail: there is a connection refused error instead.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1nLf5mz8uO83zDjIhmpoyhlt6ry8lDybdQX2ZoVgZVRM/edit?usp=sharing list].
|In progress. Added todo list.
|Mon-03-02-2020
|Mon-03-02-2020
|
|-
|Main method for stats script.
|In progress
|Sat-02-29-20
|Sat-02-29-20
|
|-
|PACE-ICE Seed individuals from Fall 2019.
|In progress. See above for updates.
|Mon-01-06-20
|Fri-03-06-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Monday March 2, 2020 ==
'''NeuroEvoAutoML'''

After discussion with group, we decide to focus on the Toxicity/ChestXRay datasets.

Made a google [https://docs.google.com/document/d/1nLf5mz8uO83zDjIhmpoyhlt6ry8lDybdQX2ZoVgZVRM/edit?usp=sharing doc] with a list of features we want. Mostly features used in the paper that are not in emade.

'''Pace: Maintenance'''

^^
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|NeuroEvoAutoML: Begin ticking off items on the TODO [https://docs.google.com/document/d/1nLf5mz8uO83zDjIhmpoyhlt6ry8lDybdQX2ZoVgZVRM/edit?usp=sharing list].
|In progress
|Mon-03-02-2020
|Mon-03-02-2020
|
|-
|Main method for stats script.
|In progress
|Sat-02-29-20
|Sat-02-29-20
|
|-
|PACE-ICE Seed individuals from Fall 2019.
|In progress
|Mon-01-06-20
|Fri-02-21-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Saturday Feb 29, 2020 - Hackathon ==
This is the first hackathon not held on a rainy day!

'''Stats Scripts'''

Fix bugs, etc. complete remainder of the skeleton stats methods, with Bek.

Note: still missing the main method that takes in the csv files and runs the tests.
* Still unsure what the format of the csv will be, since Pulak may or may not be able to successful join the two tables.
* tentatively put on the todo list. Will likely be unable to far in advance of midterm.
'''Pace/Icehammer'''

Pace maintanence is ongoing.

Pulak is out of town.

A more realistic goal for the midterm may be to demonstrate hypothesis testing capability. Just show we are ready to go anytime as long as data is gathered.

'''NeuroEvoAutoML'''

Main idea: the authors were successful in building upon codeepneat.

Quantitative results on 2 new datasets. Toxicity(NLP) and ChestXRay(Image)

DRJZ suggests using the same datasets for a fair "apples to apples" comparison.

Tentative goal? Ramp up neural_network_methods.py with more NLP/CV primitives and use paper as a benchmark comparison.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Discuss what to do about: [https://arxiv.org/abs/1902.06827 NeuroEvoAutoML] 
|In progress. See above for details.
|Sat-02-29-20
|Sat-02-29-20
|
|-
|Main method for stats script.
|In progress
|Sat-02-29-20
|Sat-02-29-20
|
|-
|PACE-ICE Seed individuals from Fall 2019. 
|In progress
|Mon-01-06-20
|Fri-02-21-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Friday Feb 28, 2020 ==
'''Subteam meeting'''

Pair code with Bek. Explain numpy keyword arg: axis.

Painfully watch Bek upload a file to github. Explain git basics for add, commit, push, pull.

'''Icehammer'''

Pulak has icehammer ready to go. Discussed which seeding files to use, where to control use of our primitives, etc. Plan to do 2 runs, 1 control, 1 variable. both are seeded.

'''PACE'''

Pace maintenance prevent discussion with Alex/Pulak.

'''Personal Progress'''

Finish unitttest for mean/variance/pvalues.

Main new task, read that paper Mohan sent by tomorrow for discussion with DRJZ.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Skim [https://arxiv.org/abs/1902.06827 NeuroEvoAutoML] paper.
|In progress
|Fri-02-28-2020
|Fri-02-28-2020
|
|-
|<s>Make unittests for items #1,2,3 on todo list.</s>
|<s>In progress</s> Complete
|Fri-01-31-20
|Sun-02-09-2020
|Fri-02-28-2020
|-
|PACE-ICE Seed individuals from Fall 2019. 
|In progress
|Mon-01-06-20
|Fri-02-21-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Monday Feb 23, 2020 ==
'''Pareto Info'''

DRJZ provides general mysql command for joining two tables in a schema based on criteria. For us, it's the hash and generation. This must mean that the hash of the string representation of a tree is computed at the very start. Otherwise the same individual would have different hashes as it evolves.

general idea of the sql command from DRJZ: select individuals.* from individuals inner join paretofront on individual.hash=paretofront.hash where paretofront.generation=GENERATION_I_CARE_ABOUT
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|<s>Ask DRJZ about pareto history.</s> See above for solution.
|<s>In progress</s> Complete
|Fri-02-21-20
|Fri-02-21-20
|Mon-02-23-20
|-
|Make unittests for items #1,2,3 on todo list.
|In progress
|Fri-01-31-20
|Sun-02-09-2020
|
|-
|PACE-ICE Seed individuals from Fall 2019.
|In progress
|Mon-01-06-20
|Fri-02-21-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Friday Feb 21, 2020 ==
'''PACE'''

Alex has emade running on pace. 

He left while I was focused on looking at error files., so I did not get to ask him all my questions.
* I've verified that I did the same mysql steps as he did.
* .my.cnf files look the same. I added the single line that differed.
* He did not have the squeue error.
* Pulak showed me how to get past squeue error. comment out 3 lines. 1 squeue 2 sbatch 1 qhost
** weird error: qsub: submit error (No default queue specified MSG=requested queue not found)
** Pulak suggest adding #PBS -o emade.out in .pbs script.
** replaced qhost with qstat. right above grid cluster detected.
** did not successfully repicate Pulak's error due to "requested queue not found error"

* Focus on making Unittests
'''Notebook:''' spent time updating notebook

'''Hypothesis testing:'''

<nowiki>*</nowiki>'''CAUTION'''* I think I accidentally created a new branch called adf, while searching for code from the ADF sub-team. I will contact DRJZ and have him handle this, since I am not 100% sure if this 'adf' branch is something I made or a branch with actual adf  work.

<nowiki>***</nowiki> CSV file of data from MySQL does not contain information for all generations. It will only keep the info from the latest generation. All data for a particular individual from prior generations is wiped out.

<nowiki>**</nowiki>potential fixes:
# Find a file that has info with all gens.
## I’ve looked out emade_worker.out files. They print out hash, fitness, age, eval time, does not include generation. Ask DRJZ.
## CSV does not have history.
# Edit Emade Worker Process to save this data
# Ask ADF team. How did they do their tests?
'''Link to commits: https://github.gatech.edu/emade/emade/commits/nlp-app/?author=rkan3'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Ask DRJZ about pareto history
|In progress
|Fri-02-21-20
|Fri-02-21-20
|
|-
|Make unittests for items #1,2,3 on todo list.
|In progress
|Fri-01-31-20
|Sun-02-09-2020
|
|-
|PACE-ICE Seed individuals from Fall 2019. See updates about squeue error above.
|In progress
|Mon-01-06-20
|Fri-02-21-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Monday Feb 17, 2020 ==
'''Pace-Ice'''

Keep 2 versions locally. Use [https://meldmerge.org/ Meld] for comparison.
* need to: git lfs install, git clone emade, cp -r emade pace-emade, delete .git and other files, sftp onto emade.

pros for pace: gcp credit expire. pace-ice is relatively permanent and convenient.

'''Peer evals and notebooks'''

Todo list. Results. Git Commits. Accomplishments and Goals. Problems. Personal contributions.

'''GCP can just use mysqlworkbench to connect to ip-address of GCP.'''

Adf team agrees downloading csv file is more convenient than their method of retrieving results from gcp runs.

Need to adjust the todolist to just read from csv. Also self assign for task #1 and unittest for #1,2,3.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Make unittests for items #1,2,3 on todo list.
|In progress
|Fri-01-31-20
|Sun-02-09-2020
|
|-
|PACE-ICE Seed individuals from Fall 2019. 
|In progress
|Mon-01-06-20
|Fri-02-14-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Friday Feb 14, 2020 ==
[[files/Give everyone permission.png|thumb|give_everyone_permission]]'''Pace-Ice'''

<u>Talked very briefly with Alex.</u>
* Putting aside small issues, seems he has Emade running on Pace-Ice?!

* Time-conflict team meeting ends before ours. Many questions.
** No processing problems
** I tried his mysql fix. Getting the same permission denied error.
<u>Personal Progress</u>
* Tried Alex's fix: giving root."*" (wildcard) all permissions. still getting the "new" permission denied error. I can use mysql to login.

* Spent rest of the meeting explaining to Bek how todo list functions would play into hypothesis testing. {| class="wikitable" !Task !Current Status !Date Assigned !Suspense Date !Date Resolved |- |Make unittests for items #1,2,3 on todo list. |In progress |Fri-01-31-20 |Sun-02-09-2020 | |- |PACE-ICE Seed individuals from Fall 2019. login node: charset error. qsub: sqlalchemy host is not allowed to connect to this MySQL server. <s>Tried adding specific host rich133-c32-10-r.pace.gatech.edu</s>. '''Tried giving all hosts permission to access mysql server (see photo).''' Still does not work as described above. |In progress |Mon-01-06-20 |Fri-02-14-20 | |- |PACE-ICE Run for N generations. |In progress |Mon-01-06-20 |Mon-01-06-20 |}
== Monday Feb 10, 2020 ==
'''Scrum'''

DRJZ absent. Not much updates from us.

'''Breakout'''

<u>Stats Todo</u>

Bek had some questions. I clarified and made necessary adjustments to function descriptions in todo list.

<u>Pace-Ice</u>

For the first time, tried running seeding script as a qsub job, on Sunday Feb 09.

Now, the charset is no longer an error. Instead, I get permission denied(NEW error) or "root"@"rich133....pace-ice.pace.gatech.edu" is not allowed to connect to this mysql !?!(OLD see Feb09 post.
* I know my password for root user. permission denied implies qsub job is trying to connect to a different mysql than the one I connect to. on login node.
* Now that I think about it, "is not allowed to connect error" could also be caused by connecting to different mysql instances.
* MySql version is different between login node and internal compute node. Otherwise we should be getting the charset error.
'''Bek''' inquired about my progress. I decided to try some things on his pace-ice.
* launch a job that starts mysql instance.
* setup root password
* tried variations of <server> parameter.
* Realized that Bek's mysql job is repeatedly shutdown. 
** Is it because I have one running? I shared my scripts after all.
** The compute node is always rich133-c32-10-r. Bek thinks this may be a sign. I disagree. <rich...> may be referring to group of nodes. This is absed off of output of pbs file qsub submission. "Selected nodes are"... always lists several nodes of the type <rich...>.
* Bek also gets permission denied (relatively NEW).
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Make unittests for items #1,2,3 on todo list.
|In progress
|Fri-01-31-20
|Sun-02-09-2020
|
|-
|PACE-ICE Seed individuals from Fall 2019. login node: charset error. qsub: sqlalchemy host is not allowed to connect to this MySQL server. Tried adding specific host rich133-c32-10-r.pace.gatech.edu. Still does not work as described above.
|In progress
|Mon-01-06-20
|Sun-09-24-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Sunday Feb 09, 2020 ==
'''MySQL (PACE-ICE)'''

Met with time-conflict people.

Alex has not a gzip file error. I think might be gi lfs. , but we get permission denied error.

Alex potential fix: sftp SSH file transfer protocol. Not yet tested.

Anuraag/Zack work on conda envs, mysql launched as job.

ERROR 2003 (HY000): Can't connect to MySQL server on 'rich133-c32-10-r' (111). Problem since Friday. Usually solved by trying in 10-15 min.

Reagan: try seeding script as qsub script. get new error: sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1130, "Host 'rich133-c32-10-r.pace.gatech.edu' is not allowed to connect to this MySQL server")
[[files/Hosts with permission to connect to root user.png|thumb]]
Tried the following
* giving <rich .. .edu> [https://stackoverflow.com/questions/19101243/error-1130-hy000-host-is-not-allowed-to-connect-to-this-mysql-server permission]
* noticed that pace-ice.gatech.edu was in permissions list. put pace-ice in <server> in templates.
* neither worked.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|<s>Add to Google Doc and Assign functions.</s>  Bek has taken a task. I added unittests to list and self assigned. Did not assign for Mohan/Pulak/Anish since they are all dedicated to a separate task.
|In progress
|Fri-01-31-20
|Sun-02-09-2020
|
|-
|<s>Try to update mysql installation on pace-ice. Does not seem to work.</s> This is no longer needed since we will be launching emade as a job.
|In progress
|Mon-02-03-2020
|Sun-02-09-2020
|Sun-02-09-2020
|-
|PACE-ICE Seed individuals from Fall 2019. <s>Fails with the same error as a MOAB job and executing directly in the login node.</s> Just deisproved. login node: charset error. qsub: sqlalchemy host is not allowed to connect to this MySQL server. Tried adding specific host rich133-c32-10-r.pace.gatech.edu. Still does not work as described above.
|In progress
|Mon-01-06-20
|Sun-09-24-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Friday Feb 07, 2020 ==
'''MySQL (PACE-ICE)''' 

DRJZ has forwarded problem to pace-ice people. 

Not much progress on my end. I'm afraid of breaking things while trying to upgrade mysql. 

Caught up with Alex. 
* Time-conflict group are cloning EMADE onto pace login. 
* Alex has tried single node access to some degree. 
* They may meet up 12pm or 1pm Sunday. I might join or at least Slack or video in. 

'''MySQL (Local)'''

Anish and Bek try connecting to each others MySQL locally. Failed.

Later Anish realized not connected to eduroam. May have influenced results.

'''Pulak'''

Pulak is sick.  

He is working on Multiprocessing side of Emade, since MOAB does not use slurm. 

He does has access to ICEHAMMER. Hence my decision to shift more focus to stats scripts. 

'''Stats Scripts'''

After unsuccessful MySQL test w/ Anish, Bek self-assigned a task from TODO list.

I begin drafting unit tests for the stats scripts. Pushed template src and test files for stats.

'''Google Cloud'''

DRJZ showed Mohan procedure for google cloud setup.

Suggestion: GUI problems in the past. try command line.

Mohan is working on it. In contact with ADF group.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|<s>Add to Google Doc and Assign functions.</s>  Bek has taken a task. I added unittests to list and self assigned. Did not assign for Mohan/Pulak/Anish since they are all dedicated to a separate task.
|In progress
|Fri-01-31-20
|Fri-01-31-20
|
|-
|Figure out mysql connection: Try to update mysql installation on pace-ice. Does not seem to work.
|In progress
|Mon-02-03-2020
|Mon-02-03-2020
|
|-
|PACE-ICE Seed individuals from Fall 2019. Fails with the same error as a MOAB job and executing directly in the login node.
|In progress
|Mon-01-06-20
|Mon-01-24-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Tuesday Feb 04, 2020 ==
'''Email DRJZ'''

Included info about mysqld_safe on compute node and connection to compute node resulting in charset error.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Add to Google Doc and Assign functions. Need to pickup the pace.
|In progress
|Fri-01-31-20
|Fri-01-31-20
|
|-
|<s>Email DRJZ about MySQL situation.</s>
|<s>In progress.</s> Complete
|Mon-02-03-2020
|<s>Mon-02-03-2020</s>
|Tues-02-04-2020
|-
|Try to update mysql installation on pace-ice.
|In progress
|Mon-02-03-2020
|Mon-02-03-2020
|
|-
|PACE-ICE Seed individuals from Fall 2019. Fails with the same error as a MOAB job and executing directly in the login node.
|In progress
|Mon-01-06-20
|Mon-01-24-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Monday Feb 3, 2020 ==
'''Dr. Rohling & DRJZ: Notebooks'''

Notebook spot checks starting Sunday. Will be factored into final grade.

'''Notes from talk with DRJZ'''

Send to DRJZ.

Want to start mysql server locally and connect from pace-ice.

able to ping from pace-ice to local.

mysqlh did not work.

Is this a problem with eduroam lawn

or can we start a sql instance on pace-ice.

'''Ver 5.5.3+.'''

Some sites indicate that we need to update mysql version to 5.5.3+.

Currrent version:

<u>(envEMADE) [rkan3@pace-ice emade]$ mysql -V</u>

<u>mysql  Ver 14.14 Distrib 5.1.73, for redhat-linux-gnu (x86_64) using readline 5.1</u>

'''Current char sets of mysqld session'''

mysql> SHOW SESSION VARIABLES LIKE 'character\_set\_%';

+--------------------------+--------+

| Variable_name            | Value  |

+--------------------------+--------+

| character_set_client     | latin1 |

| character_set_connection | latin1 |

| character_set_database   | latin1 |

| character_set_filesystem | binary |

| character_set_results    | latin1 |

| character_set_server     | latin1 |

| character_set_system     | utf8   |

+--------------------------+--------+

7 rows in set (0.00 sec)

'''Adjust .my.cnf file'''

Tried adding following to my.cnf file. (this messes with mysql, so I removed it Tues Feb 4)

[client]

default-character-set = utf8mb4

'''Full error'''

Traceback (most recent call last):

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2276, in _wrap_pool_connect

return fn()

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 363, in connect

return _ConnectionFairy._checkout(self)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 773, in _checkout

fairy = _ConnectionRecord.checkout(pool)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 492, in checkout

rec = pool._do_get()

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 139, in _do_get

self._dec_overflow()

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__

compat.reraise(exc_type, exc_value, exc_tb)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 153, in reraise

raise value

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 136, in _do_get

return self._create_connection()

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 308, in _create_connection

return _ConnectionRecord(self)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 437, in __init__

self.__connect(first_connect_check=True)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 662, in __connect

).exec_once_unless_exception(self.connection, self)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/event/attr.py", line 314, in exec_once_unless_exception

self._exec_once_impl(True, *args, **kw)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/event/attr.py", line 285, in _exec_once_impl

self(*args, **kw)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/event/attr.py", line 322, in __call__

fn(*args, **kw)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 189, in on_connect

do_on_connect(conn)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 131, in on_connect

cursor.execute("SET NAMES %s" % charset_name)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute

result = self._query(query)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query

conn.query(q)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query

self._affected_rows = self._read_query_result(unbuffered=unbuffered)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result

result.read()

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read

first_packet = self.connection._read_packet()

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet

packet.check_error()

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error

err.raise_mysql_exception(self._data)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception

raise errorclass(errno, errval)

pymysql.err.InternalError: (1115, "Unknown character set: 'utf8mb4'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):

File "src/GPFramework/seeding_from_file.py", line 162, in <module>

dataset_names=dataset_names, statistics_dict={}, cache_dict={"timeout":"300"})

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/GPFramework-1.0-py3.6.egg/GPFramework/sql_connection_orm_master.py", line 25, in __init__

super().__init__(connection_str, reuse, fitness_names, dataset_names, statistics_dict, cache_dict, is_worker)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/GPFramework-1.0-py3.6.egg/GPFramework/sql_connection_orm_base.py", line 235, in __init__

cache_dict, is_worker, is_cache)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/GPFramework-1.0-py3.6.egg/GPFramework/sql_connection_orm_base.py", line 88, in get_session

engine.execute(text('SET innodb_lock_wait_timeout = ' + cache_dict['timeout']))

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2181, in execute

connection = self._contextual_connect(close_with_result=True)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2242, in _contextual_connect

self._wrap_pool_connect(self.pool.connect, None),

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2280, in _wrap_pool_connect

e, dialect, self

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1547, in _handle_dbapi_exception_noconnection

util.raise_from_cause(sqlalchemy_exception, exc_info)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause

reraise(type(exception), exception, tb=exc_tb, cause=cause)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 152, in reraise

raise value.with_traceback(tb)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2276, in _wrap_pool_connect

return fn()

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 363, in connect

return _ConnectionFairy._checkout(self)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 773, in _checkout

fairy = _ConnectionRecord.checkout(pool)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 492, in checkout

rec = pool._do_get()

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 139, in _do_get

self._dec_overflow()

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__

compat.reraise(exc_type, exc_value, exc_tb)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 153, in reraise

raise value

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 136, in _do_get

return self._create_connection()

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 308, in _create_connection

return _ConnectionRecord(self)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 437, in __init__

self.__connect(first_connect_check=True)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 662, in __connect

).exec_once_unless_exception(self.connection, self)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/event/attr.py", line 314, in exec_once_unless_exception

self._exec_once_impl(True, *args, **kw)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/event/attr.py", line 285, in _exec_once_impl

self(*args, **kw)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/event/attr.py", line 322, in __call__

fn(*args, **kw)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 189, in on_connect

do_on_connect(conn)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/sqlalchemy/dialects/mysql/mysqldb.py", line 131, in on_connect

cursor.execute("SET NAMES %s" % charset_name)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute

result = self._query(query)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query

conn.query(q)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query

self._affected_rows = self._read_query_result(unbuffered=unbuffered)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result

result.read()

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read

first_packet = self.connection._read_packet()

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet

packet.check_error()

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error

err.raise_mysql_exception(self._data)

File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception

raise errorclass(errno, errval)

sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1115, "Unknown character set: 'utf8mb4'")

(Background on this error at: http://sqlalche.me/e/2j85)
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Add to Google Doc and Assign functions. Need to pickup the pace.
|In progress
|Fri-01-31-20
|Fri-01-31-20
|
|-
|Email DRJZ about MySQL situation.
|In progress
|Mon-02-03-2020
|Mon-02-03-2020
|
|-
|Try to update mysql installation on pace-ice.
|In progress
|Mon-02-03-2020
|Mon-02-03-2020
|
|-
|PACE-ICE Seed individuals from Fall 2019. Fails with the same error as a MOAB job and executing directly in the login node.
|In progress
|Mon-01-06-20
|Mon-01-24-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Sunday Feb 02, 2020 ==
run mysql.pbs script (see Jan 31 for complete process)

able to connect to running mysqld instance and set root password (see Jan 31 for complete process)

putting compute node name as server fails with unknown charset. (see Feb 03 entry for full error)
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Add to Google Doc and Assign functions. Need to pickup the pace.
|In progress
|Fri-01-31-20
|Fri-01-31-20
|
|-
|<s>Try to complete mysql multi-node access setup by following directions.</s> Done.
|In progress
|Fri-01-31-20
|<s>Fri-01-31-20</s> Sun-02-02-20
|Sun-02-02-20
|-
|PACE-ICE Seed individuals from Fall 2019. Fails with the same error as a MOAB job and executing directly in the login node.
|In progress
|Mon-01-06-20
|Mon-01-24-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Friday Jan 31, 2020 ==
'''Made google [https://docs.google.com/document/d/1uAkHNQD8d86XneFoFxjwGYxPfzjSWHcLeYKzprN5sps/edit?usp=sharing doc] with list of stats todo functions.'''

'''Alex suggests using mysql on pace.'''

Single-node access fails.

Setup Multi-node [https://docs.pace.gatech.edu/software/mysql/#mysql-on-pace access] from my login node.

1. get into pace-ice login node

2. run the following commands in order

$export SCRATCH=$HOME/scratch

$export DB_DIR=$SCRATCH/db

$mkdir $DB_DIR -p 

$cat << EOF > ~/.my.cnf [mysqld] datadir=$DB_DIR socket=$DB_DIR/mysqldb.sock user=$USER symbolic-links=0 [mysqld_safe] log-error=$DB_DIR/mysqldb.log pid-file=$DB_DIR/mysqldb.pid [mysql] socket=$DB_DIR/mariadb.sock EOF

$ mysql_install_db --datadir=$DB_DIR

[-----only accomplished up to here-----]

[---the final steps were finished on Sunday Feb 02---]

3. put the following in a new file called: mysql.pbs

<nowiki>#</nowiki>!/bin/bash

<nowiki>#</nowiki>PBS -N mysqldb

<nowiki>#</nowiki>PBS -q pace-ice

<nowiki>#</nowiki>PBS -l nodes=1:ppn=1

<nowiki>#</nowiki>PBS -l walltime=01:00:00

mysqld_safe

4. qsub mysql.pbs

5. qstat to look up <job id> (looks like: 8***).

6. lookup <compute node name>: qstat -n <job id>.  (looks like: rich133-c32-10-r) 

7. mysql -u root -h <compute node name>

8. CREATE SCHEMA movie_reviews;

9. SET root password; in login node, run: /usr/bin/mysqladmin -u root password 'password'

10. in .xml file, put <compute node name> in <server></server>
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Add to Google Doc and Assign functions. Need to pickup the pace.
|In progress
|Fri-01-31-20
|Fri-01-31-20
|
|-
|Try to complete mysql multi-node access setup by following [https://docs.pace.gatech.edu/software/mysql/#mysql-on-pace directions].
|In progress
|Fri-01-31-20
|Fri-01-31-20
|
|-
|PACE-ICE Seed individuals from Fall 2019. Fails with the same error as a MOAB job and executing directly in the login node.
|In progress
|Mon-01-06-20
|Mon-01-24-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Monday Jan 27, 2020 ==
'''Scrum'''

ADF: successful short run on GCP. Meanwhile writing stats scripts. Austin made edits, DJRZ want to verify those are in code.

Runs without error. Verify species is correct before integrating into EMDE. (Run Emade. try speciation on individuals.(pairwise distance of tree disimilarity)). Fitness sharing(step in neatGP), limits crossover by species(in progress). neat version of crossover. Written in deap, integrating into EMADE.

DEEP: Wrap data augmentation around keras(refactor to industry standard). torchvision/augmentor libaries. Rod work on inheritance in block class. Out of space on GCP, also using mpi library documentation scarce.

'''Takeaways.'''

Many teams are successful with GCP. Get instructions for that. 

Also plan/write stats scripts for tests. Read stats from sql, then compute.

'''More Pace'''

<u>Test MOAB scheduler and job submission.</u>

Anish shared a simple script that writes to a file with accompanying pbs script.

I think everyone was able to submit and see file with output.

<u>SQL tests by DRJZ</u>

PACE to ___.

ping ipv4: works for Reagan(pace-ice) to Reagan and Anish and Mohan(ip)

commands line: mysql -h -u -p, did not work for Reagan/Anish/Mohan
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|<s>Submit simple non-Emade job to understand qsub command and pbs scripting.</s> Success with Anish's "hello world" test.
|<s>In progress</s> Complete
|Fri-01-10-20
|Fri-01-10-20
|Mon-01-27-2020
|-
|PACE-ICE Seed individuals from Fall 2019. Fails with the same error as a MOAB job and executing directly in the login node.
|In progress
|Mon-01-06-20
|Mon-01-24-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|}

== Friday Jan 24, 2020 ==
'''Trying running seeding file'''

Login node only
# put ipv4 into .xml file. directly run python script on login node. (localhost fails as well)
# could not connect
# File "/nv/pace-ice/rkan3/.conda/envs/envEMADE/lib/python3.6/site-packages/pymysql/connections.py", line 630, in connect  raise exc  sqlalchemy.exc.OperationalError: (pymysql.err.OperationalError) (2003, "Can't connect to MySQL server on '128.61.41.49' ([Errno 110] Connection timed out)")  (Background on this error at: http://sqlalche.me/e/e3q8)
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Submit simple non-Emade job to understand qsub command and pbs scripting.
|In progress
|Fri-01-10-20
|Fri-01-10-20
|
|-
|PACE-ICE Seed individuals from Fall 2019. Fails with the same error as a MOAB job and executing directly in the login node. 
|In progress
|Mon-01-06-20
|<s>Fri-01-10-20</s> Mon-01-24-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Monday Jan 20, 2020 ==
MLK Day. No Scrum.

== Friday Jan 17, 2020 ==
Career fair.

== Monday Jan 13, 2020 ==
'''Scrum'''

All teams have a good idea of their hypothesis tests.

'''Mini-Scrum'''

Another old nlp-neuralnet member(Sakit) showed up, so Mohan switched over to BekReagan group to balance numbers.

Extra time remaining from scrum, read [https://stackoverflow.com/questions/25287981/mpiexec-vs-mpirun documentation]([https://pace.gatech.edu/sites/default/files/pace-ice_orientation_2.pdf slides]) on pace job submissions.

Mohan ssh blocker was just a command typo.

ezCGP team uses mpiexec: stackoverflow [https://stackoverflow.com/questions/25287981/mpiexec-vs-mpirun discussion] on mpirun vs mpiexec
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Submit simple non-Emade job to understand qsub command and pbs scripting.
|In progress
|Fri-01-10-20
|<s>Fri-01-10-20</s> Mon-01-13-20
|
|-
|PACE-ICE Seed individuals from Fall 2019
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Friday Jan 10, 2020 ==
'''PACE install'''

All able to login to individual accounts.

Bek and I successfully cloned EMADE. Still looking into submitting jobs.

Neural Net team needs to move code from Anish's github to nlp-app branch.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|PACE-ICE Login
|<s>In progress</s> Complete
|Mon-01-06-20
|<s>Mon-01-06-20</s>
|Fri-01-10-20
|-
|PACE-ICE Clone EMADE
|<s>In progress</s> Complete
|Mon-01-06-20
|<s>Mon-01-06-20</s>
|Fri-01-10-20
|-
|Submit simple non-Emade job to understand qsub command and pbs scripting.
|In progress
|Fri-01-10-20
|Fri-01-10-20
|
|-
|PACE-ICE Seed individuals from Fall 2019
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

== Monday Jan 06, 2020 ==
'''Stats'''

DRJZ gives lecture on Testing for Statistical Significance. Hypothesis testing.

Slides have useful python code for tests.

'''Plan'''

Bek and I will run test on primitives from last semester.

Goal for now will be to do testing on code form last semester. Split into similar groups as last time.

Need to differentiate between one and two tail tests for stemmatizer and sentiment primitives.

PACE will be useful for doing many EMADE runs. Setting this up will be a priority.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|PACE-ICE Login
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|-
|PACE-ICE Clone EMADE
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|-
|PACE-ICE Seed individuals from Fall 2019
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|-
|PACE-ICE Run for N generations.
|In progress
|Mon-01-06-20
|Mon-01-06-20
|
|}

= *Semester Two - Fall 2019 (recent on top)* =
== Wed Dec 04, 2019 ==
Link to commits.

https://github.gatech.edu/emade/emade/commits/nlp-app/?author=rkan3

Commits from icehammer that I forgot to change author to school account.

https://github.gatech.edu/emade/emade/commit/ce3932d7cffa89ee4fc58f4e30d717cea41dbcb2

https://github.gatech.edu/emade/emade/commit/263b01215b75fae0d6d9c32dd7f6404954760c47

https://github.gatech.edu/emade/emade/commit/f3d2af33be2f25e2ba34cd7516551bebca637323

Link to final presentation slide deck.

https://docs.google.com/presentation/d/1kA_dxlMJSN7iTYzrInNFgjuwnOJpmlkoHsg2z-StMFI/edit?usp=sharing

{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebooks. Due Wed 5pm.
|Complete.
|Mon-12-02-19
|Mon-12-02-19
|Wed-12-04-19
|-
|Peer Evals. Due Wed 5pm.
|Complete.
|Mon-12-02-19
|Mon-12-02-19
|Wed-12-04-19
|-
|<s>Final Presentation Slides</s>
|Complete. Updated with day7 data.
|Sat-11-23-19
|Mon-12-02-19
|Mon-12-02-19
|-
|<s>Make plots for pareto fronts and compute AUC for all gens.</s>
|Complete. day7 data plotted and added to slides.
|Mon-11-25-19
|Sun-12-01-19
|Mon-12-02-19
|-
|<s>Grab eval individuals on day7 of runs.</s>
|Complete. Saved data on day7.
|Mon-11-25-19
|Tue-11-26-19
|Mon-12-02-19
|-
|<s>Check with Mohan for Summarization seeds on Monday.</s>
|Complete. Seeds do not finish evaluation in time.
|Mon-11-25-19
|Tue-11-26-19
|Mon-12-02-19
|-
|Try PCA with movies data.
|Low priority. Stemmatizer and Sentiment first.
|Fri-11-08-19
|Fri-11-08-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|}

== Mon Dec 02, 2019 ==
'''Grab Evaluated Individuals'''

Run plotting script on all individuals evaluated on entire 7days run.

Update slides with new curves

Update slides with more interesting individuals.

- Zack can confirm the trend I noted on Tues Nov 26.

- Although these "interesting" individuals do not perform as well, they prove that our primitives are evolvable and work with other Emade blocks.

'''Summarization Run'''

Mohan has 3 seeds. 

They do not finish evaluation in time for me to send objective score back to Mohan. 

'''Bek's Comparison''' 

Seemed to be some confusion as to which datasets to use. We may not have used the same data. 

Bek's stats could not be compared to the objective scores of our individuals. 

My bad Bek, I should have been more specific about which data to use. 

'''Final Presentation'''

Nice work nlp-app team!

Great to see the progress of other teams.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Notebooks. Due Wed 5pm.
|In progress.
|Mon-12-02-19
|Mon-12-02-19
|
|-
|Peer Evals. Due Wed 5pm.
|In progress.
|Mon-12-02-19
|Mon-12-02-19
|
|-
|<s>Final Presentation Slides</s>
|Complete. Updated with day7 data.
|Sat-11-23-19
|Mon-12-02-19
|Mon-12-02-19
|-
|<s>Make plots for pareto fronts and compute AUC for all gens.</s>
|Complete. day7 data plotted and added to slides.
|Mon-11-25-19
|Sun-12-01-19
|Mon-12-02-19
|-
|<s>Grab eval individuals on day7 of runs.</s>
|Complete. Saved data on day7.
|Mon-11-25-19
|Tue-11-26-19
|Mon-12-02-19
|-
|<s>Check with Mohan for Summarization seeds on Monday.</s>
|Complete. Seeds do not finish evaluation in time.
|Mon-11-25-19
|Tue-11-26-19
|Mon-12-02-19
|-
|Try PCA with movies data.
|Low priority. Stemmatizer and Sentiment first.
|Fri-11-08-19
|Fri-11-08-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|}

== Sun Dec 01, 2019 ==
'''Final Presentation Slides'''

Outline Emade results slides

Work on script to plot pareto curves and compute AUC.

Remembered to add bounds to pareto front for decreasing AUC.

Add pareto plots to slides.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Final Presentation Slides
|Slides updated with data from day2.
|Sat-11-23-19
|Sun-12-01-19
|
|-
|Make plots for pareto fronts and compute AUC for all gens.
|Code for plots is complete. Waiting for day7 data.
|Mon-11-25-19
|Sun-12-01-19
|
|-
|Grab eval individuals on day7 of runs.
|Saved data on day2. Waiting for day7.
|Mon-11-25-19
|Tue-11-26-19
|
|-
|Check with Mohan for Summarization seeds on Monday.
|In progress. Will check back after break.
|Mon-11-25-19
|Tue-11-26-19
|
|-
|Try PCA with movies data.
|Low priority. Stemmatizer and Sentiment first.
|Fri-11-08-19
|Fri-11-08-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|}

== Tues Nov 26, 2019 ==
'''Check in on Runs'''

Runs are around 9th and 10th generations for both datasets.

Around 220 evaluated and error free individuals for both datasets.

Best accuracies hovering around 89% and 90%.

Caught a glimpse of an individual with nested Stemmatizers. Very cool.

In general seems like individuals with other Emade primitives have errors or perform poorly. Hope that changes with more evolution.

'''Check in with Mohan + Summarization'''

Looks like I will have to check back on Monday.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Final Presentation Slides
|Hoping that I can get results from Emade runs.
|Sat-11-23-19
|Sat-11-23-19
|
|-
|Make plots for pareto fronts and compute AUC for all gens.
|day2 data received. Code for plots is in progress.
|Mon-11-25-19
|Tue-11-26-19
|
|-
|Grab eval individuals on day7 of runs.
|Saved data on day2. Waiting for day7.
|Mon-11-25-19
|Tue-11-26-19
|
|-
|Check with Mohan for Summarization seeds on Monday.
|In progress. Will check back after break.
|Mon-11-25-19
|Tue-11-26-19
|
|-
|Try PCA with movies data.
|Low priority. Stemmatizer and Sentiment first.
|Fri-11-08-19
|Fri-11-08-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|}

== Mon Nov 25, 2019 ==
'''Scrum'''

<u>Classification</u>

Let Bek know about good news: Emade is running with our seeds/primitives.

Asked Bek if he could work on using Textblob and/or Spacy to classify the test sets, since he has been researching those APIs this semester.

<u>Summarization</u>

Some primitives still in progress.

Mohan is trying to reduce runtime of his primitive.

I promise to check with him Tuesday before I leave and Monday after I get back, to see if they want to run on icehammer.

I also sent him info for setting up PACE. The same info DRJZ gave me during the hackathon. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Final Presentation Slides
|Hoping that I can get results from Emade runs.
|Sat-11-23-19
|Sat-11-23-19
|
|-
|Make plots for pareto fronts and compute AUC for all gens.
|Waiting for data.
|Mon-11-25-19
|Mon-11-25-19
|
|-
|Grab eval individuals on day2 and day7 or runs.
|In progress.
|Mon-11-25-19
|Mon-11-25-19
|
|-
|Check with Mohan for Summarization seeds on Tuesday and Monday.
|In progress.
|Mon-11-25-19
|Mon-11-25-19
|
|-
|Try PCA with movies data.
|Low priority. Stemmatizer and Sentiment first.
|Fri-11-08-19
|Fri-11-08-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|}

== Sun Nov 24, 2019 ==
'''Launch Emade runs on Movies and News'''

<u>General Emade Code Changes</u>

Wrote script to generate trees. initially produced well over 1K seeds. reduce to 136 by randomly selecting learner.

Update UnitTests to run with all learners listed in learnergen() method. Verified that both Classification primitives work with 20+ learners and all vectorizers.

Tried to fix achievable bounds on objective scores in xml. 

Fixed other miscellaneous syntax typo bugs. See commit history for specifics. 

Launched!! time limit is set for 7 days. Plan on checking in Tuesday, before I leave for Thanksgiving, and again the Monday I get back. 

<u>Icehammer</u> 

Less Traffic: both masters launched. some movies worker found available ice nodes with cpus. 

GPU nodes still occupied: Adjust slurm scripts to launch workers on non-gpu ice nodes. 

<u>Summarization</u> 

Mohan and team are still working on writing and debugging primitives. Seeds are not yet ready. 

I tried running their unittests and can confrim that their code takes a long time: upwards of 10min on icehammer. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Final Presentation Slides
|Hoping that I can get results from Emade runs.
|Sat-11-23-19
|Sat-11-23-19
|
|-
|Launch Runs for Movie and News dataset
|Complete.
|Sat-11-23-19
|Sat-11-23-19
|
|-
|Try PCA with movies data.
|Low priority. Stemmatizer and Sentiment first.
|Fri-11-08-19
|Fri-11-08-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|}

== Sat Nov 23, 2019 - Hackathon ==
'''Work on Icehammer'''

Continue adding to Unit test for stemmatizer.

Git pulled Sentiment unittests. 

Found out Spacy not installed on work machine. install relevant packages.

'''Hackathon'''

<u>Sentiment</u>

- realize that input shapes had to be normalized for each document(news or movies). Took the average of all vectors for each document. Did not do padding like summarization.

- also fixed an issue with packaging back into EmadeDataPair. Had to wrap in another list. set_data([our_original_output_array])

<u>Stemmatizer</u>

- passed basic unittests that checked type and verified stemming by printing augmented EmadeDataPair.TextData.

- passed tests with a vectorizer and a learner. 

- wasted time on trying to print within unittest using console logging. Only works on linux; could not work reliabley on my macOS.

<u>Summarization</u>

Alex and Mohan work on a primitive

- realize their data is very sparse due to padding and outlier summary of size 255

- found a primitive take very long to run in unittest. They fear it will take even longer on icehammer.

New members still working hard on their primitives.

Mohan says input xml is ready. They hope to have seeds ready by tomorrow.

'''Back to Icehammer to run Emade'''. 

Icehammer is backed up, all the masters/workers were on priority queue. Will return tomorrow.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Final Presentation Slides
|Hoping that I can get results from Emade runs.
|Sat-11-23-19
|Sat-11-23-19
|
|-
|Check if Summarization has Seeds to run.
|Will message Mohan tomorrow.
|Sat-11-23-19
|Sat-11-23-19
|
|-
|Launch Runs for Movie and News dataset
|In Progress. Need Seeds and free ice nodes.
|Sat-11-23-19
|Sat-11-23-19
|
|-
|<s>Unittest for Stemmatizer with Vectorizer/Learner</s>
|Complete
|Fri-11-22-19
|Fri-11-22-19
|Sat-11-23-19
|-
|Try PCA with movies data.
|Low priority. Stemmatizer and Sentiment first.
|Fri-11-08-19
|Fri-11-08-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|}

== Friday Nov 22, 2019 ==
'''Meeting'''

Showed Bek the assertion statements.

He should be done with basic type checking unittest for Sentiment tonight.

We will work on writing more extensive tests tomorrow during Hackathon.

'''Stemmatizer UnitTests'''

<u>Drafted basic unittest.</u>

- Checks type of output and types of internal EmadeDataPair members.

- Prints modified reviews

<u>Running the test</u>

Same error as before, proves bug is with Stemmatizer, not Emade setup. (see Nov 13 for error string)

Attribute error to syntax typos, and incorrect lambda usage.

<u>Need to improve unittest</u>

Currently only checks type and prints string to show modification.

Need to verify that it works with Vectorizer and Learner.

'''Sentiment Seed Issue'''

Tried seeding basic Sentiment and Stemmatizers. 

Found/Fixed how sentiment was added to pset. Bek and I had incorrectly specified input types. Thanks to Austin for help. 

'''Git''' 

Realized that I was committing under gtri account instead of school account. 

quick fix for latest commit: git commit --amend --author="Reagan Kan <rkan3@gatech.edu>" 

failed to rebase the few older commits. will just provide links to those commits. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Unittest for Stemmatizer with Vectorizer/Learner
|Will do during Hackathon.
|Fri-11-22-19
|Fri-11-22-19
|
|-
|<s>Draft Stemmatizer UnitTest.</s>
|Complete.
|Wed-11-13-19
|Wed-11-20-19
|Fri-11-22-19
|-
|Try PCA with movies data.
|Low priority. Stemmatizer and Sentiment first.
|Fri-11-08-19
|Fri-11-08-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|} 

== Wed Nov 20, 2019 ==
Finished database eval updates. 

Now, code stalls at multiprocessing portion of evaluation.

I am not as qualified to fix this problem, so I will move on to Unittests now. Seems like Zack and Bek are having trouble with those.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|<s>Try to add cacheDict info to database_eval.</s>
|Complete. Now stalls when evaluating.
|Wed-11-13-19
|Mon-11-18-19
|Wed-11-20-19
|-
|Draft UnitTest.
|In progress. Asked Bek and Zack to try writing.
|Wed-11-13-19
|Wed-11-20-19
|
|-
|Try PCA with movies data.
|Low priority. Stemmatizer and Sentiment first.
|Fri-11-08-19
|Fri-11-08-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|}

== Monday Nov 18, 2019 ==
'''Unit Tests''' 

Showed Zack and Bek example unittest code. 

They will try to write them before Hackathon. 

'''Database Tree Evaluator''' 

Begin updating database_tree_evaluator.py with code for putting xml info into cacheDict. 

First time running the script on personal computer. SQL password issue reappears. 

Previous fix does not work, as it requires that I have access to mysql shell. 

Eventually found reproducible solution. I put steps in sql-commands.txt file. <blockquote>try: mysql -u root -p</blockquote><blockquote>Password: ? password</blockquote><blockquote>catch:</blockquote><blockquote>ps aux | grep mysql</blockquote><blockquote>kill <pid></blockquote><blockquote>turn off sql server in system preferences</blockquote><blockquote>sudo mysqld_safe --skip-grant-tables</blockquote><blockquote>mysql.server restart</blockquote><blockquote>mysql -u root -p</blockquote><blockquote>Password: ? password</blockquote>
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Try to add cacheDict info to database_eval.
|In progress.
|Wed-11-13-19
|Mon-11-18-19
|
|-
|Draft UnitTest.
|In progress. Asked Bek and Zack to try writing.
|Wed-11-13-19
|Mon-11-18-19
|
|-
|Try PCA with movies data.
|Low priority. Stemmatizer and Sentiment first.
|Fri-11-08-19
|Fri-11-08-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|}

== Friday Nov 15, 2019 ==
Discuss problem with database_tree_evaluator.py. 

Work with Bek on Sentiment code: adding to pset, adding seed with Sentiment, etc. 

Tried database_tree_evaluator.py with Sentiment primitive. Confirmed cacheDict issue.  

reinstall.bat took ages to run the first time, subsequent runs were quick.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Try to add cacheDict info to database_eval.
|In progress.
|Wed-11-13-19
|Fri-11-15-19
|
|-
|Draft UnitTest.
|In progress.
|Wed-11-13-19
|Fri-11-15-19
|
|-
|Try PCA with movies data.
|Low priority. Stemmatizer and Sentiment first.
|Fri-11-08-19
|Fri-11-08-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|
|}

== Wednesday Nov 13, 2019 ==
'''Run with Stemmatizer Seed'''

<u>Worker returns error</u>

Con: either an error with worker evaluation or bug in Stemmatizer.

Pros:

- Chances of worker evaluation error are very slim if not zero.

- Emade did not break anywhere else.

- Many options to fix this. See below.

<u>Options from Austin.</u>

1. adjust database_tree_evaluator.py to load cacheDict info.

Cons: might break elsewhere, easier for Austin to fix instead.

Pros: if fixed, can debug at home. might try myself.

2. standalone_tree_evaluator.py

Cons: requires the pkl file as input, so will be hard to debug at home. Might have same cacheDict error.

3. UnitTest.

Cons: isolated testing data.

Pros: Mohan already setup data for movies, the script is independent of Emade (can debug at home) --I will probably do this.

<u>Error</u>

Received: Learner(TfidfVectorizer(Stemmatizer(ARG0, 0, 0), falseBool, 0, 0, 45), learnerType('LOGR', {'penalty': 0, 'C': 1.0}, 'SINGLE', None))

With Hash d7fec141be6ea2a13e16ee171ef3b840e361a8e8c39ab3d89e44a43d34fd4755

Computed in: 1.8496088981628418 seconds

With Fitnesses: (inf, inf, inf)

With Age: 0

<small>With Error:  **********cannot use a string pattern on a bytes-like objectTraceback (most recent call last):</small>

<small>File "/home/rkan3-gtri/.conda/envs/envEMADE/lib/python3.6/site-packages/GPFramework-1.0-py3.6.egg/GPFramework/EMADE.py", line 1381, in handleWorker</small>

<small>result = func(dataPair)</small>

<small>File "<string>", line 1, in <lambda></small>

<small>File "/home/rkan3-gtri/.conda/envs/envEMADE/lib/python3.6/site-packages/GPFramework-1.0-py3.6.egg/GPFramework/text_processing_methods.py", line 82, in stemmatizer</small>

<small>x_train = lam(train_data, func, pos_tagger)</small>

<small>File "/home/rkan3-gtri/.conda/envs/envEMADE/lib/python3.6/site-packages/GPFramework-1.0-py3.6.egg/GPFramework/text_processing_methods.py", line 81, in <lambda></small>

<small>lam = lambda one_review, func, pos_tagger: stemlemmatize(one_review, func, pos_tagger)</small>

<small>File "/home/rkan3-gtri/.conda/envs/envEMADE/lib/python3.6/site-packages/GPFramework-1.0-py3.6.egg/GPFramework/text_processing_methods.py", line 56, in stemlemmatize</small>

<small>for w in word_tokenize(string):</small>

<small>File "/home/rkan3-gtri/.conda/envs/envEMADE/lib/python3.6/site-packages/nltk/tokenize/__init__.py", line 144, in word_tokenize</small>

<small>sentences = [text] if preserve_line else sent_tokenize(text, language)</small>

<small>File "/home/rkan3-gtri/.conda/envs/envEMADE/lib/python3.6/site-packages/nltk/tokenize/__init__.py", line 106, in sent_tokenize</small>

<small>return tokenizer.tokenize(text)</small>

<small>File "/home/rkan3-gtri/.conda/envs/envEMADE/lib/python3.6/site-packages/nltk/tokenize/punkt.py", line 1277, in tokenize</small>

<small>return list(self.sentences_from_text(text, realign_boundaries))</small>

<small>File "/home/rkan3-gtri/.conda/envs/envEMADE/lib/python3.6/site-packages/nltk/tokenize/punkt.py", line 1331, in sentences_from_text</small>

<small>return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]</small>

<small>File "/home/rkan3-gtri/.conda/envs/envEMADE/lib/python3.6/site-packages/nltk/tokenize/punkt.py", line 1331, in <listcomp></small>

<small>return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]</small>

<small>File "/home/rkan3-gtri/.conda/envs/envEMADE/lib/python3.6/site-packages/nltk/tokenize/punkt.py", line 1321, in span_tokenize</small>

<small>for sl in slices:</small>

<small>File "/home/rkan3-gtri/.conda/envs/envEMADE/lib/python3.6/site-packages/nltk/tokenize/punkt.py", line 1362, in _realign_boundaries</small>

<small>for sl1, sl2 in _pair_iter(slices):</small>

<small>File "/home/rkan3-gtri/.conda/envs/envEMADE/lib/python3.6/site-packages/nltk/tokenize/punkt.py", line 318, in _pair_iter</small>

<small>prev = next(it)</small>

<small>File "/home/rkan3-gtri/.conda/envs/envEMADE/lib/python3.6/site-packages/nltk/tokenize/punkt.py", line 1335, in _slices_from_text</small>

<small>for match in self._lang_vars.period_context_re().finditer(text):</small>

<small>TypeError: cannot use a string pattern on a bytes-like object</small>
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Try to add cacheDict info to database_eval.
|In progress.
|Wed-11-13-19
|Wed-11-13-19
|
|-
|Draft UnitTest.
|In progress.
|Wed-11-13-19
|Wed-11-13-19
|
|-
|<s>Run Emade with Stemmatizer Seed.</s>
|Complete, in some sense. See note above.
|Mon-11-11-19
|Mon-11-11-19
|Mon-11-13-19
|-
|Try PCA with movies data.
|Low priority. Stemmatizer and Sentiment first.
|Fri-11-08-19
|Fri-11-08-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|
|}

== Monday November 11, 2019 ==
'''Scrum'''

<u>Sentiment</u>

- Bek and Zack found way to get word sentiment information.

- I walked them through how Emade data works, in particular, how their primitive would use EmadeDataPair.

- They will work on drafting the primitive.

<u>Other</u>

- I report that Emade is running.

- Summarization teams wants to run things soon.

- Plan to run Emade with Stemmatizer seeds this week.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run Emade with Stemmatizer Seed.
|Planned for this week.
|Mon-11-11-19
|Mon-11-11-19
|
|-
|Try PCA with movies data.
|Low priority. Stemmatizer and Sentiment first.
|Fri-11-08-19
|Fri-11-08-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|
|}
== Friday November 08, 2019 ==
'''PCA'''

- Just recently learned about PCA in class, along with Alex and Mohan. 

- Earlier in the week, they suggest I try PCA as a block sandwiched between Learner and Vectorizer/Sentiment. 

- Found my_pca() method in decomposition_methods.py. DRJZ helped by providing the name of method.

'''Stemmatizer and Sentiment'''

- Hard to determine how to merge or use as ensemble methods.

- Ensemble like approach seems convoluted and hard to implement with time left in semester

- At least, we can write separate blocks and see if Emade can figure out what to do.

- Mohan also thinks that Stemmatizer should be separate from Sentiment primitive. 

'''Icehammer'''

<u>Duplicate entry error</u> 

- I had accidently stopped launchEMADE.py before worker slurm jobs could be submitted. 

- Letting launchEMADE.py run to completion resolved the issue. 

- Obvious now that the issue is not the same as Anish's. 

<u>New Issue: selectTournDCD</u> 

- expecting number of individuals to be multiple of 4 

- DRJZ points out this is an error VIP team is aware of. 

- Quick fix by commenting out some lines.  

- Emade now functional on icehammer. Can move to test/debugging primitives. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install Emade on icehammer.  
|Complete.
|Mon-10-07-19
|Mon-11-04-19
|Fri-11-08-19
|-
|Try PCA with movies data.
|Low priority. Stemmatizer and Sentiment first.
|Fri-11-08-19
|Fri-11-08-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|
|} 

== Monday November 04, 2019 ==
'''Sentiment'''

- Longterm goal: Bek and Zach will write sentiment extractor primitive.

- Bek has found a way to get sentiment information from sentences. 

- Bek says word level information is still in progress

- I mentioned the SentimentVaderAnalyzer I tried when looking for sentiment reversal rate of Stemmatizer.

'''Duplicate entry error'''

- DRJZ asked if it is the same as time conflict team. 

- Mohan thinks it is.

- I will work on fixing that SQL error. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install Emade on icehammer. Ask Anish about issue. 
|In progress. Fixing duplicate entry error.
|Mon-10-07-19
|Mon-11-04-19
|
|-
|Mohan put in dataset already.
|Complete.
|Mon-10-07-19
|Mon-10-21-19
|Mon-11-01-19
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|
|} 

== Friday November 01, 2019 ==
'''Anish pitches time conflict team.''' 

- New members split off.

- New Nlp-App members are assigned summarization primitives.

'''Classification'''

<u>Sentiment</u>

- Bek researching nltk and spacy sentiment capabilities.

- I will research how to throw that info into a ML algorithm. 

1. append to Stemmatizer info 

2. pass to 2nd learner and somehow aggregate results to make decision. 

<u>News dataset</u> 

- After looking at how datasets are setup in Emade, I realize Mohan already put AG news dataset into Emade.

<u>Icehammer</u>

- server connection: fixed. use ip address returned from <u>ipconfig</u> command run locally on work machine.

- new error when running Icehammer. Duplicate entry detected.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install Emade on icehammer. Duplicate entry Sql problem. <s>Fix server name issue.</s> 
|In progress. Server name issue fixed using ip. Now, duplicate entry in SQL.
|Mon-10-07-19
|Mon-11-01-19
|
|-
|<s>Get news data into emade so we can try out Stemmatizer.</s> Mohan put in dataset already.
|Complete.
|Mon-10-07-19
|Mon-10-21-19
|Mon-11-01-19
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|
|}

== Monday October 28, 2019 ==
'''New Members Brainstorm'''

- Discuss tasks for new/current members with Bek and Zach. See table below.

- It looks like Summarization team has more tasks for new students.

- Anish and NN-NLP will also need people hopefully.

- New members joined slack channel.
{| class="wikitable"
!Task
!New
!Current
|-
|Read medium post for general understanding
|X
|
|-
|Import News classification dataset. 
|X
|
|-
|Test primitive on News classification.
|
|X
|-
|<s>Emade on Amazon.</s>
|n/a
|n/a
|}
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install Emade on icehammer. Fix server name issue.
|In progress. Icehammer server name issue.
|Mon-10-07-19
|Mon-10-21-19
|
|-
|Get news data into emade so we can try out Stemmatizer.
|In progress. (move down for less priority)
|Mon-10-07-19
|Mon-10-21-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|
|}

== Monday October 21, 2019 ==
'''Tried to run on icehammer.'''

<u>GlibC and Tensorflow</u>

- Same issue I was having over the summer before starting coevolution work.

- Took a long time to figure out. More notes on work computer.

- Problem: GlibC version 2.23 is not compatible with tensorflow version used by python3.7 in conda env.

- Fix: switch to python3.6+ in conda environment, NOT module load.

<u>ServerHostNameProblem</u>

- Icehammer errors out saying it cannot connect.

- Currently put 'localhost' as ServerHostName.

- Austin hypothesize that I need sql on eosl cluster.

- or should I be entering the ip address? Mohan's template xml suggests this.

'''Get Emade running locally.'''

Finally fixed sql error on personal laptop. (note: kind of, see Mon Nov 18, 2019)

Resource I followed: https://gist.github.com/zubaer-ahammed/c81c9a0e37adc1cb9a6cdc61c4190f52

'''Midterm Presentation.'''

DRJZ suggest a primitive that looks for sentiment at a sentence or word level.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install Emade on icehammer. Fix server name issue. <s>In the mean time, get emade running locally for faster debugging.</s>
|In progress. Local machine done. Icehammer server name issue.
|Mon-10-07-19
|Mon-10-21-19
|
|-
|Get news data into emade so we can try out Stemmatizer.
|In progress. (move down for less priority)
|Mon-10-07-19
|Mon-10-21-19
|
|-
|
|
|
|
|
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19
|
|}

== Saturday, October 19, 2019 - Hackathon ==
'''Hackathon'''

Draft the Stemmatizer primitive.

- evolvable: parameters allow Emade to choose stem/lemmatization method and pos tagging method.

- extensible: to add new methods, just write a helper method and add method to the list.

- There may be bugs in the code. Need to setup emade sooner than later to test.

Added slides pertaining to Jupyter experiments to google slide deck.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get [https://www.kaggle.com/rmisra/news-category-dataset news] data into emade so we can try out Stemmatizer <s>once primitive is done.</s>
|In progress
|Mon-10-07-19
|Mon-10-19-19
|
|-
|Install Emade @ gtri. Run on icehammer. In the mean time, get emade running locally for faster debugging.
|In progress.
|Mon-10-07-19
|Mon-10-19-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold)
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-19 
|
|-
|<s>Get Emade running properly. Not locally, but on Amazon server.</s>  Icehammer. See Task 2.
|In progress. See Task 2.
|Fri-09-06-19
|<s>Fri-09-06-19</s> Sat-10-19-19
|
|}

== Friday, October 11, 2019 ==
Talk with Mohan. Will show me how to import data into Emade during hackathon? 

Bek showed me Spacy capabilities covered in first 2 sections in online tutorial
* pos tagging.

* matching. pattern match to find n-grams.

* entities:  classification on certain words into entities. money, geo political entities. 

* stemming/lemmatizers not yet seen.
I will look at importing [https://www.kaggle.com/rmisra/news-category-dataset news] data set into EMADE. and Set up emade at gtri.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get  [https://www.kaggle.com/rmisra/news-category-dataset news] data into emade so we can try out primitive once primitive is done.
|In progress
|Mon-10-07-19
|Mon-10-07-19
|
|-
|Install Emade @ gtri.
|In progress
|Mon-10-07-19
|Mon-10-07-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold) 
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-02
|
|-
|Get Emade running properly. Not locally, but on Amazon server.
|DRJZ posted link.
|Fri-09-06-19
|Fri-09-06-19
|
|}

== Monday, October 07, 2019 ==
Decided to move forward with making primitive. Put a hold on sentiment analysis. Not important in broader context of nlp and EMADE.

Zach wants to continue with his drafting process.

Bek wants to continue with his Spacy exploration.

I will look at importing [https://www.kaggle.com/rmisra/news-category-dataset news] data set into EMADE. and Set up emade at gtri.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get  [https://www.kaggle.com/rmisra/news-category-dataset news] data into emade so we can try out primitive once primitive is done.
|In progress
|Mon-10-07-19
|Mon-10-07-19
|
|-
|Install Emade @ gtri.
|In progress
|Mon-10-07-19
|Mon-10-07-19
|
|-
|Look at sentiment reversal rate in imdb. (On Hold) 
|On Hold. Priority with getting Stemmatizer into EMADE.
|Wed-09-10-02
|Wed-09-10-02
|
|-
|Get Emade running properly. Not locally, but on Amazon server.
|DRJZ posted link.
|Fri-09-06-19
|Fri-09-06-19
|
|}

== Friday, October 04, 2019 ==
'''Tag up with Bek:'''

Bek is hitting syntactic issues when using spacey. He is figuring it out and going through Spacy tutorials.

'''Individual Work:'''

Look for python sentiment classification apis. -> nltk.sentiment submodule

<code>nltk.sentiment.sentiment_analyzer.SentimentAnalyzer</code>
* has a classify() method, but I was having trouble calling it. 
* might need to use the train() method first. But, I don't have data.
<code>nltk.sentiment.vader.SentimentIntensityAnalyzer</code>
* this works. gives intensity of text being pos, neu, neg. 
* intensities sum to 1. 
* there is also a compound value. (some sort of normalized combo of others)
Begin playing with intensity analyzer.
* Looked at first review in imdb set. 
* Bare bones to PorterStemmed.
* conversion often moved positive intensity to the other intensities.
* Plan on plotting reversal rates across all reviews
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Look at sentiment reversal rate in imdb. 
|In progress
|Wed-09-10-02
|Wed-09-10-02
|
|-
|<s>Run again with 50K iterations.</s>
|Complete
|Mon-09-30-19
|Mon-09-30-19
|Wed-10-02-19
|-
|Get Emade running properly. Not locally, but on Amazon server.
|DRJZ posted link.
|Fri-09-06-19
|Fri-09-06-19
|
|}

== Wednesday, October 02, 2019 ==
'''Icehammer Run:''' Even with [https://drive.google.com/file/d/0By9DvXY0hh11VzhsSGJZWDdiam5tYktydjJJNEMxOWZFa1Br/view?usp=sharing 50K] [https://drive.google.com/file/d/0By9DvXY0hh11bXk2UzdPVktZTDRaNmhqNllOZHVUSGhCZmFJ/view?usp=sharing iterations], barebones classification does better. 

'''Individual Work:'''

Do peer evals.

<u>Thinking about why accuracy is worse.</u>

For the most part, it seems people favor stemming and lemmatization. However, their effectiveness may be dependent on the specific NLP task.

Stemming / Lemmatization probably works better for an nlp task like summarization. (Alex seems to have though about using etm/lemm on his end).

Did find a collated [http://sentiment.christopherpotts.net/stemming.html#porter list] of examples where stemming will reverse the sentiment of words.

<nowiki>*</nowiki> This seems to indicate that we should move forward with making the primitive. It can be useful for other nlp tasks.

<nowiki>*</nowiki> Since Zach has offered to start drafting a primitive, I can take a look at looking at the % of words that undergo sentiment change after stem/lemmatize in imdb set.

<nowiki>*</nowiki> Maybe look for a different classification dataset, like classifying article type. I feel stem/lemmatize will work better on such a problem because:
* multi-class. stemmed/lemmatized words may still shift but the effect will be spread out across more class labels.
* Tech words, after being stemmed 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Look at sentiment reversal rate in imdb. 
|In progress
|Wed-09-10-02
|Wed-09-10-02
|
|-
|<s>Run again with 50K iterations.</s>
|Complete
|Mon-09-30-19
|Mon-09-30-19
|Wed-10-02-19
|-
|Get Emade running properly. Not locally, but on Amazon server.
|DRJZ posted link.
|Fri-09-06-19
|Fri-09-06-19
|
|}
== Monday, September 30, 2019 ==
'''Icehammer Run:''' Barebones classification does better. Used default iterations. Forgot to use 10K iterations.

'''Scrum:'''

Alex/Mohan: Goal is to extract sentences that best summarizes text. WIll use some metrics to help annotate dataset.

Zach will start drafting skeleton of primitive. The vision is to parameterize it to let EMADE toggle replacement methods and stemmer/lemmatizers.

Bek will continue looking into Spacey. Purchased/shared NLP textbook.

Reagan will run with 50K. 

Remember to do peer evaluations. -James and Dr. Rohling.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run again with 50K iterations.
|In progress
|Mon-09-30-19
|Mon-09-30-19
|
|-
|<s>[https://github.gatech.edu/emade/emade/blob/nlp-app/testing/Reagan's%20Testing.ipynb Run] text classification pipeline using all combinations available using nlkt and sklearn.</s>
|<s>In progress</s> Complete
|Mon-09-23-19
|<s>Sun-09-29-19</s>
|Mon-09-30-19
|-
|Get Emade running properly. Not locally, but on Amazon server.
|DRJZ posted link.
|Fri-09-06-19
|Fri-09-06-19
|
|}

== Sunday, September 29, 2019 ==
'''Individual Work:'''

Fixed bug with TfIdfTranfromer vs TfIdfVectorizer.

Improvements to test code. This should help a lot when running all variations of the classification pipeline. 
* write results to file with periodic flushing. 

* log the time for each run.  
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|[https://github.gatech.edu/emade/emade/blob/nlp-app/testing/Reagan's%20Testing.ipynb Run] text classification pipeline using all combinations available using nlkt and sklearn.
|In progress
|Mon-09-23-19
|Sun-09-29-19
|
|-
|Get Emade running properly. Not locally, but on Amazon server.
|DRJZ posted link.
|Fri-09-06-19
|Fri-09-06-19
|
|}
== Friday, September 27, 2019 ==
'''NLP meeting: Tag up with Bek and Zach.'''

Zach was busy for the past week. Reported confusion matrix analysis.

1. TP is defined as classified as positive review when it is indeed positive.

2. Looks like FP counts are drifting to FN count. Domain(Barebones) Co-Domain(Stem/Lem).

Bek laptop is slow. He has been reading a NLP textbook while waiting for notebook. Wants to hopefully try out Spacy.

'''Individual''' '''Work'''

Improved code to specify pipeline components and generate all combinatorial pipelines.

I will run on Icehammer on Monday.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run text classification pipeline using all combinations available using nlkt and sklearn.
|In progress
|Mon-09-23-19
|Fri-09-27-19
|
|-
|Get Emade running properly. Not locally, but on Amazon server.
|DRJZ posted link.
|Fri-09-06-19
|Fri-09-06-19
|
|}
==Monday, September 23, 2019==

'''Scrum meeting'''

DRJZ amazon credits 75. google credits tied to credit card 10K.

<u>Brainstorm of why results are bad.</u>

DRJZ: 1. make things into primitives even if jupyter notebook experimentation suggest otherwise. 2. Think about why results are bad.

Mohan: stem/lemmatize is destroying information.

Zach: stem/lemmatize may be converting to a version of the word that has stronger or weaker positivity/negativity.

<u>Delegation of tasks.</u>

Bek will research spacey tools and try to run my code. Still having trouble with some of the syntax of my test code.

Zach will look into alternative metrics, besides testing accuracy, for comparing stem/lemmatize vs barebones classification.

Reagan will run with all combinations. Stemmer(Porter, Snowball, etc.) Lemmatizer(WordNet) Vectorizer(Tfidf, Count), Classifiers(MLP, LinearSVC, etc.)

'''Individual''' '''Work'''  

--> Look up rationale for stemming and lemmatization.  

Motivation: A single idea can be referenced via different works. Vectorization will treat different words separately.  

In theory, stemming/lemmatizing will group together theses words and the vectorized form of the texts should be more representative of the information.    

Feeling confused about why stemming and lemmatization is not improving accuracy.  

Hypothesis 1: The pipeline I used in the test code did not have the right hyperparameters. I used the default params.  

--> Try extending classifier training  to 10K iterations vs 1K.  

Stemmer does at least as good as barebones now. Lemmatizer still lags behind.  

Hypothesis 2: Different stemmers do better with different pipeline components.  

--> Emade is not yet setup, nor is primitive made yet, so I cannot try letting EMADE figure out the best pipeline.  

--> I will need to adjust test code to run across all combinations of pipeline components.  
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|[https://github.gatech.edu/emade/emade/blob/nlp-app/testing/Reagan's%20Testing.ipynb Run] text classification pipeline using all combinations available using nlkt and sklearn.
|In progress
|Mon-09-23-19
|Mon-09-23-19
|
|-
|Get Emade running properly. Not locally, but on Amazon server.
|DRJZ posted link.
|Fri-09-06-19
|Fri-09-06-19
|
|}  

==Friday, September 20, 2019==

'''NLP meeting: Demo Jupyter Notebook'''

Mohan + Alex discuss summarization.

I showed Bek the code I wrote, explaining on every level from syntax to high level purpose.

'''Individual Work:'''

Compared WordnetLemmatizer, Porter, Snowball Stemmer, and Barebones text classification.

Pipeline: Stem/Lemmatize, CountVectorizer, LinearSVC(1000 iterations).

<u>Result Summary</u>

Barebones classification has higher testing accuracy.

Lemmatization took a whopping 14 minutes to execute, compared to less than two minutes for stemming.[[files/Control.png|none|thumb|imdb test accuracy without stemming/lemmatization]][[files/PorterStem.png|none|thumb|Porter Stemmer]]
[[files/Snowball Stem 1.png|none|thumb|Snowball Stem]]
[[files/Lemmatization 1.png|none|thumb|NLTK WordNet Lemmatization]]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|<s>Many techniques of different complexity. [https://github.gatech.edu/emade/emade/blob/nlp-app/testing/Reagan's%20Testing.ipynb Test] effectiveness vs no lemma/stemming. Consider effects on n-gram.</s>
|<s>In progress.</s> Complete 
|Mon-09-09-19
|<s>Mon-09-09-19</s>
|Fri-09-20-19
|-
|Get Emade running properly. Reset SQL password.
|In progress
|Fri-09-06-19
|Fri-09-06-19
|
|-
|Get <s>google</s> Amazon cloud credits
|DRJZ posted link.
|Sat-08-24-19
|<s>Sat-08-24-19</s>
Fri-09-20-19
|
|}

==Monday, September 16, 2019==

'''Scrum meeting: Stemming/Lemmatization Regroup'''

Listen to other sub-team scrums.

<u>Discussion with Stem/Lemma sub-sub-team(Bek, Zach, Reagan)</u>

Reagan report problem: Cannot reconcile pos tags from nltk.pos_tag function and WordNetLemmatizer.lemmatize() parameter requirements.

Nltk vs Spacy debate: Mohan was already using nltk, so Reagan will focus on making nltk work.

Mohan + Alex discuss summarization. I listened in on a small portion of their conversation. Seems they have an algorithm in mind. Currently looking for good datasets.

''<nowiki/>'<nowiki/>'''''Individual Work: Jupyter Progress'''

1. Found temporary hardcode solution for reconciling output of pos_tag with argument requirements of the lemmatize function.

2. Wrote functions for comparing stemming/lemmatization and vanilla text classification methods.

<u>Stemming and Lemmatization Algorithm</u>

<code>For each movie review, r:</code>

<code>Tokenize r into tokens,  t.</code>

<code>For each word, w in t:</code>

<code>Replace w with stem(w) or lemmatize(w).</code>

{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Many techniques of different complexity. [https://github.gatech.edu/emade/emade/blob/nlp-app/testing/Reagan's%20Testing.ipynb Test] effectiveness vs no lemma/stemming. Consider effects on n-gram.
|In progress. <s>Blocked by task below.</s>
|Mon-09-09-19
|<s>Mon-09-09-19</s>
Mon-09-16-19
|
|-
|<s>Jupyter notebook. SubGoal: Examine Mohan's summer notebook. understand pipleline(Lemmatization/Stemming before vectorization then classification). End Goal: Experiment with text classification methods.</s>
|<s>In progress</s>
|Fri-09-06-19
|<s>Fri-09-06-19</s>
|Mon-09-16-19
|-
|Get Emade running properly. Sql problems. Forgot sql password?
|In progress
|Fri-09-06-19
|Fri-09-06-19
|
|-
|Get google cloud credits
|Mohan looking into it.
|Sat-08-24-19
|Sat-08-24-19
|}

==Friday, September 13, 2019==

'''NLP meeting: Stemming/Lemmatization Regroup + Fix Jupyter Notebook Error'''

I arrived late from EOSL so I missed anything Alex shared. Seems like he has his work cut out for him.

Bek is still having trouble with the imdb dataset. Unzipping takes a long time.

Zach successfully tested Mohan's code and played with nltk's stemmers and lemmatizers.

--> Lemmatizer requires POS(parts of speech) tagging to work well.

--> Also need to test effectiveness of Stem/Lem on imdb dataset.

Zach has prior engagement and left after giving his recap.

We(Zach, Mohan, Reagan) were stumped on the jupyter notebook error. -> DRJZ resolved the issue.

'''Individual Work: POS tagging, Jupyter notebook, VIP notebook cleanup'''

1. POS: nltk has a pos_tag() method. input: "string", output: tuple(string, string), a tuple of word and pos tag.

2. More work with notebook: reorganize code. Partially figured out pandas dataframe indexing. df["train"/"test"]["text"/"sentiment"]. Based on how dataframe was defined.

3. VIP notebook: did a single pass through each Fall 2019 entry, adding more detailed/accurate notes, and general cleanup. There may still be typos present. Do a pass every week?
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Resolve ModuleNotFoundError. DRJZ discovers jupyter not located in miniconda3. Jupyter was likely installed separately. This is why jupyter notebook, although launched in envEMADE, could not find modules installed in envEMADE. Fix: conda install jupyter (inside envEMADE)
|<s>In progress.</s> Complete
|Wed-09-11-19
|<s>Wed-09-11-19</s>
|Fri-09-13-19
|-
|Many techniques of different complexity. [https://github.gatech.edu/emade/emade/blob/nlp-app/testing/Reagan's%20Testing.ipynb Test] effectiveness vs no lemma/stemming.
|In progress. Blocked by task below.
|Mon-09-09-19
|Mon-09-09-19
|
|-
|[https://github.gatech.edu/emade/emade/blob/nlp-app/testing/Reagan's%20Testing.ipynb Jupyter] notebook. SubGoal: Examine Mohan's summer notebook. understand pipleline(Lemmatization/Stemming before vectorization then classification). End Goal: Experiment with text classification methods.
|In progress
|Fri-09-06-19
|Fri-09-06-19
|
|-
|Get Emade running properly. Sql problems. Forgot sql password?
|In progress
|Fri-09-06-19
|Fri-09-06-19
|
|-
|Get google cloud credits
|Mohan looking into it.
|Sat-08-24-19
|Sat-08-24-19
|}

==Wednesday, September 11, 2019==

'''Individual Work: Mohan's Notebook'''

Load Mohan's notebook into my own notebook.

Problem: ModuleNotFound: nltk. But it is installed in base and envEMADE?

Tried many potential solutions but failed:

0. make sure notebook is launched within correct environment.

1. install within the jupyter notebook. '!conda install nltk'

2. using different options within jupyter gui menu bar
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Resolve ModuleNotFoundError.
|In progress.
|Wed-09-11-19
|Wed-09-11-19
|
|-
|Many techniques of different complexity. Test effectiveness vs no lemma/stemming.
|In progress. Blocked by task below.
|Mon-09-09-19
|Mon-09-09-19
|
|-
|Jupyter notebook. SubGoal: Examine Mohan's summer notebook. understand pipleline(Lemmatization/Stemming before vectorization then classification). End Goal: Experiment with text classification methods.
|In progress
|Fri-09-06-19
|Fri-09-06-19
|
|-
|Get Emade running properly. Sql problems. Forgot sql password?
|In progress
|Fri-09-06-19
|Fri-09-06-19
|
|-
|Get google cloud credits
|Mohan looking into it.
|Sat-08-24-19
|Sat-08-24-19
|}

==Monday, September 09, 2019==

'''VIP meeting: Scrum'''

Bloating. Found toy example problem to analyze bloat.

Deap bug. something about tools.emo.selNSGA2. ask if encountered.

Deep. tensorflow. preprocessing block and mating.

ADF. brainstorm structure/form of global pool of functions. remove unnecessary deap/emade functions. find/store/represent adf.

Preprocessing. Refactor/Documentation. New learner methods. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Many techniques of different complexity. Test effectiveness vs no lemma/stemming.
|In progress. Blocked by task below.
|Mon-09-09-19
|Mon-09-09-19
|
|-
|Jupyter notebook. SubGoal: Examine Mohan's summer notebook. understand pipleline(Lemmatization/Stemming before vectorization then classification). End Goal: Experiment with text classification methods.
|In progress
|Fri-09-06-19
|Fri-09-06-19
|
|-
|Get Emade running properly. Sql problems. Forgot sql password?
|In progress
|Fri-09-06-19
|Fri-09-06-19
|
|-
|Get google cloud credits
|Mohan looking into it.
|Sat-08-24-19
|Sat-08-24-19
|
|} 
== Friday, September 06, 2019 ==
'''NLP meeting: Local Installation of EMADE.'''

DRJZ happened to be meeting with the time conflict group. Some of them split off to join nlp. 

--> NEW Setup. (2 new nlp branches in EMADE)

1. time conflict will work on infrastructure/nlp research(rNN, NEAT, etc.)

2. non-conflict work on implementation/application of nlp(Summarization, Text Generation, Classification, ...)

Alex will continue his summarization efforts.

'''Individual Work'''

1. EMADE reinstall. (still need to get it running)

2. Created envEMADE conda environment.

3. Download imdb dataset. Switch to nlp-app branch.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Switch to proper nlp branch. nlp-app
|Complete
|Fri-09-06-19
|
|Fri-09-06-19
|-
|Jupyter notebook. SubGoal: Examine Mohan's summer notebook. understand pipleline(Lemmatization/Stemming before vectorization then classification). End Goal: Experiment with text classification methods. 
|In progress
|Fri-09-06-19
|Fri-09-06-19
|
|-
|Get Emade running properly. Sql problems. Forgot sql password? 
|In progress
|Fri-09-06-19
|Fri-09-06-19
|
|-
|<s>Read about lemmatization/stemming.</s> Many techniques of different complexity. Just import library and wrap in primitive?
|Complete
|Sat-08-31-19
|
|Fri-09-06-19
|-
|Get google cloud credits
|Mohan looking into it.
|Sat-08-24-19
|Sat-08-24-19
|
|}

== Saturday, August 31, 2019 ==
'''NLP meeting: Discuss Path Forward'''

Alex suggests NEAT. Neat lends itself well to EMADE because of its evolvability. HyperNEAT deviates from EMADE's purpose.

Vectorization. Mohan reviews vectorization to a couple time conflict people that showed up.

Time conflict people want to study NEAT. They used recurrent neural networks last semester in the stocks sub-team, so will also look at neural networks in the context of EMADE.

Alex is interested in text summarization.

Bek and I decide to read about lemmatization/stemming.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read about lemmatization/stemming
|In progress
|Sat-08-31-19
|Sat-08-31-19
|
|-
|Get google cloud credits
|In progress
|Sat-08-24-19
|Sat-08-24-19
|
|}

== Monday, August 26, 2019 ==
'''VIP meeting: Scrum'''

DRJZ feedback. jupyter notebook bad performance does not mean bad primitive. Implement all primitives as they could work for other datasets/problems.

Talked with Bek. Mohan/Alex discuss NLP techniques that I am unfamiliar with.

Mohan posted a when2meet on slack. Wait for common meeting time to emerge.
Meetings will be Saturdays at 2pm.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get google cloud credits
|In progress
|Sat-08-24-19
|Sat-08-24-19
|
|}

== Saturday, August 24, 2019 ==
'''NLP meeting: Review of Summer Work'''

Mohan, Anish, Alex, and I attend.

Mohan goes over his google slides from the summer.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get google cloud credits
|In progress
|Sat-08-24-19
|Sat-08-24-19
|
|}

== Monday, August 19, 2019 ==
'''VIP meeting: Make/Choose Sub-teams'''

Meet other nlp people.

Subteams = { ADF, Preprocessing, Bloat Control, Deep, NLP }
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Join nlp slack channel
|Complete
|M-08-19-19
|
|M-08-19-19
|}

=*Semester One - Spring 2019 (oldest on top)* =

== January 7, 2019 ==
'''New Student Intro:'''
* Dr. Rohling gave an overview of the structure of the AAD team and new/returning members split up. (Start in CoC 16 in future)
* Importance of documentation was really stressed.
* Jason walked us new members through the wiki syllabus.
* Introduced operational definitions and terminology, inspired by evolutionary biology.
** Genome/DNA/Chromosome/Individual: an algorithm with all its properties.
** Gene: a single property of an genome(algorithm)
** Population: a collection of all existing genomes.
** Objective Score?: a score/rating that should either be minimized or maximized.
** Fitness: the performance of a genome in relation to other genomes within the same population. Based on Objective Score.
** Mating/Crossover: Mixing of genomes to produce next generation.
** Importance of Randomness during the Selection Process.
*** Probability of selection for mating is proportional to fitness score. This gives the "weak" a chance at survival.
*** Wars. Select batches of size-k for a "death match". The winner is kept for mating.
*** Merely selecting the "fittest" k-number of genomes.
*** etc. many more. draw inspiration from real-world evolution and breeding methods.


'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Setup wiki-notebook.
|Complete
|January 7, 2019
|
|January 7, 2019
|-
|Email about time conflict for extended presentation days.
|Complete
|January 7, 2019
|
|January 7, 2019
|-
|Join Slack channel
|Complete
|January 7, 2019
|
|January 7, 2019
|-
|Lab 1
|In progress
|January 7, 2019
|January 7, 2019
|January 13, 2019
|-
|Peruse git tutorials provided by VIP
|In progress
|January 7, 2019
|January 7, 2019
|
|}

== January 12, 2019 ==
'''Followed installation procedure on ReadMe.'''

'''Read Deap tutorial: Creating Types'''
*Two important libraries imported from deap: base and creator
*creator creates the types using the create() method. Analogous to nouns.
**param1: (string) name of type. ex: MyFitness
**param2: (class) parent class. ex:Fitness
**param3...n: anything after first 2 params become attributes of the type we are creating.
**ex: since we are inheriting the Fitness class (see param2) we need to give a tuple weights
**param3: weights=(1.0, 2.0, -1.0, -2.0, ). here there are 4 weights. first two should be maximized thus they are positive. last two are negative thus should be minimized. the magnitudes indicate which weight is more important.
**Fitness inherently has some attributes
***values: can be accessed by individual.fitness.values
***valid: boolean: whether or not fitness value is valid.
***dominates(anotherObject, obj = objectives)
****compares this with anotherObject based on the criteria(objectives) passed in thru obj
****if no obj is passed, default to all objectives.
*base creates functions. Think of them as verbs.
**base.register(param1, param2, sub1, sub2, ... subn)
**param1: name of function
**param2: already defined function that provides the functionality of whatever new function we are defining
**sub1,2..n: if param2 requires parameters, this is where you put them.
***any required subparam not explicitly stated will be a param for the new function.
***ex: toolbox.register("attr_bool", random.randint, 0, 1) //usage: toolbox.attr_bool()  // 0 or 1
***vs. toolbox.register("attr_bool", random.randint, 0)    //usage: toolbox.attr_bool(1) // 0 or 1
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Lab 1
|In progress
|January 7, 2019
|January 12, 2019
|
|}
==January 13, 2019==
'''Initial Read & Synthesis of Lab 1'''

'''2nd Read with focus on Python syntax'''
*zip: the equivalent of Riffle[] in Mathematica
**zip({1,2,3},{a,b,c}) // output: {(1, a), (2, b), (3, c)}
*we can extract elements from each internal grouping using a for loop
** for num, letter in zip({1,2,3},{a,b,c})
***//do something with num and letter
*map(f, iterable)
**ex: list(map(sum, {{1,2,3}, {2,3,4}, {3,4,5}}))
**output: {6, 9, 12}//the outer list() puts everything in a list.
**more concise than using for loop.
*toolbox.clone()-not sure why this is necessary.
*accessing subranges of a list in python
**l = [1,2,3,4,5,6,7,8,9,10]
**l[::2] or l[0::2] //takes elements starting at index 0, incrementing at 2;
***=[1,3,5,7,9]
**therefore l[1::2] takes all the odd indexed elements.
**l[::-1] //reverses the list.
*note on mutate: it changes its parameter. does not return a copy
**similar to c++: reverse(vec.begin(), vec.end());
**ex:
***>>three = toolbox.individual_test(7)
***>>clone = toolbox.clone(three)
***>>print(three)
***>>toolbox.mutate(three)
***>>print(three)
***>>print(three == clone)
***[0, 0, 0, 1, 1, 0, 1]
***[1, 1, 0, 1, 1, 0, 1]
***False
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Lab 1
|Complete
|January 7, 2019
|January 13, 2019
|January 13, 2019
|}
==January 14, 2019==
'''Subteam presentation'''
*Deep with DEAP
**combining DEAP with deep learning
**ezCGP
*Emory
**data on patients.
**help predictions
*Visualization
'''Dr. Zutty Genetic Programming'''
Primary Components
*Evaluation
*Fitness Computation
*Selection
*Mating*
*Mutation*
**(*)these change depending on structure of individual.
**Structure can be list, or tree, or graph, etc.

Trees
*leaves - terminals usually what functions are operating on.
*nodes - primitives usually functions. +,-,/,*,%
*Ex 1
individual: 1 + (3*4)
                |
                +
            /       \
            1        *
                  /     \
                3        4
individual represented as a list: [+1*34] 
*recall prefix (and infix and postfix) from ACSL.

*Ex 2
individual1: (0+1) - 2 as list [-+012]
NOT THE SAME as list [-2+01] ==> 2 - (0+1)
^^ for functions above, the arity is 2.

CROSSOVER
*some techniques:
**Randomly identify random points in each tree and swap subtrees originating at those points.
**Strongly typed search: make sure the Type of the output at each point matches. 

MUTATION
*techniques:
**1. randomly pick a primitive and change to something else.
**2. insertion: make a random tree. randomly insert it.
**3. delete a primitive
**4. anything you can do with a tree structure.

Symbolic Regression Example. y = sin(x)
*target: y = sin(x)
*primitive set: +, -, *, /
*terminals: x(input), and any constants
*use taylor approx: x - x3/3! + x5/5! - x7/7! ...etc
*tree diagram
                        -
                      /   \
                     x     div
                          /   \
                         *     *
                        / \   / \
...etc
//this gets hard with restrictive primitive set.
add new operations, such as (!) and (pow), to primitive set.
*wise guy hack: put (sin) into primitive set

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Git Tutorials - Looked Up CS2340 resources
|Complete
|January 7, 2019
|January 7, 2019
|January 14, 2019
|-
|Notes on Dr. Zutty's Lecture
|Complete
|January 14, 2019
|
|January 14, 2019
|-
|Lab 2: Single Objective
|In progress
|January 14, 2019
|January 14, 2019
|
|}
==January 20, 2019==
Adding to tools in toolbox register.
*//define creator, fitness, and Individual
*//define primitive_set(pset)
*toolbox = base.Toolbox();
*toolbox.register("expr", gp.genHalfAndHalf, pset=pset, min_=2, max_=5) //iinitialize a tree
*toolbox.register("individual", tools.initIterate, creator.Individual, toolbox.expr)
*//add other tools: evaluate, select, mutate, and mate
*//suppose we want to ADD LIMITS to the mutate tool.
**toolbox.decorate("mutate", gp.staticLimit(key=operator.attrgetter("height"), max_value=17)) //limits resultant tree, to max height of 17.
Plots
*similar to javafx.
**create an object
**adjust its instance vars, and attributes.
***plot_example.plot(gen, min_list, label="minimum")
***plot_example.plot(gen, max_list, label="maximum")
***plot_example.xlabel("Generation")
***plot_example.ylabel("Fitness")
***plot_example.legend(loc="upper right")
**show it. 
***plot_example.show()  
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Lab 2: Single Objective
|Complete
|January 14, 2019
|January 20, 2019
|January 20, 2019
|}
== January 28, 2019 ==
Meeting: Dr. Rohling talks about pareto fronts, co-dominance, and confusion matrices.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Lab 2: Multi-Objective
|In progress
|January 21, 2019
|January 28, 2019
|
|}
==January 30, 2019==
Review and wrap up Lab 2.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Lab 2: Multi-Objective
|Complete
|January 21, 2019
|January 28, 2019
|January 30, 2019
|}
==February 4, 2019==
James Rick walks through his titanic notebook.
Part 1: preprocessing data
*converting values to numerical values.
*resolving nan or n/a values.
*saving section of training data for cross validation.
**Also use this to produce confusion matrix.
Part 2: machine learning
*sci-kit learn library
Part 3: cv, accuracy, and predict on test data.
*create confusion matrix and calculate accuracy.
*run best model on test data.
*load data to csv file and upload to kaggle.

Used pareto front graph to create rankings for draft.
Sub-teams tasked with attempting titanic problem with sklearn.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|ML Titanic - use sklearn
|In progress
|February 4, 2019
|February 4, 2019
|
|}
==February 10, 2019==
Work on titanic with sklearn.
*Kept the data processing from example notebook.
*logistic regression vs gradient boosting.
*more info on sub-team [https://vip.gatech.edu/wiki/index.php/Bootcamp_Sub-team_Spring_2019 wiki]

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|ML Titanic - use sklearn
|In progress
|February 4, 2019
|February 10, 2019
|
|}
==February 11, 2019==
Sent confusion matrix to Alex, who makes the pareto graph.
Meeting: Start GP Titanic
*Data processing
**partition data into 7 groups.
**encode Embarked as 1, 2, 3
*Genetic programming
**single objective gp.
**arity = 7. 
**primitive set same as lab 2.
**individual: function to calculate a value, in this case: survival [0:1]
**fitness: minimizing error. same as lab 2.
**evaluate:
***will take 2 + 8 arguments
***[2]: individual, primitive set
***[8]: 7 datatypes(sex, ticket_price, age, etc) + 1 truth(survived or not)
*Challenges:
**evaluate method inconsistently throw an error
**invalid number of arguments
**forgetting individual?

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|ML Titanic - use sklearn
|Complete
|February 4, 2019
|February 10, 2019
|February 11, 2019
|}
==February 12, 2019==
Resolved invalid number of arguments error
*reason: typo. add primitive had an arity was set to 7 not 2. 
Completed version 1 of gp algorithm
*arity = 7 //uses all available empirical data
*pset = pset(lab2) + [x^2, x^3, x^3 - x^2]
*stops training at 45 rounds to temporarily prevent bloating
*score() method is functional: returns accuracy
**Best score: 0.7932203389830509
*predict() method is functional: returns list of predictions
**Best Kaggle score: 0.70334

Challenges
*1. Tree size is growing to large. Bloat error.
*2. adding to primitive set. some operations produce nan or have restrictions
**ex: log(0) -> error
Potential Solution
*1. staticLimit method or other bloat control [https://deap.readthedocs.io/en/master/api/tools.html#bloat-control techniques].
*2. handle special cases inside wrapper method

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|GP Titanic
|In progress
|February 11, 2019
|February 12, 2019
|
|-
|Resolve Tree Bloating Problem
|in progress
|Feb 12, 2019
|Feb 12, 2019
|
|-
|Resolve Primitive Set Problem
|Complete
|Feb 12, 2019
|Feb 12, 2019
|Feb 12, 2019
|}
==February 17, 2019==
Tried fixing tree height issue. 
*1. Added staticLimits to mutate, mate, and select methods in toolbox.
*2. Tried Alex's suggestion. Adjust min_, max_ in expr.
*3. Allocate more training data.
**Before: [test, train] => [0.33, 0.67]
**After: [test, train] => [0.25, 0.75]
*Still an issue.
Made some tweaks:
*1. change population to 350
*2. added a second mutation. mutNodeReplacement with same probability(p = 0.2)
*3. adjusted generations (gen = 50) to forcibly avoid tree height issue.
*4. somewhere during the process, reached a cv accuracy high of [0.834]. eventually lost. did not make kaggle submission for [0.834].
Results
*1. Raised cross validation accuracy to :  > 0.8251121076233184
*2. Confusion Matrix  [[141   6]  [ 33  43]]  True Negatives 141 False Positives 6 False Negatives 33 True Positives 43

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|GP Titanic
|In progress
|February 11, 2019
|February 12, 2019
|February 17, 2019
|-
|Resolve Tree Bloating Problem
|in progress
|Feb 12, 2019
|Feb 17, 2019
|
|}
==February 21, 2019==
Used best model from Sunday Feb 21 to make Kaggle submission
*Kaggle Score:  0.77990, which is up 7.656% from 0.70334
Thoughts
*Taller trees does not correspond to better performance.
**Searching for ways to fix tree height issue may not be worth it. 
*Using a more diverse set of mutate functions produces better results.
*Positive correlation between cv accuracy and real world accuracy.
**cv accuracy improvement: ~2.5%
**-->kaggle score improvement: ~7.6%
Went to Help Desk
*1. James Rick helped me with EMADE installation -> how to setup database.
**downloaded sqlDesktop gui
**created server called: test
**created new user: rkan3_user
***with password

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Resolve Tree Bloating Problem
|In progress
|Feb 12, 2019
|Feb 17, 2019
|
|-
|Install Emade with database
|In progress
|Feb 18, 2019
|Jan 12, 2019 - started before assigned -
|Feb 21, 2019
|}
==February 22, 2019==
Went to Help Desk
*James Rick confirmed that staticLimit is the proper bloating control technique to use. 
**Also noted that bloating of the tree size can result in the same error message.
**My tree bloating error was due to the size of the trees being to big, ie the trees were too wide.

*Tried to put a staticLimit on the "size" attribute of each individual
**Apparently there is no such thing as a "size" attribute
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Resolve Tree Bloating Problem
|Complete
|Feb 12, 2019
|Feb 17, 2019
|Feb 22, 2019
|}
==February 28, 2019==
Met with Alex and Daniel @ Klaus. 6pm.
*Installed mysql for mac terminal for testing database connections.
**Tried to do the connection via mac terminal
*Edited input_titanic.xml with Alex's database info.
**then ran the python command in the terminal.
**this was the solution.

[[files/---Users-reagankan-Reagan GT-spring2019-vip-emade new-notebooks-22feb2019.png]]

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run Emade
|Complete
|Feb 25, 2019
|
|Feb 25, 2019
|-
|Test Database connection
|Complete
|Feb 25, 2019
|
|Feb 28, 2019
|}

==March 7, 2019==
Met Michael and Alex in Klaus.
* Examined the data our master and workers produced over the past few days. 
** Area under the curve graphs was not straightforward.
** Alex will try and run EMADE again. Remember to start a worker.
** Apparently IP address changes at different locations across campus. 
* Alex was successful in testing Anthony D'Achille's visualization software.
** Michael and I could not get it to work on our machines.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run worker for better results
|Complete
|March 7, 2019
|
|March 7, 2019
|}

==March 11, 2019==
Bootcamp Presentation
Takeaways
* Pizza is good. Antico's not Tico's
* Dr. Rohling stressed the importance of having labels on the graphs.
* Some groups forgot purpose of pareto front graphs. 
* Grid Search is a tool that does Alex's brute force method of trying all possible hyper-parameter values
* Next time, should explicitly show best individual, including the primitive and accuracy. 
* Caching team
**when successful will drastically reduce EMADE runtime.
**works closely with EMADE infrastructure.
* Visualization
**building visualization tools for EMADE developers.
Left early for Recitation; did not see other teams.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Create priority list of sub-teams
|In progress
|March 11, 2019
|March 11, 2019
|
|}

==March 25, 2019==
Back from Spring Break. 
* Split into subteams.
* Priority: DEEP, Stocks, EEG
* Initially assigned to EEG.
** Swapped with Michael. Now on DEEP.
** Unfortunately, unable to attend weekly sub-team meetings.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Create priority list of sub-teams
|Completed
|March 11, 2019
|March 11, 2019
|March 21, 2019
|}

==April 1, 2019==
Mr. Rodd Talebi gives an overview of Cartesian GP.
*Structure
**Traditional GP evolves individuals with a tree structure.
**Cartesian GP uses a directed acyclic graphs.
***allows for reuse of previous calculations.
***latent DNA
***fixed genome size: No more bloating!
***only mutations for now.
****mating is currently non-existent.
****would only destroy any beneficial structures created thus far.
**Blocking
***grouping of primitives.
***still in early stages of implementation. potentially beneficial.
*Primitives are advanced
**basically experimenting with deep learning layers and methods.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Create local repo of DEEP github repo
|In progress
|April 1, 2019
|April 1, 2019
|
|}

==April 8, 2019==
[[files/Talebi TF Intro.png|thumb|435x435px]]
Mr. Rodd Talebi gave an introductory explanation of tensorflow
* Creation of model
** must create placeholders for input.
** ? wildcard variable. value determined at runtime.
** can also specify specific values.
* Keyword: fetches
**specify breakpoint in previously constructed model
** for training/backprop
** for using trained model for predictions
He also showed us tensorflow usage in the context of the DEEP code. Hard to understand.

{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Create local repo of DEEP github repo
|In progress
|April 1, 2019
|April 1, 2019
|April 8, 2019
|-
|Try running problems.py in the SymbRegression branch.
|In progress
|April 8, 2019
|April 8, 2019
|
|-
|Get familiar with the structure of code. How are genomes, blocks, individuals encoded?
|In progress
|April 8, 2019
|April 8, 2019
|
|}

==April 15, 2019==
* Ani talked about the roles of sub-team A and B a bit more in depth.
** It seems like the subteams  may not be needed in the future. 
** They are trying to evolve a best individual and test it against various benchmarks, CIFAR-10, CIFAR-100, Housing Prices.
* Actual assignment
** try to produce our own model and run 100 epochs on CIFAR-10 and CIFAR-100.
** Will hopefully serve as comparison against DEEP best individual. 
** Discussed with Mohan and Animesh. They are considering using Convolutional layers.
** Given my lack of experience, I should explore Ani's notebook and try using dense layers first.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get familiar with the structure of code. How are genomes, blocks, individuals encoded?
|In progress
|April 8, 2019
|April 15, 2019
|
|-
|Try running problems.py in the SymbRegression branch.
|In progress
|April 8, 2019
|April 15, 2019
|
|-
|Explore and breakdown Ani's code.
|In progress
|April 15, 2019
|April 15, 2019
|
|-
|Try to create a tensorflow model with dense layers only to start off.
|In progress
|April 15, 2019
|April 15, 2019
|
|}

==April 17, 2019==
[[files/CIFAR-10 training and testing graph.png|thumb|252x252px]]
[[files/MNIST training-test accuracy.png|thumb|258x258px|dense layers trained on MNIST]]
Based my models off of Ani's models.
* added dropout layers.
* added 1 by 1 convolutional layers.
* change optimizer: Adam -> Adagrad
* Accuracies for both CIFAR-10 and CIFAR-100
** ~60%
** trained on each dataset for 50, 100, and 200 epochs.
Try dense layers on MNIST
* CIFAR-10 testing accuracy: ~97%
* not sure why the accuracy is so high for such a simple model.
** may have setup the training and testing code incorrectly.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get familiar with the structure of code. How are genomes, blocks, individuals encoded?
|In progress
|April 8, 2019
|April 17, 2019
|
|-
|Try running problems.py in the SymbRegression branch.
|In progress
|April 8, 2019
|April 15, 2019
|April 17, 2019
|-
|Explore and breakdown Ani's code.
|In progress
|April 15, 2019
|April 15, 2019
|April 17, 2019
|-
|Try to create a tensorflow model with dense layers only to start off.
|In progress
|April 15, 2019
|April 15, 2019
|April 17, 2019
|-
|Learn Tensorflow
|In progress
|April 17, 2019
|April 17, 2019
|
|-
|Learn Keras. Is this separate from Tensorflow?
|In progress
|April 17, 2019
|April 17, 2019
|
|}
==April 19, 2019==
Research difference between keras and tensorflow.
* Keras provides a simpler interface on top of tensorflow?
* Should probably learn tensorflow first.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get familiar with the structure of code. How are genomes, blocks, individuals encoded?
|In progress
|April 8, 2019
|April 19, 2019
|
|-
|Learn Tensorflow
|In progress
|April 17, 2019
|April 19, 2019
|
|-
|Learn Keras. Is this separate from Tensorflow?
|In progress
|April 17, 2019
|April 19, 2019
|
|}

==April 22, 2019==
Review my assigned slide.
* Discussed blocks with Jinghua and Samuel
* Added more notes to the final slides
Final Presentation.
* Sudden drop in validation accuracy on CIFAR-100
* See pattern with two pooling layers in series
* Best individual is complex. Dr. Rohling likes it.

* Dr. Rohling brings up a few points
** 1D convolutions are a subset of 2D ones. 
*** Why can't it be implemented?
*** Seems to be constrained by the design of python's methods.
** Minor pareto front graph error. Front lines are inverted in the wrong direction.
** Diversify genome
*** Why not use larger populations?
*** Currently start with population size 9
**** each individual is mutated 4/5 times
**** from the set of offspring, choose next reproducing set of 9
*** Takes too long to train. 24hrs ~3 generations
*** Elitism?
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get familiar with the structure of code. How are genomes, blocks, individuals encoded?
|In progress
|April 8, 2019
|April 22, 2019
|
|-
|Learn Tensorflow
|In progress
|April 17, 2019
|April 22, 2019
|
|-
|Learn Keras. Is this separate from Tensorflow?
|In progress
|April 17, 2019
|April 22, 2019
|
|}

==Final Grade==
[A-, A] range.
I have completed the assignments to the best of my ability.

==Action Items Cumulative Version:==
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Setup wiki-notebook.
|Complete
|January 7, 2019
|
|January 7, 2019
|-
|Email about time conflict for extended presentation days.
|Complete
|January 7, 2019
|
|January 7, 2019
|-
|Join Slack channel
|Complete
|January 7, 2019
|
|January 7, 2019
|-
|Lab 1
|Complete
|January 7, 2019
|January 7, 2019
|January 13, 2019
|-
|Peruse git tutorials provided by VIP
|Cannot find them.
|January 7, 2019
|January 14, 2019
|
|-
|Record Jan 14 Meeting
|Complete
|January 14, 2019
|
|January 20, 2019
|-
|Lab 2
|Complete
|January 14, 2019
|
|January 20, 2019
|-
|Lab 2: Multi-objective GP
|Complete*
|January 14, 2019
|January 20, 2019
|January 25, 2019
|-
|ML Titanic
|Complete
|Feb 4, 2019
|Feb 10, 2019
|Feb 11, 2019
|-
|GP Titanic
|Complete
|Feb 11, 2019
|Feb 12, 2019
|Feb 17, 2019
|-
|Resolve Tree Bloating Problem
|In Progress
|Feb 12, 2019
|Feb 12, 2019
|
|-
|Resolve Primitive Set Problem
|Complete
|Feb 12, 2019
|Feb 12, 2019
|Feb 12, 2019
|-
|Install Emade with database
|Complete
|Feb 18, 2019
|Feb 18, 2019
|Feb 22, 2019
|-
|Run Emade
|Complete
|Feb 25, 2019
|
|Feb 25, 2019
|-
|Test Database connection 
|Complete
|Feb 25, 2019
|
|Feb 28, 2019
|-
|Run worker for better results
|Complete
|March 7, 2019
|
|March 7, 2019
|-
|Create priority list of sub-teams
|In progress
|March 11, 2019
|March 11, 2019
|March 21, 2019
|-
|Create local repo of DEEP github repo
|In progress
|April 1, 2019
|April 1, 2019
|April 8, 2019
|-
|Try running problems.py in the SymbRegression branch.
|In progress
|April 8, 2019
|April 8, 2019
|April 17, 2019
|-
|Get familiar with the structure of code. How are genomes, blocks, individuals encoded?
|In progress
|April 8, 2019
|April 8, 2019
|
|-
|Explore and breakdown Ani's code.
|In progress
|April 15, 2019
|April 15, 2019
|April 17, 2019
|-
|Try to create a tensorflow model with dense layers only to start off.
|In progress
|April 15, 2019
|April 15, 2019
|April 17, 2019
|-
|Learn Tensorflow
|In progress
|April 17, 2019
|April 22, 2019
|
|-
|Learn Keras. Is this separate from Tensorflow?
|In progress
|April 17, 2019
|April 22, 2019
|
|}