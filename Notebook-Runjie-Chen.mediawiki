'''Name:''' Jessi Runjie Chen

'''Email:''' rchen417@gatech.edu

'''Cell Phone:''' 703-627-6826

'''Interests:''' Artificial intelligence, Machine Learning, Cybersecurity, Python, Java, Snowboarding, Anime 

= Fall 2021 =

== Week 14: November 22nd - November 28th ==

===November 22nd, 2021 Team Meeting Notes===
*scrums:
** modularity
*** documentation and refactoring has been done
*** all bad variable names have been changed
*** First year members have been improving google cloud scripts
*** First year members have also been working on data visualization
*** Cache V2 integration is mostly done
** NLP
*** We have all the primitives that we need to get results
*** NNLearner2 works on classification
*** New members are almost set up with PACE, once set up, everyone can help run the experiment

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Resolve errors from running EMADE on PACE
|In progress
|November 15th, 2021
|November 29th, 2021
|
|}

== Week 13: November 15th - November 21th ==

===November 15th, 2021 Team Meeting Notes===
* New members should continue to keep notebook updated with detail
* Clearly identify individual contributions and provide evidence of them
* If reading papers, include notes for them on our notebooks
Scrums:
* Modularity
** Dividing BootCamp students into different tasks
*** recursive function
*** fix: cloudcopy.sh is downloading stuff over and over again
* NLP (our team)
** Found that there are still quite a few bugs after the big merge
** divided the team into subteams to focus on specific tasks
** Reducing the scope to only regression to for this semester
** Input: context & query, Output: start and end index of the context (extract the answer from the context as a substring)
** Need Dr.Zutty's advice on a weird issue that we are encountering
*** memory issues

===November 17th, 2021 sub-team Meeting Notes===
* Our team has determined that the output layer problem that I got assigned to work on was too hard to solve for this semester, so my task team was dissolved and I got reassigned to a different task: NNLearner for 2 Data Pairs
* Task description:
** Dr. Zutty previously mentioned there should be NNLearner code for two data pairs (for example, NNLearner(ARG0, ARG1, layer list, optimizer, X). Look into this, and debug with a dataset with at least two textual inputs (one for each data pair) and a number for classification. Here's one on Twitter Sentiment analysis that could work: http://help.sentiment140.com/for-students/
** NNLearner 2 task notes
*** In neural_network_methods.py, we only care about code related to textdata (for example we can ignore code related to imagedata because that doesn't apply to NLP)
*** For everything that we did with textdata, we are repeating the same process twice with NNlearner 2
*** The code might look long and intimidating, but most of the stuff we can ignore and we can just focus on textdata related things
*** we need to run EMADE regularly with seeded individuals, we start out with NNLearner, and once that works properly, we run NNLearner 2, which should error out, and then we can start debugging
*** Unsure of what kind of output we'd expect from NNLearner 2 yet
* My Progress:
** I reviewed code in EMADE.py and general_methods.py and tried to understand our codebase
** I reviewed changes in EMADE.py: https://github.gatech.edu/sleone6/emade/commit/77992e059d9d10b5174632a859c514b626d31d92
** My notes and questions:
*** I'm a bit confused, so all we are doing is looking at only the changes that were made in EMADE.py according to the github link that was sent (so like the one line of code were NNLearner2 was added?)  and based on that change, we need to see what else needs to be changed in the load_environment method in general_methods.py?
*** If my assumption was correct, I think we need to first understand what each of the code file is doing so that we can then determine what needs to be integrated, however right now I'm having trouble understanding the code, does anyone have any tips on that?

===November 21st, 2021 Hackathon Notes===
*Resolved some issues from running EMADE on PACE
*Found that I was missing this line from the pbsmysql.pbs file
<blockquote> 
mysqld_safe --datadir='/storage/home/hpaceice1/rchen417/scratch/db'
</blockquote> 
*To run standalone tree evaluator, I must clone the updated branch using:
<blockquote> 
git clone --depth 1 https://github.gatech.edu/sleone6/emade.git --branch feature/nnlearner2 --single-branch 
</blockquote> 
* I tried running that, however, it isn't merging with the old branch correctly, therefore I decided to delete the old branch on PACE and clone the updated branch locally and scp over the updated branch. That failed miserably because of disk quota exceeded error, need to figure out what went wrong.


===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|compare changes that were made in EMADE.py with the load_environment method in general_methods.py, and determine which changes we need to integrate
|Completed
|November 15th, 2021
|November 17th, 2021
|November 17th, 2021
|-
|Run EMADE successfully with NNLearner
|
|November 17th, 2021
|November 21th, 2021
|
|-
|Attempt to run EMADE with NNLearner2 and identify steps that need to be done based on errors
|
|November 17th, 2021
|November 21th, 2021
|
|}

== Week 12: November 8th - November 14th ==

===November 8th, 2021 Team Meeting Notes===
Scrums:
*Image Processing Subteam
** looking at selection methods
*** Lexicase
**hyper features
*** sharpening feature
*** strongly-typed GP
* Modularity
** introducing first-semester students to the team, the tools they use, etc.
** work on documentation
*NLP
** got new members onboard
** tried to have new members set up PACE but have to postpone it due to PACE going under maintenance
** Focus on integrating the primitives that we finished this week
*NAS
**Made video on how to setup Emade
Discussion: Should we include Neuro Network in Bootcamp?
* I voted agree and that Bootcamp should be extended a week to include the Neuro Network lecture
* maybe each subteam can make tutorial on it
* maybe Dr.Zutty can provide some resources on it to new team members
Sub-team notes:
*Assigning tasks
*Assigned 4 task teams:
**NNLearner for 2 Data Pairs
**Solve Output Layer Probability Vector to words problem (I got assigned to this task team)
*** First get PACE working
*** Make sure to understand the output layer part of the paper provided

===November 12th, 2021 sub-team Meeting Notes===
*I reached out to some of my NLP teammates and set up a call to clarify some of the concepts and tasks that need to be completed
*Tasks:
** Read this paper (An Illustrated Guide to Bi-Directional Attention Flow (BiDAF)): https://towardsdatascience.com/the-definitive-guide-to-bi-directional-attention-flow-d0e96e9e666b
** Understand the Colab notebook: https://colab.research.google.com/drive/1dx66YZSFYXimJAcZtU35yTkt_PYpiVL9?usp=sharing
** After understanding the concepts in the papers, we will be assigned potential tasks such as coming up with a better evaluation function
*Notes:
** F1 means weighted average between precision and recall
** Always do bash reinstall after making local changes
*My Progress:
** I'm mostly set up with EMADE on PACE-ICE (there are a few errors present in the master.err file that I need to resolve)
*** I ran into weird module not found issues after installing everything, need to ask teammates for help during our next meeting
*** Fix: manually install these modules again
** Read the paper "An Illustrated Guide to Bi-Directional Attention Flow (BiDAF)", now I have a better grasp of what NLP is doing and understand the concepts of BiDAF much better now, especially the output layer as that's the layer that I got assigned to be focusing on
*** I would recommend this paper to any new NLP team members as it explains the BiDAF model really well
**** https://towardsdatascience.com/the-definitive-guide-to-bi-directional-attention-flow-d0e96e9e666b
*** My notes of the paper:
**** Bi-Directional Attention Flow (BiDAF) is an NLP model that is very influential in the Question and Answer domain.
**** Specifically, BiDAF is a closed-domain, extractive Q&A model that can only answer factoid questions. 
**** BiDAF has 3 major parts: Embedding layers, Attention and Modeling layers, Output layer
**** I'm focusing on the Output layer, so I'm abstracting the technical details of the Embedding, Attention, and Modeling layers and just gained an overview of what these layers do. 
**** Imagine each word in the context as a minion with an empty brain, after going through the Embedding layers, the minions learns about their own and each other's identity.
**** After going through the attention layer, each minions knows their own importance to the query. 
**** After going through the attention layer, each minions knows each other's importance to the query. 
**** Finally, the output layer returns two probability vectors. One vector represent the probability of each word in the context to be the start index of the answer, another vector represent the probability of each word in the context to be the end index of the answer. This is determined based on each word's importance to the query which were the ouputs from the previous layers


===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Make sure to understand the output layer part of the papers provided
|Completed
|November 7th, 2021
|November 15th, 2021
|November 15th, 2021
|-
|Resolve errors from running EMADE on PACE
|In progress
|November 15th, 2021
|November 17th, 2021
|
|-
|Read additional papers that explain the BiDAF model in an easier-to-understand way 
|Completed
|November 12th, 2021
|November 15th, 2021
|November 15th, 2021
|}

== Week 11: November 1st - November 7th ==

===November 1st, 2021 Team Meeting Notes===
*Assigned team: NLP
*Scrums:
** Image processing
*** difference between multi-class and multi-label: multi-label is more tricky
*** Need to squash bugs
** Modularity
*** improving midterm presentation
*** problems encountered:
**** Stocks uses Cache V2 but they are not using it, which caused some issues
*** hopefully to get better data than presented in midterm presentation
*** Tips from Dr. Zutty:
**** Do the merge
**** Make a fresh branch when merging with Cache V2
** NLP
*** Figured out required primitives
*** About halfway done with Bidirectional Attention Layer
*** Output layer is almost done
*** Modeling layer is done
*** Dr. Zutty inputs:
**** Make sure we are doing Unit tests
** NAS
*** goals for next week: look into literatures about predicting performance, also optimize hyperparameters without going through training 
*** Old version of Tensorflow is deprecating, make changes accordingly
* Subteam (NLP) Notes:
** Joined NLP slack
** NLP is trying to find a way to represent words as numbers and features
** given a passage and a question, being able to return an answer (the answer will be a word for word excerpt taken from the passage)
** primitives are layers to the network, output from one layer is input to another layer
** resources:
*** BI-DIRECTIONAL ATTENTION FLOW FOR MACHINE COMPREHENSION: https://arxiv.org/pdf/1611.01603.pdf
*** PACE ICE Setup Video Tutorial: https://www.youtube.com/watch?v=LashYCCJF3E&feature=youtu.be
*** PACE ICE Guide: https://github.gatech.edu/emade/emade/wiki/Guide-to-Using-PACE-ICE
*** There's a MySQL common errors table on emade github
** Meeting: Wednesdays at 2pm, meeting virtually, Bluejeans link will be sent in slack on the day of

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read reference articles provided by the NLP subteam
|Completed
|November 1st, 2021
|November 7th, 2021
|November 3rd, 2021
|-
|Setup PACE ICE following the video provided by the NLP subteam
|Completed
|November 1st, 2021
|November 15th, 2021
|November 14th, 2021
|}

===November 1st, 2021 sub-team Meeting Notes===
*PACE-ICE is under maintenance from November 3, 6:00 am to November 5, 11:59 pm, therefore new members like myself cannot set it up until PACE's maintenance is done
*Finding a workaround to debugging as we cannot use PACE to debug
**set up a local conda environment to run primitive code outside of EMADE
*NN/NLP Introduction (presented by Steven)
**Neural Networks
***only need to understand this at a high level for now
***ML: we focus more on supervised learning
***Neural Network: 
[[files/Jessi/images/nn.png]]
**After we trained our data, which process we don't need to know for now:
***be aware of overfitting (high variance) - the data fits the trained data really well but does not necessarily fit other real-world data 
****To fix this, we use Regularization
***There could also be underfitting
**Recurrent Layer (RNN)
***Used a lot in NLP
***Focus on input and output layers
[[files/Jessi/images/rnn.png|thumb|100x70px]]
***We feed in x, output y, along with another output that feeds into itself that changes its state
**LSTM (long-short term memory)
***basically a fancy recurrent layer with multiple activations
***We use this a lot recently
**Attention Layer
***Focus on the keywords in the query, while paying less attention to other words in the passage
***long story short: attention allows us to pay more attention to some words than others
**NN learner
**ARGs
***ARG0 is question or query
***ARG1 is the passage
**primitives are found in neural_network_methods.py, 90% of our work is going to be in that file
*Intro to QA (presented by Devan)
**NLP is teaching computers how to understand natural language including the many nuisances associated with it
**QA is asking questions and get answers based on the context given in the query and the passage from which the answer will be produced
**BiDAF Model:
[[files/Jessi/images/bidaf.png]]


== Week 10: October 25th - October 31th ==

===October 25th, 2021 Team Meeting Notes===
* Sub team presentations
**Natural Language Processing (NLP)
***Problem: question and answering system 
***Vision: Make machines understand natural language
***Method:
****Use SQUAD dataset
****BiDAF
***Literature review
****Deep Learning Approaches for question answer system by Yashvardhan Sharma and Sahil Gupta
****Machine Comprehension Using Match-LSTM
***Next steps
****Implement output layer form BiDaf
***New Members
**** Meeting time: Wednesday 2:00 pm
**** Learn about question answering
**** Solve cool problems with Neural Architecture Search

**NAS
***Goal: Improve productivity of emade
***Time Stopping: Lower training time is the same as minimizing the number of parameters
***Preprocessing:
****Text tokenization
****One hot encoding for multiclass target data
****Growing complex individuals
*** Changes in EMADE: Changed inputs to adfs
*** NNLearner SQL table
*** New analysis methods:
****nn_ind_from_has(hash)
****Given an individual’s hash, return all generations that individual is a part of
***Recruiting:
****Meeting: Friday 2 - 3pm
****Automate ways to find optimal neuro networks 
****Creating more tutorials and documentation on Emade

* Bootcamp team presentations
** Team 1 (my team): we presented first
** Team 2:
*** Data preprocessing: Dropped columns that won’t help in predicting if a passenger survived or not such as ‘’name”, “passenger ID”, etc.
*** MOGP design: Used SPEA2 for select function
*** MOGP results:
**** Got 0.12 AUC
**** one hot encoding might have improved results
***Emade:
****Used FP and FN instead of FPR and FNR because slow computer no time to rerun
****Used one hot encoding this time
****Only got 10 generations due to slow PC and PC crashes
****Also found that AdaBoostLeaner being the favored primitive, same as what we found

* I had another class at 6:30 so I was only able to stay and take notes on the presentations above.

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update notebook weekly
|Completed
|October 25th, 2021
|November 1st, 2021
|October 30th, 2021
|-
|Read Subteams' presentation slides, rank them based on my preference and submit my rankings to Canvas
|In progress
|October 25th, 2021
|November 1st, 2021
|
|}

== Week 9: October 20th - October 26th ==

===October 20th, 2021 Team Meeting Notes===
*Emade Installation Work Session
*Created data preprocess files
*Successfully ran workers

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Change Emade input file to achieve better AUC
|Completed
|October 20th, 2021
|October 25th, 2021
|October 25th, 2021
|-
|Make Presentation
|Completed
|October 20th, 2021
|October 25th, 2021
|October 24th, 2021
|-
|Rehearse Presentation
|Completed
|October 20th, 2021
|October 25th, 2021
|October 25th, 2021
|}

===October 22th, 2021 Sub Team Meeting Notes===
*Most of the team is able to connect to master through SQL and run Emade correctly
*Edited the data preprocessing files so that Emade doesn't keep returning infinity values
*Next steps to complete individually:
** 1. Make sure the default files work with the input_titanic.xml and the titanic database (completed)
** 2. Copy the input_titanic file -> emade_titanic with the database changed to emade_titantic and the datasets changed to train and test preprocessed csv.gzs (completed)
** 3. Copy the emade_titanic.xml -> super_titanic.xml Database is now super_titanic, change mutation and mating functions (in-progress)

===October 24th, 2021 Sub Team Meeting Notes===
* Team efforts:
** Made presentation
** successfully ran EMADE for 70 generations with working preprocessed data and input file
** Results:
<blockquote> 
Emade Algorithm AUC = 0.1311417 <br>
 Genetic Algorithm AUC = 0.1798859 <br>
 ML AUC = 0.3201224
</blockquote>

[[files/Jessi/images/EMADEvsMLvsGP.png]]
** Rehearsed presentation
** Link to our presentation: https://docs.google.com/presentation/d/1YIiVWW3tQe2RZSRNIsomlLb2mUbaaj1bZN-rHt9KRb0/edit?usp=sharing
* My contributions:
** My PC has a lot of RAM so I left it on to run EMADE overnight and got to 216 generations, however in the morning we realized that the preprocessed datasets are faulty (The test preprocessed dataset doesn't have a "survived" column, and that's why we kept getting "inf" values) Therefore the data we obtained by running EMADE thus far have been useless
** After we fixed the preprocessed datasets and input file, I ran EMADE for another 36 generations with working preprocessed data and input file
** While EMADE is running, I worked on the presentation slides and took charge of presenting the Multi-objective Genetic Programming (MOGP) portion of the presentation. 
**I wrote the slides for the MOGP part as well as edited some of the slides of my teammates' parts
**I rehearsed the MOGP part of the presentation by practicing presenting it and timing myself to make sure that I stay within my allotted time (3 minutes)

== Week 8: October 13th - October 19th ==

===October 13th, 2021 Team Meeting and October 16th, 2021 Hackathon Notes===
Emade Installation Session
*Cloned Emade using Git Bash
*Added Conda to bashrc file
*Created Conda virtual environment named "emadeEnv"
*Installed Emade dependencies using conda and git
*Installed SQL
*SQL connection to Elan's server was successful but ran into some issues which still need to be further investigated
<blockquote> 
mysql -uguest -pemademade -h71.204.44.212 -P6603 
</blockquote>
*Tested Emade by running:
<blockquote> 
python src/GPFramework/launchGTMOEP.py -w templates/input_titanic.xml 
</blockquote>
** Got errors with python 3.8, used python 3.7 with Conda virtual environment to resolve the error
** Got errors with modules not found, error was resolved after reinstalling all packages and dependencies in conda virtual environment
** No more errors are shown in the worker error file 
** Investigating worker output file

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Resolve issues with SQL client 
|Completed
|October 16th, 2021
|October 20th, 2021
|October 20th, 2021
|}

== Week 7: October 6th - October 12th ==

===October 6th, 2021 Team Meeting Notes===
*Multi-week project introduction
**The presentation will be on 10/25
**Afterwards, everyone will be on Monday and no Wednesday Bootcamp sessions anymore
**Hackathon on 10/16 or 10/17
*Update notebook by Friday
**Document every single detail
**Separate individual contributions from group efforts, document both
**Insert links to presentation and team wiki page
**Make sure to write down which slides I presented
*Emade
**Automated machine learning
**One person will be the “master process”, other teammates will be “workers”
**The last column of train data is the truth data
**Use minimization for now
**Make sure the MySQL command (found in lecture slides) works before troubleshooting emade

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install Emade, preferably on my build machine because it needs a lot of memory. Instructions found in lecture slide
|Completed
|October 6th, 2021
|October 13th, 2021
|October 16th, 2021
|-
|Make sure my notebook is up to date before 10/8 at 11:59 pm
|Completed
|October 6th, 2021
|October 8th, 2021
|October 8th, 2021
|}

== Week 6: September 29th - October 5th ==

===September 29, 2021 Team Meeting Notes===
*Peer eval open next week
**If don’t submit peer eval, automatic letter grade drop
*Presentations
**Group 4
***Used logical terminals
***Used np.greater, np.less, np.less_equal, np.logical_and primitives
***Used gp.mutNodeReplacement which is what we did
***Num_gen = 50, we did num_gen = 40
***Their GP AUC is around 0.2, which is similar to what we got 
***Used hall of fame, which is a pretty good way to do things
***Missing constants in primitive set
***Did not put pareto fronts on top of each other 
**Group 3
***Data preprocessing: 
****Extracted titles from name and mapped to integer values
*****Mr = 1, miss = 2, mrs = 3, master = 4, rare = 5
****Did not use one hot encoding which might lead to unintended relationships between features
*****For example, since rare is assigned 5 and master is assigned 4, the program might be trained to think that rare is closer to master than Mr, when in reality there’s no such relationship 
***Used random forests, KNN, logistic regression, MLP, and SVM
***Got 0.11 AUC for ML, which is pretty good
***GP:
****Used muteUniform
****Used tools.selLexicase
****Higher discrepancy between false positive and false negative will be penalized more
****Got higher AUC for GP (AUC: 0.17)
****GP graph does not display not fn/fp rate so the comparison might be off
**Group 2
***ML:
****decision tree classifier
****Random forest
****Ada boost classifier
****MLP 
****SVM
***GP:
****Used gp.mutUniform
****Max tree height = 17
****Used hall of fame
****Missing Pareto front line on the graph
**Group 1
***I am part of Group 1 and we presented

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Peer Evaluation
|Completed
|September 29, 2021
|October 8th, 2021
|October 3rd, 2021
|-
|Insert diagrams for the completed labs and projects in my notebook
|Completed
|September 29, 2021
|October 8th, 2021
|October 8th, 2021
|}

== Week 5: September 22nd - September 28th ==

===September 22, 2021 Team Meeting Notes===

*Thoughts on titanic example
**Sometimes we have to sacrifice performance on one objective to achieve higher performance on the other objective in order to achieve codominance 
**There’s not really an intuitive way to interpret how changing hyper-parameters will affect the result, there’s not a linear relationship, it’s mostly a guessing game
*Group project
**Not allow using default algorithms in DEAP, have to code our own
**Have to write the genetic loop as a group
**The presentation is going to look like a graph of Pareto optimal frontier graphing GP and ML results 
**Submit a CSV file (each algorithm that is deemed Pareto optimal by our algorithm gets a column in the CSV file)
**Only use selection functions that work for multi-objective in the DEAP framework (don’t use selTournament)
**2 types of step functions
***“Post” for minimization
***“Pre” for maximization
***Points will be docked if the steps are going in the wrong way
**Use false positive/negative rates so that it can be comparable with classmates
**Include bounded/trivial points on the graph when computing the AUC
*Presentation
**Check Reference material for presentation guideline
**It has useful code for graphing steps and AUC

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Create a multiple objective evolutionary algorithm and make a presentation on it with my team
|Completed
|September 22, 2021
|September 29, 2021
|September 27, 2021
|-
|Generate and upload one CSV file as a group that contains the predictions on test.csv for each Pareto optimal individual of our GP algorithm
|Completed
|September 22, 2021
|September 29, 2021
|September 28, 2021
|-
|Presentation Rehersal 
|Completed
|September 22, 2021
|September 29, 2021
|September 28, 2021
|}

===September 24, 2021 Sub-team Meeting Notes===
* Team Progress
**Developed our own selection method
**Developed our own evolutionary algorithm using our custom selection tournament method, one point crossOver mate method, and node replacement mutation method
**Our best individual: add(multiply(multiply(Embarked_S, SibSp), subtract(Sex_female, Embarked_S)), add(subtract(Sex_female, Embarked_S), subtract(subtract(subtract(Sex_female, Embarked_S), Sex_male), Sex_male)))
**Our Genetic programming (GP) AUC: 0.21, Machine learning (ML) AUC: 0.32
**36% decrease in AUC observed in our GP algorithm compared to the ML algorithm
**observed more diversity in GP Pareto front compared to the ML front
**Compiled our project into a presentation PowerPoint Presentation and practiced presenting it
***Our presentation can be found here: https://docs.google.com/presentation/d/1wyaq1Y04CNTXB_JWdlfzPPz3gGLgqZepK5NC_Olhn2U/edit?usp=sharing
*My Contributions
** Changed the mate and mutate methods to use "One Point CrossOver" and "Node Replacement"
** Added more primitives (sine, cosine, tangent, exponent)
** Added code for Pareto front diagram for our Genetic Programming algorithm
** Best AUC I've gotten with the changes I made: 0.198
** Wrote the "MOGP v. ML" slide in our project PowerPoint and practiced presenting it

== Week 4: September 15th - September 21st ==

===September 15, 2021 Team Meeting Notes===
* Assigned to be in Boot Camp team 1
* Machine Learning Algorithms
** Titanic - Machine Learning from Disaster
*** find out if a given passenger from the Titanic died or survived
*** 1 = survived, 0 = did not survive
* Resources: 
** Scikit Documentation (scikit-learn.org)
*** Have documentation on what the models are and how to use them
*** helpful to achieve codominance with team
** Pandas Documentation (pandas.pydata.org)
** Code section in the Kaggle challenge to see works that other people have done
*** How they preprocessed data, what models they used, etc.
*** For this assignment though, stick with Scikit and Pandas, so don't use everything that other people have used and import random packages and tools

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Generate and upload a CSV of my Titanic ML prediction (that is codominant with my group) to the Canvas ZZZ section
|Completed
|September 15, 2021
|September 22, 2021
|September 20, 2021
|}

=== September 19, 2021 Sub-team Meeting Notes ===
*Team Progress
**Worked on Titanic Example
**Preprocessed the data
***Removed Name, Ticket, & Cabin columns
***Replaced missing Age and Fare with the mean for nulls, changed missing Embarked to the most occurring value (mode)
***One-hot encoded Sex and Embarked columns
****Sex represented by 0s and 1s
****Used pd.get_dummies()
**We each chose a Machine Learning algorithm to attempt to achieve a Pareto optimal front in which each of us is codominant with each other.
**My team's ML Pareto Optimal Front graph:
**[[files/Jessi/images/SubTeamTitanicResults.png|thumb|123x123px]]
**Updated subteam 1 wiki page at: https://github.gatech.edu/emade/emade/wiki/Bootcamp-Subteam-1
*My Contributions
**Researched on pd.get_dummies() from the Pandas library 
**Chose my ML algorithm to be the Gradient Descent algorithm, which is an optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point because this is the direction of steepest descent.
**I used the default parameters of the Gradient Descent algorithm
**My result that is codominant with my teammates is "FPR = 0.067   FPR = 0.414"
**Peer coded with my teammates

== Week 3: September 8th - September 14th ==

===September 8, 2021 Team Meeting Notes===
* Logistics
** rated my skill level in Python and Machine Learning
** For the question regarding inserting images to wiki notebooks, for now just insert a link to the image while the technical difficulty of uploading an image is being resolved
* Lecture
** confusion matrix
*** True positives (TP), false positives (FP), true negatives (TN), false negatives(FN)
** Maximization Measures
***sensitivity/ true positive rate: TP/(TP + FN)
***specificity/ true negative rate: TN/(FP + TN)
**Minimization Measures
***instead of measuring true positives/negatives, we are measuring false positives rates (FPR) and false negative rates (FNR)
*** FNR = FN / P
*** FPR = FP / N
** Other measures
*** precision or positive predictive value (PPV)
****PPV = TP / (TP + FP)
****Bigger is better
*** False Discovery Rate
****FDR = FP / (TP + FP)
****FDR = 1 - PPV
****Smaller is better
**Pareto Optimality: individuals that outperforms other individuals on all objectives
**Diveristy is important, we try to preserve diversity whenever possible
**Strength Pareto Evolutionary Algorithms 2
*** each individual is given a strength S, S = how many others in the population that the individual dominates
*** each individual receives a rank R, R = the sum of S's of the individuals that dominate it
**** pareto individuals are nondominated an receive an R of 0
*** A distance to the Kth nearest neighbor (d^k) is calculated and a fitness of (R + 1) / (d^k + 2) is obtained so that individuals with larger crowd distance is favored to promote diversity

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-

|-
|Add explanations, justifications, and reflections to Lab 2 results
|Completed
|September 8, 2021
|September 15, 2021
|September 15, 2021
|-
|Notebook Self-assessment
|Completed
|September 8, 2021
|September 15, 2021
|September 15, 2021
|-
|Lab 2 - Multi-Objective Genetic Programming and take notes
|Completed
|September 8, 2021
|September 15, 2021
|September 15, 2021
|}

=== Notebook Self Assessment===
The graded rubric can be found at: https://drive.google.com/file/d/16oCakT022EO_RXLo3WiVdYInDDIjtFKP/view

=== Lab 2 - Multi-Objective Genetic Programming (part 2) ===
* Objectives 
** Minimize mean squared error
** Minimize the size of our tree
* Background/context
** Added three new primitives (sin, cos, tan) to the primitive set
** Set a seed for randomization
** Added another objective to the evaluation function
** A pareto_dominance function is defined to visualize the objective space
*Experiment
**A random population of 300 individuals is generated
**The population is sorted by Pareto dominance and plotted
**[[files/Jessi/images/lab2_2_Objective_Space.png|thumb|123x123px]]
**The blue point is the given individual we set aside and compared all the other individuals to. The black points are uncomparable, the green points are dominated by the given individual, and the red points dominate the given individual.
**The main evolutionary algorithm is defined and ran
* Results
**Graph 1
***Best individual is: negative(cos(multiply(add(cos(sin(cos(multiply(add(cos(cos(x)), cos(add(multiply(x, x), sin(x)))), tan(x))))), cos(x)), tan(x)))) with fitness: (0.27530582924947056, 25.0)
***[[files/Jessi/images/lab2_2_bestIndividual_Results.png|thumb|123x123px]]
***Tree size: red and orange plots
***MSE: blue and green plots
***Trends:
**** The size of the primitive tree increased as generations evolved
**** The MSE quickly decreased to between 0 and 1 within the first few generations
***This graph does not neccessarily represent accurate results for both objectives, therefore, we need Graph 2, which represents the objective space and the pareto front, to represent both objectives accurately
** Graph 2 (objective space and pareto front)
***[[files/Jessi/images/lab2_2_results_graph2.png|thumb|123x123px]]
***Area Under Curve: 2.463792426733847
***The performance of the pareto front is measured by the area under the curve (AUC) of the pareto front seen in the visualization. The lower our AUC is, the better the pareto front is
** My implementation of the genetic programming problem which produces at least a 25% decrease in the AUC
*** I changed the mutation method to be gp.mutNodeReplacement
*** [[files/Jessi/images/lab2_2_my_implementation_code.png]]
*** Here's the resulting graph
*** [[files/Jessi/images/lab2_2_my_implementation.png]]
*** Which is approximately a 36% decrease in the AUC from the previous result
* Explanations, justifications & reflections
** My implementation performed better due to the change in the mutation method, which means that the mutation method I used is more suited for achieving the objectives in this lab
** I think the mutation method gp.mutNodeReplacement might add more randomization abilities than gp.mutUniform, which is the method that was previously used
** gp.mutUniform randomly select a point in the primitive tree, then replace the subtree at that point as a root by the expression generated using another method chosen by us. The method we chose was the gp.genFull, which generates a full tree with all leaves at the same depth, which in our case, is a number between 0 to 2. Because the maximum depth is 2, this mutation method might not generate enough randomization or enough "mutation", therefore the generations would be evolving slower. Also, if the root node of a tree with a large depth or size is chosen to be mutated, then the tree depth will be auotmatically reduced to a maximum of 2, which might set us back in the evolution process
** gp.mutNodeReplacement replaces a randomly chosen primitive from the individual by a randomly chosen primitive from the attributes of the individual. This might be a better mutation function since it does not change the tree size, and therefore individuals with a better fitness (likely due to a larger primitive tree size because of the trend that we noticed earlier) will be more likely to preserve their size and pass it down to their children without a sudden set back to a small size of 0 to 2. 

== Week 2: September 1st - September 7th ==

===September 1, 2021 Team Meeting Notes===
* Genetic Programming (GP) Lecture
** Instead of taking an individual and having a function evaluator to obtain objective scores, the individual is the function itself, so that the function gets improved over time
** To represent this, we can use a tree structure
** Nodes are called primitives and represent functions
** Leaves are terminals and represent parameters
** Inputs are at the leaves of the tree
** Output is at the root of the tree
** Crossover in GP
*** Pick random nodes/leaves in the trees participating in the crossover, swap the subtrees of the nodes/leafs
** Mutation in GP
*** Inserting a node or subtree
*** Deleting a node or subtree
*** Changing a node
** Evaluating a tree
*** We can feed a number of input points to the functions to get outputs
*** We can measure the difference between the truth and what was outputted
** Primitives that can make the evolution tree easier
*** power()
*** factorial()
*** sin()
*** cos()
*** tan()
* This is the goal of EMADE, to evolve algorithms and functions so that the best and most efficient choice is selected

===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Migrate notes from google docs to GitHub notebooks
|Completed
|September 1, 2021
|September 8, 2021
|September 4, 2021
|-
|Finish Lecture 2 notes
|Completed
|September 1, 2021
|September 8, 2021
|September 4, 2021
|-
|Finish Lab 2 - Genetic Programming (part 1) and take notes
|Completed
|September 1, 2021
|September 8, 2021
|September 8, 2021
|-
|Understand the graphs returned by Lab 2 by asking questions about them during the next team meeting
|Completed
|September 8, 2021
|September 8, 2021
|September 8, 2021
|-
|Find out how to insert pictures in my notebook and if pictures are required by asking questions about them during the next team meeting
|Completed
|September 8, 2021
|September 8, 2021
|September 8, 2021
|}

===Lab 2 - Genetic Programming (part 1)===
*Purpose
**This lab focuses on genetic programming which is the tool that will be used for automated algorithm design
***The problem that Genetic programming is trying to solve is to find the best combination of the given primitives in order to get as close as possible to the ideal function and to reach the objectives
*Background/context
**The fitness is created with a weight of -1.0, the individuals are created and represented as tree structures
**A primitive set is initialized and the primitives "add", "subtract", "multiply", "negative" are added to the tree
*** I checked out NumPy documentation and added the primitives "numpy.power" and "numpy.mod" to the tree. They both take two required arguments, so I specified "arity=2" for both
**The toolbox, individual, population, and compiler are defined
**The evaluation function is defined to find the mean squared error between the function of the primitive tree and the function that we are trying to generate
***The goal is to optimize the primitive tree by minimizing this mean squared error
***We already know what the ideal function is and the primitives that it utilizes
***Our primitive tree contains all the primitives that the ideal function utilizes
***we need to find the best combination of these primitives that achieve the ideal function
**The genetic operators are registered
***"evaluate", "select", "mate", "expr_mut" (which is a function that will be passed in as a parameter for the gp.mutUniform method), and "mutate"
***I checked out the DEAP source code and added a new mutation method, gp.mutNodeReplacement, as "mutateNodeReplace"
***gp.mutNodeReplacement replaces a randomly chosen primitive from an individual by a randomly chosen primitive with the same number of arguments from the attributes of the individual
** Experiment
*** A population of 300 individuals is generated (n = 300)
*** 40 generations are initiated
*** During each generation, individuals are evolved by selecting, mating, and mutating in order to create the next generation
*** statistics are printed
** Results
*** After running the experiment with the mutation method provided by the lab default, "mutate", the best individual is: multiply(add(power(x, subtract(x, add(remainder(x, subtract(x, x)), x))), add(power(remainder(subtract(x, x), remainder(x, x)), subtract(power(x, x), x)), x)), add(x, x)), (nan,)
*** After running the experiment with the mutation method I created, "mutateNodeReplace", the best individual is add(add(x, multiply(multiply(x, add(x, multiply(x, x))), x)), multiply(remainder(add(x, multiply(x, power(x, x))), add(x, x)), x)), (nan,)


== Week 1: August 25th - September 1st ==
===August 25, 2021 Team Meeting Notes===
* Generic Algorithms Lecture:
** Goal: keep repeating the generation cycle overtime to try to find the best solution
** Advantages of Genetic Algorithms:
*** Good for when the search base is large, discontinuous, and largely non-linear
** Objective vs. fitness:
*** For example, the objective could be the score a student receives on an exam, and fitness is how that score fits on a curve, in comparison to all other students
** Selection:
*** Fitness proportionate: The greater the fitness value, the higher the probability of being selected for mating
*** The lowest fitness value has a probability to be selected
** Tournament: 
*** Several tournaments among individuals
*** Winners are selected for mating
*** The lowest fitness value will never be selected because it will just lose in the tournament
** Mate/Crossover: 
*** Mating between individuals
*** Single point: swapping DNA between the two individuals at a single point
*** Double point: swapping DNA between the two individuals at two points
** Mutate: introduces random modifications to maintain diversity
** Algorithms: various evolutionary algorithms to create a solution or best individual
*** Step 1: Randomly initialize population
*** Step 2: Determine fitness of the population
*** Step 3: Repeat the loop...
**** Select parents form population
**** Perform crossover on parents
**** Perform mutation
**** Determine fitness
*** End the loop until the best individual is good enough

* Python notebook setup
** Find labs on Github -> raw -> save with type .ipynb
** Open the saved lab file with Jupyter notebook


===Action Items===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install Anaconda and learn how to use Jupyter notebook
|Completed
|August 25, 2021
|September 1, 2021
|August 28, 2021
|-
|check out team GitHub and wiki page for note-taking examples, rubrics, and format
|Completed
|August 25, 2021
|September 1, 2021
|August 25, 2021
|-
|Finish GA Walkthrough and take notes on thoughts and results
|Completed
|August 25, 2021
|September 1, 2021
|August 30, 2021
|-
|Finish Lab 1 and take notes on results and thoughts
|Completed
|August 25, 2021
|September 1, 2021
|August 31, 2021
|}

===GA Walkthrough===
* Downloaded Anaconda and loaded the walkthrough python notebook using Jupyter
* This walkthrough utilizes the DEAP python package, DEAP stands for Distributed Evolutionary Algorithms in Python, it is useful for rapid prototyping and testing of ideas
* The FitnessMax class keeps track of the desired objective that we want to achieve, in this case, it is a fitness score of 1
* The individual class represents each individual in the population, it inherits a list and has fitness as an attribute
* Toolbox.attr_bool() generates the random 1s and 0s that make up the genome, running the function correctly yields either a 1 or a 0
* Calling toolbox.individual() will generate an individual instance that has a genome of 100 randomized 1s and 0s
* Calling toolbox.population(n) will generate n individuals with genomes of 100 randomized 1s and 0s
* evalOneMax(individual) evaluates the individual’s fitness level, in this case, it’s the sum of the 1s and 0s of its genome
** My individual 1 has a score of 46.0
** My individual 2 has a score of 49.0
* tools.cxTwoPoint(parent1, parent2) returns two children from parent1 and parant2
** My child 1 has a score of 44.0
*** Child 1 has a worse score than both parents
*** Child 1 deviates from its first parent at 14 different bits
** My child 2 has a score of 51.0
*** Child 2 has a better score than both parents
* tools.mutFlipBit(child, indpb=probablility) flips bits in the child’s genome sequence with a certain probability, the purpose of this is to add mutation
** After mutation, my mutated child differs from the unmutated child at 4 different bits

===Lab 1 - Genetic Algorithms with DEAP===
* One Max Problem
** Purpose
*** This lab solves the One Max Problem, which is a simple genetic algorithm problem with the goal of finding an individual with the best fitness
** Background/context
*** A population of individuals will be generated
*** Each individual will have a genome sequence with a length of 100 and made up of arbitrary 1s and 0s
*** The individual whose sequence contains all 1s will be considered to have the best fitness and finding such an individual is the goal of this lab
*** The fitness score of each individual is calculated by summing its genome sequence, therefore, individuals with more 1s will have a higher fitness score. The maximum score is 100
*** “Mate”, “mutate”, and “select” are methods used to evolve and produce individuals with better fitness scores
**** Mate is a 2-point crossover function, that takes in parent individuals to produce children
**** Mutate is flipping bits arbitrarily with a probability of 5%
**** Select is a tournament of 3 individuals who will be competing against each other to find the individual that has the best fitness score out of the 3
** Experiment
*** A population of 300 individuals is created
*** Each of the 300 individuals is evaluated to obtain their fitness score
*** Then, the evolution process of 40 generations is initiated
*** During the evolution process, offsprings are first selected by tournament, and then mated with a 50% probability and mutated with a 20% probability
*** Then, the population is replaced by the modified offspring, whose fitness scores are re-evaluated
*** Finally, statistics are printed to find out who the best individual is
** Results
*** The objective was reached in Generation 31
*** The average fitness value of the population got higher and higher as the number of generations increase
*** After running the code several times, there was an instance where the objective of a max fitness score of 100 wasn’t achieved in 40 generations, the max score was 99. This makes sense because due to the varied factors that contribute to the selecting, mating, and mutating process, the result has certain unpredictability and will not always achieve the desired value

* The N Queens Problem
** Purpose
*** Place n queens on an nxn chessboard in a way such that no queen can be taken by one another.
** Background/context
*** Default n = 20
*** The weight of the fitness objective is -1.0, because we are minimizing an objective instead of maximizing an objective as seen on the One Max problem. This is because we want to minimize the conflict between two queens on the chessboard
*** Individuals are defined by a list of integers, with each integer defining the column number of each queen, and the row number of each queen is defined by the indices of the corresponding integers. 
** Experiment
*** A population of 300 individuals is generated (n = 300)
*** 100 generations are initiated
*** Generations are evolved by selecting, mating, and mutating
*** statistics are printed
** Result
*** After 100 generations, a global minimum of 0 is still not reached (the best fitness score is 1 for most of the time
*** I implemented a new mutation function, that once called upon, will make at least one swap and at most all indices will be swapped. The number of swaps is stored in a variable “swapNum”. The two indices that will be swapped per “swapNum” are determined by two other random function calls. After utilizing this mutation function, the best fitness score was able to consistently achieve 0.
*** I think that my mutation function worked better than the one provided by the lab because it adds more randomization. in the mutate method provided by the lab, each index is looped in increasing order to obtain a chance of it being swapped by another random index, there could be a possibility where no index will be swapped even when the mutate function is called. However, my mutate function will guarantee that at least one swap will be made, and the number of swaps made and the indices swapped are all randomized.