== Team Member ==

* Team Member: Samuel Zhang

* Email: szhang460@gatech.edu

* Cell Phone: 917-584-7239

== January 7, 2019, VIP Meeting ==
'''VIP Meeting:'''
* Mr. Rodd become the subteam leader, transitioning old Deep Team code from last semester (Sep 2018 -> Dec 2018) to new ezCGP
* [https://github.com/ezCGP/ezCGP|New Repository (ezCGP)]
* Talking over CGP : DAG graph
** genem = [node1, node2, ..., output, input]
*** Size Structure ==> genem = [None] x (100 + 1 + 1)
*** Each node is a dictionary = {"ftn": sum, "inputs": [0, 1], "args":[5]}. 
**** Arg is also a list, so the "args" parameter takes in index of argument needed.
* Newly implemented details: 
**Hierarchy class: Genome() -> Mutate(Genome) -> Block(Mate, Mutate)
***Mate would be nice, but is too complicated to implement right now
**Individual class can have unlimited number of blocks, each block is a new *separate* genome

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Send Rodd GitHub email on Slack
|Completed
|Jan 7, 2019
|Jan 7, 2019
|Jan 7, 2019
|-
|Study code 
|Completed
|Jan 7, 2019
|Jan 14, 2019
|Jan 14, 2019
|}

'''Code Study:'''
* main.py
** Reads in training data and labels
** Loops through universes to append to final_population
*** See universe.create_universe in universe.py
* universe.py
** create_universe inits population with input data/labels
*** runs universe and records stores until score passes threshhold
** run_universe mates and mutates 
*** mutate adds to population
*** finally evaluates all population (including mutants) and returns population for score eval
* individual.py
** Individual mate/mutate methods
** QUESTION: Where are the mate/mutate/evaluate methods that self.skeleton["block_object"] calls?

== January 14, 2019, VIP Meeting ==
'''VIP Meeting'''
* Talked about whether to use Joel's CGN-CNN old code or invest full team on ezCGP
** Discussed how we got from 80-96% accuracy on MNIST using CGP-CNN
** Not very good, since MNIST should be at 98-99% accuracy
* Decided on team of 7 + Rodd on getting ezCGP
** Eventually want to be integrated with EMADE and private, but keep public for now

'''Code Overview:'''
*Fixed size genome -> list
**Main node
** Input
** Outputs

genem = [node1, node2, node3, ... , node k, output, input]
* nodes earlier in this list can be used as input in later nodes

* dictionary of a single node 
** "ftn":
** "inputs": [indices of the input to that node (before current node in genem)]

The motivation behind backwards tracing from output -> first node (in input chain, not necessarily genem) is just to save time and not trace through the entire tree.
Once evaluation starts, it will go forward from first node -> output, where the node's will use ftn(inputs) -> next node -> ... -> output.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Clone and investigate ezCGP, definitely look at genome.py 
|Completed
|Jan 14, 2019
|Jan 28, 2019
|Jan 22, 2019
|-
|Read paper Rod posted, focus on Sections 1-2, Conclusion, then Section 3...
|Completed
|Jan 14, 2019
|Jan 28, 2019
|Jan 22, 2019
|}

[https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6815728&tag=1|IEEE Paper mentioned, also on Slack]

== January 24, 2019, Subteam Meeting ==
'''Subteam Notes:'''
* Discussed GitHub Project workflow
* [https://github.com/ezCGP/ezCGP/projects/6|Initialized Symbolic Regression tasks for each team member and how to test]
* Discussed possibility of optimizing primitives after testing validity of ezCGP, may possibly use larger primitives (DNNs, etc.)
* Reported on Skip, Accumulation, and Single methods in CGP
** ezCGP uses Single replacement

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run ezCGP for 20 universes to test convergence as detailed in GitHub Symbolic Regression Project
|Completed
|Jan 24, 2019
|Jan 27, 2019
|Jan 27, 2019
|-
|Visualize and plot results from the symbolic regression convergence tests
|Completed
|Jan 27, 2019
|Jan 28, 2019
|Jan 28, 2019
|}

== January 27, 2019, Subteam Meeting ==
'''Subteam Meeting'''
* Created [https://github.com/ezCGP/ezCGP/issues?utf8=%E2%9C%93&q=is%3Aissue+author%3ACodeSammich+ multiple issues] while running ezCGP

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run ezCGP for 20 universes to test convergence as detailed in GitHub Symbolic Regression Project
|Completed
|Jan 24, 2019
|Jan 27, 2019
|Jan 27, 2019
|-
|Visualize and plot results from the symbolic regression convergence tests
|Completed
|Jan 27, 2019
|Jan 28, 2019
|Jan 28, 2019
|}

== January 28, 2019, VIP Meeting ==
'''VIP Meeting'''
* Attended SCRUM meeting from different subteams
* Focus on visualizing convergence tests success from the text results
* I am put into the TensorFlow sub-subteam to add TensorFlow into ezCGP
** Need to meet to decide next steps and how to optimize primitives, multithread for runtime, and test models
** Finished mathematical models (Taylor Series, Symbolic Regression), so FOCUS on MNIST for non-arithmetic primitive models (maybe use CNN)
** Look for evaluate() function and start look into TensorFlow primitives (if we can create one TF block, then we can create multiple)
*** Possibly even include multithread stuff so that TF can work with Google Cloud
* Primitives make genome of an individual, which splits into blocks to be a model
** Data in/out and labels are just to test the model

'''Symbolic Regression Results'''
* [https://github.com/ezCGP/ezCGP/projects/6|GitHub Project @CodeSammich]
* Results from Sym. Reg. GitHub Project assignment (20 universes, see how many generations it takes to converge RMSE below 0.1 if there is NO subtract primitive)
* If generation hits 200, then that means that particular universe does not converge
* If we remove a subtraction primitive, it's much harder for ezCGP to figure out how to subtract (has to multiply by -1 and THEN add)
[[files/SymbolicRegression20Universe0.01Convergence.png]]
* Takeaway: We need a diverse set of primitives, but how can we generate better primitives and not generate too much? (may need subject domain expert to select primitives, hard to automate)

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Visualize and plot results from the symbolic regression convergence tests
|Completed
|Jan 24, 2019
|Jan 28, 2019
|Jan 28, 2019
|-
|Run ezCGP on MNIST and see if we can use TF on partial code and use CNN/DNN primitive (use pure TF, no Numpy functions or primitives for now)
|Completed
|Jan 28, 2019
|Feb 1, 2019
|Feb 4, 2019
|-
|Meet with TensorFlow sub-subteam to convert all of ezCGP into TensorFlow 
|Completed
|Jan 28, 2019
|Feb, 3,, 2019
|Feb 7, 2019
|}

== January 31, 2019, Subteam Meeting ==
'''Subteam Notes:'''
* Each individual's genome creates the NN for evaluation
** We're using TensorFlow to DO that NN evaluation for each and every individual in the generation
* Then, that genome is mutated as per CGP

[[files/Submeeting notes.jpg]]

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run ezCGP on MNIST and see if we can use TF on partial code and use CNN/DNN primitive (use pure TF, no Numpy functions or primitives for now)
|Completed
|Jan 28, 2019
|Feb 1, 2019
|Feb 4, 2019
|-
|Meet with TensorFlow sub-subteam to convert all of ezCGP into TensorFlow 
|Completed
|Jan 28, 2019
|Feb 3, 2019
|Feb 7, 2019
|}

== February 3, 2019, Subteam Meeting==
'''Subteam Notes:'''
* Met up with Tensorflow sub-subteam to review code and implement TF primitives
* Decided to keep [https://github.com/ezCGP/ezCGP/blob/tensorflow-nn/blocks.py blocks.py]
** evaluate() for the individual as a whole (with self.fetch_nodes and self.feed_dict)
** tensorflow_evaluate() for the block within that individual, which is called inside evaluate()
** individual.py's evaluate() calls the blocks.py evaluate()
* Changed block input types to tf.Tensor inside of np.ndarray in order to shift block evaluation away from Numpy and to Tensorflow
* Currently trying to test an Individual creation in tester.py before shifting all of main.py into TF

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Figure out how to pass params into feed_dict
|Completed
|Feb 3, 2019
|Feb 11, 2019
|Feb 11, 2019
|-
|Implement and convert ezCGP from NumPy to Tensorflow
|Completed
|Jan 28, 2019
|Feb 4, 2019
|Feb 7, 2019
|}

== February 4, 2019, VIP Meeting ==
'''Class Meeting'''
* Contributed to stand-up meeting by enumerating possible next steps
* Reviewed [https://github.com/ezCGP/ezCGP/blob/tensorflow-nn/blocks.py evaluate() in blocks.py] with team members

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Figure out how to pass params into feed_dict
|Completed
|Feb 3, 2019
|Feb 11, 2019
|Feb 11, 2019
|-
|Implement and convert ezCGP from NumPy to Tensorflow
|Completed
|Jan 28, 2019
|Feb 4, 2019
|Feb 7, 2019
|-
|Debug and make sure evaluate() works with tensorflow_evaluate()
|Completed
|Feb 4, 2019
|Feb 7, 2019
|Feb 7, 2019
|}

== February 7, 2019, Subteam Meeting ==
'''Subteam Meeting'''
* [https://github.com/ezCGP/ezCGP/commit/29d22bf6aa9ac73926ac16fd49f94e404b45f898 feed_dict error resulting from None key (Feb 7th, 2019 commit by CodeSammich]
* Tensorflow-NN of ezCGP can now evaluate neural nets correctly
** Validated this by observing gradient descent values lowering over time, as it should
** By extension, the evaluate() and tensorflow_evaluate() functions in block.py is now functional, as well as evaluate() in individual.py
** Errors encountered included:
*** None key referencing feed_dict, caused by TF placeholders not having values to initialize due to it being the first iteration
*** TF nodes not being flattened properly before inputting into the neural net, causing logits to be misshaped
*** Placeholder nodes not having the correct shape
*** Input data not loaded properly
*** ...and many other complex nested errors
* Total debugging time was around 4 hours
** Worked with Jinghua and Aniruddha

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Print out and verify loss functions work with Neural Net / continue testing with other models
|Completed
|Feb 7, 2019
|Feb 11, 2019
|Feb 14, 2019
|-
|Clean up code (blocks.py) and add documentation to clarify flow, remove outdated comments
|Completed
|Feb 8, 2019
|Feb 11, 2019
|Feb 25, 2019
|}

== February 11, 2019, VIP Meeting ==
'''VIP Meeting'''
* Presented successful results from last week and the big milestone of getting tensorflow to work
* Introduced idea of batch processing in order to speed up primitive testing and produce faster generations
* Debated over merits of size and number of batches

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Clean up code (blocks.py) and add documentation to clarify flow, remove outdated comments
|Completed
|Feb 8, 2019
|Feb 17, 2019
|Feb 25, 2019
|-
|Debug initial batch data implementation
|Completed
|Feb 11, 2019
|Feb 11, 2019
|Feb 14, 2019
|}

== February 14, 2019, Subteam Meeting ==
'''Subteam Meeting'''
* Added batch support to ezCGP tensorflow.
* Discussed what batch support is and cleared out possible overfitting issues due to small sample size
* Confirmed primitives work with DNN (without batch support)
** conv layer still takes A LOT of time and sometimes crashes

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Clean up code (blocks.py) and add documentation to clarify flow, remove outdated comments
|Completed
|Feb 8, 2019
|Feb 17, 2019
|Feb 25, 2019
|-
|Print out and verify loss functions work with Neural Net / continue testing with other models
|Completed
|Feb 7, 2019
|Feb 11, 2019
|Feb 14, 2019
|-
|Debug initial batch data implementation
|Completed
|Feb 14, 2019
|Feb 17, 2019
|Feb 18, 2019
|}

== February 18, 2019, VIP Meeting ==
'''VIP Meeting'''
* Decided to start exhaustive primitive testing, one for each person
* I decided to do squeeze_excitation_block
* Team's aim is to successfully run main.py and start end-to-end evolutionary process
* Decided to create batch_size as a parameter input to the tensorblock

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Clean up code (blocks.py) and add documentation to clarify flow, remove outdated comments
|Completed
|Feb 8, 2019
|Feb 17, 2019
|Feb 25, 2019
|-
|Make batch_size a parameter passed to the tensorblock
|Completed
|Feb 18, 2019
|Feb 21, 2019
|Feb 21, 2019
|-
|Start exhaustive testing for one primitive (squeeze_excitation_block and conv_layer)
|Completed
|Feb 18, 2019
|Feb 21, 2019
|Feb 21, 2019
|}

== February 21, 2019, Subteam Meeting ==
'''Subteam Meeting'''
* Spent most of the time trying to figure out deepcopy in universe.py
** Tried JSON-style shallow copy with the 1 key in skeleton_genome
** The block cannot be deep copied because it contains a dictionary of dictionary
** Tried switching 1 to string '1', but the recursive deep copy still won't work with Tensor objects, etc.
* Led discussion on generalizing future problem implementations
** Generalized all problems into problem.py and made past_problems/ folder to store previous problems
** Need to change name to problem.py if you want to run a new problem
** Configured imports and load times to make main.py run

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Clean up code (blocks.py) and add documentation to clarify flow, remove outdated comments
|Completed
|Feb 8, 2019
|Feb 17, 2019
|Feb 25, 2019
|-
|Make batch_size a parameter passed to the tensorblock
|Completed
|Feb 18, 2019
|Feb 21, 2019
|Feb 21, 2019
|-
|Start exhaustive testing for one primitive (squeeze_excitation_block and conv_layer)
|Completed
|Feb 18, 2019
|Feb 21, 2019
|Feb 21, 2019
|-
|}

== February 25, 2019, VIP Meeting ==
'''VIP Meeting'''
* Discussed eventual deployment to Google Cloud
* Went into [https://github.com/ezCGP/ezCGP/commit/aa537a7c5454002175f8a7fa7a8a2f52e063cb29 the code and cleaned up documentation, code ordering]
* Can I use tiered datasets to see if a particular configuration of primitives is a "dud" early on?
** Jason's dissertation for reference on tiered datasets
** Need to run faster, so we can test after implementing Google Cloud
* Presented and discussed ways to speed up training with Dr. Greg Rohling

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Clean up code (blocks.py) and add documentation to clarify flow, remove outdated comments
|Completed
|Feb 8, 2019
|Feb 17, 2019
|Feb 25, 2019
|-
|Test that mutation is actually being run by increasing number of primitives, discuss scalability with Google Cloud to run more than 2 population
|Completed
|Feb 25, 2019
|Feb 28, 2019
|Feb 28, 2019
|-
|Investigate if we can use tiered datasets to cut down idiot evaluation, speed up time (do after Google Cloud)
|Completed
|Feb 25, 2019
|Feb 28, 2019
|Mar 11, 2019
|}

== February 28, 2019, Subteam Meeting ==
'''Subteam Meeting'''
* Tested duration of single epoch conv_layer
** Discussed possibility of scaling number of epochs with generation number to decrease training time 
** Inspired by [https://smartech.gatech.edu/bitstream/handle/1853/60768/ZUTTY-DISSERTATION-2018.pdf?sequence=1&isAllowed=y| Jason Zutty's tiered datasets] approach to cut out early idiots
* For certain layers, like conv_layer or max/avg_pooling, we may need to run the whole dataset, which is why tiered datasets may not work
** Could use above approach for those layers, and tiered datasets for everything else
** Seems like conv_layer converges around 20 epochs, which could be a cutting off point
* Tested whether mutation actually works
** It seems to work
** Under testing a single primitive (dense_layer), it converges to global optima after 5-7 generations and no longer mutates (which is good)

'''Post-Meeting Work'''
* Fixed Value Errors for dense -> pooling misshapen input, and changed scoring function
* Fixed inconsistent shape issue with MNIST batches
* Verified mutation works
* Pooling functions, amongst possible others, are deprecated in tf.layers, and we will need to update to tf.keras.layers eventually
** [https://www.tensorflow.org/api_docs/python/tf/layers/max_pooling2d| Example of deprecated tf.layers function]
*** [https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D| Here is Max Pooling Keras documentation to replace tf.layers]
*** [https://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/python/keras/layers/pooling.py| Source code for pooling in Keras]
** Other primitives may require re-examination as well, especially the other layers. 
** This is not relevant to tf.layers, but I'm not sure if we are keeping arithmetic tensors still, since they are legacy from Symbolic Regression and are not relevant to MNIST

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Test that mutation is actually being run by increasing number of primitives, discuss scalability with Google Cloud to run more than 2 population
|Completed
|Feb 25, 2019
|Feb 28, 2019
|Feb 28, 2019
|-
|Investigate if we can use tiered datasets to cut down idiot evaluation, speed up time (do after Google Cloud)
|Completed
|Feb 25, 2019
|Feb 28, 2019
|Mar 11, 2019
|-
|Implement try-catch for Value Error in case of dense -> pooling, if tensorblock_evaluate errors, set self.dead = True, investigate scoring as well
|Completed
|Feb 28, 2019
|Feb 28, 2019
|Feb 28, 2019
|}

== March 4, 2019, VIP Meeting ==
'''VIP Meeting'''
* Try to find more general structure for the code such that it can handle all kinds of problems
* End goal is to create an ezCGP API
** Can structure user-endpoint to just take (train, test), like how SciKit-Learn does
* Can make a Batch object to help user split up data easier
** Can even just do one batch for input if needed
* Can take the most optimal individuals on Thursday to get visualization and accuracy for presentation slides
** Can also make animation of all the individuals
** Started slides organizations

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Investigate if we can use tiered datasets to cut down idiot evaluation, speed up time (do after Google Cloud)
|Completed
|Feb 25, 2019
|Feb 28, 2019
|Mar 11, 2019
|-
|Make slides and pick one to fill up with information
|Completed
|Mar 4, 2019
|Mar 11, 2019
|Mar 11, 2019
|}

== March 7, 2019, Subteam Meeting ==
'''Subteam Meeting'''
* Made GP vs. CGP slide
* Helped resolve memory issues with unnecessarily copying the dataset

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Investigate if we can use tiered datasets to cut down idiot evaluation, speed up time (do after Google Cloud)
|Completed
|Feb 25, 2019
|Feb 28, 2019
|Mar 11, 2019
|-
|Make slides and pick one to fill up with information
|Completed
|Mar 4, 2019
|Mar 11, 2019
|Mar 11, 2019
|}

== March 11, 2019, VIP Meeting ==
'''VIP Meeting'''
* Presented semester "recruitment" and [https://docs.google.com/presentation/d/1UmH5CSSlO2NPVMmBe_Kqo3sie2gQs4Sm2fldg9JC6lE/edit?usp=sharing ezCGP presentation]

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Investigate if we can use tiered datasets to cut down idiot evaluation, speed up time (do after Google Cloud)
|Completed
|Feb 25, 2019
|Feb 28, 2019
|Mar 11, 2019
|-
|Make slides and pick one to fill up with information
|Completed
|Mar 4, 2019
|Mar 11, 2019
|Mar 11, 2019
|}

== March 14, 2019, Subteam Meeting ==
'''Subteam Meeting'''
* Discussed future plans
** Talked about dividing team up into research team and development team
** Research would be reading papers and finding more creative ways to make ezCGP better and more diverse
** Development team would be software engineering the code to make it faster and much cleaner and user friendly
* Obtained a paper titled [https://link.springer.com/article/10.1007/s10710-018-9339-y DENSER: Deep Evolutionary Network Structured Representation]
** Referred to as DENSER paper, can be a good primitive generator or structural inspiration for Regressive problems

'''Team Plans'''
*Jason suggestions:
** Tiered datasets. Stop early when you fail on a small dataset. 
** Testing different types of primitives and finding the maximum number to use
*Rodd Suggestion:
** Check active nodes throughout time. Use this information to inform us of how big genome size should be. 
*Michael P. suggestion:
** 1/2 works on Experimentation. 
** Working on other primitives.
** Seeding individuals.
** Maybe add preprocessing block add functionality for regression.
** Get results for CIFAR-100. Better to stick to Tensorflow primitives. 
** Adding learning rate and dropout layers. 
** Hardcoded number of filters in conv2d need to change.
* 1/2 Thinking of functionality (kind of like DEAP. Something user-friendly.) 
** Easily usable. 
** Datasets class support. 
** Feed in function pointers. 
** Change the number of epochs as a param of sorts. 
*Far future Work:
** If the functionality improves we can throw in imageNet. CIFAR-100 is about the same time as CIFAR-10. Maybe have a YAML input file. 

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read the [https://link.springer.com/article/10.1007/s10710-018-9339-y DENSER] paper and annotate
|Completed
|Mar 14, 2019
|Mar 25, 2019
|Apr 8, 2019
|-
|Decide on what sub-team to work on (Dev or Research)
|Completed
|Mar 14, 2019
|Mar 28, 2019
|Mar 28, 2019
|
|}

== March 25, 2019, VIP Meeting ==
'''Meeting Notes'''
* Caught up and onboarded new members
* Split the team into Research and Dev teams, started voting process
* Discussing kinds of validation datasets available

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read the [https://link.springer.com/article/10.1007/s10710-018-9339-y DENSER] paper and annotate
|Completed
|Mar 14, 2019
|Mar 25, 2019
|Apr 8, 2019
|-
|Decide on what sub-team to work on (Dev or Research)
|Completed
|Mar 14, 2019
|Mar 28, 2019
|Mar 28, 2019
|}

== March 28, 2019, VIP Meeting ==
'''Meeting Notes'''
* Decided who is going to be on Team A and Team B, but may integrate regularly or swap over if needed

F: Focus and doable by this semester

'''Team A Rodd Squad: User-Friendly Development'''
* Ani, Gib, Jinghua, Michael Piseno
* Feed datasets in an organized way, scalable (F)
** Potentially send only filenames of data
* Add more mutations (F)
* Mutate constants
** Rodd required
* Seeding
* Potential extensions

'''Team B Talebi Tubbies: DL Specific Primitives & Functionality'''
* Johnny, Sam, M.J., Animesh, Mohan
* Extend to regression (F)
* Add primitives (e.g. LSTM, Inception)
** Dense: units = 64
** Conv2D: filters = 64, size = (3,3)
* Results on CIFAR-100 & and whatever stock team is doing (F)
** Trying to use Stock's dataset and overtake them
*** There could be a larger dataset on Kaggle for daily stock data from 1997 we could use
** Benchmark regression

Classification is comparing against discrete classes
Regression is comparing against non-discrete classes (output layer/back prop is continuous function instead)

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read the [https://link.springer.com/article/10.1007/s10710-018-9339-y DENSER] paper and annotate
|Completed
|Mar 14, 2019
|Mar 25, 2019
|Apr 8, 2019
|-
|Decide on what sub-team to work on (Dev or Research)
|Completed
|Mar 14, 2019
|Mar 28, 2019
|Mar 28, 2019
|-
|Try to add regression to ezCGP by augmenting or replacing softmax call in blocks.py evaluate output 'probabilities' field (Team B)
|Completed
|Mar 28, 2019
|April 15, 2019
|April 15, 2019
|}

== April 1, 2019, VIP Meeting ==
'''Meeting Notes'''
* Found several datasets that could be used as proof of concept for regression in ezCGP
** [https://archive.ics.uci.edu/ml/datasets/Solar+Flare Solar Flare dataset]
** [https://www.kaggle.com/tags/weather Weather dataset]
** [https://www.kaggle.com/gabriellima/house-sales-in-king-county-usa House Sales in King County]
*** Likely going to use this one because it is predicting a price is an easily understood regression problem

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read the [https://link.springer.com/article/10.1007/s10710-018-9339-y DENSER] paper and annotate
|Completed
|Mar 14, 2019
|Mar 25, 2019
|Apr 8, 2019
|-
|Try to add regression to ezCGP by augmenting or replacing softmax call in blocks.py evaluate output 'probabilities' field (Team B)
|Completed
|Mar 28, 2019
|Apr 4, 2019
|Apr, 15, 2019
|-
|Investigate Housing dataset for import and preprocess/scoring
|Completed
|Apr 1, 2019
|Apr 4, 2019
|Apr 8, 2019
|}

== April 4, 2019, VIP Meeting ==
'''Meeting Notes'''
* Imported housing dataset and created scoring function
* Created a new branch [https://github.com/ezCGP/ezCGP/tree/talebi-tubbies talebi-tubbies]
** [https://github.com/ezCGP/ezCGP/commit/414291b56e2b2ebf7ffc0b0a4b61476c9db0d5f5 Completed scoring and problem.py cleanup for Housing dataset]
** [https://github.com/ezCGP/ezCGP/commit/6fd73aaab123a2c3a4346a93ed26b04bc81cde74 Completed preprocessing/normalization for Housing dataset]

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read the [https://link.springer.com/article/10.1007/s10710-018-9339-y DENSER] paper and annotate
|Completed
|Mar 14, 2019
|Mar 25, 2019
|Apr 8, 2019
|-
|Try to add regression to ezCGP by augmenting or replacing softmax call in blocks.py evaluate output 'probabilities' field (Team B)
|Completed
|Mar 28, 2019
|Apr 4, 2019
|Apr 15, 2019
|-
|Investigate Housing dataset for import and preprocess/scoring
|Completed
|Apr 1, 2019
|Apr 4, 2019
|Apr 8, 2019
|}

== April 8, 2019, VIP Meeting ==
'''Meeting Notes'''
* Talked about dense layer to replace softmax or just a manual average of softmax outputs in groups
** Number of groups depend on how many layers we need as output
* For Stock dataset (for fine tuning after regression is added), we have 3 current options
** GE dataset (James should have it)
** [https://www.kaggle.com/borismarjanovic/price-volume-data-for-all-us-stocks-etfs Kaggle "Huge Stock Market Dataset"]
** EMADE Stock team dataset
*** May not be a good idea because of small size

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Try to add regression to ezCGP by augmenting or replacing softmax call in blocks.py evaluate output 'probabilities' field (Team B)
|Completed
|Mar 28, 2019
|Apr 4, 2019
|Apr 11, 2019
|-
|Investigate Housing dataset for import and preprocess/scoring
|Completed
|Apr 1, 2019
|Apr 4, 2019
|Apr 8, 2019
|-
|Find good Stock dataset (either from EMADE or Kaggle) to use as fine-tuning for regression
|Abandoned
|Apr 8, 2019
|Apr 11, 2019
|Apr 11, 2019
|}

== April 11, 2019, VIP Meeting ==
'''Meeting Notes'''
* Abandoned Stock dataset dream
* Debated between LSTM and regular NN, and decided NN was easier and better
* Implemented regular dense layer for regression and tested with Housing dataset

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Try to add regression to ezCGP by augmenting or replacing softmax call in blocks.py evaluate output 'probabilities' field (Team B)
|Completed
|Mar 28, 2019
|Apr 4, 2019
|Apr 11, 2019
|-
|Investigate Housing dataset for import and preprocess/scoring
|Completed
|Apr 1, 2019
|Apr 4, 2019
|Apr 8, 2019
|-
|Find good Stock dataset (either from EMADE or Kaggle) to use as fine-tuning for regression
|Abandoned
|Apr 8, 2019
|Apr 11, 2019
|Apr 11, 2019
|}

== April 15, 2019, VIP Meeting ==
'''Meeting Notes'''
* Implemented regression vs. classification flag while reducing imports
* Created requirements.txt file for easier streamlined installation
* Fixed NSException error with result_analysis.py, [https://github.com/ezCGP/ezCGP/issues/5 issue here]

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update final presentation with slides
|Completed
|Apr 15, 2019
|Apr 18, 2019
|Apr 22, 2019
|-
|Relabel the results' axis' to the correct borders (MAE, APC in scoreFunction)
|Completed
|Apr 15, 2019
|Apr 18, 2019
|Apr 18, 2019
|}

== April 18, 2019, VIP Meeting ==
'''Meeting Notes'''
* Fixed NSException error with result_analysis.py, [https://github.com/ezCGP/ezCGP/issues/5 issue here]
* Actually fixed that error using Qt5Agg and included notes and flexible imports for MacOS and other systems

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update presentation with slides
|Completed
|Apr 15, 2019
|Apr 18, 2019
|Apr 22, 2019
|-
|Relabel the results' axis' to the correct borders (MAE, APC in scoreFunction)
|Completed
|Apr 15, 2019
|Apr 18, 2019
|Apr 18, 2019
|-
|Run CIFAR-10 on personal desktop
|Completed
|Apr 18, 2019
|Apr 20, 2019
|Apr 22, 2019
|}

== April 20, 2019, VIP Meeting ==
'''Meeting Notes'''
* Tried to run CIFAR-10 on TI-1050 GPU using Windows Linux Subsystem
** Run failed multiple times due to Windows limitation using the subsystem
** Possible solution is to run it on a native Linux machine or dual boot, otherwise memory shortages limit runs

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update presentation with slides
|Completed
|Apr 15, 2019
|Apr 18, 2019
|Apr 22, 2019
|-
|Relabel the results' axis' to the correct borders (MAE, APC in scoreFunction)
|Completed
|Apr 15, 2019
|Apr 18, 2019
|Apr 18, 2019
|-
|Run CIFAR-10 on personal desktop
|Completed
|Apr 18, 2019
|Apr 20, 2019
|Apr 22, 2019
|}

== April 22, 2019, VIP Meeting ==
'''LAST DAY OF CLASS'''

'''Meeting Notes'''
* [https://docs.google.com/presentation/d/10t_-9TvkV_GwWpHTPa6wG7tWbhio_NAjP8u-f-bfWqE/edit?usp=sharing Final Presentation] 

Possible things to talk about with Rodd: How are they initialized? Why do most of the individuals seem to have similar amounts of genes?

'''Why Do I Deserve My Grade?'''

I believe I deserve an A for several reasons. For starters, as my team notes, I am active in meetings and contribute to keeping the team on track. In addition, I frequently collaborate with other team members, including Aniruddha, Jinghua, and Michael in writing large portions of evaluate() in blocks.py during team meetings.

In my midterm peer evaluation, I received feedback that I could be putting forth more effort to complete my individual assignments. 

In order to do so, I have taken the initiative to run CIFAR-10 on my personal GPU, even to the point of trying to reformat my disk to run Linux natively. In addition, I have begun augmenting the README and documentation for ezCGP. While this is not entirely complete due to time limitations, it is currently set up with dynamic badges, skeleton, and just requires some text input to describe the specific implementation details we will flesh out next semester.

Furthermore, since the midterm, I have discovered, tracked, and solved major compatibility issues with MacOS and MatPlotLib. Without this detailed manual bug trace and fix, it would be entirely impossible to obtain any graphical results from ezCGP. Furthermore, the fix for the bug was critical and difficult, as it applied specifically to our rendering packages and almost all of the answers found online were grossly incorrect. This has also aided in testing installations in order to make future problem run sessions easier, with Google Cloud Platform's Linux in mind as the ultimate goal. For example, I began steps to streamline ezCGP's installation process with a requirements.txt file. 

As a member of the Talebi Tubbies Deep Learning subteam, I implemented the ability for ezCGP to differentiate between classification, regression, and any other type of problem. I also collaborated with Michael and George (Robert) in finding and evaluating large datasets across several domains. For example, I was able to locate high-quality Stock, Housing, Solar Flare datasets. Unfortunately, due to time constraints, we were only able to explore the Housing dataset, but we plan to use the Stock dataset extensively next semester.

Once we found the dataset, Michael, George, and I collaborated over several hours to implement preprocessing and scoring functions for Housing, obtaining very good graphics and results in the final presentation.

Much of these contributions were committed after the midterm peer evaluation, and I believe if you check my notebook from before the midterm, you will find several contributions there from early in the semester as well. Some of these contributions include fixing the dense to pooling layers bug, extensive documentation/code cleanup, generalized dataset input, aid in the conversion from NumPy to Tensorflow, and fixing the feed_dict initialization bug.

== August 24, 2019, VIP Meeting ==
'''Goals for the semester'''
* [https://docs.google.com/presentation/d/1CUDOAWzBPTPcjmkoCfKI4vsWj9RRN_GYMSOhbgiDjBo/edit?usp=sharing Goals]

Michael becomes team leader

== August 26, 2019, VIP Meeting ==
'''Meeting Notes'''
* Decided on a double block structure (static "preprocessing" block + training block)
** We questioned about the functionality of having two networks back to back, and if that was trainable at all.

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Think about how to integrate multiple blocks into the ezCGP codebase, and consider ways to make multiple blocks functional
|Completed
|Aug 26, 2019
|Aug 28, 2019
|Aug 28, 2019
|}

== August 30, 2019, VIP Meeting ==
'''Meeting Notes'''
* Implemented ability to skip preprocessing block training in tensorblock_preprocessing to set the stage for testing the infrastructure for second block (e.g. preprocessing block)
** The preprocessing block isn't really full of primitive layers yet, it's just an identity block/matrix, basically just to test that multiple blocks CAN interact first
** [https://github.com/ezCGP/ezCGP/commit/686eaf39939713f5476980d21d5b260566604635 Git Commit]
* Explained overall architecture to Tran and Mai and caught them up to speed about the project's goals and some code details

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Implement multiple repositories pushing (simultaneous pushing for public and GT side)
|Completed
|Aug 30, 2019
|Sep 6, 2019
|Sep 9, 2019
|}

== September 3, 2019, VIP Meeting ==
'''Meeting Notes'''
* Figured out we need to get multiple repository push capabilities to maintain parallel synced repos on the public and private (GT) side
** Still need to test, as GT Github is down

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Implement multiple repositories pushing (simultaneous pushing for public and GT side)
|Completed
|Aug 30, 2019
|Sep 6, 2019
|Sep 9, 2019
|}

== September 7, 2019, VIP Meeting ==
'''Meeting Notes'''
* Still need to add multiple repository push capabilities to maintain parallel synced repos on the public and private (GT) side
** Still need to test, as GT Github is down
** Rodd is in China, so we don't have access to GT side repo
* Added multiple block support and refactored preprocessing and training block skeleton blocks, so we can create multiple blocks with their own primitives for each
* Now training block can train while we skip training on preprocessing, and removed some legacy code from CGP-CNN

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Implement multiple repositories pushing (simultaneous pushing for public and GT side)
|Completed
|Aug 30, 2019
|Sep 6, 2019
|Sep 9, 2019
|-
|Added multiple block support with refactored skeleton block and block primitive structure
|Completed
|Sep 7, 2019
|Sep 7, 2019
|Sep 7, 2019
|-
|Make OpenCV operator and put it as a primitive for preprocessing
|Completed
|Sep 7, 2019
|Sep 13, 2019
|Sep 13, 2019
|}

== September 9, 2019, VIP Meeting ==
'''Meeting Notes'''
* Added multiple Github repository management (push/pull) for [https://github.com/ezCGP/ezCGP public] and [https://github.gatech.edu/emade/ezCGP private] Github repos

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Implement multiple repositories pushing (simultaneous pushing for public and GT side)
|Completed
|Aug 30, 2019
|Sep 6, 2019
|Sep 9, 2019
|-
|Make OpenCV operator and put it as a primitive for preprocessing
|Completed
|Sep 7, 2019
|Sep 13, 2019
|Sep 13, 2019
|}

== September 13, 2019, VIP Meeting ==
'''Meeting Notes'''
* Added OpenCV 3 primitive support (e.g. Gaussian blur) and fixed some support issues for Tensorflow and made it conformable with OpenCV ndarrays
** [https://github.com/ezCGP/ezCGP/commit/aca600c5ba36ae514d8ab95ab4ea02e7da87835a Git Commit]
* Caught everyone on the team up with multi-GitHub support BESIDES RODD because he's in China

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Create second preprocessing block for data augmentation and make variable to make x_val pass through optionally so we can make sure train, validation, and test pipeline is good
|Completed
|Sep 13, 2019
|Sep 22, 2019
|Sep 22, 2019
|}

== September 16, 2019, VIP Meeting ==
'''Meeting Notes'''
* Had team meeting about parallelization and set initiatives to get benchmark between single individual per slave or batch per slave parallelization benchmarks
* Discussed with Jinghua, Michael, and Rodd about the multiple block structure, including what we should do for validation vs. training set for preprocessing block
** I think we decided that it was good to have a flag for a preprocessing block (whether it will take validation datasets)

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Create second preprocessing block for data augmentation and make variable to make x_val pass through optionally so we can make sure train, validation, and test pipeline is good
|Completed
|Sep 13, 2019
|Sep 22, 2019
|Sep 22, 2019
|}

== September 23, 2019, VIP Meeting ==
'''Meeting Notes'''
* Parallelization team ran into memory leakage issues causing 7GB memory usage with only 2 individuals over 20 generations
** Likely explanation is that old generation individuals are still being kept and not properly deleted, since each individual's CIFAR-10 dataset size (even after preprocessing so that they're all unique) is only about 200 MB
** I suggested three possible methods to resolve them, including manual garbage collection for unused prior generations, optimizing dataset loading, and potentially caching base data before preprocessing block
* Github issues to be posted later tonight by Michael

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Clean up code and reorganize some extraneous operators
|Completed
|Sep 23, 2019
|Sep 23, 2019
|Sep 23, 2019
|-
|Check out [https://github.com/ezCGP/ezCGP/issues GitHub issues] and pick up one tab to work on
|Completed
|Sep 23, 2019
|Sep 26, 2019
|Sep 26, 2019
|}

== September 26, 2019, VIP Meeting ==
'''Meeting Notes'''
* Fixed Gaussian blur primitive and logging
* Created new primitive for normalization

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Clean up code and reorganize some extraneous operators
|Completed
|Sep 23, 2019
|Sep 23, 2019
|Sep 23, 2019
|-
|Check out [https://github.com/ezCGP/ezCGP/issues GitHub issues] and pick up one tab to work on
|Completed
|Sep 23, 2019
|Sep 26, 2019
|Sep 26, 2019
|-
|Find various preprocessing techniques and papers that outline them, each team member should read one and decide if its a good primitive to get some higher results
|Completed
|Sep 26, 2019
|Oct 21, 2019
|Oct 21, 2019
|}

== October 7, 2019, VIP Meeting ==
'''Meeting Notes'''
* Team caught up and started paralleization testing and can run under 30 minutes, but has scalability problems with I/O bus
* Cleaned up code and created hierarchical block generation structure 

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Continue to test and properly instantiate more blocks with varied primitives
|Completed
|Oct 7, 2019
|Oct 21, 2019
|Oct 21, 2019
|-
|Work with parallelization team to fix scalability by changing skeleton block structure to clear out useless bloated genome_output_values in mutants and resolve memory issues because mutants don't need the outputs, just the genome structure
|Completed
|Oct 7, 2019
|Oct 21, 2019
|Nov 4, 2019
|}

== October 12 2019, VIP Meeting ==
'''Meeting Notes'''
* Started creating and testing runs on IceHammer GT computing clusters
* Discussed possible downsides to parallelization implementation
* Mused over mating possibilities

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Continue to test and properly instantiate more blocks with varied primitives
|Completed
|Oct 7, 2019
|Oct 21, 2019
|Oct 21, 2019
|-
|Work with parallelization team to fix scalability by changing skeleton block structure to clear out useless bloated genome_output_values in mutants and resolve memory issues because mutants don't need the outputs, just the genome structure
|Completed
|Oct 7, 2019
|Oct 21, 2019
|Nov 4, 2019
|}

== October 14 2019, VIP Meeting ==
'''Meeting Notes'''
* Was told that midterm presentation is next week before
* FALL BREAK CAMPING TRIP TEAM BONDING!

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Continue to test and properly instantiate more blocks with varied primitives
|Completed
|Oct 7, 2019
|Oct 21, 2019
|Oct 21, 2019
|-
|Work with parallelization team to fix scalability by changing skeleton block structure to clear out useless bloated genome_output_values in mutants and resolve memory issues because mutants don't need the outputs, just the genome structure
|Completed
|Oct 7, 2019
|Oct 21, 2019
|Nov 4, 2019
|}

== October 19 2019, VIP Meeting ==
'''Meeting Notes'''
* Created presentation and wrapped up runs, found mistakes in error catching (self.dead = True not run, throws error instead) so run is interrupted
* Random seed is not set, so we have inconsistent and bad results
* Dataset is being transmitted per individual as well, causing likely I/O overload problem

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Continue to test and properly instantiate more blocks with varied primitives
|Completed
|Oct 7, 2019
|Oct 21, 2019
|Oct 21, 2019
|-
|Work with parallelization team to fix scalability by changing skeleton block structure to clear out useless bloated genome_output_values in mutants and resolve memory issues because mutants don't need the outputs, just the genome structure
|Completed
|Oct 7, 2019
|Oct 21, 2019
|Nov 4, 2019
|}

== October 25 2019, VIP Meeting ==
'''Meeting Notes'''

Summary of today’s meeting:

'''Mating'''

Discussed how there is a “find_active” (or similar) method that gets the list of active genes (aka layers + metadata). Majority of the mating should occur with these. However, *a small percentage (e.g. 10%) should be with the inactive nodes just to have genetic diversity* with mating.

Possible mating methods:

1) Whole block swapping by type (e.g. training with training), and solve any block output to input shape compatibility issues. This is what we will start off with for this semester, since it is easier. To keep diversity with inactive nodes, we might also spontaneously turn on some inactive nodes (maybe mutate into them?)

2) Partial block swapping, by swapping only parts of a block, most notably layers:
     Introduces a host of primitive shape compatibility issues similar to number 1's block to block (e.g. dense -> conv doesn’t work), which can be solved a number of ways:
              2a) Assigning primitives to groups by output shape (e.g. max pooling w/ fractional pooling). Then, in those groups, assign a hierarchical layout of which groups can output to which other groups and simply pick layers in that group or child groups to substitute or add in between incompatible layers
              2b) Doing an exhaustive search of preemptive compatibility searching (see the mating.py code Rodd wrote, I don’t fully understand it yet, but the comments are good)
              2c) Killing the individual and essentially relying on random chance to return to that individual if it is good (probably not preferred, but it is what we use in mutation (e.g. try catch self.dead), so we could just be consistent for mating).

'''Selection'''

Ultimately, we should keep a baseline number of best individuals for next generation before mating. Therefore, for each generation, a certain percentage would be allocated from each process:

       Just for example, say 33% of previous pareto optimal individuals, 33% of mutated, 33% of mated children

There are other ways to do selection after mutation/mating, but '''we should talk about that after mating'''. Trai and Mai have their own k-select method for post-mutating right now, I believe.

'''Parallelization'''

Michael, Sam, Trai, and Mai are to discuss what to do with large_dataset and if that can be properly deleted to remove I/O bottleneck.

Trai is debugging that today to see if large_dataset is actually holding a lot of memory, or if something else is and can be deleted. Right now, '''each CPU core already has access to the dataset, so we just need to remove that from the individual skeleton structure and I/O bottleneck should be solved'''.

'''Design Doc'''

We should make a '''design document of the high-level and key workflows of the ezCGP process'''. This could be something '''Rodd and Sam can work with the new students''' in creating as a softer onboarding, so they understand ezCGP before diving too deep in the code. This can include extra ideas (like number 2 of mating earlier) that we need to work on next semester.

'''Topics to avoid''': detailed primitive information, complex evaluation and TensorFlow graph structures, etc. Anything that will move the focus away from architecture of ezCGP.

'''Topic to include''': high-level ideas, certain details that aid in explaining certain key decisions (killing broken individuals)

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Implement block swap mating 
|Completed
|Oct 26, 2019
|Nov 2, 2019
|Nov 10, 2019
|-
|Work with parallelization team to fix scalability by changing skeleton block structure to clear out useless bloated genome_output_values in mutants and resolve memory issues because mutants don't need the outputs, just the genome structure
|Completed
|Oct 7, 2019
|Oct 21, 2019
|Nov 4, 2019
|}

== November 2 2019, VIP Meeting ==
'''Meeting Notes'''

* Met with Parallelization team and discussed goals for next week, including benchmarks and how to delete/recreate an individual to minimize potential memory issues
* Created mating master class and implemented whole block swapping
* Have yet to implement that class fully into universe.py, waiting on parallelization team to wrap up their code in universe.py in order to implement and start running
* Started and wrote several sections for [https://docs.google.com/document/d/1X8jGDXHAKkMBgOCYCtgT5v-wSqSLjVhxtZnGqr2hwz4/edit?usp=sharing Design Doc]

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Implement block swap mating first
|Completed
|Oct 26, 2019
|Nov 2, 2019
|Nov 10, 2019
|-
|Work with parallelization team to fix scalability by changing skeleton block structure to clear out useless bloated genome_output_values in mutants and resolve memory issues because mutants don't need the outputs, just the genome structure
|Completed
|Oct 7, 2019
|Oct 21, 2019
|Nov 4, 2019
|}

== November 4 2019, VIP Meeting ==
'''Meeting Notes'''

* Met with Parallelization team and discussed goals for next week, including benchmarks and how to delete/recreate an individual to minimize potential memory issues
* Continued to fix mating and logging issues
* FOUND MEMORY LEAKS IN MUTANT DEEPCOPY because genome_outputs is huge (~200MB) for each mutant
** Can just clear that out after deepcopying
** Currently testing sequentially and parallel, but it looks really good
* Be careful to clear out genome_outputs in mating once that is fully implemented too
** Fixed genome_outputs mating leak too

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Implement block swap mating first
|Completed
|Oct 26, 2019
|Nov 2, 2019
|Nov 10, 2019
|-
|Work with parallelization team to fix scalability by changing skeleton block structure to clear out useless bloated genome_output_values in mutants and resolve memory issues because mutants don't need the outputs, just the genome structure
|Completed
|Oct 7, 2019
|Oct 21, 2019
|Nov 4, 2019
|}


== November 9 2019, VIP Meeting ==
'''Meeting Notes'''

* Finished block swap mating and merged multiple-blocks and mpi-fix branches into ezHPC branch
* Consolidated installation requirements into a requirements.txt file and added installation instructions to [https://docs.google.com/document/d/1X8jGDXHAKkMBgOCYCtgT5v-wSqSLjVhxtZnGqr2hwz4/edit?usp=sharing the design doc]
** Tested for both MacOS and Linux (using a VM)
* Will start initial runs on IceHammer and Trai's computing cluster this week while Trai and Mai finish up calculating their alpha values to further optimize runtime

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Start running evolutions on computing clusters with varying population, genome, and epoch sizes
|Completed
|Nov 9, 2019
|Nov 18, 2019
|Jan 7, 2020
|-
|Test requirements.txt installation file on MacOS and Linux
|Completed
|Nov 9, 2019
|Nov 10, 2019
|Nov 10, 2019
|}

== November 18 2019, VIP Meeting ==
'''Meeting Notes'''
* Worked with Mai to correctly integrate mating and population in to mpi_universe
* Found out that the population array in mpi_universe is composed of genome lists (e.g. genome_output_values)
* Assigned tasks to Jinghua and myself in order to properly integrate (convert to individuals objects and convert back)
* May also think about mating in terms of genome_output_values as well in order to avoid extra computation of converting to and from Individual object form just for mating
* Got research paper template from Rodd, can work on this for the winter break
** [https://gecco-2020.sigevo.org/index.html/Papers+Submission+Instructions see LaTeX copy]
* Michael and Trai have difficulties running tests on IceHammer right now, they are working on it

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Start running evolutions on computing clusters with varying population, genome, and epoch sizes
|Completed
|Nov 9, 2019
|Nov 18, 2019
|Jan 6, 2019
|-
|Implement mating into mpi_universe properly with testing by converting to and from genome_output_values
|Completed
|Nov 18, 2019
|Nov 22, 2019
|Nov 22, 2019
|}

== November 22 2019, VIP Meeting ==
'''Meeting Notes'''
* Worked to run properly on local machine and implemented individual object conversion for mating (and back)
* Ran into several issues with new_pop being None, that was because rank 1+ CPUs (non-main CPUs) were returning first, but only main cpu should have the final pop
* There were skeleton block copying issues, so Jinghua and I worked to convert mating to using genome_output_list instead of individual object
** But we still need individual object (probably...?) in order to set some flags, this might be able to be further optimized, but for sake of running, it's okay for now
** Memory and CPU footprint seems to be pretty small

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Start running evolutions on computing clusters with varying population, genome, and epoch sizes
|Completed
|Nov 9, 2019
|Nov 18, 2019
|Jan 7, 2019
|-
|Implement mating into mpi_universe properly with testing by converting to and from genome_output_values
|Completed
|Nov 18, 2019
|Nov 22, 2019
|Nov 22, 2019
|}

== December 1 2019, VIP Meeting ==
'''Meeting Notes'''
* Trying to run on PACE Gatech cluster
* These are some helpful links

https://docs.pace.gatech.edu/software/anacondaEnv/

Follow the recommended instructions (esp step 4)

https://pace.gatech.edu/install-tensorflow-redhat-67 (possibly good, but I didn't find use in it)

Main issue running is that the glibcc version is outdated on PACE and will cause Tensorflow to not get the proper version it needs. 

ImportError: /usr/local/pacerepov1/anaconda/anaconda3/4.2.0/lib/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by /nv/pace-ice/mjurado3/.conda/envs/ezCGP/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)

Trying to fix currently. It is a huge pain. Keep in mind we must use python 3.6!! Not the default 3.7, so specify accordingly in Conda create command.

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Start running evolutions on computing clusters with varying population, genome, and epoch sizes
|Completed
|Nov 9, 2019
|Nov 18, 2019
|Jan 6, 2020
|}

== December 2, 2019, VIP Meeting ==
'''LAST DAY OF CLASS'''

'''Meeting Notes'''
* [https://docs.google.com/presentation/d/1jAWlWmQj94DfXsNsuke80kzpa3EUEJJKMgvQ2TTC_zg/edit?usp=sharing Final Presentation] 
* Continued to run more evolutions, maximum current generation achieved is anywhere from 4-9, depending on the hyperparameter sizes and the individual sizes
* Decided to focus on four primary goals for early next semester (and during the winter break)

1. Implement recurrent individual seeding so that the experimental runs can proceed longer than 12 hours and work around the PACE maximum walltime.

2. Implement new primitives, particularly for preprocessing. We can take ideas from the preprocessing EMADE team and from deep learning class for activation functions/layers.

3. Take Jason's feedback into account, about how to not mutate offspring, although I believe we are already doing that. Made a Slack thread about that for record-keeping.

4. Implement GPU support for Tensorflow, particularly with the tensorflow_evaluate function. I believe we can do CPU multiprocessing (as we are right now with MPI) and build GPU multiprocessing/support on top for the Tensorflow objects themselves in order to maximize both individual training time (GPU) and the overall evolutionary time (CPU MPI). We can work this out with Mai and Trai, starting January. Anticipated ~40x speedup.

I will be working on these goals throughout the winter, as well as preparing a basic paper for ezCGP that I will bring to the team in January for fleshing out. At the very least, I am hoping we can submit a yellow paper (concept idea) to GECCO 2020 or a similar conference. 

'''Why Do I Deserve My Grade?'''

I believe I deserve an A for many reasons. This extends to the rest of the second and third semesters on this team as well, as I have seen their individual contributions, but I will let them speak for themselves.

I helped architect and organize much of the team meetings and discussions, whether it was related to overall design, next goals, or overarching future plans. This included all of the topics and advancements we made this semester, including multiple block support, high-performance computing for CPUs with multiprocessing (MPI), integrating whole block swap mating, and the initial runs during the last week before the final presentation on PACE. This includes nearly all of the code merges between Parallelization and Multiple-Blocks/Mating, as well as many environmental and sysadmin type work. When the first semesters came on to the team, I also helped them get started with the visualization subteam and coordinate that process, although I do wish I could have been more detailed with them since there was not always enough time. However, they still managed to create a great visualization extension and I am proud of that.

In more detail, here is a non-exhaustive list of my main contributions:

'''1. Multiple Blocks'''

I raised many concerns about its design and implementation in the old dictionary-focused code. In doing so, I architected a new, cleaner, and more efficient set of block classes inspired by an abstract/concrete type object-oriented design principle. In short, I helped design the currently used skeleton block, preprocessing/data augmentation block, and training block class architecture. This merges with the Block class structure Rodd built in 2018 and has caused us to be able to better work with whole block mating.

'''2. Whole Block Swap Mating'''

Instead of going for a complete mating class, I correctly decided we did not have enough time for a complete mating system (whole block, partial block, and interblock mating) and discussed and orchestrated our current mating system. This mating system is able to utilize what we know about the general ML process and separate data augmentation, preprocessing, and training. While we are not completely certain of its effectiveness (due to lack of experimentation), I believe this is a good step in the right direction and will be soon proven in the coming months. 

I worked extensively with Michael and Jinghua in implementing these two changes, as you will see throughout the code commits (please refer to Github link at the bottom). There are other things not mentioned, like fixing dead individuals, the pickling errors cascading from that, and many **many** legacy issues from last semester.

'''3. High Performance Computing with MPI Multiprocessing (for CPUs)'''

I worked extensively with Trai and Mai throughout the semester on interpreting their benchmarks and providing ideas on what could be causing our previous memory leaks and other performance issues. I helped them optimize our code, along with Michael, and our work is why ezCGP is even able to run more than one individual at once (e.g. sequential). I look forward to working with them on GPU integration so that our experiments can be further optimized in runtime.

'''4. PACE, Anaconda, and Experimentation'''

Michael, Mai, Jinghua, and I were finally able to run PACE experiements starting Nov 31. However, in the days leading up to that over Thanksgiving, I began to experiment deeply with PACE. Michael had begun to wrestle with that system earlier that week, but he could not figure out how to actually run ezCGP. I spent nearly 72 hours not only figuring out how to run ezCGP on PACE, but also in the weeks before that on how to properly standardize and sanitize our environments so future workflows could be smooth. I was able to properly document and explain to the team how to set up Anaconda specifically for ezCGP. Given how many errors and hours spent when we had when members were still adapting to and not always using that environment, I believe this standardization may have saved us weeks, if not months.

In addition, I created the convert.py alongside Michael's evaluator.py to help us see our best individuals and train the best through a large number of epochs.

On a similar vein, I am currently working on recurrent seeding so that our PACE experiments can run for longer.

Overall, I believe we have two primary goals if we want to create truly spectacular individuals:

'''1. Run for far longer than are able to right now, whether that is from seeding, GPU support, or both.'''

'''2. Implement far more primitives for deep learning. This is anecdotal, but there have been people who have Deep Learning experience who have taken a look at our primitives and expressed their surprise that we are even able to get 67% accuracy with only such few basic primitives and almost no activation layers.'''

On the same vein, I still would like to make sure our evolutionary process is at least sensible (mating and mutation hyperparameters/order). If these conditions are met, I believe we can run many many experiments and eventually evolve truly spectacular individuals. I am hoping to do so before I graduate, but if something were to slow us down, I will continue to work with ezCGP even after graduation. I believe this project will be a great take on AutoML, and I would love to do my part for it for a long time.

'''GitHub'''

I would love to share my commits in detail, as Jason/Greg had requested in class. However, I'm not sure what commits to pick, as I worked on 2 branches this semester and gave my input to 2 more. I helped set up the GT Github repository for ezCGP (in parallel with Rodd's public repo), but I prefer the public one, so here is the link to that:

https://github.com/ezCGP/ezCGP

I believe you will find most of my commits under these branches:

'''multiple-blocks'''

'''ezHPC'''

and perhaps a few under:

'''mpi-fix'''

For your convenience, here are a few commits:

Mating Whole Block Swap v1: https://github.com/ezCGP/ezCGP/commit/b71f5ae6c1926d7becfa82bf6c3371e08570c8a4

Pushing to both repositories: https://github.com/ezCGP/ezCGP/commit/f4465923421384013ac974d59cf647bbe5ffc77c

Refactoring blocks dictionary to classes v1: https://github.com/ezCGP/ezCGP/commit/a3f1cee8369521612bec64ff0e4d5e0059ba2a7f

and here are some Slack guides / Design Doc I created:

PACE guide: https://emade-vip.slack.com/archives/CFDN277GV/p1575240026060600

Anaconda guide: https://emade-vip.slack.com/archives/CFDN277GV/p1573334758007800

Design Doc: https://docs.google.com/document/d/1X8jGDXHAKkMBgOCYCtgT5v-wSqSLjVhxtZnGqr2hwz4/edit?usp=sharing

'''Conclusions'''

I really like this team and this project. I sincerely hope we will finish our infrastructure changes as mentioned above (including good primitives) by February of next year and be in a position to run for 100 generations rapidly to obtain some near state-of-the-art individuals for CIFAR-10 (and maybe back for MNIST too, haha) before graduation. In the meantime, I will start to work on the paper this winter, and I hope we will be able to publish a yellow paper (primarily on architecture and ideas) by summer 2020 and a white paper by winter 2020 (with good, if not near state-of-the-art, individuals). This is very ambitious, but I also believe we have a clear list of goals and action items we can accomplish with this effective team.

Thank you! If possible, I would love to run through some more details about the paper and evolutionary design choices with you in January.

== December 9, 2019 ==
'''Private Thoughts'''
* We must re-examine our primitives, their kernel sizes, rotation and flip percentages, and every base hyperparameter
* I am unsure if we change the hyperparameters right now, or if we need to. Everything seems standard, except for gaussian blur, salt-pepper noise, and maybe augmentation blocks
* We MUST find scientifically sound primitives and implement them early next semester, otherwise we are suboptimal, if not doomed, from the very start!!!

== December 19, 2019 ==
'''Private Thoughts'''
* Salt and Pepper noise may not generalize well
* Best individuals without this primitive have actually been able to beat validation accuracy (78.83%) with a testing accuracy of 85.12%
* This is best individual to date with data augmentation block implemented
** Best previous semester result with JUST training block and manual data augmentation was 90% testing
* [Best Individual for Sam's run_13 generation 21 https://emade-vip.slack.com/files/UA0LSQLMU/FRWMN2YMS/image.png]
** This is with a split of 60 training, 20 test, 20 validation
* Previous runs had best individuals with a single salt/pepper data augmentation layer, which generalized a lot worse
** However, previous runs also had dataset split of 70 training, 20 testing, 10 validation
** So, more runs will need to be done with and without salt/pepper in order to see if it is not generalizing well

We need to know what primitives/factors are causing our individuals to not generalize well to CIFAR-10

I created a temporary learning curve for evaluator.py to select the best epoch number to run

Michael is working on a long term solution to find the learning curve and determine best epoch number to use

We need to run more organized experiments once we have one really good individual, so that we can see that the settings for our ezCGP is at least decent (e.g. main_count, split size, evaluator epoch framework, etc.)

== January 6, 2020, VIP Meeting ==
'''Meeting Notes'''
* Onboarding Tan, Bojun, and Ford as new members
* Decided top priorities are multi-GPUs and preprocessing primitives
* Will be experimenting with epoch 10, 20 base pop, mate 5 (aka. 10), mutation 4 for a total of 120 individuals per generation
* One GPU per model is most efficient, it is not good to split one GPU for multiple models simultaneously, according to the internet
* We should start with 2 GPUs just to test that Horovd is working, then scale up
* GCP Pricing: https://cloud.google.com/compute/all-pricing#gpus
* This semester's goals and overall direction
** [[files/Screen Shot 2020-04-09 at 2.56.20 PM.png]]

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Start investigating GCP and Horovod in order to get multiple GPUs running
|Completed
|Jan 6, 2020
|Jan 18, 2020
|Feb 9, 2020
|}

== January 13, 2020, VIP Meeting ==
'''Meeting Notes'''
* Split team into Primitives/Data Augmentation and GPU/Parallelization teams
* ZenHub integration, split up GitHub branches into stable versions per semester, and one for each team
* Asked Jason about GCP deployment. He said he will need a startup script for each virtual instance, and an instance script if we need multiple. Otherwise, just specify what instance you want if the GPU count is enough.
** GCP Guide
*** [[files/Screen Shot 2020-04-09 at 2.49.05 PM.png]]

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Start investigating GCP and Horovod in order to get multiple GPUs running
|Completed
|Jan 6, 2020
|Jan 18, 2020
|Feb 9, 2020
|-
|Create startup/instance script for GCP on Thursday with Jason
|Completed
|Jan 16, 2020
|Jan 22, 2020
|Jan 22, 2020
|}

== January 18, 2020, VIP Meeting ==
'''Meeting Notes'''
* Reviewed potential Horovod architectures
** Likely will go with single CPU per GPU structure with mpi4py, but unsure of the dependencies and compatibility with optimizers
** Horovod has its own optimizer averaging function
** Got GCP provision from Jason, working on startup script: https://github.com/ezCGP/ezCGP/blob/2020S-gpu/install.sh

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Start investigating GCP and Horovod in order to get multiple GPUs running
|Completed
|Jan 6, 2020
|Jan 18, 2020
|Feb 9, 2020
|-
|Create startup/instance script for GCP on Thursday with Jason
|Completed
|Jan 16, 2020
|Jan 22, 2020
|Jan 22, 2020
|}

== January 25, 2020, VIP Meeting ==
'''Meeting Notes'''
* Decided to focus on Google Cloud deployment onto multiple instances and see if MPI can work with multiple instances through LAN IP routing
** Trying to decide how that would work out with Horovod, since the dependency is still unclear
** Package management is done, as we are able to get stable versions with Anaconda, I think
** Test run is still TBD

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Start investigating GCP and Horovod in order to get multiple GPUs running
|Completed
|Jan 6, 2020
|Jan 18, 2020
|Feb 9, 2020
|-
|Create startup/instance script for GCP on Thursday with Jason
|Completed
|Jan 16, 2020
|Jan 18, 2020
|Jan 25, 2020
|}

== Feb 2, 2020, VIP Meeting ==
'''Meeting Notes'''
* Continued to run into issues with GCP instance access
* Recreated Instance with Jason and Mai
* Discovered multiple issues with Horovod, so we decided to potentially abandon and look into TF 2.0, but there is issues with refactoring from Rodd too, so we need to solve that and redo the entire codebase such that there is no more terrible inheritance and dictionary issues. INTERFACES LET'S GO

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Start investigating GCP and Horovod in order to get multiple GPUs running and networking
|Completed
|Jan 6, 2020
|Jan 18, 2020
|Feb 9, 2020
|}

== Feb 9, 2020, VIP Meeting ==
'''Meeting Notes'''
* Discussed with Trai and Mai and Rodd on how to refactor code to use interfaces instead of inheritance for genome block individual trio
* Convinced Rodd to switch over
* We need TF 2.0+ switch, so we will refactor and redo code
* Once that is refactored and upgraded, it will run multiple GPUs automatically on GCP
* Refactoring to TF 2.0 rough UML diagram
** [[files/Ezcgp refactor.jpg]]

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Upgrade and Refactor to TF 2.0
|Stable, but not Complete
|Feb 9, 2020
|Mar 22, 2020
|Apr 9, 2020
|}

== Feb 17, 2020, VIP Meeting ==
'''Meeting Notes'''
* I missed last weekend's meeting due to illness
* Wrote problem_interface.py in the new repository under ezCGP at https://github.com/ezCGP/ezExperimental that will eventually be merged back into the primary repo
* Helped new students (Tan, Ford, Henry) on PACE issues
* Gave weekly SCRUM report

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Upgrade and Refactor to TF 2.0
|Stable, but not Complete
|Feb 9, 2020
|Mar 22, 2020
|Apr 9, 2020
|}

== Feb 21, 2020, VIP Meeting ==
'''Meeting Notes'''
* Collaborated on details for code redesign architecture, specifically on how universe vs. mpi_universe would be implemented (and avoiding MPI library was decided)
* Offered implementation details for combining arguments and operators to simplify the overengineering in mutation argument types
* New Experimental repo: https://github.com/ezCGP/ezexperimental

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Upgrade and Refactor to TF 2.0
|Stable, but not Complete
|Feb 9, 2020
|Mar 22, 2020
|Apr 9, 2020
|}

== Feb 28, 2020, VIP Meeting ==
'''Meeting Notes'''
* Met with Michael to clean up the operators.py and utils.py file in order to simplify the massive function used to normalize weights in the operators file
* Most of Rodd's code in operators, utils, and simple_numpy is uncommented or simply with a meaningless "words"
** Spent most of the day trying to understand and write down clarifications for the code
* Added more comments and documentation to clarify the meaning of each class

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Upgrade and Refactor to TF 2.0
|Stable, but not Complete
|Feb 9, 2020
|Mar 22, 2020
|Apr 9, 2020
|-
|Focus on implementing the Operators class and doing the TF 2.0 primitive implementation (graphless)
|Completed
|Feb 28, 2019
|Mar 9, 2020
|Mar 23, 2020
|}

== Mar 2, 2020, VIP Meeting ==
'''Meeting Notes'''
* Met with the first semester students to plan out their primitive runs
* Understood what they had done with adding activation functions!!! Very good job first semesters!
* Will wait until Mar 5 to see if PACE will come back up for experiments (currently is out of service)
** If not, will ask Trai for his computer to run experiments before Mar 9 presentation
* Meeting with Michael to discuss potential issues with Rodd's commit and whether to discard our changes or attempt to merge
** May have to meet with Greg or Jason to further discuss possible friction in the team due to conflicts with the new design/lack of comments and other code bloat discovered on Feb 28
** The commit in question: https://github.com/ezCGP/ezExperimental/commit/31318d82db6dfc26a20384202947c69e86702aa4

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Upgrade and Refactor to TF 2.0
|Stable, but not Complete
|Feb 9, 2020
|Mar 22, 2020
|Apr 9, 2020
|-
|Focus on implementing the Operators class and doing the TF 2.0 primitive implementation (graphless)
|Failed to Convince Rodd to Accept Our Changes
|Feb 28, 2019
|Mar 9, 2020
|Mar 23, 2020
|}

== Mar 9, 2020, VIP Meeting ==
'''Meeting Notes'''
* Presented midterm presentation: https://docs.google.com/presentation/d/1DaGSf2-x87oNFT5oukKR1jfI0m2wtXs--56K3mf7q38/edit?usp=sharing
* Was told to focus more on statistical significant demonstrations and rigorous demonstrations of design decisions
* First semesters should focus on continuing runs
* Need to start running with preprocessing as well

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Upgrade and Refactor to TF 2.0
|Stable, but not Complete
|Feb 9, 2020
|Mar 22, 2020
|Apr 9, 2020
|-
|Focus on implementing the Operators class and doing the TF 2.0 primitive implementation (graphless)
|Failed to Convince Rodd to Accept Our Changes
|Feb 28, 2020
|Mar 9, 2020
|Mar 23, 2020
|}

== Mar 23, 2020, VIP Meeting ==
'''Meeting Notes'''
* Met with new semesters and started preparing for training workshops on deep learning and other ideas
* Sent out email to Jason and scheduled meeting for tomorrow to talk about team conflicts

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Upgrade and Refactor to TF 2.0, collaborate with Mai and Trai on this
|Stable, but not Complete
|Feb 9, 2020
|Mar 22, 2020
|Apr 9, 2020
|-
|Focus on preparing deep learning workshop slides and preparing lecture for the new students
|Completed
|Mar 23, 2020
|Mar 24, 2020
|Mar 25, 2020
|}

== Mar 24, 2020, VIP Meeting ==
'''Meeting Notes'''
* Finally met with Jason about how to deal with Rodd and code conflicts
* Continued to work on the Deep Learning Crash Course for new students
** https://docs.google.com/presentation/d/1NDYt_0MIUn6Qikmn7JFCHi62-tKKHwKSKM1bQwlak3o/edit?usp=sharing

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Upgrade and Refactor to TF 2.0, collaborate with Mai and Trai on this
|Stable, but not Complete
|Feb 9, 2020
|Mar 22, 2020
|Apr 9, 2020
|-
|Focus on preparing deep learning workshop slides and preparing lecture for the new students
|Completed
|Mar 23, 2020
|Mar 24, 2020
|Mar 25, 2020
|}

== Mar 25, 2020, VIP Meeting ==
'''Meeting Notes'''
* Had first workshop with first semesters on an overview of deep learning
* All workshop slides can be found here: https://drive.google.com/open?id=1y1Ybczg9sL57SM2E5F5X53FPwOHb-Uc6
* Asked first semesters to brush up on optimizers and activation functions
* Compiled MANY resources for the first semesters to read if they want, including Deep Learning coursework, papers on layers, and CGP evolution
** Slack post: https://emade-vip.slack.com/archives/CFDN277GV/p1585604562024600
** [[files/Screen Shot 2020-04-09 at 2.35.28 PM.png]]
* Slack Resources, in case link doesn't work:
** 3b1b NN tutorial: https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi
** CGP CNN Evolution (2019): https://www.mitpressjournals.org/doi/pdf/10.1162/evco_a_00253
** The original CGP CNN paper (2017): https://arxiv.org/pdf/1704.00764.pdf
** Other interesting papers I've been reading on evolution: https://drive.google.com/file/d/1z8_3fDgsSO6N7iZdQvnxes055WIJ-vLT/view?usp=sharing
*** https://drive.google.com/file/d/1JJV4lekB8NZlIC94eQrkfrjiK3WHTBkr/view?usp=sharing
** Layers we use for CIFAR-10 and their in-depth analysis, this is helpful if you want to understand particular layers: https://drive.google.com/drive/folders/12dFJP-zsBFWqKG8MP5AmPLI0C-x2DtOt?usp=sharing
** An excellent Stanford course (just skim the notes). The first 2 modules here are REALLY REALLY REALLY GOOD. Tech's course is a spin-off (rip-off) of this: http://cs231n.github.io/

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Upgrade and Refactor to TF 2.0, collaborate with Mai and Trai on this
|Stable, but not Complete
|Feb 9, 2020
|Mar 22, 2020
|Apr 9, 2020
|-
|Prepare GA/CGP lecture slides
|Completed
|Mar 25, 2020
|Mar 28, 2020
|Apr 1, 2020
|}

== Apr 1, 2020, VIP Meeting ==
'''Meeting Notes'''
* Went through ezCGP codebase
[[files/EzCGP v1 overview.png]]
* Asked first semesters to run through a TF 2.0 tutorial, read the 2019 CGP paper, and prepare for codebase installation for next Wednesday
* Went through CGP theory: https://drive.google.com/file/d/1uyCKKcVulDN0uEIi8WR2CFQVsAPTPvaE/view?usp=sharing
** Clarified deep learning theory concerns from last week

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Upgrade and Refactor to TF 2.0, collaborate with Mai and Trai on this
|Stable, but not Complete
|Feb 9, 2020
|Mar 22, 2020
|Apr 9, 2020
|-
|Prepare codebase and Anaconda environment installation for PACE demonstration / follow-along
|Completed
|Apr 2, 2020
|Apr 6, 2020
|Apr 8, 2020
|}

== Apr 6, 2020, VIP Meeting ==
'''Meeting Notes'''
* Prepared materials for the first semesters on how to install ezCGP and run on PACE
** PACE Guide:
*** [[files/Screen Shot 2020-04-09 at 2.47.07 PM.png]]
* Finished writing statement of purpose regarding my roles in the team for graduate school

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Upgrade and Refactor to TF 2.0, collaborate with Mai and Trai on this
|Stable, but not Complete
|Feb 9, 2020
|Mar 22, 2020
|Apr 9, 2020
|-
|Prepare codebase and Anaconda environment installation for PACE demonstration / follow-along
|Completed
|Apr 2, 2020
|Apr 6, 2020
|Apr 8, 2020
|}

== Apr 13, 2020, VIP Meeting ==
'''Meeting Notes'''
* Met with new students and clarified their assignment
* Helped out with their initialization and will go over PACE on Wednesday
[[files/Image123.png]]

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Go over PACE and new model comparisons for new students
|Completed
|Apr 8, 2020
|Apr 13, 2020
|Apr 19, 2020
|}

== Apr 18, 2020, VIP Meeting ==
'''Meeting Notes'''
* Met with new students and continued to debug their PACE runs
* Settled on Kinnera having the only successful ezCGP run as benchmark
* Helped Luke, Kinnera, and Alex with their models and organized their slides
* Created a checklist for new students to fulfill and guided them continuously on how to do so
* Met several times over the last few days and held prolonged office hours (~3-6 hours a day) to debug and solve issues for every student
** There are still many issues that they have run into, due to lack of experience with command-line tools and PACE

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Work on the slides and presentation and guide new students through that process too
|Completed
|Apr 17, 2020
|Apr 18, 2020
|Apr 19, 2020
|}

== Apr 19, 2020, VIP Meeting ==
'''Meeting Notes'''
* Working with new students to set up their [slides https://docs.google.com/presentation/d/1TV78U_DNYqzz7cwFAqhuXwjJl6Ou8qVV0f8nkKiARjY/edit?usp=sharing] and organize it well
* Worked with Michael to create pareto front graph for ezCGP 1.0 benchmark run
* Helped Kinnera with setting up ezCGP and evaluator for the best model

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Work on the slides and presentation and guide new students through that process too
|Completed
|Apr 17, 2020
|Apr 18, 2020
|Apr 19, 2020
|}

== Apr 20, 2020, VIP Meeting ==
'''Meeting Notes'''
* Presented the final presentation of ezCGP

== Apr 24, 2020, VIP Meeting ==
'''Final Semester Summary: Why do I deserve an A?'''

I believe I deserve my grade for several reasons.

'''Winter Progress'''

For starters, I have been working on ezCGP since the end of last semester, including over the winter break. I ran over twenty complete runs of ezCGP, each taking several days and spanning dozens of generations. Over these runs, I made significant progress on debugging the genome copy, which basically was not keeping any individual across generations.

In addition, I read several papers regarding the state of the art in CIFAR-10 and implemented several new primitives. You can access them [https://drive.google.com/drive/folders/12dFJP-zsBFWqKG8MP5AmPLI0C-x2DtOt?usp=sharing here].

Finally, I researched and consolidated the Anaconda environments for Tensorflow GPU for running on PACE, which helped increase the total speed by over 40x, when running on PACE. This included many painful hours remedying CUDA driver versions and planning for multiple GPU support.

As a result, I managed to get testing accuracies from below 60% average to nearly 85%+ consistently, which is a massive improvement. This accomplishes both of the end-of-semester goals we had in the Fall.

In addition, I started working on a first draft of a paper describing our results with ezCGP. Unfortunately, I was not able to completely flesh it out, but I did manage to introduce the concepts. I would like to leave this draft for the future semesters to improve on and, with a bit of luck, eventually publish to GECCO. You can download that first draft here: [[files/EzCGP gecco 2020.docx]].

'''New Semester Goals'''

Now, with the new semester, I returned to the team and jumpstarted us on what needed to be done, now that the GPU support was in place and the evolution was actually functional. I pointed us in two major directions: 

1) multiple GPU

2) new primitive support/data augmentation reworking

First, for the multiple GPU subteam, I worked with Trai and Mai in trying to get us scaled onto GCP and implementing Horovod, which turned out to be a disaster due to TF 1.0 being deprecated. However, this did help us get started on Google Cloud, including the first forays into environment standardization and networking.

Second, I helped reorganize the Github branch system into a semester subteam organization. For example, for this semester, we had a 2020S-gpu and a 2020S-primitives branch, which helped reduce Github confusion. This was especially helpful when syncing to the GT Github, which required me to manually set up everyone's GitHub accounts to be able to push to both.

In the future, if this issue comes up, please refer to the ezCGP 1.0 Design Doc [https://docs.google.com/document/d/1X8jGDXHAKkMBgOCYCtgT5v-wSqSLjVhxtZnGqr2hwz4/edit?usp=sharing here]. There is a clearly documented section on how to set up Git.

'''Code Redesign / Conflicts'''

However, this is when we realized that we needed a [https://github.com/ezCGP/ezExperimental redesign] of the code because ezCGP 1.0 was confusing to update. I worked with Trai, Mai, and Michael in sketching out UML diagrams and rethinking the way we handled the genomes at the actual code level for further clarity. Unfortunately, Rodd had many concerns about the redesign, which ended up sparking significant debate without much progress.

Once we managed to get Rodd onboard with the cleaner interface design (as opposed to the old inheritance structure), Rodd went and created the entire code skeleton overnight, with very few comments and certain design decisions that were unjustified. As a result, we had several prolonged debates with Rodd, who dismissed many architectural and code changes we suggested. This caused communication to gradually break down with Rodd, because Mai, Trai, Michael, and I struggled to understand what exactly he wanted and why he wanted it. 

Michael and I spent '''many''' nights together trying to figure out how to keep the team together despite this conflict. We did not want to debate forever; so, after much consideration, we decided to contact Jason and it was gradually sorted out. Unfortunately, this delay set us back approximately two months in the semester, which we were unable to fully recover from.

'''Second Semester Students'''

Thankfully, in the meantime, I was able to continue to collaborate with Michael in helping the 2nd/3rd semester students (e.g. Bojun, Ford, Henry, Tan) make progress despite the standstill regarding the redesign. We helped them understand ezCGP at a deeper level, and what primitives needed to be implemented.

After 3-4 weeks of workshops, they were able to demonstrate a proficient understanding of the core ideas of ezCGP, despite being in the midst of the transition from ezCGP 1.0 to 2.0. I continued to research the literature for primitives and tasked them with implementing those primitives and running experiments on PACE. This took some significant effort, as PACE documentation was lackluster. 

However, in the end, we were able to make significant progress by fixing the way activation functions were mutating and applied to the computational graph. In essence, the activation functions were not being selected properly before, which was a significant, undetected error.

Furthermore, I helped support Ford and Bojun throughout the semester. 

With Ford, I am impressed by his positive attitude, and we worked together until the end of the semester. Towards the end, I helped him get started on the visualization code. Unfortunately, it was not completed in time, but we managed to get Pareto front, AUC, hypervolume, and accuracy over time visualizations concretized in [https://github.com/ezCGP/ezCGP/commit/241961fa8ed1efde514f8451647007ab240bf0ec results_analysis.py] with Michael's help.

With Bojun, I liked how much he was able to work with and understand the GPU parallelization goals. In Trai's words, "I hope Bo can carry the torch, you know?". I believe Bojun can do so, after working with him on networking, GCP, and benchmarking ezCGP's performance. My only concern is that he lacks a bit of confidence, which causes him to occasionally choose someone else's idea, even if his idea was better in the first place.

'''First Semester Students'''

This semester, I had the privilege of leading the first semester students onto ezCGP. This included: Kinnera, Sumit, Wooseok (Luke), Alex, Tanishq, David, and Reagan.

I led them through weekly workshops, which you can access [https://drive.google.com/drive/folders/1y1Ybczg9sL57SM2E5F5X53FPwOHb-Uc6?usp=sharing here]. After these introductory lectures on deep learning, NAS, and CGP, I led them through running experiments on PACE. This included them implementing existing models and comparing them to ezCGP 1.0's results.

Unfortunately, this was '''not''' an easy task. However, I found a lot of joy in guiding the new students. I ended up hosting office hours almost every night for several hours throughout the COVID-19 situation after Spring Break. In addition, I responded to their many questions via Slack and helped to clarify many misconceptions. I tried my best to impart an intuitive understanding of ezCGP and the effects of certain primitives, as well as what we were trying to accomplish and why it was relevant.

Throughout the process, all the students were very engaged and wanted to learn more, which I was happy to support. However, two students particularly shined in the brief time I worked with them. '''Luke and Kinnera both stepped up at the very end of the semester'''. 

Luke was very engaged and always wanted to learn more. He helped provide the code templates the rest of the students used, and I have spoken at great length with him regarding the project and left him with notes on the future goals and steps we need to take to get there. I trust he will be a capable leader for this team in the semesters to come.

Kinnera was also very engaged. Despite having a busy schedule, she made time to run many experiments on PACE. She was the only one to successfully install the Anaconda environment and complete an ezCGP run. Without her, we would not have the second complete benchmark run with fixed primitives for the rest of the first semester students to compare to.

I hope that Kinnera, Luke, Ford, and Bojun will be able to step up and lead the team in future semesters since many of us will be graduating this semester. I cannot speak for the others, but I would like to be available for them to ask any questions and help support them with the research as well. They have tremendous potential, and I would like to see that put to good use.

'''Conclusion'''

As I mentioned in my previous semester summary, I had hoped we could achieve publishable results, but we were unable to run as many generations as we would have liked due to the GCP redesign and subsequent communication issues. However, in spite of this setback, I believe we still made decent progress this semester and achieved the changes we planned.

As mentioned above, I believe there are four solid team members in ezCGP able to carry the torch, and I hope we will achieve good results in the future. I had fun supporting the team throughout my tenure in VIP, whether with documentation, code design/implementation, debugging, environmental setup, or educational workshops. 

Thank you to Jason and Greg for this opportunity! I learned a lot about evolutionary programming and deep learning through this VIP. It really helped me dive into topics I was interested in but had no experience with. Even after taking the Deep Learning class, I still think this VIP helped me put those skills into practice and understand more about what I was learning.

I really appreciate it! If possible, I would love to continue similar research in the future. To Jason especially, I appreciate your guidance and patience over the semesters, and I want to thank you again for agreeing to write a recommendation letter :)

Thank you all very much!