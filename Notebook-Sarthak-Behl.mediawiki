== Team Member ==
Team Member: Sarthak Behl

Email: sbehl6@gatech.edu, sarthakbehl3@gmail.com

Cell Phone: 203-349-1089

Interests: Machine Learning/Artificial Intelligence, FinTech, Basketball, Film, Music

== Week 15: November 25th, 2019 ==
'''Lecture 15:'''

- Final Presentations the following week

COMPLETE PEER EVALUATIONS OTHERWISE THERE WILL BE A DROP IN LETTER GRADE
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update notebook
|IN PROGRESS
|November 25th, 2019
|DECEMBER 2ND
|DECEMBER 2ND
|-
|Wrap up VIP
|IN PROGRESS
|November 25th, 2019
|DECEMBER 2ND
|DECEMBER 2ND
|}

== Week 14: November 18th, 2019 ==
'''Lecture 14:'''

Multiple Articles and Resources to Go Over
* Evolutionary Algorithms for Extractive Automatic Text Summarization: [https://www.sciencedirect.com/science/article/pii/S1877050915006869 https://www.sciencedirect.com/science/article/pii/S187705091500686]
* Continue upon research in trends of NN in NLP
** Recent Trends in Deep Learning Based Natural Language Processing: https://arxiv.org/pdf/1708.02709.pdf
* Research Tensorflow and play around with the newest version and 1.4
* https://www.tensorflow.org/guide
- Utilized Logistic Regression, Random Forest Classifier, and attempted Neural Networks which did not work (gave low accuracy). Cannot seem to point finger on why?!

FALLING BEHIND IN TERMS OF VIP WORK, NEED TO BE BETTER AT WORKING IT INTO MY SCHEDULE!!!
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Work more with TensorFlow
|COMPLETE
|November 18th, 2019
|November 25th, 2019
|November 25th, 2019
|-
|Go through the additional articles and resources provided
|COMPLETE
|November 18th, 2019
|November 25th, 2019
|November 25th, 2019
|}

== Week 13: November 11th, 2019 ==
'''Lecture 13:'''

General Notes:

Multiple Articles and Resources to Go Over
* Evolutionary Algorithms for Extractive Automatic Text Summarization: [https://www.sciencedirect.com/science/article/pii/S1877050915006869 https://www.sciencedirect.com/science/article/pii/S187705091500686]
* Continue upon research in trends of NN in NLP
** Recent Trends in Deep Learning Based Natural Language Processing: https://arxiv.org/pdf/1708.02709.pdf
* Research Tensorflow and play around with the newest version and 1.4
* https://www.tensorflow.org/guide {| class="wikitable" !Task !Current Status !Date Assigned !Suspense Date !Date Resolved |- |Work with TensorFlow |COMPLETE |November 11th, 2019 |November 18th, 2019 |November 18th, 2019 |- |Go through the articles and resources provided |COMPLETE |November 11th, 2019 |November 18th, 2019 |November 18th, 2019 |}

== Week 12: November 4th, 2019 ==
'''Lecture 12:'''

WILL MISS UPCOMING SUBTEAM MEETING DUE TO DOCUMENTED TRAVEL TO SEATTLE

General Notes:
* Running seeding: <code>python src/GPFramework/seeding_from_file.py templates/input_movie_reviews.xml seeding_test_nn</code>
* Running EMADE: <code>python src/GPFramework/launchEMADE.py templates/input_movie_reviews.xml</code>
* Guide for Neural Networks: https://towardsdatascience.com/a-gentle-introduction-to-neural-networks-series-part-1-2b90b87795bc
* Andrew Ngs course on Neural Networks
* Current Trends of NN in NLP: https://medium.com/dair-ai/deep-learning-for-nlp-an-overview-of-recent-trends-d0d8f40a776d
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update notebook
|IN PROGRESS
|November 4th, 2019
|November 11th, 2019
|November 11th, 2019
|-
|Read about NN and Keras
|IN PROGRESS
|November 4th, 2019
|November 11th, 2019
|November 11th, 2019
|}

== Week 11: October 28th, 2019 ==
'''Lecture 11:'''

Joined SubTeams, spoke to multiple subteams. Initially was primarily interested in Stock Prediction subteam but they do not seem to offer it anymore.

I spoke with Prof. Greg Rohling to see if I can start it next semester.

Decided to join the Natural Language Processing subteam, primary mission of which is to integrate Neural Networks into EMADE for NLP Purposes. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update notebook
|IN PROGRESS
|October 28th, 2019
|November 4th, 2019
|November 4th, 2019
|-
|Read about NN and Keras
|IN PROGRESS
|October 28th, 2019
|November 4th, 2019
|November 4th, 2019
|}

== Week 10: October 21st, 2019 ==
'''Lecture 10:'''

Presented on solving Titanic with EMADE

https://docs.google.com/presentation/d/1aEkLMt0cyisYtIDkD2OINMQz-2n3jkPhdxsj7STqWyM/edit?usp=sharing

input_titanic.xml
* Changed 0 to 1: <reuse> 1 </reuse>
* Changed # of workers from 5 to 3
Emo.py in Deap Library
[[files/EmoInDeap.png|thumb|Emo.py in Deap Library]]
Run (Overnight: 10+ hours)
* # of generations: 19
* Ended with 4471 individuals
** 330 individuals whose FN count was not null
* Elapsed_time /60/60 = 25.25 (units?)
[[files/MachineLearning.png|thumb|Machine Learning]]

Example Trees
* AdaBoostLearner(myRMS2D(ARG0, 7, 1), ModifyLearnerFloat(learnerType('RandForest', {'n_estimators': 100, 'class_weight': 0, 'criterion': 0}), 0.01), 3, myFloatDiv(passFloat(0.1), 0.1))
** FN = 15.8 & FP = 18.6
* AdaBoostLearner(ARG0, learnerType('Boosting', {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3}), passInt(10), myFloatDiv(0.1, 0.1))
** FN = 15.6 & FP = 18.4
[[files/MultiObjGP.png|thumb|Multi Obj GP]]
[[files/EMADE.png|thumb|EMADE]]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update notebook
|COMPLETE
|October 21st, 2019
|October 23rd, 2019
|October 23rd, 2019
|-
|Present on EMADE with Titanic
|COMPLETE
|October 9th, 2019
|October 16th, 2019
|October 16th, 2019
|}

== Week 9: October 16th, 2019 ==
'''Lecture 9:'''

General Meeting: We worked on getting the kinks in EMADE installation fixed as well as MySQL

Subteam Meeting: got a better understanding of how EMADE applies to the overall Titanic Project and got EMADE working in general.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Set up MySQL
|COMPLETE
|October 9th, 2019
|October 16th, 2019
|October 16th, 2019
|-
|Run EMADE on Titanic
|COMPLETE
|October 9th, 2019
|October 16th, 2019
|October 16th, 2019
|}

== Week 8: October 9th, 2019 ==
'''Lecture 8:'''

Official Introduction to EMADE was given: Combines multi-objective search with a high-level process to automate the process. 

EMADE requires Python v3.6 

EMADE requires the following Python libraries:
* numpy
* pandas
* keras
* deap
* scipy
* psutil
* lxml
* matplotlib
* hmmlearn
* PyWavelets
* multiprocess
* sqlalchemy
* networkx
* tensorflow
* networkx
* lmfit
* cython
* scikit-image
* opencv-python (imported as cv2)
* pymysql
* mysqlclient Optional:
* tensorflow-gpu Required Only For Windows:
* scoop
Tough to Download, will need additional help the following week to set up MySQL.  

STEPS FROM THE OFFICIAL GitHub page 
# Install [https://git-scm.com/ Git]. Run <code>sudo apt-get install git</code> (for Ubuntu/Debian) in the terminal. Check [https://git-scm.com/download/linux here] for package managers on other Linux distros.
#* On Windows download the [https://git-scm.com/download/win .exe], run it, and follow the install instructions.
#* On Windows and macOS, you may need to add Git to your PATH environment variable. Windows instructions can be found [https://stackoverflow.com/questions/26620312/installing-git-in-path-with-github-client-for-windows here] and macOS instructions can be found [https://stackoverflow.com/questions/1835837/git-command-not-found-on-os-x-10-5 here].
# Install [https://git-lfs.github.com/ Git LFS]. You can find Linux installation instructions [https://help.github.com/articles/installing-git-large-file-storage/ here].
#* This includes running the <code>git lfs install</code> command, this must be done ''prior to'' the cloning of the repository from github or the data files will not be properly downloaded.
# Run <code>git config --global credential.helper cache</code> in the terminal to reduce username and password prompts
# Clone the git repository. Run <code>git clone <nowiki>https://github.gatech.edu/emade/emade</nowiki></code> at your home directory.
#* If you struggle with authentication, try <nowiki>https://USERNAME@github.gatech.edu/emade/emade</nowiki>
# Install [https://www.continuum.io/downloads Anaconda 3]. Read documentation for conda environment management [https://conda.io/docs/using/envs.html here].
#* Make sure to type <code>yes</code> when it asks if you would like the 'installer to prepend the Anaconda3 install location to PATH'.
# Close your current terminal and open a new terminal to change your default python version.
# Run <code>cd emade</code> in the terminal.
# Run <code>conda install opencv</code> in the terminal.
# Install the required packages by running <code>conda install numpy pandas tensorflow keras scipy psutil lxml matplotlib PyWavelets sqlalchemy networkx cython scikit-image mysqlclient pymysql scikit-learn</code> and subsequently <code>pip install xgboost lmfit multiprocess hmmlearn deap opencv-python</code>. Conda has superior features resolving dependencies, but not all required packages are in the standard conda repositories. Therefore, we use both.
#* If mysqlclient fails to install due to a missing mysql_config dependency, try to install libmysqlclient-dev or search for a similar package for your OS. [e.g. on Debian use apt-cache search libmysqlclient]
#* If a recently upgraded package has created a version conflict, you can force conda to install a previous version of a package by using this syntax: conda install numpy=1.14.5
#* Install scoop as well if you're on Windows
#* If hmmlearn fails to build on Windows, install the [https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=BuildTools&rel=15 Microsoft 2017 build tools], then <code>conda install -c conda-forge hmmlearn</code>
# Run <code>bash reinstall.sh</code> (macOS/Linux) or <code>reinstall</code> (windows) in the terminal to build all the required files.
# Install MySQL server (https://dev.mysql.com/downloads/installer/) and configure an empty SQL schema (i.e. a database with a name and login credentials, but no tables). Note that you can do a local run of EMADE with sqllite by manually running didLaunch.py as described below, but to take advantage of Emade's distributed architecture, you will need MySQL. Also, the GUI of [https://www.mysql.com/products/workbench/ MySQL Workbench] is very helpful. [note on Debian linux you may simply run sudo apt-get install mysql-client mysql server] 

THINGS TO KNOW 
* Always remember EMADE uses the last column for scoring purposes
* Objectives generally used are false positives, false negatives, and num of elements
* Can connect to MySQL server from cmd: <code>mysql -h hostname -u username</code> 
* Templates are where the inputs are
* Datasets/are where we have datasets
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Set up MySQL
|COMPLATE
|October 9th, 2019
|October 16th, 2019
|October 16th, 2019
|-
|Run EMADE on Titance
|COMPLETE
|October 9th, 2019
|October 16th, 2019
|October 16th, 2019
|}

== Week 7: October 2nd, 2019 ==
'''Lecture 7 :'''

Presented powerpoint: https://docs.google.com/presentation/d/1oaC0Is_jjkwAc0ToTgiJYIB7IYMocIl-GiFOkBp3eK4/edit?usp=sharing


'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|SET UP EMADE
|INCOMPLETE
|October 2nd, 2019
|October 9th, 2019
|<nowiki>--</nowiki>
|-
|Update Notebook
|COMPLETE
|October 2nd, 2019
|October 4th, 2019
|October 3rd, 2019
|}

== Week 6: September 25th, 2019 ==
'''Lecture 6 :'''

Peer Evaluations and Notebook Checks coming around the corner.

New Project: Titanic disaster dataset with multi-objective genetic programming
* MY GOALS:
** FNR vs FPR graph (codominant individuals in the end)
** AUC over the generations graphs
* Dr.Zutty and Office Hours Suggestions:
** bound number of generations to around 200 or so
** change selection method from selTournament to something else
** use Lab 2 as a starting point
Submit on Canvas: predictions.csv for all codominant individuals

Put together a Google Slides PPT with Subteam
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Titanic GP Lab
|Completed
|September 25th, 2019
|October 2nd, 2019
|October 1st, 2019
|-
|Peer Evals
|Completed 
|September 30th, 2019
|October 4th, 2019
|October 2nd, 2019
|}

== Week 5: September 18th, 2019 ==
'''Lecture 5 :'''

VIP Presentation 1: https://docs.google.com/presentation/d/1eVSsjRtP_opPCcgSSecr57Pq_uGYz-LPZ42eA7d2m1M/edit?usp=sharing 

Presented our findings on the Kaggle Dataset 

My predictions and Jupyter Notebook (where I ran Neural Network Algorithm) have been submitted 

There is a brief graphic of my slide on the right.  

 [[files/Slide View.png|thumb]]
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update Wiki Tables
|Completed
|September 18th, 2019
|September 25th, 2019
|September 25th, 2019
|}

== Week 4: September 11th, 2019 ==
'''Lecture 4 :'''

Placed into bootcamp subteams based on self-ratings

Subteam: Me, Chaudhary, Ruarai, Leo

Group Assignment: Find 5 Codominant ML Algos for the Titanic ML dataset from Kaggle.

Dropped: Name, Cabin, SibSp, Parch, & Ticket
* Filled in missing Age values with random values between mean and one standard deviation & divided Age into 5 numerical categories
* Divided Fare into 4 numerical categories
* Mapped Sex & Embarked (filled in missing values with "S"- the mode) to numerical categories
Met on Monday (September 16th). Over the weekend experimenting with features, Random K, Neural Networks. 
* Dropped: Name, Cabin, Ticket & P-class
* Filled in Age with mean value; Filled in Embarked with mode value
* Did not "bucket" Age, SibSp, Parch or Fare into categories (left as original values)


'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Titanic ML Lab 3
|Completed
|September 11th, 2019
|September 18th, 2019
|September 16th, 2019
|-
|Monday Meeting
|Completed 
|September 11th, 2019
|September 16th, 2019
|September 16th, 2019
|}

== Week 3: September 4th, 2019 ==
'''Lecture 3 :'''

Intro: "'''Genotype versus phenotype'''. An organism's '''genotype''' is the set of genes that it carries. An organism's '''phenotype''' is all of its observable characteristics — which are influenced both by its '''genotype''' and by the environment."  https://evolution.berkeley.edu/evolibrary/article/genovspheno_01

In our Lab, the '''GENOTYPE''' was the '''list of genes''' and the '''PHENOTYPE''' was the '''score of how well the gene did'''
* Kahoot Question on Tree Structure 
* What is an Algorithm Looking For in A Mate?
** Side Note: Review FFT Transform, Wavelet Transform, and K Nearest Neighbors
** Space Efficiency (Memory Usage)
** Minimization of Errors (Classification)
*** True Positive, Minimize False Positive
** Time Efficiency (Timely)
** Security
** Precision of Results
** Usability (Human-Computer Interface)
** Cost-Effectiveness
*Gene Pool is the set of the genome to be evaluated during the current generation
**Evaluation of a Genome associate a genome/individual with a set of scores
***True Positive, False Positive, False Positive, True Negative
*Classification measures
**Dataset (+ samples, - samples) -> Classifier -> Confusion Matrix (Refer to Slides)
*Maximization Measures
**Maximization of Specificity (TNR = TN/(FP + TN)) and Sensitivity (TPR)
*Minimization Measures
**Minimization of (FNR) and (FPR) 
*Other Measures
**Precision, or Positive Predictive Value (PPV) - Bigger is better
**False Discovery Rate - Smaller is better
**Accuracy (ACC) - ACC = (TP + TN)/(TP + TN + FP + FN). Bigger is better

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Experiment more with Lab 2
|Completed
|September 4th, 2019
|September 11th, 2019
|September 9th, 2019
|}

== Week 2: August 28th, 2019 ==
'''Lecture 2 - Part 2 Genetic Programming:'''
* REVIEW: Genetic Algos - each new generation is generated through '''mating/mutation''' of '''individuals''' in the previous population. Also, '''Evaluate''' their '''fitness.''' Eventually, after multiple operations, we can produce the '''best''' possible individuals
* Intro
** The individual is the function itself
** We use trees to represent them
** Use PREORDERED parse/traversal to go through trees
** Mating, Mutation - change nodes, insert/delete subtrees/nodes
*Symbolic Regression
**Using Simple Primitives and genetic programming to evolve a solution to y = sin(x)
**Primitives: +, -, *, /
**Terminals Include Integers and... Variable X
**How did Calc 1 Solve this?
***Taylor Series for Sin(x), 3rd Order x - x^3/3
*Evaluating a Tree
**We can feed a number of input points into the function to get outputs X = [0...2pi] 
**Run F(x)
**We can measure the error between outputs and truth, sum square error could be computed as Error = Sun of f(x) - sin(x) across all points
**Smaller Error = Better
**THINK LINEAR REGRESSION FROM ML
*What primitives could make this evolution easier
**Power()
**Factorial()
**Sin, Cos, Tan
*This is the idea behind EMADE! We want our primitives and functions to be high-level and understandable so we can do meaningful things with our data

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Lab 2
|Completed
|August 28, 2019
|September 4th, 2019
|September 3rd, 2019
|-
|Review Machine Learning Fundamentals
|Completed 
|August 28, 2019
|August 31st, 2019
|August 31st, 2019
|-
|Work more with SciKitLearn 
|Completed
|August 28, 2019
|August 31st, 2019
|August 31st, 2019
|}

== Week 1: August 21st, 2019 ==
'''Introductory Meeting Notes:'''
* Automated Algorithm Design VIP: [[Automated Algorithm Design|https://vip.gatech.edu/wiki/index.php/Automated_Algorithm_Design]]
* Github: https://github.gatech.edu/emade
* Use EMADE (genetic algorithms) to enhance algorithms, potentially apply to stock prediction and time series analysis
'''Lecture 1 - Part 1 Genetic Algorithms:'''
* Genetic Algos - each new generation is generated through '''mating/mutation''' of '''individuals''' in the previous population. Also, '''Evaluate''' their '''fitness'''
* Eventually, after multiple operations, we can produce the '''best''' possible individual
* Review Keywords such as Individual, Objective, Mutate, Mate, Selection
* Mating: Single Point and Double Point
Algorithm 
# Randomly initialize population
2. Determine the fitness of the population

3. Repeat…

4. select parents from population

5. perform crossover on parents creating population

6. perform mutation of population

7. determine the fitness of the population

… until the best individual is good enough.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Lab 1
|Completed
|August 21, 2019
|August 28, 2019
|August 23, 2019
|-
|Review Python Fundamentals w/Notes
|Completed 
|August 21, 2019
|August 25, 2019
|August 25, 2019
|-
|Download Anaconda 
|Completed
|August 21, 2019
|August 21, 2019
|August 21, 2019
|-
|
|
|
|
|
|-
|
|
|
|
|
|}