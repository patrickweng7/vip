= Team Member =
Team Member: Shiyi Wang

Email: swang793@gatech.edu

Cell Phone: 470-334-5880

Classes Taking: Machine Learning, Design & Analysis Algorithms, Intro to Cognitive Science, Math Statistics I

Interests: Cooking, Ultimate Frisbee, HipHop, Phone Photography, Cats 🐈

Subteam: [[Natural Language Processing]] (Current) [[Modularity]] (Past)

Team members: [[Notebook Steven Anthony Leone|Steven Anthony Leone]], [[Notebook Devan Moses|Devan Moses]], [[Notebook Kevin Zheng|Kevin Zheng]], [[Notebook Karthik Subramanian|Karthik Subramanian]]

Fall 2021 Week 04 Self-grading: [https://drive.google.com/file/d/13bnkVUBPj4NqeRjyic1YlTf10oYrC027/view?usp=sharing Shiyi Wang's Fall 2021 Self Evaluation]

= Fall 2021 =
== Week 07 ==
=== October 06, 2021 ===
'''Sub Team Meeting Notes:'''
* While waiting for Dr. Zutty to get the code supporting the functionality of loading in multiple EMADE Data Pairs, we assigned subtasks to team members
** Read up on NNLearner, get familiar with what's changed
** When Dr. Zutty uploads the new code, merge it with NN-VIP
** Read up on State of the Art QA models (SQUAD leaderboard, BiDAF, papers, Transformer Models)
** Make Trees w/ Primitives to be Seeded Individuals
* I was specifically assigned to come up with some seeded individuals in a tree structure that we could test in standalone_tree_evaluator.py, looking at BiDAF and the SQUAD leaderboard as examples. This would also help us figure out what primitives to write to make QA work.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Further readings on QA models
|Ongoing
|October 4, 2021
|October 11, 2021
|
|-
|Work on seeding individuals
|Ongoing
|October 4, 2021
|October 11, 2021
|
|-
|Complete Peer Evaluation
|Completed
|October 4, 2021
|October 8, 2021
|October 4, 2021
|}

=== October 04, 2021 ===
'''Team Meeting Notes:'''
* Image Processing
** NSGA-III Implementation - Tweak p parameter, test against working datasets
** Mating/Mutation - New method
** Trouble with seeds
** Hyper feature ideas
* Modularity
** Implemented workaround for add_all_subtrees large individuals bug.
** Fixed bug regarding incorrect arities in contract_arls.
** Switch back to Google Colab as PACE-ICE still causing issues.
* Neural Architectural Search
** Went through the entirety of the main master algorithm loop within EMADE.py. 
** Included a discussion of the different arguments within the master algorithm such as MUTPB, CXPB and reuse. 
** Different chunks of the main loop were explained such as the one which handles creation of new individuals.

== Week 06 ==
=== September 29, 2021 ===
'''Sub Team Meeting Notes:'''
* Went over through some QA Systems basics for the new onboarding members and discussed new sub tasks.
* Steven will make a new fork for us.
* Assigned everyone to start trying to get the SQUAD dataset loaded in.
* Try implement load_textdata_for_QA to handle context/query split
* Try create the XML for SQUAD dataset
=== September 27, 2021 ===
'''Team Meeting Notes:'''
* Image Processing
** Selection Methods using NSGA-III Implementation.
** Search for combinations of Hyper-feature & Primitive Packaging.
** Baseline run unsuccessful, retrying with seed file.
** Update on geometric semantic genetic programming methods.
* Modularity
** Contract ARLs method wasn't properly updating arities of the node(s) surrounding the contracted ARL.
** Problem with add_all_subtrees method: causes problems with decently sized individuals.
** MNIST team working through getting everyone on PACE-ICE to do runs.
* Neural Architectural Search
** A global "supernet" which would operate like a dynamic acyclic graph which stores information about submodel accuracy and weights of most optimal subnet based on a prior generation run (Do not proceed with this idea).
** Weight Sharing to the existing NNLearner evolution process in EMADE.
** Writes to disk which would improve memory usage within EMADE.

'''Individual Progress'''
* Discovered the dictionary type structure in GPFramework that maps data types to functions.
* Because Dr. Zutty was unable to attend, the team met with Anish to explore a method to use the EMADE architecture to produce datapairs organized as "((Context, Query), Answer/Label)".
** We considered developing our own datatype, but that would need us to alter each later in the "neural networks methods.py" script.
** Anish recommended that instead of introducing that risk, we create an overloaded "nn learner" function that takes in "two inputs" and does embedding independently before using BiDaf on the context and query [https://drive.google.com/file/d/16sbKZ2JRheoqeHsNChpx3daltsVClF0K/view?usp=sharing Here] is how the idea is visualized.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Overload NNLearner to pass in query and context separately
|Completed
|September 27, 2021
|October 04, 2021
|September 29, 2021
|-
|Research NNLearners and how to implement QA
|Completed
|October 27, 2021
|October 04, 2021
|September 29, 2021
|}

== Week 05 ==
=== September 22, 2021 ===
'''Sub Team Meeting Notes:'''
* Designed primitives/infrastructure needed to tackle the QA problem with EMADE.
* Encountered a few problem that existing EMADE framework cannot resolve.
** Problem 1: Unlike other datasets, we have two inputs that the model needs to handle separately: the context and the query.
** Solution 1: We create 2 new primitives, the ContextEmbeddingLayer and the QueryEmbeddingLayer. We also create a new type of data pair that we can fetch both the context and query separately in. Therefore, if the passed in data pair is of this new type, we can return the context and query in the ContextEmbeddingLayer and the QueryEmbeddingLayer, respectively.
** Problem 2: The output is determined by calculating the max probabilities of start and end words of the answer (detailed more in Steven's notebook and below). We cannot solely determine the output by calling model.predict(), as the final output should be a list of size 2N with a softmax applied, where N is the number of words in the context.
** Solution 2: With the different type of data pair, we can check in the NNLearner's code for the type via an "if" statement, and determine the output in this way.

=== September 20, 2021 ===
'''Team Meeting Notes:'''
* Market Analysis and Portfolio Optimization
** Prediction-based portfolio optimization model using neural networks
** Support vector machine with adaptive parameters in financial time series forecasting
** Algorithmic Financial Trading with Deep Convolutional Neural Networks: Time Series to Image Conversion Approach
* Image Processing
** Focus on a multi-label image classification problem using the chest x-ray dataset.
** Improve EMADE’s selection methods and mating/mutation process to better handle images with multiple labels.
** NSGA-III and Lexicase as selection methods
** Improve existing features by looking for synergies and packaging them together.
* Modularity
** Extended ARL runs starting off with max depth 10 trees, Everything seems to be working, there exist ARLs with depth > 2.
** Test the significance of the depth of ARLs on the performance of individuals with problems.
* Neural Architecture Search
** Debugging/Reproducing issue with test_swap line 300 EMADE.py
** Modifying the reuse parameter within EMADE.py to allow reuse of all individuals after starting a previously stopped EMADE run
** Adding CIFAR-10 Input Template to EMADE
** Modifying eval_methods.py to check if test_data being input has 90% same classification
** Adding a method for keeping track of NNLearner layer frequency

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Familiarize with the relevant code 
|Completed
|September 20, 2021
|September 27, 2021
|September 22, 2021
|-
|Brainstorm how to effectively implement the query/context data split
|Completed
|September 20, 2021
|September 27, 2021
|September 22, 2021
|}

== Week 04 ==
=== September 15, 2021 ===
'''Sub Team Meeting Notes:'''
* Everyone has been able to get EMADE to run the Amazon dataset on PACE.
* Went over the objectives we needed to figure out to get EMADE to work.
* Decided our objectives would be F1 and number of parameters, to strike a balance between a match/accuracy and complexity. 
** Steven is looking into F1 for QA systems and find out how they worked.
** Karthik created a Google Collab notebook to begin looking at the dataset.
* We would familiarize ourselves with the different layers of a QA system before planning what primitives to make.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Literature review on QA systems
|Completed
|September 13, 2021
|September 20, 2021
|September 15, 2021
|-
|Understand different layers in QA Systems
|Completed
|September 13, 2021
|September 20, 2021
|September 15, 2021
|}

=== September 13, 2021 ===
'''Team Meeting Notes:'''
* Market Analysis and Portfolio Optimization
** Stock generalization: Finding models/individuals that perform well on multiple stocks.
** Fundamental Analysis: Using company quarterly balance sheets along with technical analysis to predict stock buy/sells.
** Found empirical study of Genetic Programming generated trading rules in computerized stock trading service system.
* Image Processing
** Add new primitives to EMADE that can help with image processing tasks.
** Explore how can use autoML for either image classification or object detection problems.
** Further paper research in fundamental analysis.
* Modularity
** Explore runs using stock data
** Explore left off work from last semester including New Models, Selection Method, Diversity Measures, etc.
* Neural Architecture Search
** Presented background information about the subteam and topics of neuroevolution.
** Reviewed the top 6 ideas plan to work on in order to improve neural architecture search in EMADE.

'''Individual Progress'''
* Attempted to solve MySQL connection issue on Campus.
** Attempted to reconfigure Port number.
** Attempted to solve through commnon error codes (table credits to Steven Leone).
* Resolved the connection issue after reconnect to Campus VPN.
{| class="wikitable"
!Index
!Error Title
!Cause of Error
!How to Resolve
|-
|1
|Server won't start
|Port is likely in use via submitted job or terminal
|qstat or lsof -i:Port# , then “qdel ID” or “kill Port#” (respectively)
|-
|2
|Access Denied
|It's likely that this is a new database created, or permissions weren't granted correctly.
|Re-grant privileges, specify user address
|-
|3
|Can't Connect to MySQL
|MySQL may be running in the wrong manner (not a terminal, not a submitted job)
|Ensure proper server address (job or from terminal)
|}

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Continue to configure EMADE on PACE ICE
|Completed
|September 8, 2021
|September 13, 2021
|September 13, 2021
|-
|Literature review on QA systems
|Completed
|September 13, 2021
|September 20, 2021
|September 15, 2021
|-
|Understand different layers in QA Systems
|Completed
|September 13, 2021
|September 20, 2021
|September 15, 2021
|}

== Week 03 ==
=== September 8, 2021 ===
''' Sub Team Meeting Notes:'''
* Steven gave a presentation on how QA systems work, producing probabilities for where the answer in a given paragraph starts and stops
* Outlined steps for our problem with Question Answering Systems
** Setup everyone on EMADE/PACE
** Work with dataset, make it work on EMADE
** Implement primitives and infrastructure to make Question Answering problems work with EMADE
** Collect and analyze run results
* Decided on our goal as using EMADE to look for less complex, yet as accurate Neural Architecture for state of the art Question Answering Systems, similar to how BORT was made as a less complex BERT: https://arxiv.org/abs/2010.10499

'''Individual Progress'''
* Familiarized with Natural Language Processing and Question and Answering (QA) Systems.
* Attempt to Setup EMADE on PACE ICE based on [https://github.gatech.edu/emade/emade/wiki/Guide-to-Using-PACE-ICE Guide to Using PACE ICE] and Cameron Whaley's [https://www.youtube.com/watch?v=LashYCCJF3E PACE ICE Setup] video.
** Getting On PACE - Complete
** Transferring EMADE with SCP - Complete
** Setting Up MySQL - Complete
** Setting Up EMADE & Configuring the XML file - Complete
** Launch MySQL - Error
*** Experience mysql working only under campus “VPN” instead of physically being on campus (resolved through campus VPN)
** Launch EMADE on PACE - Error
*** Experience Import error: keras.backend.tensorflow_backend (resolved through re-setup)
*** Experience Disk Space Full issue: 15GB/15GB (resolved by delete all library and re-setup)
* Reflection on [https://arxiv.org/abs/2010.10499 Optimal Subarchitecture Extraction For BERT]
** By applying state-of-the-art algorithmic techniques, they extract the optimal subarchitecture set for the family of BERT-like architectures, as parametrized by their depth, number of attention heads, and sizes of the hidden and intermediate layer.
** They showed that this model is smaller, faster and more efficient to pre-train, and able to outperform nearly every other member of the family across a wide variety of NLU tasks.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Setup EMADE on PACE ICE
|Completed
|September 8, 2021
|September 13, 2021
|September 13, 2021
|-
|Run the Amazon Dataset on EMADE in PACE ICE
|Completed
|September 8, 2021
|September 13, 2021
|September 13, 2021
|-
|Read related literatures on QA Systems
|Completed
|September 8, 2021
|September 13, 2021
|September 10, 2021
|}

=== September 6, 2021 ===
'''Team Meeting Notes:'''
* Labor Day. No meetings.

== Week 02 ==
=== August 30, 2021 ===
'''Team Meeting Notes:'''
* Assigned to the Natural Language Processing Sub Team
* Steven reiterate the brainstorming ideas. Devan suggested adding more primitives for more than embeddings.
* Decided on Wednesday at 2:00 pm EST on Bluejeans for Weekly Sub Team Meetings

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Join the NLP Fall 2021 Slack Channel
|Completed
|August 30, 2021
|August 30, 2021
|August 30, 2021
|-
|Complete Sub Team Rankings on Canvas
|Completed
|August 29, 2021
|August 30, 2021
|August 29, 2021
|}


== Week 01 ==
=== August 26, 2021 ===
''' Sub Team Meeting Notes'''
* Portfolio Optimization and Stocks Team Brainstorming Session
** Research methods of visualizing technical indicators in neural net/CNN
** Extend on last semester’s work and focus on determining most useful technical indicators and EMADE configuration
** Add fundamental analysis methods to EMADE implementation
** Switch gears to Portfolio Optimization
* Natural Language Processing Brainstorming Session
** NLP team worked on researching why individuals produced by EMADE weren’t very complex.
** Add infrastructure to solve more complicated NLP or CV problems (potentially question answering or machine translation) by taking advantage of the NAS team's progress in the same branch.
* Infrastructure Brainstorming Session
** Containerization
** Container Orchestration
** Caching
** Database Improvements
** Message/Work Queues
** AI Optimization

'''Individual Progress'''
* [https://www.researchgate.net/publication/324802031_Algorithmic_Financial_Trading_with_Deep_Convolutional_Neural_Networks_Time_Series_to_Image_Conversion_Approach Algorithmic Financial Trading with Deep Convolutional Neural Networks: Time Series to Image Conversion Approach]
** They propose an algorithmic trading model CNN-TA using a 2-D Convolutional Neural Network based on image processing properties. 
** In order to convert ﬁnancial time series into 2-D images, 15 different technical indicators with different parameter selections are utilized. 
** Each indicator instance gen-erates data for a 15 day period.
** The results indicate that when compared with the Buy & Hold Strategy andother common trading systems over a long out-of-sample period, the trained model providesbetter results for stocks and ETFs.
* [https://ieeexplore.ieee.org/abstract/document/9095246 Searching Better Architectures for Neural Machine Translation]
** Neural architecture search (NAS) has played important roles in the evolution of neural architectures.
** They propose a gradient-based NAS algorithm for NMT, which automatically discovers architectures with better performances. They search the network operations (e.g., LSTM, CNN, self-attention etc) as well as dropout rates to ensure better results.
** They show that with reasonable resources it is possible to discover novel neural network architectures for NMT, which achieve consistently better performances than Transformer, the state-of-the-art NMT model, across different tasks. 
** They discovered architectures could obtain  great improvement over Transformer baselines. 
** They empirically verify that the discovered model on one task can be transferred to other tasks.
* [http://proceedings.mlr.press/v97/so19a.html The Evolved Transformer]
** Apply NAS to search for a better alternative to the Transformer.
** They construct a large search space inspired by the recent advances in feed-forward sequence models and then run evolutionary architecture search with warm starting by seeding initial population with the Transformer
** They develop the Progressive Dynamic Hurdles method, which allows to dynamically allocate more resources to more promising candidate models.
** The Evolved Transformer found in experiments demonstrates consistent improvement over the Transformer on WMT 2014 English-German, WMT 2014 English-French, WMT 2014 English-Czech and LM1B.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Join Brainstorming meetings
|Completed
|August 26, 2021
|August 26, 2021
|August 26, 2021
|-
|Read literatures in brainstorming sessions
|Completed
|August 26, 2021
|August 30, 2021
|August 26, 2021
|}

=== August 23, 2021 ===
'''Team Meeting Notes:'''
* Discussed potential ideas and directions for the new subteams.
** Stock Portfolio Optimization
** Natural Language Processing(NLP)
** Neural Architecture Search(NAS)
** Modularity
** EZCGP
** Interpretability
** Image Processing
** Genetic Fundamentals
** COVID
** Infrastructure
* Voted on the interest of different subteams.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Access VIP Notebook on GitHub Wiki
|Completed
|August 23, 2021
|August 30, 2021
|August 23, 2021
|-
|Join Brainstorming Channels on Slack
|Completed
|August 23, 2021
|August 30, 2021
|August 24, 2021
|}


