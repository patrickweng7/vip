= Team Member =
Team Member: Shiyi Wang

Email: swang793@gatech.edu

Cell Phone: 470-334-5880

Classes Taking: Machine Learning, Design & Analysis Algorithms, Intro to Cognitive Science, Math Statistics I

Interests: Cooking, Ultimate Frisbee, HipHop, Phone Photography, Cats üêà

Subteam: [[Natural Language Processing]] (Current) [[Modularity]] (Past)

Team members: [[Notebook Steven Anthony Leone|Steven Anthony Leone]], [[Notebook Devan Moses|Devan Moses]], [[Notebook Kevin Zheng|Kevin Zheng]], [[Notebook Karthik Subramanian|Karthik Subramanian]]

Fall 2021 Week 04 Self-grading: [https://drive.google.com/file/d/13bnkVUBPj4NqeRjyic1YlTf10oYrC027/view?usp=sharing Shiyi Wang's Fall 2021 Self Evaluation]

= Fall 2021 =
== Week 07 ==
=== October 04, 2021 ===
=== October 06, 2021 ===
'''Team Meeting Notes:'''
* Started lecture on genetic programming.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Continue in making of true positive training data
|Completed
|March 25, 2019
|April 29, 2019
|April 5, 2019
|-
|Setup a meeting with the deep learning team
|Completed
|April 1, 2019
|April 8, 2019
|April 6, 2019
|-
|Create a git large file system repository of the training data and test data we have in order to share withe the deep learning team
|
|April 1, 2019
|April 17, 2019
|
|-
|Create a set of existing algorithms
|
|April 1, 2019
|April 17, 2019
|
|}

== Week 06 ==
=== September 27, 2021 ===
=== September 29, 2021 ===
'''Team Meeting Notes:'''
* Started lecture on genetic programming.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Continue in making of true positive training data
|Completed
|March 25, 2019
|April 29, 2019
|April 5, 2019
|-
|Setup a meeting with the deep learning team
|Completed
|April 1, 2019
|April 8, 2019
|April 6, 2019
|-
|Create a git large file system repository of the training data and test data we have in order to share withe the deep learning team
|
|April 1, 2019
|April 17, 2019
|
|-
|Create a set of existing algorithms
|
|April 1, 2019
|April 17, 2019
|
|}

== Week 05 ==
=== September 20, 2021 ===
=== September 22, 2021 ===
'''Team Meeting Notes:'''
* Started lecture on genetic programming.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Continue in making of true positive training data
|Completed
|March 25, 2019
|April 29, 2019
|April 5, 2019
|-
|Setup a meeting with the deep learning team
|Completed
|April 1, 2019
|April 8, 2019
|April 6, 2019
|-
|Create a git large file system repository of the training data and test data we have in order to share withe the deep learning team
|
|April 1, 2019
|April 17, 2019
|
|-
|Create a set of existing algorithms
|
|April 1, 2019
|April 17, 2019
|
|}

== Week 04 ==
=== September 15, 2021 ===
=== September 13, 2021 ===
'''Team Meeting Notes:'''
* Started lecture on genetic programming.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Continue in making of true positive training data
|Completed
|March 25, 2019
|April 29, 2019
|April 5, 2019
|-
|Setup a meeting with the deep learning team
|Completed
|April 1, 2019
|April 8, 2019
|April 6, 2019
|-
|Create a git large file system repository of the training data and test data we have in order to share withe the deep learning team
|
|April 1, 2019
|April 17, 2019
|
|-
|Create a set of existing algorithms
|
|April 1, 2019
|April 17, 2019
|
|}

== Week 03 ==
=== September 8, 2021 ===
'''Team Meeting Notes:'''
* There was no General Meeting this week
* We decided on Wednesday at 2 pm for our Weekly Sub Team Meetings

''' Sub Team Meeting Notes'''
* We organized our first sub team meeting of the year
* We discussed QA systems, and I gave a brief presentation on how they work, producing probabilities for where the answer in a given paragraph starts and stops
* We then made a brief list of steps to explore our problem with Question Answering Systems
* We assigned tasks. For Monday, everyone was to setup EMADE on PACE and start runs with the Amazon dataset.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Continue in making of true positive training data
|Completed
|March 25, 2019
|April 29, 2019
|April 5, 2019
|-
|Setup a meeting with the deep learning team
|Completed
|April 1, 2019
|April 8, 2019
|April 6, 2019
|-
|Create a git large file system repository of the training data and test data we have in order to share withe the deep learning team
|
|April 1, 2019
|April 17, 2019
|
|-
|Create a set of existing algorithms
|
|April 1, 2019
|April 17, 2019
|
|}

=== September 6, 2021 ===
'''Team Meeting Notes:'''
* Labor Day. No meetings.

== Week 02 ==
=== August 30, 2021 ===
'''Team Meeting Notes:'''
* Started lecture on genetic programming.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Continue in making of true positive training data
|Completed
|March 25, 2019
|April 29, 2019
|April 5, 2019
|-
|Setup a meeting with the deep learning team
|Completed
|April 1, 2019
|April 8, 2019
|April 6, 2019
|-
|Create a git large file system repository of the training data and test data we have in order to share withe the deep learning team
|
|April 1, 2019
|April 17, 2019
|
|-
|Create a set of existing algorithms
|
|April 1, 2019
|April 17, 2019
|
|}


== Week 01 ==
=== August 26, 2021 ===
''' Sub Team Meeting Notes'''
* Portfolio Optimization and Stocks Team Brainstorming Session
** Research methods of visualizing technical indicators in neural net/CNN
** Extend on last semester‚Äôs work and focus on determining most useful technical indicators and EMADE configuration
** Add fundamental analysis methods to EMADE implementation
** Switch gears to Portfolio Optimization
* Infrastructure Brainstorming Session
** Containerization
** Container Orchestration
** Caching
** Database Improvements
** Message/Work Queues
** AI Optimization
''' Individual Reflection'''
* [https://www.researchgate.net/publication/324802031_Algorithmic_Financial_Trading_with_Deep_Convolutional_Neural_Networks_Time_Series_to_Image_Conversion_Approach Algorithmic Financial Trading with Deep Convolutional Neural Networks: Time Series to Image Conversion Approach]
** They propose an algorithmic trading model CNN-TA using a 2-D Convolutional Neural Network based on image processing properties. 
** In order to convert Ô¨Ånancial time series into 2-D images, 15 different technical indicators with different parameter selections are utilized. 
** Each indicator instance gen-erates data for a 15 day period.
** The results indicate that when compared with the Buy & Hold Strategy andother common trading systems over a long out-of-sample period, the trained model providesbetter results for stocks and ETFs.
* [https://arxiv.org/abs/2010.10499 Optimal Subarchitecture Extraction For BERT]
** By applying state-of-the-art algorithmic techniques, they extract the optimal subarchitecture set for the family of BERT-like architectures, as parametrized by their depth, number of attention heads, and sizes of the hidden and intermediate layer.
** They showed that this model is smaller, faster and more efficient to pre-train, and able to outperform nearly every other member of the family across a wide variety of NLU tasks.
* [https://ieeexplore.ieee.org/abstract/document/9095246 Searching Better Architectures for Neural Machine Translation]
** Neural architecture search (NAS) has played important roles in the evolution of neural architectures.
** They propose a gradient-based NAS algorithm for NMT, which automatically discovers architectures with better performances. They search the network operations (e.g., LSTM, CNN, self-attention etc) as well as dropout rates to ensure better results.
** They show that with reasonable resources it is possible to discover novel neural network architectures for NMT, which achieve consistently better performances than Transformer, the state-of-the-art NMT model, across different tasks. 
** They discovered architectures could obtain  great improvement over Transformer baselines. 
** They empirically verify that the discovered model on one task can be transferred to other tasks.
* [http://proceedings.mlr.press/v97/so19a.html The Evolved Transformer]
** Apply NAS to search for a better alternative to the Transformer.
** They construct a large search space inspired by the recent advances in feed-forward sequence models and then run evolutionary architecture search with warm starting by seeding initial population with the Transformer
** They develop the Progressive Dynamic Hurdles method, which allows to dynamically allocate more resources to more promising candidate models.
** The Evolved Transformer found in experiments demonstrates consistent improvement over the Transformer on WMT 2014 English-German, WMT 2014 English-French, WMT 2014 English-Czech and LM1B.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Join Brainstorming meetings
|Completed
|August 26, 2021
|August 26, 2021
|August 26, 2021
|-
|Read literatures in brainstorming sessions
|Completed
|August 26, 2021
|August 26, 2021
|August 30, 2021
|}

=== August 23, 2021 ===
'''Team Meeting Notes:'''
* Discussed potential ideas and directions for the new subteams.
* Voted on the interest of different subteams.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Access VIP Notebook on GitHub Wiki
|Completed
|August 23, 2021
|August 23, 2021
|August 30, 2021
|-
|Join Brainstorming Channels on Slack
|Completed
|August 23, 2021
|August 24, 2021
|August 30, 2021
|}


