== Team Member ==
Team Member: Sumit Choudhury

Email: schoudhury40@gatech.edu

Mobile: 339-235-8805

Interests: Machine Learning, Artificial Intelligence, Swimming

''Discliamer: For some of the images in the latest update, the wiki does not seem to render the image. I assure you, the images are there and uploaded. Please click on the media box itself to view the relevant media for this notebook. I suspect this an issue related to the wiki and not something I can fix.''

== April 30, 2020 ==
'''Team Meeting Notes:''' 
* Final Presentation Day! 
** Talked primarily about our progress over the semester:
*** Introduced the dataset we are using and its benefits.
*** Discussed the benchmark we had set for ourselves at the midterm.
*** Presented the results from my run of EMADE on PACE with non-trivil solutions!
**Dr. Zutty was a little confused about statistical methods and even stopped us mid presentation with confusion about some of our graphs 
**He also gave a word of caution about partitioning the train-set for auto ML as this needs to be used specifically for validation accuracy as to not add additional chance for overfitting.
* NLP sub-team presentation: https://docs.google.com/presentation/d/13PfLTDQnA1Lct5-SkOJLb8uzvkISPMzfuC6GnMvAmsk/edit?usp=sharing
* Listened to other teams as well:
** Stocks:
***Team wanted to implement TA-lib indicators, increase evolvability, test on different &larger datasets, and improve individuals for the final presentation.
***The team split into sub-groups focusing on research, data analysis, and EMADE implementation.
***They added new technical indicators from a TA-lib library such as Volume Weighted Moving Average, Volume Weighted Average Price & FIBRET and added new datasets to EMADE
***They completed 2 long runs on EMADE with 4 objectives and got significant results with decreasing hypervolume. They analyzed 2 notable individuals with good performance and asked if the individuals doing anything by looking at monte carlo simulations, buy hold comparisons and buy/sell lag.
***In the future, team wants to perform further statistical and fundamental analysis and compare the generalization ability of optimal models and create bounded objective functions.
** ezCGP:
*** The team focused on recreating results on CIFAR-10 without relying on transfer learning by diversifying population, improve ability to visualize genomes, research develop, and testing mating strategies for CGP.
*** They identified that many key properties through experiementation:
****Larger individuals performed worse on CIFAR-10.
****Activation layers had no significant impact to best individuals.
****Pooling layers helped come up with better architectures while those with drop out layers showed worse performance.
**** Dense layers helped reduce overfitting with dropout and increased test performance. However, the team is no where near state of the art.
***Team developed a much cleaner way to visualize individuals generated by ezCGP evolution.
*** They implemented seeding so that evolution can find better individuals and looked at crossover and symbolic regressing from a paper and also meta-parameter search.
*** Team researched mating one-point crossover (selecting a common crossover point and swap subtrees). No evidence that runs with mating do better. They also looked at point mutation,.
*** In the future, team wants to continue research, development, and testing of new mating functions and use existing CNN architectures for seeds.
** Modularity:
*** Abstracting individuals which can be used as building blocks in EMADE using Adaptive Representation through Learning (ARL) 
****Good sections of trees are turned into primitives
***Main project was to increase the allowed complexity of ARLs by increasing tree depth and allowing imbalanced trees using lambda functions.
***Team worked with Titanic and MNIST dataset with new objectives such as precision, recall, f1, accuracy, cohen kappa.
***Team used seeded individuals with MNIST. They admitted that they can improve by using individuals from experimental runs and diversifying seeded individuals.
***MNIST runs were dominated by "super individuals" with specific primitives. Team needs more runs and data to see if ARLS are useful here.
***They want to store ARLs in true tree form instead of lambda form for new interactions with database.
***In the future, team wants to work with new models, selections methods, potentially new dataset training, diversity measures, ARL database storage, EMADE integration, and have more runs.

'''Action Items:'''

Polished up notebook for a final evaluation. It is sad that my entire VIP experience aside from Bootcamp was online. I would've love to meet my team members in person and go to the VIP hackathons. Nonetheless, I really enjoyed working with the team for the past three semesters, and I look forward to utilizing the knowledge I've gained regarding auto ML, Neural Architecture Search, genetic programming, and EMADE in the future. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Finalize Notebook
|Complete
|April 30, 2020
|May 1, 2020
|}

== April 26, 2021 ==
[[files/best_ind_mine.png|frame|592Ã—270px|The best individual that I was able to generate accuracy-wise on EMADE runs for the Amazon Product Reviews dataset. Achieved 92.8% Accuracy.]]
'''Team Meeting Notes:'''
* Preparing for the final presentations on Friday! 
* The code freeze will occur on Wednesday at noon. We also want to finish our runs by then. 
* We need to collect the results from all our runs and analyze them so that we can properly explain our findings in the presentation.
** Here is where the team is compiling .out files: https://drive.google.com/drive/u/0/folders/1pe-8ooFgxWIMSbpvxaB7nGROA_ba0fmt
* Member are using a script I wrote and building of it to generate cool visualizations for our presentation and statistical graphs for our presentation. These notebooks are linker here:
** Visualizations 1: https://colab.research.google.com/drive/1oKltZODK1JEkNUpllT0X7w2h7UF56xIT?usp=sharing
** Visualizations 2: https://colab.research.google.com/drive/17vC-WvvFMBhG3y8yROE8qSIwhjMEWrdM

'''Sub-Team Meeting Notes:'''
* Discussed some final findings on Wednesday. Did a lot of the work on the presentation
* Talked about results on the FPR/FNR runs that Karthik and Nishant did. 
* Assigned roles for who is presenting what slide on Friday. 
* Did a practice run of the presentation Thursday evening. We're looking good timewise. 

'''Action Items:'''

My EMADE run of the Amazon Product Reviews dataset was successful. Would have liked to run it longer but I hit a disk quota limit on PACE. 

Pareto Front and Hypervolume after 22 generations in seeded with no queue limit for 16 hours on PACE with GPUs: 
* Hypervolume:  72481795.46712363
* Pareto Individual 0 after gen 22 is NNLearner(ARG0, OutputLayer(DenseLayer(10, defaultActivation, 10, LSTMLayer(16, defaultActivation, 0, trueBool, trueBool, EmbeddingLayer(90, ARG0, randomUniformWeights, InputLayer())))), 89, AdamOptimizer)(0.07213768034420087, 649027.0) 
* Pareto Individual 1 after gen 22 is NNLearner(ARG0, OutputLayer(GRULayer(100, reluActivation, 2, falseBool, falseBool, EmbeddingLayer(49, ARG0, randomUniformWeights, * InputLayer()))), 91, AdamOptimizer)(0.08160020400051005, 388401.0)
* Pareto Individual 2 after gen 22 is NNLearner(ARG0, OutputLayer(EmbeddingLayer(49, ARG0, randomUniformWeights, InputLayer())), 91, AdamOptimizer)(0.10365025912564785, 367501.0)

The best individual from this run (see image left) had an accuracy of 92.8% which isn't the best individual we've seen but it exceeds the benchmark of 91.7% accuracy that I set earlier in the semester using the FastText model. The number of parameters (i.e. complexity) of this model was 649027.0. This is also great news because the model is complex meaning we are not getting trivial solutions. The pareto from individuals contain and LSTM or GRU layer adding a complexity to the individuals generated by EMADE. Runs with similar results were done by other team members meaning  we had replicable results. This is delightful news meaning that there has definetly been some progress made from where we were at the beginning of the semester to where we've ended up at the end of the semester! 

I am looking forward to taking part in the VIP presentation on Friday and presenting these results to Dr. Zutty, Dr. Rohling, and the rest of the team. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|April 26, 2021
|May 1, 2021
|-
|Complete Seeded EMADE Run on Amazon
|Completed
|April 23, 2021
|April 27, 20201
|-
|Prepare for Final Presentation
|Completed
|April 26, 2021
|April 30, 20201
|}

== April 19, 2021 ==
[[files/mysql_cnf.jpg|thumb|329x236px|The configuration file for MySQL on PACE. I had to use part 3349 for it to work.]]
'''Team Meeting Notes:'''
* Dr. Zutty reminded us of some key deadlines   as the end of the semester approaches. Final Notebooks due on 5/1/ Final Peer-Evaluations due on 4/27.
* Or goal for these final two weeks will be to develop a results oriented presentation. For the presentation we want to show non-triviality of individuals generated by EMADE on the Amazon Product Reviews dataset.
* Dr. Zutty and Cameron talked about utilizing NNLearners as subtrees. Cameron has also made a pretty big commit to the nn-vip branch of EMADE. I have re-cloned this and moved it over to PACE. 
* We are finding mediocre individuals for a mediocre seeded run of EMADE using the stand-alone evaluator. 
* Some of the new members want to play around with False Positive Rate and False Negative Rate as objectives in are EMADE run. This is very interesting as it may lead to some different individuals being generated by EMADE that may perform better than those generated with accuracy and complexity as objectives.
* Several of us are getting results on PACE. Of the runs that succeed, many of the individuals are looking competitive with the benchmark from earlier. 

'''Sub-Team Meeting Notes:'''
[[files/best_ind_team.png|thumb|577x180px|The best individual that team was able to generate accuracy-wise on EMADE runs for the Amazon Product Reviews dataset. Achieved 93.2% Accuracy.]]
* Sub-team meeting notes
* Team is focused on getting runs in before the final presentation. Before the presentation we should have a myriad of different results with different experiments.
** The focus of my run will be to show that EMADE is capable of generating non-trivial individuals with the NNLEarned give a straightforward problem such as the one posed by the Amazon dataset.
** There is a group working on runs with False Positive Rate and False Negative Rate as objectives.
** Steven is working on a run with mediocre seeded individuals. 
** Cameron is working on runs with many EMADE workers
*** Had some issues with GPUs but in the EMADE got the evolutionary process to happen much faster.
*** Got an individual with 93.2% accuracy but did not get much more depth than the seeded individuals themselves.
* Team discussed a code freeze in the upcoming week and will focus on creating the final presentation.
* The end of the meeting was again focused on PACE trouble shooting. 
** I was able to resolve all of the MySQL errors and got a run up on PACE.
** Other members were also able to get started on some runs

'''Action Items:'''
[[files/mysql_err.png|thumb|527x104px|MySQL error I got when trying to use port 3306 as instructed in the PACE guide. The resolution was to change what port number I was using.]]
I spent most of the week running into a plethora of MySQL issues. I have listed all of the ones I encountered and their fixes here. I had to use a different port (port 3349) than what was specified in the guide because port 3306 was just too busy as well as port 337. It was frustrating when PACE took a significant amount of time to give feedback about the database not interfacing correctly, but I was able to resolve all my errors after spending hours reading through logs and asking Cameron and Steven for help since they had encountered many of the issues themselves. 
* Error: Server on Port XXXX won't start.
** Solution: Check if anything is on the port with <b> lsof -i:<XXXX> </b> and if there is something you can run <b> skill -KILL mysqld </b>. There were cases where lsof didn't show anything but the server still wouldn't start. In that case, I just changed the port number that I was using. 
* Error: 1504 Access Denied
** Solution: I forgot to give myself MySQL privileges. Log into MySQL (mysql -u root) and do DELETE FROM mysql.user WHERE user=""; GRANT ALL PRIVILEGES ON *.* TO 'USERNAME'@'%' WITH GRANT OPTION; FLUSH PRIVILEGES;
* Error: MySQL won't connect.
** Solution: Double check to make sure that the server address is correct. If it's not, restart the MySQL instance. 
* Error: 2003 Unable to connect with MySQL server
** Solution: PACE has too many active users so the host server doesn't match that in the input.xml file. FInd the host address on PACE and change the input.xml file to match with the correct port number. 
* Error: Database Amazon not found.
**Solution: Make sure you have actually created the server instance in MySQL. This can be done by logging in to MySQL (mysql -u root) and doing CREATE DATABASE Amazon; USE Amazon. 

In the end I got a seeded run of EMADE going with no waiting queue limit going. My goal is to let it run for 24 hours on GPUs to see if I can get any non-trivial individuals.  
[[files/mysqlxml.jpg|thumb|807x249px|Database configuration in input_amzon.xml.]]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|April 19, 2021
|April 25, 2021
|-
|Resolve MySQL errors on PACE
|Completed
|April 16, 2021
|April 23, 2021
|-
|Complete a seeded run of EMADE on PACE
|Completed
|April 23, 2021
|
|-
|Complete Peer-evals
|Completed
|April 19, 2021
|April 27, 2021
|}

== April 12, 2021 ==
[[files/pace_issue1.png|thumb|535x107px|One of the many dependency errors I ran into while trying to run EMADE on PACE.]]
'''Team Meeting Notes:'''
*All of us are chugging along with PACE. We are all at various points with some of us having it completely set-up and others running into issues.
**I am currently working on resolving some dependency issues. I am having issues with the keras.backend import in neural_network_methods.py and the small_words package from SciKit Learn.
**Karthik wrote a shell script to automatically connect to PACE and launch EMADE.
*Cameron and Steven were both able to complete useful runs on PACE with the GPU. They were both able to generate individuals with around 93% accuracy which is surpassing our benchmark. 
'''Sub-Team Meeting Notes:'''
* More PACE troubleshooting. People are having varying issues with MySQL and EMADE not running past generation 1.
** I have gotten past a lot of my dependency issues and am now working on resolving MySQL issues. 
* Performed a more formal tasking of group members. See the linked Google Doc:
** End of Semester Team Focus Document: https://docs.google.com/document/d/1V-etbhOdzUfgjwMLX7qtFNQEVGNnmrx5GfaQxfeosJ4/edit
*Cameron working on having many EMADE workers available in one run. This could help speed up the evolutionary process. 
*On additional EMADE runs, we surprisingly got an individual with greater than 90% accuracy that doesn't utilize and LSTM.
*Before the final presentation, we want to experiment with a seeded run containing mediocre individuals instead of the 9 good ones to see if EMADE evolution still works
'''Action Items:'''
[[files/pace_issue2.png|thumb|535x107px|Another dependency error I ran into while trying to run EMADE on PACE. My sklearn library was out of date for some reason even though I used the same .yml file that Cameron did. I dealt with this by creating a new conda envorinment.]]
This week was quite frustrating because it was taking a lot of time to work around dependency issues in PACE. I feel like whenever I resolved one error, another one kept popping up. At one point, I decided to completely uninstall the conda environment I was using and re-install it based of the .yml file Cameron provided. This still did not resolve the keras.backend issue but StackOverflow revealed that it was because the import that was currently used in EMADE was for an older version of keras.backend. I asked Cameron to fix this in the commit he was working on for the nn-vip branch of EMADE> By Friday, I got a lot of these errors resolved, but I am getting a lot of MySQL trouble now. Back down the rabbit hole I go. 
*These file that Cameron sent me were extremely useful in getting PACE working. I modified them to suit my PACE environment:
** https://github.gatech.edu/cwhaley9/PACE-files
*The correct import was: <b> import tensorflow.python.keras.backend</b> instead of <b> import keras.backend.tensorflow_backend </b>
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|April 12, 2021
|April 18, 2021
|-
|Resolve issues with library dependencies on PACE
|Completed
|April 12, 2021
|April 16, 2021
|-
|Resolve issues with MySQL on PACE
|In Progress
|April 16, 2021
|
|}

== April 5, 2021 ==
[[files/pbs1sc.jpg|thumb|575x149px|PACE script for starting the MySQL server.]]
'''Team Meeting Notes:'''
*Most of the meeting was spent listening to Dr. Zutty's presentation about statistical analysis with respect to EMADE.
**Learned about the how to perform hypothesis testing in a more scientific, less hand-wavy way. What type I and type II error tell us.
* Due to reduced meeting time, we only did a preview to the deep learning presentation. Spent a lot of the meeting talking about PACE setup and issues.
** I was able to clone EMADE and send it over to PACE using SCP. (WinSCP is actually beautiful). I've started on the database setup as according to the PACE guide. 
'''Sub-Team Meeting Notes:'''
* Anshul finally did his presentation on deep learning. I helped answer any questions that the new members had and directed them to useful resources.
** Here is the presentation: https://docs.google.com/presentation/d/1CB7nFttRU0psaFTDHHWIScy8nFkvT0X5bTc3T_En808/edit#slide=id.gc84dce302c_2_50
* Rest of the meeting was spent on PACE setup. I will focus on the complexity problem and getting non-trivial solutions. Other members will focus on fixing pre-trianed embedding layers and looking into increasing the number of workers on PACE.
* One of the new members designed a nifty script that can automatically log onto PACE and run EMADE. 
* Cameron resolved an issue regarding GPUs on PACE. The PACE script needed to explicitly specify a path to the GPU library. 
'''Action Items:'''
[[files/pbs2sc.jpg|thumb|727Ã—362px|PACE script for seeding Amazon.]]
Got further in the PACE guide working on the MySQL integration, goal is to get to the point where I can start doing EMADE runs by next week. I am really looking forward to trying to get non-trivial individuals which can surpass the benchmark model that I found in the early part of the semester. Especially since we are using a much simpler dataset this semester, the results should be a lot more promising that the flat line evolution that I was getting on the Chest X-Ray dataset last semester.
[[files/pbs3sc.jpg|thumb|697x381px|PACE script for launching EMADE on the Amazon dataset.]]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|April 5, 2021
|April 11, 2021
|-
|Continue PACE Setup
|Complete
|April 5, 2021
|April 12, 2021
|}

== March 29, 2021 ==
'''Team Meeting Notes:'''
*We have received our shipment of new members. Did introductions and got acquainted with them. They all seem very interested in the team and its goals.
*Our end of semester goal is to get a non-trivial outcomes from the evolutionary process of EMADE.
*All team members are going to focus on setting up in PACE and getting runs. This will be to future-proof our team for work in later semesters. 
**Steven will serve as a person to reach out to with PACE issues as that was his task for the beginning half of the semester.
*Cameron and I discussed why certain individuals may be going to infinity. Dr. Zutty gave some opinions on this.
*Anshul is preparing an deep-dive into EMADE and deep learning presentation for new members. 
'''Sub-Team Meeting Notes:'''
*Issues with the wiki throughout the week has made it difficult to access the guide to installing PACE. This has severely hindered my progress and that of the rest of the team. 
*Anshul's presentation on intro to deep learning has been postponed. Cameron did his presentation on the basics of EMADE. 
*We have figured out some of the issues which were causing individuals to fail in EMADE runs. 
**The Amazon dataset is too large for EMADE to handle. This was addressed by taking only 5% of the training data.
**Could also use SciPy sparse matrices or consider splitting the data into folds. 
'''Action Items:'''

My progress this week wasn't that great because of the issues with the wiki and accessing PACE. I'm also finding it increasingly difficult to perform notebook updates on the wiki as well. From now on, I'm considering typing up my notebook entries in a separate document and later copying them over to the wiki. Otherwise, my goal is to hopefully make some more progress on PACE. I've been able to successfully gain SSH access to it (had to mess around with some SSH keys). I'm a little unsure as to how to set up the MySQL database as required for EMADE so I will wait until I am able to access the guide again.

Additionally, I helped a lot in the onboarding of new members. I answered questions they had about deep learning and EMADE as well as any questions they had about PACE. Some of the new members, especially Karthik, are quite inquisitive. The outlook for the team's future is good. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|March 29, 2021
|April 4, 2021
|-
|Being PACE Set-Up
|In Progress
|April 2, 2021
|
|}

== March 22, 2021 ==
[[files/amazon_data.jpg|thumb|297x192px|Here is the example data point from the Amazon Product Reviews dataset we are using this semester. This is a positive sentiment review (label 2) in Spanish.]]
'''Team Meeting Notes:'''
* Midterm Presentation Day! 
**Introduced the Amazon Product Reviews Dataset and described how it's simplicity through being a balanced, binary-classification problem has helped us this semester.
**Discussed the results and challenges from my benchmarking endeavors with the LSTM and FastText models over the course of the first half of the term.  
**Dr. Zutty asked where we want to be at the end of the semester.
***We want to have replicable, concrete, non-trivial networks generated by EMADE runs on the Amazon dataset. (i.e. no overly simple models guessing one label) 
**Listened to new member groups present results regarding performance on the Titanic dataset when using standard ML, MOGP, and EMADE. Tried to recruit the brightest of them to the NLP sub-team.
* NLP sub-team presentation: https://docs.google.com/presentation/d/1bpIN_1nL6PB8fMq1yvEDQnuy_ktcSY87HV2nxNsvmas/edit?usp=sharing
* Listened to other teams as well:
** Stocks:
*** The team is using technical indicators to predict specific stock trends. EMADE will help optimize existing trading algorithms.
***They have found a new paper and processed the data from that paper into EMADE while using the same technical indicators that were used in the paper. This would later lead to some technical issues as there was some confusion in interpreting parts of the paper.
***The team implemented the PLR trading signal algorithm in EMADE and were able to get a run on EMADE which generated valid individuals.
***In the future, the group wants the incorporate more technical indicators, try different derivatives and different time granularities, and experiment with isolated evolution.
** ezCGP 
*** Instead of the typical tree structures found in EMADE, the team is looking into graph structures (CGP) that have a block structure as a pipeline for individuals. 
****Block structures contain the following elements: data augmentation, data pre-processing, transfer learning, neural network.
*** Team ran experiments on CIFAR10 with their new code base. They explored transformers and RNNs which performed well on generative tasks but took longer to train.
*** They benchmarked training parameters which allowed them to improve the accuracy and speed of new primitives.
** Modularity:
*** Team is using ARLs to improve EMADE's search and optimization capabilities which will explain why certain solutions perform better.
*** They are currently documenting with sphinx (a self-documenting package), adding complexity, and generating ARLs using a database structure and ARL storage.
*** For future work, the team will look into mutation methods, experiments on the MNIST dataset, EMADE integration, and adding an all subtrees algorithm.
'''Sub-Team Meeting Notes:'''
* We did a post-presentation reflection.
** We need to focus on getting results and take a more goal-oriented approach to the rest of the semester
** PyTorch will probably be a second priority. Dr. Zutty is pushing us in this direction and has not been a large fan of the PyTorch integration plan to begin with. 
** We need to get a non-trivial outcomes from the evolutionary process. This will show progress from the previous semester.
* We've decided to build an army of PACE users to future-proof the team for later semesters. This will help us get a lot of runs of EMADE.
* I spent some time working with Cameron to identify why models were evaluating to inf. We used my script to help make the .out files from Cameron's run easier to understand in order to pinpoint the problem. However, it seems that the problem may have something to do with how EMADE is set up instead of the evolutionary process itself.
'''Action Items:'''

This week will be an easy week as a consequence of the midterm presentation on Monday. In the Friday meeting, we discussed what directions we want to go in for the remainder of the semester. In the presentation, Dr. Zutty wanted us to steer away form overly-complicated tasks such as PyTorch integration and instead focusing on getting results we can talk about during the final presentation. For this reason, we decided to make our efforts results-oriented towards getting EMADE runs on PACE. After getting a successful benchmark for EMADE to beat, my goal for the remainder of the semester will be to get EMADE runs where non-trivial individuals are generated which can surpass the benchmark that I have set. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|March 22, 2021
|March 28, 2021
|-
|Look into PACE
|In Progress
|March 26, 2021
|
|}

== March 15, 2021 ==
'''Team Meeting Notes:'''
*Jon is going to take charge regarding setting up our midterm presentation. We'll be trying to sell NLP and talk about what we've done up to now.
*Anshul ran into the same zmq error in a local Jupyter Notebook. Alex and I are going to try to build this model in EMADE by hand with a LayerList and evaluate using the stand-alone evaluator to see if it works there. Else, we are going to scrap this model for good.
*For the EMADE runs, we are running into some seeding issues. This needs to be debugged.
*Cameron is going to look into EMADE individuals that are going to infinity. I have supplied him with the script I wrote last semester to help him in his investigation.
'''Sub-Team Meeting Notes:'''
*We have another EMADE run on PACE. This is mainly for furthering the investigation about individuals evaluating to infinity.
**Steven is still running into some errors on his side. He will focus on debugging.
*We have realized that the LSTM model is really a graph and not supported by the tree structure of EMADE. :-(
**I think we have kind of reached a stopping point for benchmarking. I will look into seeing if FastText can be integrated with EMADE or if it already is. 
*Focusing on the midterm presentation. Conducted an extra meeting on Sunday (3/21) to perform a dry run and polish it up before Monday's presentation.
'''Action Items:'''

I think this week served as a conclusions to our benchmarking work for the first half semester. The LSTM model which we had been looking at was rather disappointing as not only did it cause Google Collab and Jupyter Notebook to crash but is also was based on a graph structure which cannot be replicated by EMADE's tree structure. For these reasons, I have decided to completely disregard the LSTM model and focus on the other FastText model. This model will serve as a good enough baseline for our EMADE runs and can be replicated by EMADE since, according to Alex, there is a FastText primitive buried in EMADE. 
These thoughts will all be reflected in our midterm presentation where I talk about our new dataset and benchmarking efforts.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|March 15, 2021
|March 21, 2021
|-
|Build benchmark models in EMADE.
|Completed
|March 15, 2021
|March 19, 2021
|-
|Work on Midterm Presentation
|Completed
|March 15, 2021
|March 21, 20201
|}

== March 8, 2021 ==
[[files/fasttext.jpg|thumb|492x492px|Here is the FastText model that will be used as a baseline for our EMADE runs.]]
'''Team Meeting Notes:'''
*We were able to get a successful run of EMADE on the Amazon Product Reviews Dataset. There were some shortcomings to this run as a GPU was not used/ Nevertheless, it's good that we were able to get EMADE working on the dataset.
**EMADE didn't add the parent individuals properly, but this should be resolved by adding a GPU.
**Thought that the this issue came from the CUDA library, but it was actually just a missing component from the PACE script.
*As for benchmarking, I am searching for new models to serve as a benchmark. I have discovered that a lot of these models use FastText embeddings. This is something we need to double check if EMADE can use otherwise it is not a good benchmark for EMADE.
*Alex and Anshul are going to try building the model from last week in an EMADE format and in a local Jupyter Notebook respectfully. Hopefully, we can bypass the issue we were getting in the Google Collab notebook.
**Here is a video of said issue: https://drive.google.com/file/d/1bz3kyn2vNTeIaqfsBpqO90R_9tV1ajtc/view?usp=sharing
*Jon is going to continue learning about Pytorch and begin to examine where it can be implemented in EMADE.
'''Sub-Team Meeting Notes:'''
*EMADE run from Monday was more disappointing then we thought.
**One of the runs got stuck at generation 0 with the evolutionary process not starting. Another run attempt ran for 6 hours but hit a error in mutation. 
**Neither run had good individuals. This may be because the runs were not seeded as non-seeded individuals may have caused runs to fail. Seeding EMADE will raise new MySQL challenges.
*I was able to find a benchmark model that utilizes FastText embeddings which can serve as a baseline for our EMADE runs. The model was able achieve 91.7% test accuracy on the Amazon dataset.
**FastText Model Collab Notebook: https://colab.research.google.com/drive/1VAxG-SB6eHLjjjpcvpj2B1rfyESs0Dhm?usp=sharing
*Alex will work on getting the CuDNNLSTM model from last week to run stand-alone on EMADE. (CuDNNLSTM is just a GPU optimized LSTM)
*The team will begin working on the midterm presentation coming up.
'''Action Items:'''

The old LSTM model had become infuriating to work with. So I have decided to search for a different benchmark model instead. After some research, it seems that models that utilize FastText word embeddings perform well on the Amazom. I replicated and tuned a model from Kaggle (see image) which elegantly uses FastText's API to trian and evaluate a model on the Amazon dataset. I was able to port this model to Google Collab and successfull train and evaluate it. The model gave a 91.7% test accuracy score on the dataset. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|March 8, 2021
|March 14, 2021
|-
|Search for and run new Amazon Product Reviews benchmark model.
|Completed
|March 8, 2021
|March 12, 2021
|}

== March 1, 2021 ==
[[files/Collab Error.png|thumb|492x492px|This is the error I am getting in Google Collab with the type conversions. I will resolve this by using a different embeddings file.]]
'''Team Meeting Notes:'''
*Dr. Zutty reminded us about notebooks and peer evaluations.    
*I ran into a type conversion error when trying to run Anshul's Google Collab notebook where we are running a benchmark model which will used to compare to EMADE. This issue is quite strange because it is reading the embeddings array as Strings even though the numbers are floats. Anish's suggestion is to use a different embeddings file.    
*Jon is almost done with the documentation work. This opens the door for work on using Pytorch in EMADE.
**Dr.Zutty disapproved of a full Pytorch re-factor of EMADE. Instead we will be focusing on utilizing Pytorch in a hybrid fashion with EMADE (i.e. not a complete re-factor).   
*Getting in baseline EMADE runs with the newly added Amazon product reviews dataset. 
**Had the classic issue with the DEAP version. Will perform the classic solution of downgrading to DEAP 1.2.2.   
'''Sub-Team Meeting Notes:'''
*Cameron needed to update some files in his local version of the Amazon dataset before running EMADE. An issue regarding max recursion depth in EMADE was resolved during the meeting.
*Anshul and I are unable to make any progress on the Google Collab issue (see video). We are getting a <b> zmq message on closed channel </b> error. We are considering asking other members on the VIP team about this. Additionally, we have posted this error on StackOverflow to see if the internet has any answers. For now, I will try to find a different baseline model so that the team actually has a benchmark going into the presentation.
*Sub-team had a discussion about adding PyTorch to the nn-vip branch of EMADE. Dr. Zutty is skeptical of this but we discussed installation and requirements starting at the population label. This discussion will continue once Jon begins some of the implementation. 
'''Action Items:'''
[[files/zmq.png|thumb|687x200px|Error received from Google Collab when running the LSTM Model. This error has been discussed with the rest of the team and even asked on StackOverflow.]]
Anish suggested that the main reason I am unable to run the Collab notebook is because there may be an issue with the Twitter GLOVE word embeddings file that I am using. He suggested using either of the following instead. These files are really large, but I will try to download them and run tests prior to the Friday meeting.
* https://github.gatech.edu/emade/emade/blob/nn/pretrained/download_pretrained.sh
* http://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip
In the sub-team meeting, we were able to get past the type mismatch issue in the Collab Notebook. However, now Anshul and I have returned back to the original error where calling model.fit() on the LSTM that is used in benchmarking model from Kaggle causes the Google Collab runtime to disconnect. Since it has been difficult to get past this blocker, I will now look for a new baseline model which we can compare our EMADE runs to. 
 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Complete
|March 1, 2021
|March 7, 2021
|-
|Try re-running the Amazon Model with a different word embeddings file to fix error
|Complete
|March 1, 2021
|March 5, 2021
|-
|Complete Peer-Evals
|Complete
|March 1, 2021
|March 2, 2021
|-
|Look for a new potential baseline Amazon Product Reviews model. 
|In Progress
|March 5, 2021
|
|}

== February 22, 2021 ==
'''Team Meeting Notes:'''
*Google Collab is being obnoxious when trying to run the benchmarking model as it requires a long time to upload the dataset and embeddings file to Collab every single time.   
*We are having an issue with the gzipped files in EMADE. Ideally, this is how we would like to add the Amazon Product Reviews dataset to EMADE. After this is run, we should be able to set up and Amazon EMADE run.   
*Collab is throwing an memory/runtime issue when trying to run the Kaggle model. This issue has never been seen before by the team.   
[[files/Kaggle model.jpg|thumb|748x748px|This is the LSTM model that we are using to benchmark EMADE for the Amazon Product Reviews Dataset.]]
'''Sub-Team Meeting Notes:'''
* Anshul and I are trying to run the Kaggle model in Google Collab. This model achieved 93.7% accuracy on the Amazon Product Reviews dataset and we want to use it as a benchmark for EMADE. 
** Google Collab Notebook: https://colab.research.google.com/drive/1TrGf6sUfyXn5Tksyp_yIN-D2t9kp8RCz?authuser=1#scrollTo=cxxraASL-smb 
** Currently running into issues with the cell that is executing model.fit(). The cell seems to be finishing but the code as not executing as model.evaluate() is giving an error.
** Maybe this is some sort of memory/runtime issue
* Cameron is setting up a run on PACE-ICE for EMADE using the Amazon Product reviews dataset which as been successfully added. Having slight PACE server issues though.
* Jon is almost done with the documentation for the EMADE primitives. I have shared with him some resources regarding PyTorch so that he can get started on the PyTorch re-factor once he is done. 
'''Action Items:'''

I will be working on training the Kaggle model in the Google Collab notebook with Anshul. We are trying to identify what the Collab notebook issue is. We have also reached out to Abhiram from the Stocks team who is more familiar with Google Collab to see if he could help identify the issue with model.fit()
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Compelete
|February 22, 2021
|February 28, 2021
|-
|Build Hand-Trained Model
|In Progress
|February 19, 2021
|
|}

== February 15, 2021 ==
'''Team Meeting Notes:'''
*Anshul and I are making progress on the benchmarking model. We are starting to set-up hand-trained model.   
*The Amazon Product Reviews dataset is almost set up in EMADE.   
*PACE is giving the same issues it always does with the disk quota and MySQL. Hopefully, we can reach out to people from previous semesters to find a solution.   
'''Sub-Team Meeting Notes:'''
* PACE-ICE issues seemed to have been resolved. :-)
* Amazon dataset should be ready to go in EMADE.
* Also trying to get CIFAR-10 to work on EMADE so we can run experiments using PACE.
* I am trying to run the Kaggle model locally and Anshul is trying to run it in Google Collab. It seems Google Collab may be the way to go as a GPU will speed things up by a lot. 
'''Action Items:'''

I have made a GitHub repo so that Anshul and I can work collaboratively on setting up a benchmarking run for the Amazon.
* Github Repo: https://github.gatech.edu/schoudhury40/amazon-product-reviews 
Additionally, I have worked with Alex and Anshul to get the Kaggle Model imported and set up on Google Collab. We still have yet to successfully run it, but we should be getting results soon.  
[[files/Self-eval-sp21.jpg|thumb|444x444px|Self-Evaluation of this Notebook for Spring 2021]]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Complete
|February 15, 2021
|February 21, 2021
|-
|Build Hand-Trained Model
|In Progress
|February 19, 2021
|
|}

== February 8, 2021 ==
'''Team Meeting Notes:'''
*Dr. Zutty reminded all of us to complete our notebook self-evaluations 
*Anish is working on implementing pre-processing for both the  Amazon Product reviews and Chest X-Ray datasets.
*Alex will help Anshul and I in the benchmarking process.
*Jon will continue documenting the EMADE primitives. 
'''Sub-Team Meeting Notes:'''
*I found papers that can be used for comparisons with EMADE. 
**The Kaggle model looks especially good to hand-train as all of its components are already in the NNLearner framework.
* Steven and Cameron are working on Amazon dataset is being added to EMADE should be ready soon. Currently working on setting up MySQL.
* Also working on learning how to format data for the Amazon dataset for use in EMADE and dataset pre-processing.
'''Action Items:'''

I focused on identifying reputable papers for which a baseline run could be measured against this week. These two papers seemed promising to serve as benchmarks for our EMADE run.
* Paper 1: This paper that uses a novel model to achieve competitive results on the Amazon dataset.:Â https://www.sciencedirect.com/science/article/pii/S0167739X20309195
* Paper 2: This paper on seems to apply to both Amazon and Yelp reviews.Â https://ieeexplore.ieee.org/iel7/8764048/8768805/08768887.pdf 
Additionally, I found a model online which is compatible with existing primitives in EMADE that can be used. This model was publicly available on Kaggle and claims to achieve high accuracy on the Amazon Product Reviews Dataset:
* Kaggle Model: The model uses CuDNNLSTM model which appears to work well on this dataset.Â https://www.kaggle.com/anshulrai/cudnnlstm-implementation-93-7-accuracy 
I also completed the mandatory self-evaluation of this notebook. Please see the image at the top-right for reference. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|February 8, 2021
|February 14, 2021
|-
|Research Existing Models for the Amazon Reviews Dataset
|Completed
|February 5, 2021
|February 12, 2021
|-
|Complete Notebook Self-Evaluation
|Complete
|February 8, 2021
|February 14, 2021
|}

== February 1, 2021 ==
'''Team Meeting Notes:'''
*Teams outlined their goals. NLP needs to get on top of things.   
*Discussed with Dr. Zutty where the NLP team left off and what directions we should go in the future.
**There is a need to perform "forensics": A couple points of interest are as follows:
***Looking at NLP side more. Focusing on BERT and adaptive mutations functions.   
***Continuing the CV work from last semester with chest x-ray. Research why EMADE is giving trivial solutions.   
'''Sub-Team Meeting Notes:'''
* Discussed future of the team with Dr.Zutty and Anish. The main problem will be to try and identify the problem with the NNLearner.
* Agreed upon looking into  the Amazon product reviews data set as it is a binary classification problem instead of toxicity which is multi-class classification.
** Dataset: https://www.kaggle.com/bittlingmayer/amazonreviews
* I will be working with Anshul to hand-train existing models on this dataset so that we can compare results to EMADE.
'''Action Items:'''

My goal this week will be to research existing literature regarding performance on the Amazon Product reviews dataset. This way we can compare existing models and hopefully get EMADE to generate models which will outperform these existing ones. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|February 1, 2021
|February 7, 2021
|-
|Research Existing Models for the Amazon Reviews Dataset
|In Progress
|February 5, 2021
|
|}


== January 25, 2021 ==
'''Team Meeting Notes:'''
*First meeting of the year. Introduced to the available sub-teams. Debating which sub-team to join this semester.  
'''Sub-Team Meeting Notes:'''
* Re-joined the NLP sub-team for the Spring 2021 VIP Semester. I look forward to working with this sub-team again!
* Team did not really meet. Need to be a little more organized.
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|January 25, 2021
|January 31, 2021
|-
|Join Sub-Team
|Completed
|January 25, 2021
|February 1, 20201
|}


== December 2, 2020 ==
'''Team Meeting Notes:''' 
* Final Presentation Day! 
** Talked more about the visualization and parsing work done over the course of the semester. 
** Introduced the Chest X-Ray dataset and why my sub-team was using it. 
** Discussed the results of our EMADE runs on the Chest X-Ray dataset and hypothesized potential faults. Mentioned our un-expected results from our Chest X-Ray runs.
*** Dr. Zutty and Dr. Rohling brought up how the over-simplicity of our model may be because we are not reaping the full benefit of '''multi-objective''' genetic programming in the base-line chest X-ray run  
*** In future semesters, I will look into optimizing for different objectives instead of number of parameters and accuracy such as AUROC, precision, or recall.  
* NLP sub-team presentation: https://docs.google.com/presentation/d/1Z8PjzaP_LjhyycpGSeXX7rIHdVYkxHzqg8vaKVEYhdU/edit?usp=sharing
* Listened to other teams as well:
** Stocks:
*** The team has realized that the calculations for trading prices in their bench mark research paper were inconsistent from prior research. This led to a need for other methods like genetic labelling which resulted in an overall lower mean difference. 
*** Team has developed many  technical indicator primitives for EMADE that  work off stock prices. 
**** Some examples include exponential moving average, stochastic oscillators, ease of movement, on-balance volume, Bollinger bands, CCI, and  MFI 
*** The team then compared ther reference paper to EMADE by testing with and without normalization 
*** In the future, the team wants to test larger time ranges, test on more granular data, improve genetic labelling, and find a better baseline paper. 
** ezCGP:
*** The coding sub-sub-team has worked on cleaning up OpenCV primitives used for pre-processing, changed objectives from Accuracy & F1 to Precision & Recall, and continued to work with PACE-ICE GPU by using TensorFlow-GPU. They are also working on genome seeding so that runs on PACE can be continuous and not limited by wall time on PACE 
*** The team benchmarked results using the CIFAR-10 dataset to test the ezCGP framework using aforementioned objectives, seedings.
**** This resulted in high fitness but low diversity. Highlighted that this was because of transfer learning primitives and suggested increasing randomness. 
**** The AUC remains stagnant after generation 1  due to smaller population size. Transfer learning helps start out with a really good model from generation 1. 
*** Research wise, the team was looking into super-convergence by using cyclical learning rates. This would hlp get the most out of each training epoch. They also looked into aging evolution and early termination to help increase population diversity.  
*** In the future, the team wants to experiment with block structures, use MNIST instead of CIFAR-10, continue their neural architecture search experiment, and '''marry''' EMADE and ezCGP.[[files/Last minute graph.jpg|alt=Another one.|thumb|331x331px|A plot generated as a last-minute request for the presentation with the code. This illustrates the performance of the addition of the adaptive mutation function. The code and graph can be found in the visualization notebook.]]
** Modularity:
***  The team performed 4 experiments in hopes of gaining statistical significance with regards to the usage of ARLs.
****  <u>Differential Fitness:</u> The difference between an individual and its most fit parent which is used as a search heuristic an only the individuals with a positive differential fitness are considered.
*****  The main impact of ARLS was seen in middle generations but it converged with baseline in later generations, and only some pareto individuals used ARLs.
****  <u>Alternate Selection Methods</u>: Modifying tournament selection directly to increase the probability of getting ARLs
*****  Again, the main impact was seen in middle generations, and  it converges with the baseline in later generations.
****  <u>Data Pair Recognition</u>: Implementing a check so  that only allows EMADE Data Pairs make up ARLS to have ARLs that are composed of "more useful" primitives.
*****  Better results at later generations but doesn't reach statistical significance which maybe due to the dataset (Titanic).
****  <u>Alternate Selection 2</u>: Adding data pair restrictions with alternate selection to reduce bloat.
*****  The only experiment that did worse than the baseline. Possible reason could be the increased effect of crowding distance
***  In the future, the team plans the use the MNIST dataset, integrate ARLS and ADFs, and add new heuristics.
****  The want to understand if ARLs help in later generations at all.
****  The team did a run using MNIST that had less valid individuals, but 28 ARLs. EMADE performance is suspiciously good probably due to overtraining.
'''Action Items:'''

Polished up notebook for a final evaluation. A fully online semester of VIP was interesting, but I still wish someday I will be able to meet some of my team members face to face.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Finalize Notebook
|Complete
|December 2, 2020
|December 3, 2020
|}
== November 30, 2020 ==
[[files/The model is dumb.png|alt=Why is it only guessing one lable?|thumb|The confusion matrix on test data performance for the simple model. As is evident, the model is learning to only only guessing one label (12). Somehow this is resulting in Pareto optimal AUROC and accuracy. Could this potentially indicate faults in the dataset?
AUROC: 0.510643445303311

Accuracy: 0.53665715305
]]
'''Team Meeting Notes:'''

''Due to a Power Outage in my area, I was unable to join the Team/Sub-Team Meeting on November 30th. My notes come from the team-meeting recording.''  
* Dr. Zutty reminded the team about good practices in notebook maintenance.
* Team discussed run results as well as brought up last-minute comments for the final presentation.  

'''Sub-Team Meeting Notes:'''
* Main objective was to finalize the presentation for Wednesday with the results that we had.
* Worked with Anish on slides discussing the results of the chest x-ray runs and the benchmarking experiments.
* Did a run-through of the presentation as a sub-team. Looked good time-wise. 
[[files/Complex confused.jpg|alt=The complex model is dumber?|thumb|I was unable to get a successful run of XCeption in the small time frame, but for comparison's sake, I have included the confusion matrix from Anish's run of MobileNet. The large model is more actively trying to guess the correct label of the input image. This oddly results in worse accuracy but better AUROC.
AUROC: 0.5928323820989334

Accuracy: 0.18551551908
]]
'''Action Items:'''

Personally, I was surprised by the fact that our results repository consisted of significantly fewer runs than we had anticipated.  

Otherwise, our hand-training experiment has illustrated that EMADE starts off with a small network, and falls into a local minima of guessing only one label. Possible ways to address this may be to add more mutations to help it get higher, modify the parameter complexity objective we are currently using, or seed in large models and try to use other EMADE primitives.  

Additionally, I completed the required evaluations of my peers as well as polished up my slides for the presentation on Wednesday.   
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Complete
|November 30, 2020
|December 3, 2020
|-
|Peer Evaluations
|Complete
|November 23, 2020
|December 1, 2020
|-
|Add Slides for Final Presentation
|Complete
|November 30, 2020
|December 2, 2020
|-
|Hand-Train Pre-Existing Models on Chest X-Ray
|Complete
|November 23, 2020
|December 1, 2020
|}

== November 23, 2020 ==
[[files/Simp.jpg|alt=Simple Architechture|thumb|330x330px|This is an example of a simple architecture that was used in our experiments for understanding why EMADE was performing so poorly. This Architecture is similar to some of the individuals that EMADE was putting on the Pareto front. ]]
'''Team Meeting Notes:'''
* Runs, Runs, Runs!  
* Team is still struggling with PACE in some areas. The main issues have to do with Anaconda environments and running out of memory.
* Team also wants to push novelty change results and runs with the Amazon Reviews dataset as future work.
'''Sub-Team Meeting Notes:'''
* As the semester is coming to a close, out goal remains to grind out as many EMADE runs as possible prior to final presentation to get results.
* Members are fine-tuning everything that we have been working on: adaptive mutation, CV primitives, BERT
* Told by Anish to switch gears from focusing on an an AUROC script to replicating some experiments on the Chest X-Ray dataset.  
** "EMADE run results are pointless until we figure out why EMADE is only making the smallest net possible." 
* Parsed results from a second base run using the Chest X-Ray data. Getting similar results as before.   
[[files/Complex.jpg|alt=Complex Architechture|thumb|397x397px|This is an example of a complex pre-trained architecture from Keras called XCeption. We are using this in our experiments for understanding why EMADE is performing so poorly. This architecture has been used in existing publications on the same dataset (Chest X-Ray), so we wanted to see if we could compare a well known architecture to the simple one.]]
'''Action Items:'''

Focused on hand-training models on the Chest X-ray dataset to see why the complexity of the EMADE individuals is so small. We decided to hand-train pre-existing models and very simple architectures as EMADE only seems to make the smallest net possible for the Chest X-Ray Dataset 

Some of the pre-exiting models we tied to use are XCeption, MobileNet, Inceptionv3, and VGGNet to benchmark our results. (See image of XCpetion model). 

Ran into some complications in the experimentation process:
* Complication 1: Lower complexity models end up having higher AUROC, than pre-trained models like Inception, XCeption, or VGG.
** Less Complex Models are performing better by learning to always guess 1 label.
* Complication 2: Lot of the major pre-trained models uses 3-channel images instead of the grayscale images found in chest-ray
** Addressed this by repeating the training and testing image 3 times
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Complete
|November 23, 2020
|November 29, 2020
|-
|Hand-Train Pre-Existing Models on Chest X-Ray
|In Progress
|November 23, 2020
|
|}

== November 16, 2020 ==
[[files/Bruhmoment2.jpg|alt="Bruh"|thumb|465x465px|The top-left graph shows the best individual error rate over the generations. The top-left graph shows the best individual number of parameters over the generations. The bottom graph shows hypervolume over generations. The collections of these graphs show that the evolutionary process did not properly search for better individuals as evident by that flat lines. ]]
'''Team Meeting Notes:'''
* In anticipation of the final presentation, our team moving forward with experimentation and trial runs:
** We want some baseline runs first and then we will compare those with runs using adaptive mutation and/or BERT
** Team plans on having feature freeze aside from quick fixes and debugging runs.
** Hopefully, we can get runs with the novelty changes as well as a run on the new dataset.
* One of the new members used the same template as the PACE documentation to write documentation on the CV Primitives the CV sub-sub-team had been working on in the later half of the semester.

'''Sub-Team Meeting Notes:'''
* The sub-team's primary goal for the next 2 weeks will be to complete runs and reporting results on both datasets.
** Runs split between ICE-HAMMER and PACE-ICE
** Need baseline runs for both toxicity and chest x-ray datasets (probably going to do another one for chest x-ray), runs with all of the new primitives added, runs with the new adaptive mutation function, runs with BERT, and runs with a larger population.
* Discussed progress with the implementation of BERT word embeddings. BERT layer almost complete!
* Since we have a base chest x-ray run, we are going to analyze the runs, calculate the AUROC, and compare it with the LEAF paper.
** I will be focusing on the analysis of the base chest x-ray run, and the calculation of AUROC.
'''Action Items:'''

Continued working on the script that can find AUROC for Chest X-Ray EMADE runs. I was having some trouble with the script as a result of an initial mis-understanding what the .out files contained. These files gave finesses as tuple containing the number of parameters and accuracy. To find AUROC, I needed to find the true positive and false positive rates of the model. Additionally, I was only able to extract the models as strings. Anish suggested using the standalone_tree_evalutor.py file in EMADE so I will look into it. 
[[files/Bruhmoment1.jpg|alt=Not what we wanted to see..|thumb|316x316px|The average individual error over the course of two baseline chest x-ray runs on EMADE. There is no discernable trend other than the fact that the accuracy was generally pretty bad throughout. The blue line is the first run on the dataset. The orange one is the second.]]
Utilized the existing visualization notebook (see notebook entry on October 12th, 2020) to look at results from baseline Chest X-Ray runs. To be honest, the results were abysmal. 
* After 665 generations these were the best and worst induvials on the Pareto Front, respectively. 
** "NNLearner(ARG0, OutputLayer(ARG0, GlobalAveragePoolingLayer2D(MaxPoolingLayer2D(2, Conv2DLayer(32, defaultActivation, 3, 3, trueBool, 1, InputLayer(ARG0))))), 95, NadamOptimizer)" 
*** 1 - Accuracy: 0.46334284694969674
*** Number of Parameters: 815.0
** "NNLearner(ARG0, OutputLayer(ARG0, GlobalAveragePoolingLayer2D(DropoutLayer(1.0, InputLayer(ARG0)))), 8, FtrlOptimizer)"
*** 1 - Accuracy: 0.7036211202283268
*** Number of Parameters: 30.0
What is striking is that the number of parameters in these Pareto individuals is shockingly low alongside the horrendous accuracy. The graphs (see right) illustrate that evolution did not help find better models as a single Pareto Individual persisted from generation 1 to generation 665. This needs to be further investigated. 

Repo for Runs: [https://github.gatech.edu/pagarwal80/EMADEResults NN-Team EMADE Runs]
[[files/I really don't know what this is.png|alt=Awkward graph|thumb|240x240px|Resulting Pareto Front and AUC from first attempt at script. Tried to utilize the evolution_wrapper() function from standalone_tree_evalutaor.py but got some unexpected results. Additionally used false positive instead of true positive, so instead of AUROC, I got a minimization AUC. Nevertheless, this still highlights that the chest x-ray run performed poorly. ]]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Complete
|November 16, 2020
|November 22, 2020
|-
|Re-write Script for AUROC of runs 
|In Progress
|November 13, 2020
|
|-
|Analyze Base Runs from Chest X-Ray
|Complete
|November 20, 2020
|November 23, 2020
|}

== November 9, 2020 ==
'''Team Meeting Notes:'''
* The team is continuing to work on the coding portions as aforementioned: Adaptive Mutation, BERT, new CV primitivizes
* As the end of the semester is fast approaching, much of the team needs get in runs via ICE-HAMMER, PACE-ICE, or Google Collab 
* One of the new team members created a stunning website documenting how to set up runs on PACE-ICE.
'''Sub-Team Meeting Notes:'''
* Dr. Zutty commented on the CV sub-sub-team's progress in adding new primitives.
* The issue about GPU usage is still persisting.
* The team has decided to try out runs on the Amazon product review dataset as well as on the Wikidetox and Chest X-Ray runs
* Received an update on the progress regarding the new adaptive mutation functions. They are almost ready!
* In anticipation of the large number of runs we will be doing, I have been tasked with writing a script that can calculate the AUROC directly from the .out files 
'''Action Items:'''

In setting up for a Chest X-Ray on ICE-HAMMER, Anish was getting a dimensionality error where the model was receiving (224,224,1,4) instead of  (224,224,1) which is the correct dimensionality of a single input image. Mentioned that it looks like he was trying to put 4 data points into a place that requires 1. After some investigation, it was identified that the error came from how EMADE creates data instance. This got us started on a chest x-ray run on EMADE after Anish converted the data types on all of the input images to save memory. 

As for my task, I will be trying to expand upon my existing work on parsing .out files. I plan on extracting the the Pareto Front individuals and constructing these individuals by hand. By doing so, I will be able to manually evaluate these individuals and calculate the true positive and false positive (will probably utilize Sci-Kit Learn here). Then I can use Matplotlib to design stunning visuals for the presentation. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Complete 
|November 9, 2020
|November 15, 2020
|-
|Write Script that can calculate AUROC of runs
|In Progress
|November 13, 2020
|
|}
== November 2, 2020 ==
'''Team Meeting Notes:'''
* Team is continuing with the tasks we outlined last week: Bounding Boxes, Adaptive Mutation, BERT, new CV primitivizes
* One of the new members was able to successfully set up on PACE-ICE and run EMADE there. This was surprising as some other team members had been unable to resolve similar PACE related issues for the first half of the semester.
** The problem of getting only individuals with no fitness came. I suggested using my script and the Visualization notebook as an aid for debugging here.
'''Sub-Team Meeting Notes'''
*According to Anish, bounding boxes didn't work on the Chest X-ray dataset
**This may be because only a fraction of  the training set is compatible with bounding boxes.
**Tried reducing to only the sub-set of training data that were compatible but received poor results. 
**Considering looking at pretrained models like VGGNet.
* Identified trouble with GPU utilization. Apparently, GPUs apparently being used in specific cases, but not on our ICE-HAMMER runs.
* The new members tasked with finding a new dataset are going to be using the Amazon product review for sentiment analysis dataset as a new problem
[[files/Xray2 electric boogaloo.jpg|alt=Processed Chest X-Ray|thumb|This is an example of a pre-processed 224x224 Chest X-Ray which will be used as the input data for our EMADE runs. Our goal is to match the performance of the CoDeepNeat comparison paper. ]]
'''Action Items:'''

Anish suggested that looking into the Chest X-Ray dataset and helping out there would be a more valuable use of my time. 

Upon first download, I actually forgot how much space was left on my computer and apparently there wasn't enough room to downlead a 42 GB dataset. Thankfully, Anish was able to create .npz pickle files which only took up 3 GB and were much easier to work with.

I took the time to get familiar with the dataset in order to better understand the experiments that Anish and the remainder of the CV team wanted to perform 
[[files/XrayExamples1.jpg|alt=Chest X-Ray Dataset as illustrated by the NIH.|thumb|325x325px|This is the an snippet of example data with labels from the NIH dataset description. Essentially, this is what we want EMADE to do.  ]]
The Dataset: 
* 112,120 NIH Chest X-rays with Disease labels
* Multi-label Classification with 14 possible diseases meaning there are 15 classes if we included the label "no disease"
* For our purpose, the images are converter to 224x224 grayscale images where some of them have annotations.
* Splits: Train: 70%, Validation: 10%, Test: 20%
Repository I was given containing the Chest X-Ray Dataset: [https://github.gatech.edu/athite3/chestxray Dataset]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Complete
|November 2, 2020
|November 8, 2020
|-
|Look at Chest X-Ray Dataset
|Complete
|November 6, 2020
|November 11, 2020
|}
== October 26, 2020 ==
'''Team Meeting Notes:'''
* Re-capped how the midterm presentations went. Overall opinion was fairly positive.  
* Assigned and become acquainting with the new members to the sub-team: Jon, Maxim, Steven & Chris. 
* Talked about the directions we want to take as team for the latter half of the semester. 
'''Sub-Team Meeting Notes:'''
* Continued the discussion about novelty in our work. Dr. Zutty gives a potential example of adding a Sobel Filter within an NNLearner individual. 
* First half of the meeting was primarily tasking the new members. We want them to look into how to reliably run experiments on PACE-ICE. One of the new members suggested exploring a new dataset to run on EMADE and comparing them to existing models.
* Goal of the entire teams is to continue coding out the new features and primitives that can support our case about novelty. 
** The CV sub-sub-team plans on looking into the YOLO architecture with bounding boxes for the Chest X-Ray dataset
** They also want to add primitives for edge detection, thresholding, and filtering which could be used in our upcoming EMADE run on Chest X-Ray.
** Our adaptive mutation functions are almost complete, and we are looking at ways of getting BERT integrated into our architecture. 

'''Action Items:'''

I am interested in the implementation of word-embeddings into the existing EMADE architecture. As such, I plan on looking at the papers Cameron found out sub-architecture extraction from BERT.
* Paper 1: https://arxiv.org/abs/2010.08512
** This paper introduces an approximation algorithm that can optimally extract a sub-architecture with a given approximation error threshold and a specification of input parameters.
* Paper 2: https://arxiv.org/abs/2010.10499
** This paper also discusses sub-architecture extraction but specifically for BERT by applying recent breakthroughs in algorithms for neural architecture search.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Complete
|October 26, 2020
|November 1, 2020
|-
|Read BERT papers
|Complete
|October 31, 2020
|November 6, 2020
|}
== October 19, 2020 ==
[[files/Concat run results.jpg|alt=Graphs showing ConcatenateLayer Trends.|thumb|383x383px|The top graph shows how many individuals with a ConcatenateLayer were on the Pareto Front. Only one individual with a ConcatenateLayer from the smaller run is was ever on the Pareto Front. The bottom graph shows how many individuals with a ConcatenateLayer were successfully evaluated. 
The blue line is for the run with a smaller starting set of individuals and the orange line is for the run with a larger starting set of individuals. 
]]
'''Team Meeting Notes:''' 
* Presentation Day! 
** Talked about visualization and parsing work done over the course of the semester. 
** Highlighted some of the results from our large and small EMADE runs.  
** Discussed the ongoing investigation regarding why ConcatenateLayer individuals are not appearing on the Pareto Front.[[files/More run results ahhh.jpg|alt=More Run Results|thumb|359x359px|The top graph shows average individual error at each generation and the bottom graph shows minimum individual error at each generation. The small run had a higher average error per generation and the minimum individual error generally constant. The blue line represents a run with a smaller starting set of individuals whereas the orange line represents a run with a larger starting set of individuals. These runs were done on the toxicity dataset. ]]
* NLP sub-team presentation: https://docs.google.com/presentation/d/1Z8PjzaP_LjhyycpGSeXX7rIHdVYkxHzqg8vaKVEYhdU/edit?usp=sharing 
* Listened to other teams as well:
** Stocks:
*** The sub-team had split into two sub-sub-teams over the course of the semester: one focused on research and another focused on EMADE implementation.
**** The research team is looking into a paper which outlines a CEFLANN architecture for trading. They are researching technical indicators that the model is using an looking at how to adopt this into EMADE using Keras. 
**** The implementation teams did a run of EMADE with a regression objective using existing technical indicator and data pre-processing primitives. Their run was able to make a profit.  
** Modularity:
*** The team's goal is to abstract out parts of individuals by creating building blocks that help in the genetic process. This will lead to more code reuse by using implementation based on ARLs  
***  The team wants to achieve statistical significance when compared to baseline runs with no ARLs.
***  The team performed 2 experiments. 
****  Data Pair Limitation filtered ARLs so that only useful filters and learners would be used.
****  Testing an Alternate Selection Method that directly increases the probability of getting ARLs.
***  In the future, the team wants to see if the can achieve statistical significance by implementing new heuristics and performing experiments on the MNIST data set. 
** ezCGP:
*** The sub-team had also split into two sub-sub-teams over the course of the semester: one focused on code development and another focused on research.
*** The coding group  is building new primitives and re-factoring existing ones. 
*** The research group was looking into interesting techniques for existing papers that can be applied to ezCGP.
**** Ongoing research in addressing diversity/individual exploration.
**** Looking into super-convergence as a way of reducing run-time. 
** New teams:
*** 5 different groups of new members presented regarding their experiments in comparing the performance of standard ML, MOGP, and EMADE on the Titanic datasets. 
*** These presentations were solid albeit repetitive. Nevertheless, I believe that a lot of there is lot of potential for good work from these members.  
*Encouraged new members to join the newly rebranded Neural Networks sub-team. Our sub-team has decided to re-brand itself since we want to expand the scope of our research past just NLP applications towards general Neural Architecture Search as we also want to explore applications with image datasets such as Chest X-Ray, CIFAR-10, and MNIST among others.
'''Sub-Team Meeting Notes:'''
* Presentation was quite successful albeit a little over the allotted time.

* Friday meeting focused on outlining goals for the remainder of the semester as well as identifying potential tasks for newer members (Documentation of our approached was suggested)
* Continued our prior discussion about novelty. 
** Talked about outperforming the comparison paper does on the same datasets (Chest X-Ray & Wikidetox). 
** Focus on adapting attention layers, adaptive mutation functions, and word embeddings (i.e. BERT)
** Identifying new problems and solving them with EMADE.
** Implementing co-evolution
** Looking at edge detection primitives and thresholding primitives for CV based tasks like Chest X-Ray
'''Action Items:'''

Not that much to do this week. I will update my notebook and look forward to getting re-tasked on Monday. 
{| class="wikitable"
!Task
!Current-Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Complete
|October 19, 2020
|October 25, 2020
|}

== October 12, 2020 ==
[[files/Preliminary Run results.jpg|alt=Hypervolume/Best Accuracy Graphs.|thumb|362x362px|The top graph shows the trends in hypervolume over generations. The bottom run shows how much the accuracy of the best individual increased over generations. Smaller run had lower Hypervolume as expected since it ran for more generations. The best Pareto Individuals hovered around a 0.035 error rate.
The blue line represents the run with a smaller initial set of individuals and the orange line represents the run with a larger initial set of individuals.
]]
'''Team Meeting Notes:'''
* Focusing on the midterm presentation next week as well as figuring out priorities for the latter half of the semester.
* Had a discussion with Dr. Zutty about gaining novelty. Talked about looking at tree complexity in EMADE. 
* Questioned whether or not beating the comparison paper was the right direction to shoot for. Instead we could look for new forms of novelty such as optimizing towards different objectives.
'''Sub-Team Meeting Notes:'''

The primary sub-team goal this week was to focus on presentation
* Discussed the results from our large run that had approximately ten times more individuals than a regular run
** Large run ran for 46 generations. Regular run ran for 89 generations. 
** Many of individuals evaluating to infinity. The script may give insight onto why this may be happening. 
* Had a group discussion about novelty expanding upon our prior discussion with Dr. Zutty. Talked about applying some of our approaches to new problems.
** Conversed about the advantages and disadvantages of depending on EMADE to achieve novelty. 
** Concluded that EMADE's library of primitives may be the novelty required in order to submit a paper. 
'''Action Items:'''

Last week's script gives us JSON files with the relevant information from the 2 major runs (large and small)  
* We can now look at individuals that were received at each generation and the finesses of these individuals   
[[files/Viz code.jpg|alt=Visualization Code.|thumb|461x461px|Code snippet from the Visualization Notebook that was used to generate relevant graphs that would help the team visualize trends in an EMADE run.]]
Collaborated on a Collab notebook that will help the sub-team visualize trends in the evolutionary process of EMADE runs.  

Generating graphs to visualize results from the EMADE runs on the toxicity data set. 
* Graphs for looking at Hypervolume, Best Individual Accuracy, Average Accuracy, Number of Parameters at each generation. 
* Graphs identifying what proportion of individuals were unable to be evaluated (i.e.INF individuals) 
* Graphs looking into frequencies of individuals containing a concatenate layer.  
See Google Collab Notebook: [https://colab.research.google.com/drive/17vC-WvvFMBhG3y8yROE8qSIwhjMEWrdM?usp=sharing Visualization of nlp-nn EMADE Runs]

After finishing work on the Visualizations, I focused on creating professional slides for the midterm presentation for this Monday. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Complete
|October 12, 2020
|October 18, 2020
|-
|Design a Visualization Collab Notebook
|Complete
|October 12, 2020
|October 15, 2020
|-
|Complete Slide for Midterm Presentation
|Complete
|October 15, 2020
|October 19, 2020
|}

== October 5, 2020 ==
[[files/ScriptForParsing.jpg|alt=Parsing Script for .out Files|thumb|529x529px|Reading .out files has been virtually impossible. This script will allow us to '''visualize''' what individuals were being received at each generations, '''understand''' which individuals were appearing on the Pareto Front, '''identify''' generational trends in hypervolume and test accuracy, '''gain better insight''' on issues such asÂ why individuals were failing to evaluate and returning fitness scores of INF, and '''learn''' more about why individuals that are and are not appearing on the Pareto Front.]]
'''Team Meeting Notes:'''
*Experimental runs with different mating functions and optimizers were inconclusive
**Having stale runs dues to invalid individuals propagating: script will find out when this happens 
**Think about looking at feasibility of a tree before evaluating to save time 
*Discussed adding a 2-point crossover function and trying other adaptive mutation functions that could use prior fitness scores during execution 
*Thought about experimenting with features that are available in the PyTorch library and co-dominance 
'''Sub-Team Meeting Notes:'''
* With the midterm presentation fast approaching, we had discussion about what exactly is the novelty this team is trying to implement
** Is the goal to beat the state-of-the-art or to try and get comparable results to the paper we are comparing ourselves too?
** Team considered trying to run experiments with different datasets such as news classification, CIFAR-10, et. al.
* Discussed the utility for my script (see left) for parsing out files and analyzing whether certain layer types are present or not and at what generations they are appearing
* Recapped progress on the adaptive mutation functions and considered looking at attention and shuffle layers after the midterm presentation. 
* Considered looking at defining training time as an objective to minimize along side the number of parameters and accuracy.
'''Action Items:'''

Goal is to finish the .out file parsing script before this week's sub-team meeting on Friday. I'm having some difficulty with some awkward new-line characters in the out file, but  

After the script is finished I will be working with Anish to create a Google Collab notebook that will be able to generate relevant graphs for our EMADE runs. These graphs will be especially useful in our discussion for comparing multiple runs during the midterm presentation in two weeks. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|October 5, 2020
|October 11, 2020
|-
|Write .out File Parsing Script
|Completed
|October 2, 2020
|October 11, 2020
|}
== September 28, 2020 ==
'''Team Meeting Notes:'''
*Discussed the NLP team's progress on implementing the adaptive mutation functions 
*Results from some of the runs are still conclusive and there seems to be an inf issue with individuals in later generations. 
*Brought up PACE issues which need to resolved (maybe need to update gcc on PACE?) 
'''Sub-Team Meeting Notes:'''
* Decided the applying regularization may not be the right option for these issues
* Also decided to stray away from working on PACE and to instead focus on Google Collab
* Brought up the difficulty of reading through the .out files and identifying a reason why the fitness of individuals suddenly becomes inf.
'''Action Items:'''

The purpose of the script will be to extract the Pareto Front and the received individuals for each generation.

The .out files contain information about the Pareto Front and about the individuals received in each generation.

There may be a point where individuals are always inf, so a plotting it out could help visualize the plateau. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|September 28, 2020
|October 4, 2020
|-
|Complete Peer Evals
|Completed
|September 28, 2020
|October 2, 2020
|-
|Write .out File Parsing Script
|In Progress
|October 2, 2020
|
|}

== September 21, 2020 ==
'''Team Meeting Notes:'''
*Continued discussions about adding new mating and mutation functions. 
*Discussed the results of a run that included both the optimizers and new mating functions 
*Since there wasn't an improvement in fitness, other approaches need to take. 
**These included testing the optimizers and new mating functions separately, or adding some sort of regularization. 
'''Sub-Team Meeting Notes:'''
* Further discussed the results of a new run that included both the optimizers and new mating functions
** Anish is thinking about experimenting with the individuals generated by the mating functions manually
* As of right now, the new mating function is not having substantial improvements in fitness
* Regularization is still on the table, as well as experimenting with other types of optimizers.
'''Action Items:'''

Will continue working on Collab notebook. Asked Anish about any outstanding tasks that need to be completed.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|September 21, 2020
|September 27, 2020
|-
|Look Into Collab Notebook
|Completed
|Septeber 7, 2020
|September 25, 2020
|-
|Read Papers
|Completed
|September 25, 2020
|October 1, 2020
|}

== September 14, 2020 ==
[[files/Self-Evaluation of Notebook.jpg|thumb|445x445px|Self-Evaluation of this Notebook]]
'''Team Meeting Notes:'''
*Requested push access to the nlp-nn branch on GitHub 
*Told to perform a self-evaluation of notebook (see attached image) 
'''Sub-Team Meeting Notes:'''
* Discussed developments of the nn branch with the sub-sub team
* Brought up my questions regarding the Collab notebook and clarified certain concepts with Anish
* Anish brought up some relevant papers regarding nlp-nn project. Will try to read through some of these papers in order to gain a clearer understanding of the sub-sub team goals. 
'''Action Items:'''

Will continue working on Collab while looking at the papers Anish brought up.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|September 14, 2020
|September 20, 2020
|-
|Complete Notebook Self-Review
|Completed
|September 14, 2020
|September 20, 2020
|-
|Look Into Collab Notebook
|In Progress
|Septeber 7, 2020
|
|}

== September 7, 2020 ==
[[files/Collab.jpg|thumb|449x449px|NLP-NN Collab Notebook]]
'''Team Meeting Notes:'''
*No whole-team meeting due to holiday 
*Was given access to the nlp-nn Collab Notebook; Began reading through the notebook and understanding how it works.  
'''Sub-Team Meeting:'''
* Unable to attend meeting due to an external conflict. Let Pulak know ahead of time. 
* Continued working on understanding the Collab Notebook for the nlp-nn sub-sub team
* Working my way through understanding the mating and mutation functions 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|September 7, 2020
|September 13, 2020
|-
|Look Into Collab Notebook
|In Progress
|September 7, 2020
|
|}

== August 31, 2020 ==
'''Team Meeting Notes:'''
*Sub-team brought up PACE Issues to Dr. Zutty 
*Continued to make progress on researching the Concatenate Layer Issue 
[[files/Concat.jpg|thumb|420x420px|Example of a NNLearner with a Concatenate Layer in Generation 68 of an NLP EMADE run. Trying to understand why the accuracy value is relatively lowers than other individuals on the Pareto front. ]]'''Sub-Team Meeting Notes:'''
* Discussed findings from the concatenate layer investigation
* Worked on a potential script that could make parsing the .out files easier
* Instructed to focus more on Google Collab related issues
'''Action Items:'''

Focus more on using the NLP-NN Collab over the concatenate issue. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|August 31, 2020
|September 6, 2020
|-
|Research Concatenate Issues
|Completed
|August 21, 2020
|September 4, 2020 
|}

== August 24, 2020 ==
'''Team Meeting Notes:'''
*Team Leaders outlined the team goals for the duration of the semester.  
*Signed up for specific team assignment on a Google Doc outlined by Pulak and Anish
**Researching the concatenate layers and relevant issues 
**Look into adaptive mutation layers.  
'''Sub-Team Meeting Notes:'''
* Broke off into sub-sub team meetings
* Examined the .out files provided by Anish to better understand the concatenate learners
** A primary analysis indicates that  they are being generated, but they are not evaluating to be as well as sequential models
** A potential solution might be  to generate some concatenate learners to see if we can get better concatenate learners
'''Action Items:'''

Continue examining the .out files. Try writing quick Python scripts to parse files instead of scrolling through manually. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|August 24, 2020
|August 30, 2020
|-
|Research Concatenate Issue
|In Progress
|August 21, 2020
|
|}


== August 17, 2020 ==
'''Team Meeting Notes:'''
*First meeting of the year. Introduced to the available sub-teams. Will join the NLP sub-team for the duration of the semester. 
'''Sub-Team Meeting Notes:'''
* Outlined team goals for the semester. 
* Joined the Neural-Networks sub-sub team 
* Received task of identifying why Concatenate Layers are not appearing on the Pareto front on recent NLP EMADE runs.
** Possible Reasons for this could be that concatenate layers are not good enough or concatenate functions are not evolving properly because individuals are being evolved multiple times in a single generation
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|August 17, 2020
|August 23, 2020
|-
|Join Sub-Team
|Completed
|August 17, 2020
|August 17, 2020
|}

== April 20, 2020 ==
[[files/Best individual graph ezCGP.jpg|thumb|Testing accuracy over 30 epochs of the best individual from the 39th generation of an ezCGP run on the CIFAR-10 dataset. The individual reached a peak test accuracy of 84.7%.]][[files/Best individual ezCGP.jpg|thumb|Visual model of the best individual created in the 39th generation of an ezCGP run. Individual does not contain a pre-processing block.|398x398px]]'''Team Meeting Notes:'''
* Presentation Day! Presented upon ezCGP bench-marking and test runs using the CIFAR-10 data set.
* Talked about the best individual that my group was able to create:
** Individual came from the 39th generation of an ezCGP run without data-augmentation or pre-processing
** Individual achieved a peak test accuracy of 84.7% on the CIFAR-10 data-set
* ezCGP Sub-Team Presentation: https://docs.google.com/presentation/d/1TV78U_DNYqzz7cwFAqhuXwjJl6Ou8qVV0f8nkKiARjY/edit?usp=sharing
* Listened to the presentations made by other teams and made the following key takeaways:
** NLP:
*** Integrating Keras into EMADE by using an NNLearner and Adding primitives that will do NLP with EMADE  
*** Experimented with different activation layers by working with the toxicity data set  
** Research Fundamentals:
*** Making the evolutionary process faster and more efficient by reducing bloat (using Neat-GP)  
*** Found statistically significance difference in hyper-volume and bloat when higher speciation thresholds were used  
*** Team explored how Neat Crossover performs with speciation and fitness sharing  
**ADFs:
*** Team is trying to get ADFs to select useful components (reducing the number of ADFs while improving quality and ADFs contribute to the Pareto Front)  
*** <u>Differential Fitness with Intel ADFs</u> --> evaluating the change in the fitness of an individual from parents (how much better each ADF is getting every generation) // higher quality ADFs will appear more on the Pareto front  
*** <u>Selection Methods</u> --> Increasing the frequency of Pareto ADFs in individuals, setting tournaments to pick more individuals with ADFs.  
***No statistically significant relationship between adding ADFs and AUCs, but seemingly ADFs have some impact in the middle generations when used in the evolutionary process   
'''Action Items:'''

Cleaned up VIP notebook for final evaluation.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|April 20, 2020
|April 27, 2020
|}

== April 13, 2020 ==
[[files/EzCGP Individual.jpg|thumb|Best Individual from Generation 15 of my run of ezCGP.  Individual reported 77% accuracy on the CIFAR-10 dataset after 10 epochs.|502x502px]]
[[files/Generations.jpg|thumb|Illustrating the number of generations ezCGP was able to evolve after running for 32 hours. |502x502px]]'''Team Meeting Notes:'''
* Sub-teams presented the steps they were taking towards finalizing their final presentations
* New ezCGP members were asked to each run ezCGP on the data-set they had chosen for bench-marking
[[files/Pbs script.jpg|thumb|PBS Script used to run ezCGP on the CIFAR-10 dataset using PACE.|442x442px]]'''Sub-Team Notes:'''
* Presented results found on a standard CNN in order to benchmark ezCGP
* Learned how to properly write a .pbs script in order to submit a compute request to PACE for ezCGP
*Submitted a dummy request to PACE to make sure .pbs script was working properly and I was properly able to run ezCGP   

'''Action Items:'''

Made the following changes to the ezCGP code in order to perform a proper bench-marking run: 
* Modified problem.py so that our run of ezCGP would work without data-augmentation or pre-processing, 
* Adjusted the evolutionary parameters as instructed by a team mentor
* Changed skeleton_blocks.py such that only primitives from the bench-marking model and simple functions (e.g. sum and concat) were used --> this was done to see if our CNN architectures will be useful in seeding when the code structure switches from TensorFlow 1.0 to TensorFlow 2.0 
Started an ezCGP run on Georgia Tech's PACE computing cluster with GPUs by submitting a .pbs script. Initially had some problems due to PACE memory quota limitations. Resolved this by removing unnecessary Anaconda modules. 

Ran ezCGP for 32 hours which allowed for 15 generations. Used evaluator.py to identify the best individual from the 15th generation of the run. This individual reported 77% accuracy after 10 epochs (see top figure).

Worked on creating and finalizing the sub-team's final presentation.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|April 13, 2020
|April 20, 2020
|-
|Run ezCGP on CIFAR-10
|Completed
|April 13, 2020
|April 19, 2020
|-
|Presentation Slide
|Competed
|April 15, 2020
|April 19, 2020
|}[[files/Accuracy and Loss for PraneetK CNN.png|thumb|Graph with the accuracy and loss metrics for the CNN architecture on the CIFAR-10 data set over 100 epochs. Accuracy Plateaus around 18 epochs at  72.18%|316x316px]]
== April 6, 2020 ==
'''Team Meeting Notes:'''
* Sub-teams presented their progress towards their end of semester goals
* New ezCGP members were tasked with finding a data set and showing that ezCGP outperforms a standard CNN architecture for that data set
'''Sub-Team Notes:'''
* Created a GitHub Gist that contained the python code for the chosen CNN architecture for bench-marking 
* Learned how to upload a data sets to ezCGP. Set ezCGP version on PACE to work with the CIFAR-10 data-set.  
* Learned how to submit requests to PACE 
[[files/Model diagram.jpg|thumb|UML Diagram illustrating the primitives in the CNN architecture that will be used for bench-marking ezCGP. |382x382px]]'''Action Items:'''

Decided to use the '''CIFAR-10''' image data set for both the CNN architecture that would be used for bench-marking and the run of ezCGP.

Found a CNN architecture that performs relatively well on the CIFAR-10 Data-Set. This architecture was developed by a researcher at Johnson & Johnson as an improvement to the basic architecture provided in the documentation for Keras. 

Wrote python code for the CNN model using the Keras framework (see bottom figure). Cloned the architecture into PACE. Created an anaconda environment on PACE to run the CNN architecture and trained the architecture on PACE.

Used FireZilla to extract the performance results of the CNN architecture to my local machine. (see top figure)[[files/PraneetK CNN.jpg|thumb|Python Code for CNN architecture for the CIFAR-10 dataset that will be used for bench-marking ezCGP.|382x382px]]Results from the Bench-marking CNN Architecture:
* Test accuracy w/o augmentation:Â  '''72.18%'''
* Test accuracy w/ augmentation: '''84.07%'''
* Accuracy and Loss plateau around '''18 epochs'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|April 6, 2020
|April 13, 2020
|-
|Find a CNN architechture for Benchmarking
|Completed
|April 6, 2020
|April 10, 2020
|-
|Run the model using PACE
|Completed
|April 6, 2020
|April 13, 2020
|}
== March 30, 2020 ==
'''Team Meeting Notes'''
* Sub-teams presented their goals for the end of the semester
* Broke into virtual sub-team meetings
[[files/EzCGP UML.png|thumb|Current code structure for ezCGP as explained by a sub-team leader. This structure will need to be updated as the team transfers from Tensorflow 1.0 to Tensorflow 2.0.]]
'''Sub-Team Notes'''
* Reviewed the properties of GP and gained an introductory understanding of CGP and its applications in Deep Learning:
** Layer of a Neural Network can act as a primitive in a DAG for CGP
** ezCGP treats NNs as a set of blocks // Each block is a neural network that performs different processes
** <u>Partial-block mating</u> --> taking part of block and swapping it with another part of a compatible block
** Mating and Mutation are done at the block level in CGP
* Introduced to the project team's code-base:
** GPUs are better than CPUs and tensorflow-gpu is used during ezCGP runs
** <u>Genomes</u> --> Weights between layers (how ezCGP chooses the layers for creating a NN)
** Long term goals for the ezCGP sub-team include:
*** Need to refactor inheritance to interfaces (abstract training_block class)
*** Working on decoupling the structure in order to make it more cohesive

'''Action Items:'''

Followed a provided tutorial to gain SSH access into PACE. Cloned the GitHub repository into pace and set up the Anaconda environment needed to run ezCGP. 

Skimmed over the ezCGP design document. Gained a basic understanding of the code structure for ezCGP and how to run ezCGP on an image data set. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Updtae Notebook
|Completed
|March 30, 2020
|April 6, 2020
|-
|Set up PACE
|Completed
|April 1, 2020
|April 7, 2020
|-
|Read ezCGP Design Doc
|Compteted
|April 1, 2020
|April 3, 2020
|}

== March 23, 2020 ==
[[files/ExampleCGP.jpg|thumb|Example of a CGP from a CGP CNN paper]]
'''Team Meeting Notes:'''
* First team meeting in a new online format
* Assigned to the project team '''ezCGP'''
* Introduced to other team members and gained a broad overview of the sub-team's goals

'''Sub-Team Notes'''
* Reviewed the properties of Deep Neural Networks and the components of a CNN architecture
* Was introduced to TensorFlow and Keras machine learning frameworks

'''Action Items:'''

Read about Cartesian Genetic Programming through a 2019 Paper of CGP CNN Evolution. 

Reviewed Deep Learning concepts such as Back Propagation, Activation, Optimizers, Mathematics, and Visualizations using resources provided by Sam Zhang.  
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|March 23, 2020
|March 30, 2020
|-
|Read more about DL / CGP
|Completed
|March 25, 2020
|April 1, 2020
|}

== March 10, 2020 ==
'''Team Meeting Notes'''

Presentation Day! Presented upon EMADE results for Titanic Data Set.

Listened to the presentations made by other teams. 
* Particularly interested in the sub-team that was working on using EMADE in Natural Language Processing by adding a Neural Net as a component to a GP tree structure.  

Boot-Camp Group 1 Presentation: https://docs.google.com/presentation/d/1XAhszW_1XZNIei0VixClj5FC9dHq_TpkVtQBTuIp3cI/edit?usp=sharing 

== March 4, 2020 ==
[[files/Combined Pareto Frontier.png|thumb|Minimization Result with AUC: 0.0026710519327496365. This Pareto front is acquired by taking all Pareto individuals from each of our sets and finding the Pareto front.
|302x302px]]
'''Team Meeting Notes'''

Worked more on the EMADE Project.
* Was able to successful run EMADE on local machine
* Received errors with regards to individuals being unable to interact in a tournament
* Resolved this issue by downgrading DEAP to 1.2.2

'''Sub-Team Notes'''
* Decided to set-up individual computers to support EMADE. Realized that the Georgia Tech firewalls were the issue in connecting servers.
* SQL Workbench was being problematic.
* Able to successfully Run SQL on local host.
* Was able to generate a group Pareto Frontier for the titanic data-set by using EMADE (see figure on right)

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|March 4, 2020
|March 9, 2020
|-
|EMADE Presentation
|Completed
|February 26, 2020
|March 10, 2020
|}


== February 26, 2020 ==
'''Team Meeting Notes'''

Continued Working on the Titanic EMADE assignment:
* Had to Downgrade MySQL fro Version 8.1 to Version 5.27 in order to make MySQL compatible with EMADE.
* Spent time trying to connect the MySQL database with EMADE.
'''Sub-Team Notes'''
* Decided to set-up computers to support EMADE. by attempting to connect mySQL servers
* Connecting EMADE with mySQL has become increasingly difficult.
* Attempted to understand and resolve the errors that EMADE was placing in an .err file after deciding to run EMADE locally

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|February 26, 2020
|March 5, 2020
|-
|Set-Up emade
|Completed
|February 26, 2020
|In Progress
|}

== February 19, 2020 ==
[[files/Input.jpg|thumb|464x464px|Snippets from the input_titanic.xml file which highlight the multiple objectives and the gzipped datasets that EMADE was given.]]
'''Team Meeting Notes'''

Introduction to EMADE (Evolutionary Multi-objective Algorithm Design Engine):
* Running EMADE--> gzipped csv files for datasets (provided on GitHub)
* '''vectorization''' --> different vector for each category using  one-hot encoding method
* Working with the input files/
** Adding objectives to the input file (e.g. minimize false positives) 
** Setting evolutionary parameters
** Running 2 to 3 evaluations at a time on local computer
** Mating and mutation probabilities set in the input file
** Looking at mySQL databases to understand EMADE output
** Understanding src/GPFramework to see what EMADE is doing behind the scenes

'''Sub-Team Notes'''
* Decided to set-up computers to support EMADE.
* Downloaded git-lfs, Anaconda 3, and MySQL.
* Cloned the EMADE repository from GitHub.
* Began modifying the input file (input_titaninc.xml) that would be used for the duration of this project.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|February 19, 2020
|February 24, 2020
|-
|Downloaded EMADE
|Completed
|February 19, 2020
|February 26, 2020
|}
[[files/EvolutionaryAlgoParetoFrontBruh.png|thumb|Pareto[[files/Pareto Titanic group1.png|thumb|301x301px|Final Pareto-Optimal Set generated from the ML algorithms used]]Frontier for Evolutionary Algorithm
|288x288px]]
== February 12, 2020 ==
'''Team Meeting Notes'''
* Presented findings from Titanic ML/GP Lab assignment.
* Listened to other sub-teams present their findings on the same assignment. 
* Link to presentation: https://docs.google.com/presentation/d/1Ua2wgkX03OrGl3nXhy6C6K-CST-cDyyKyDBDAIvVCnQ/edit?usp=sharing 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|February 12, 2020
|February 19, 2020
|-
|Worked on Sub-Team Presentation
|Completed 
|February 12, 2020
|February 19, 2020
|}

== February 5, 2020 ==
'''Team Meeting Notes:'''
* Worked with sub-team in order to create a Pareto frontier for the Titanic Data Set based on the results from Traditional Machine Learning Models
* Listened to a presentation about how to deliver a proper technical presentation. 

'''Sub-Team Meeting Notes:'''
* Created a Pareto Frontier for the Titanic Data Set by using MOGP
* Utilized MOGP and other evolutionary design principles to evolve a classifier processing the Titanic Data.
* Created a CSV file that contains the predictions on test.csv for each Pareto optimal individual you discover on the train.csv in separate columns.
[[files/Folds.png|thumb|416x416px|Code that is Splitting the Titanic Data Set into Folds]]'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|February 5, 2020
|February 10, 2020
|-
|Worked on Sub-Team Presentation
|Completed 
|February 5, 2020
|February 12, 2020
|}


== January 29, 2020 ==
'''Team Meeting Notes:'''
[[files/Svm confusion matrix.png|thumb|274x274px|Confusion matrix on Titanic Dataset using SVMs]]
* Gained an introduction to the Kaggle Titanic Data Set
* Assigned to a sub-team in order to create a Pareto frontier for the Titanic Data Set
* Teammates for the remainder of Bootcamp are Katie Jooyoung Kim, Min Htat Kyaw, Kevin Lu, Varun Valada and Jacob Wang.

'''Sub-Team Meeting Notes:'''
* Decided upon folds that will be used while training model to Titanic Data Set.
* Assigned to Use SVM Classification on the Titanic Data Set.
* SVM reached 70.11% accuracy with the following confusion matrix (see figure on the right)

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|January 29, 2020
|February 5, 2020
|-
|Complete Lab 3 (Working with Titanic Data Set)
|Completed 
|January 29, 2020
|February 4, 2020
|}

== January 22, 2020 ==
'''Team Meeting Notes:'''

Multiple Objectives - The MO in MOGA and MOGP: (Pareto model)
* Translation of the vector of scores from evaluation into a fitness value
* Gene pool -> the set of genome to be evaluated during the current generation; genome -> (GA set of values); (GP tree structure or string)
* Evaluation of a genome associates an individual with a set of scores (True Positive; False Positive)
* Objectives -> set of measurements each genome is scored againstÂ  (objective space -> set of objectives)
* Evaluation maps a genome/individualÂ from a location in the search space to a location in the objective space
* Classification Measures -> (P/N) -> classifier performance metric
** maximization measures -> maximize true positive/negative
** sensitivity or true positive rate (tpr) aka hit rate or recall TPR = TP/P = TP/(TP+FN);
** specificity or True Negative rate (tpr/spc) TNR = TN/N = TN/(TN+FP)
** other measures - Precision or positive predictive value (PPV = TP/(TP+FP), false discovery rate, negative predictive value
** accuracy (ACC= (TP+TN)/(P+N)) --> Higher Accuracy Values are Better
* Objective space has multiple dimensions
* EACH INDIVIDUAL IS EVALUATED USING AND OBJECTIVE FUNCTION
* Objective scores give each individual a point in the objective space (i.e. phenotype)
* Applicable for up to N objectives
Pareto Optimal Sets:
* An individual is Pareto if there is no other individual in the population that outperforms the individual on all objectives
* Set of all Pareto individuals is known as the Pareto frontier --> these individuals represent unique contributions
* Drive selection by favoring Pareto individuals (nevertheless, maintain diversity by giving all individuals a probability of mating)
* Use Riemann sums to determine AUC --> successive Pareto frontiers should have smaller AUCs --> hyper-volume (want to minimize/maximize)
* Non-dominated Sorting Genetic Algorithm 2 (NSGA 2)
** population is separated into non-domination ranks
** individuals are selected using a binary tournament (lower Pareto rank wins; ties are broken by crowding distance --> summation of normalized Euclidean distance to all points within the front (exlpore sparser areas)
** pushes curve towards the origin
* Strength Pareto Evolutionary Algorithm 2 (SPEA 2)
** Each individual gets strength S (how many in the population it dominates)
** Each individual receives a rank R (R is the sum of S's of the individuals that dominate it; Pareto individuals are non-dominated and receive an R of 0)
** A distance to the Kth nearest neighbor sigma(k) is calculated and a fitness of R + 1/(sigma(k) + 2

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|January 22, 2020
|January 29, 2020
|-
|Complete Lab 2 pt.2
|Completed 
|January 22, 2020
|January 29, 2020
|}

== January 15, 2020 ==
'''Team Meeting Notes:'''

Learned more about Genetic Programming:
* Genetic algorithms are a population based solutions that pass data through an individual and take the output and evaluate it using an elevator.
* Programs can be represented as tree structures.
* Nodes are called primitives and represent functions.
* Leaves are called terminal sand represent parameters.
* Trees can be converted to a lisp pre-ordered parse tree.
* Mutations involve inserting/removing/changing a node or sub-tree. 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Update Notebook
|Completed
|January 15, 2020
|January 22, 2020
|-
|Complete Lab 2 pt.1
|Completed 
|January 15, 2020
|January 22, 2020
|}

== January 8, 2020 ==
'''Team Meeting Notes:'''
* Gained introductory knowledge of genetic algorithms and was exposed to some key vocabulary terms.
** '''individual''' -> specific candidate in population '''population''' -> group of individuals whose properties will be altered  '''objective''' -> value used to characterize individuals that is being maximized or minimized  '''fitness''' -> relative comparison to other individuals  '''selection''' -> 'survival of the fittest'; preference to better individuals  -> fitness proportionate // probability of being selected based on fitness value  -> tournament -> certain individuals are directly compared, winners are mated  '''crossover''' -> represents mating between individuals (single point or double point)  '''mutate''' -> introducing random modifications to maintain diversity (small change)  '''algorithms''' -> various evolutionary algorithms to create a solution/ best individual
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Create Notebook
|Completed
|January 8, 2020
|January 14, 2020
|-
|Complete Lab 1
|Completed 
|January 8, 2020
|January 14, 2020
|-
|Join Slack
|Completed
|January 8, 2020
|January 15, 2020
|}