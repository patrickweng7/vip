Team Member: Tri Nguyen

Email: tnguyen624@gatech.edu

Interests: Machine Learning, Statistics

== Week 1: January 8th, 2020 ==
'''Team Meeting Notes:'''
* Introduction to the Team and Syllabus
* Introduction to Genetic Algorithms
* Introduction to DEAP and Python 
* Began the setup of DEAP 
* Apply DEAP to Lab 1 in Jupyter Notebooks
'''Sub-team Action Items:'''

No sub team assigned.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Setup environment and install required libraries
|Completed
|Jan 8, 2020
|Jan 15, 2020
|Jan 14, 2020
|-
|Complete Lab 1
|Completed
|Jan 8, 2020
|Jan 15, 2020
|Jan 14, 2020
|}
* Code ran without errors.
* Being able to explain the basic use of genetic coding.

== Week 2: January 15, 2020 ==

=== Team Meeting Notes: ===
* Genetic Programming
** Same as Genetic Algorithms except Mating and Mutation are different due to change in representation of genome of individuals
** Uses graphs: tree structure
** Nodes --Primitives (+,-,*,%)
** Leaves - Terminals
** Instead of evaluating genome, the genome tree itself is the function/evaluation
*** Ex: 1 + (3 * 4) = [+, 1, *, 3, 4]
** Mutations, many ways to mutate individuals: change primitive function of a node, randomly generate a tree and insert it into the genome tree, delete a tree and move its children up etc.
* DEAP
** Primitive function set
** Arity: number of inputs to a primitive function in the Primitive function set
* Symbolic Regression
** y = sin(x)
** Primitive set: +, -, *, /, !, exp (exponents)
** Terminals: x, constants

=== Sub-Team Notes: ===
* N/A: No team assigned

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class lecture slides with notes
|In Progress
|January 15, 2019
|January 22, 2019
|January 21
|-
|Finish the last part of the DEAP Lab #1 and first part of the DEAP Lab #2
|In Progress
|January 15, 2019
|January 22, 2019
|January 27
|}

== Week 3: January 22, 2020 ==

=== Team Meeting Notes: ===
* Multi-Objective Optimization
** Gene Pool: set of genome to be evaluated during the current generation\
*** Genome: Genotypic description of an individual analogous to DNA
*** Search Space: set of all possible genomes (Important to consider as it may affect how many generations we should run for and whether we need to add more primitives
** Evaluation: A function that takes in an individual (as a set of parameters in GA or a string in GP) and maps each individual to a set of scores based on objectives we want to maximize or minimize
*** Some examples of these scores include True Positives (TP) and False Positives (FP)
*** Objectives: The set of measurements against which each individual is scored against
*** Phenotype
** Objective Space: Set of objectives
** Evaluation is essentially a function from the Search Space to the Objective Space (the phenotype description of each genome in the search space
** Classification Measures: Confusion Matrix: {| class="wikitable" ! !Predicted Positve !Predicted Negative |- |Actual Positve (P) |True Positive (TP) |False Negative (FN) |- |Actual Negative (N) |False Positive (FP) |True Negative (TN) |}
** Maximization Measures:
*** Sensitivity/True Positive Rate (TPR): TPR = TP/P = TP/(TP + FN)
**** Also known as hit rate or recall
*** Specificity (SPC) or True Negative Rate (TNR): TNR = TN/N = TN/(TN + FP)
** Minimization Measures:
*** False Negative Rate (FNR): FNR = FN/P = FN/(TP + FN) = 1 - TPR
*** Fallout or False Positive Rate (FPR): FPR = FP/N = FP/(TN + FP) = 1 - TNR
** Other Measures:
*** (Want to maximize) Precision of Positive Predictive Value (PPV): PPV = TP/(TP + FP)
*** (Want to minimize) False Discovery Rate (FDR): FDR = FP/(TP + FP) = 1 - PPV
*** (Want to maximize) Negative Predictive Value (NPV): NPV = TN/(TN + FN)
*** (Want to maximize) Accuracy (ACC): ACC = (TP + TN)/(P + N) = (TP + TN)/(TP + TN + FP + FN)
** Fitness Computation
*** Objective Space: Each individual is evaluated using objective functions including mean squared error, cost, complexity, TPR, TNR etc.
*** The Objective score calculated for each individual can be used to map each individual to a point in the Objective Space (Phenotype of the individual)
** Pareto Optimality:
*** An individual is Pareto if there is no other individual that outperforms it in '''all''' objectives
*** The set of Pareto individuals forms the Pareto Frontier
*** Selection favors Pareto individuals but is able to maintain diversity by giving all individuals some chance of mating
** Non-Dominated Sorting Genetic Algorithm II (NSGA ||)
*** Population separated into non-domination ranks where the lower ranked non-domination frontier individuals dominate all individuals in higher ranked frontiers
*** Individuals Selected using binary tournament
*** Ties on any given front are broken using crowding distance
**** Crowding Distance: Summation of normalized Euclidean distances to all points within the front
**** The higher crowding distance individual wins the tie
** Strength Pareto Evolutionary Algorithm 2 (SPEA2)
*** Each Individual possesses a strength ''S'': the number of individuals in the population the given individual dominates
*** Each Individual possess a rank ''R'': R is the sum of the ''strength'' ''S'' 's of the individuals that dominate the given individual
*** The distance to the k<sup>th</sup> nearest neighboring individual (σ<sup>k</sup>) is calculated to obtain fitness: R + 1/ (σ<sup>k</sup> + 2)

=== Sub-Team Notes: ===
* N/A: No team assigned

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class lecture slides with notes
|Completed
|January 14, 2019
|January 28, 2019
|January 28, 2019
|-
|Finish the last part the DEAP Lab #2
|Completed
|January 28, 2019
|February 4, 2019
|February 3, 2019
|}

== Week 4: January 29, 2020 ==

=== Team Meeting Notes: ===
* Introduction Titanic Dataset and Kaggle's get started beginner Machine Learning competition
* Went over basic python code and useful libraries useful for data processing and training a model over dataset
* Discussed briefly topics of feature selection/extraction, model selections, data splitting with cross validation and hyper parameter tuning.
* Formed bootcamp subteam

=== Sub-Team Notes: ===
* N/A: No team assigned

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review example python code for Kaggle Competion
|Completed
|February 4, 2019
|February 11, 2019
|
|-
|Enter Titanic Dataset Competition on Kaggle using any Machine Learning Mode
|Completed
|February 4, 2019
|February 11, 2019
|
|-
|Meet with team, ensure co-dominance with all members and obtain Pareto front of each members Kaggle code
|Completed
|February 4, 2019
|February 11, 2019
|
|}

== Week 5: February 2, 2020 ==

=== Team Meeting Notes: ===
* As a team, we went through possible modification on the process of manipulating the data for analysis. 
* After discussion, we proposed the change on the number of columns that we would use for data analysis
* We reduced the number of columns, and dropped the following columns ('Name', 'Cabin','Fare','Parch','Ticket','Embarked'), as these variables might not significantly affected our algorithm's prediction.
[[files/Modifications on pre-processing data.png|center|887x887px]]
* As a result, after manipulating the Titanic's test data, we chose the following features to train our model : "Sex", "Age", "SibSp", and "Pclass". 
* During the process of filling the missing data, I used median for the age missing data instead of using the mean for better result.
[[files/Mean to median.png|center]]
* Discussed briefly topics of feature selection/extraction, model selections, data splitting with cross validation and hyper parameter tuning.

=== Sub-Team Notes: ===
* Each of the team member should evaluate new machine learning based on the documentation from scikit-learn library.
* Each of the team member should create a confusion matrix, and parental lobe frontier based on their prediction

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Applying new machine learning algorithm on the Titanic test data set
|In Progress
|February 2, 2019
|February 5, 2019
|
|-
|Reading and exploring some machine learning classifier algorithm and their parameters for modifications 
|In Progress
|February 2, 2019
|February 5, 2019
|
|-
|Reviewing lab 2 to deeply understand how to create confusion matrix and draw parental lobe frontier with my own algorithm
|In Progress
|February 2, 2019
|February 5, 2019
|
|}
== Week 5: February 5, 2020 ==

=== Team Meeting Notes: ===
* I spent my around 2 hours reading the documentation for some of the possible machine learning algorithms on the Scikit-learn library  
* I noticed that these algorithms required the me to have a strong mathematical backgrounds to deeply absorb the idea behind each statistical learning methods ranging from mean squared error, split test-data, to conditional probability for Bayesian classifier.  
* It is a difficult task to grab all of the mathematical concepts, thus I decided to use them as a tool box by only understand the intuition and when to apply it. 
* The machine learning model that I implemented in my data set : Random-Forest-Classifier 

* Applying feature selection/extraction, model selections, data splitting with cross validation and hyper parameter tuning.
[[files/Applying Random Forest Classifier .png|center|1098x1098px]]
* After reviewing lab 2, I am able to analyze the true negatives, false positives, false negative, true positive, and create a confusion matrix based on the random-forest classifier.
* [[files/Tri Confusion Matrix.png|border]]

[[files/Image 111.png]]
* I am still trying to draw the parental lobe frontier for my machine learning model. 

=== Sub-Team Notes: ===
* Each of the team member should evaluate new machine learning based on the documentation from scikit-learn library.
* Each of the team member should create a confusion matrix, and parental lobe frontier based on their prediction

=== Action Items: ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Applying new machine learning algorithm on the Titanic test data set
|Completed
|February 2, 2019
|February 5, 2019
|February 4, 2019
|-
|Reading and exploring some machine learning classifier algorithm and their parameters for modifications 
|Completed
|February 2, 2019
|February 5, 2019
|February 4, 2019
|-
|Reviewing lab 2 to deeply understand how to create confusion matrix and draw parental lobe frontier with my own algorithm
|Completed 
|February 2, 2019
|February 5, 2019
|February 4, 2019
|}
== Week 6: February 9, 2020 ==

=== Team Meeting Notes: ===
* During this team meeting, we focused on creating an evolutionary algorithm using strongly-typed genetic programming.  
* As a team, we realized that there are lots of factors that we must account and evaluate before building the algorithm.  
* We found an significant issue of feature scaling on the input feature "age", since we use mean as an indicator for "age", the output data of age range from 0 to 60 which causes us errors in constructing the evolutionary algorithms.  
* Apart from working with the team, I read the DEAP documentation again to ensure that I have a good understanding of strongly-typed genetic programming.   
* I was in charge of creating the power-point presentation for the team that we can practice presenting our work on Monday --  February 10, 2020.  
* After reading the DEAP documentation, I did not fully grab the concept, thus I decided to review lab 2 for better understanding.   
* We have 5 people in our group, and each person was assigned a particular job.   
* My job was to synthesize the result of all members, organizing the data, and placing them into our presentation.   

Action Items:
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Collecting all confusion matrix and parental lobe from each member of the group 
|In progress
|February 9, 2019
|February 11, 2019
|February 10, 2019
|-
|Practicing presenting in our work through mock presentation  
|Completed
|February 9, 2019
|February 11, 2019
|February 10, 2019
|-
|Collaborating with other team member on feature scaling for evolutionary algorithm 
|Completed 
|February 9, 2019
|February 11, 2019
|February 10, 2019
|}

== Week 6: February 12, 2020 ==

=== Team Meeting Notes: ===
* During this team meeting, we focused on completing and evaluating our evolutionary algorithms  
* After analyzing the evolutionary algorithms, we generated the parental lobe of this algorithm and compared with that of the machine learning algorithms  
* Our result shows that the machine learning models perform better with higher accuracy in compared with the evolutionary algorithm.  
* One possible explanation for result is that evolutionary algorithms utilizes a large amount of sample data, thus creating multiple generations and errors along the side.   
* After comparing the results, we as a group divide assign each member a particular part from the presentation.  
* Due to the time constraint, we did not have enough time to practice presenting the google slides together.  
* However, each of the member was assigned to practice their own part during their free time.  
* For my part, I was assigned to introduce the machine learning algorithms that each of the team's member apply for the titanic's problem  
* Because of my lack of understanding, I constantly searched up the sci-kit-learn documentation to understand these machine learning models  
* After 2 days, I was able to explain the general background information of each model including their history, advantages and disadvantages.  
Action Items:
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Collecting all confusion matrix and parental lobe from each member of the group 
|Completed
|February 9, 2019
|February 11, 2019
|February 10, 2019
|-
|Practicing presenting in our work through mock presentation  
|Completed
|February 9, 2019
|February 11, 2019
|February 10, 2019
|-
|Collaborating with other team member on feature scaling for evolutionary algorithm 
|Completed 
|February 9, 2019
|February 11, 2019
|February 10, 2019
|}

== Week 7: February 19, 2020 ==

=== Team Meeting Notes: ===

=== Class Notes: ===
How to install EMADE into your computer:
* Configured a mysql server on your machine (Homebrew for MAC users)
* Downloaded and installed git-lfs
* Cloned the emade repository
* Run the setup module to install the package 
What is required to run EMADE?
* Python command: python src/GPFramework/launchGTMOEP.py templates/input.titanic.xml
What is the input file?
* XML document
* Configures all moving parts in EMADE 
* Automatically detects cluster management software for grid engine 
Configuring Data Configuration
* MySQL connection 
* Server can be localhost 127.0.0.1
* Set up username, password through MySQL
Data-sets:
* Data is pre-processed into gzipped csv files.
* Cross folded 5 times 
* Data-set cleaning / Feature Construction
* Vectorization -- Categorical features (size of each vector) one hot encoding  ex: distance between 1, 2, 3 

Action Items:
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Downloading and Installing EMADE into the computers 
|In Progress
|February 19, 2019
|February 26, 2019
|
|-
|Enter Titanic Dataset Competition on Kaggle using any Machine Learning Mode
|Completed
|February 4, 2019
|February 11, 2019
|
|-
|Meet with team, ensure co-dominance with all members and obtain Pareto front of each members Kaggle code
|Completed
|February 4, 2019
|February 11, 2019
|
|}
== Week 8: February 26, 2020 ==

=== Team Meeting Notes: ===
Successfully install EMADE into my computer:
* Configured a mysql server on Alex's machine (MySQL Workbench 5.0)
* Successfully downloaded and installed git-lfs
* Cloned the emade repository with the titanic data sets 
* Run the setup module to install all the required package such as Tensorflow 2.0, numpy, scipy, etc. 
Run EMADE as a worker:
* Python command: python src/GPFramework/launchGTMOEP.py templates/input.titanic.xml -w (adding -w at the end of the code) 
Modified the input_titanic file?
* Change the user_name of the database 
* Change the IP_address 
* Change the password 
Configuring Data Configuration
* MySQL connection 
[[files/Image11111.png|left|frame]]

Action Items:
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Running Emade on March 1 with other team members  
|In Progress
|February 26, 2019
|March 4, 2020
|
|-
|Fix any errors related to EMADE 
|In Progress
|February 26, 2019
|March 4, 2020
|
|-
|Works on the presentation 
|In Progress
|February 26, 2019
|March 4, 2020
|
|}
== Week 9: March 4, 2020 ==

=== Team Meeting Notes: ===
Start running EMADE as a worker, connecting to the master's server.

+ Encountering multiple errors and warning in the error file:
* The incompatible version of scipy (should be in 1.4.1 instead of 1.3.0)
* The incorrect number of IP Address (IP address change) 
* The GtMOEP unable to find module GPFramework (use reinstall command in anaconda prompt to fix)
* Tensorflow warning (cudart - GPU related)
+ Things that I have learned about EMADE:
* I expect that EMADE will provide better result in terms of AUC and best individual in Pareto frontier in terms of distance from the origin
* However, our results shows that AUC did not significantly outperformed machine learning and evolutionary algorithm
* One possible explanation that might account for the result is the number of generation we ran on titanic_dataset for EMADE
* We were only able to run for 22 generations where 312 individuals were evaluated, and 58 individuals are in the Pareto frontier
* Moreover, we used the default settings for EMADE, applying EMADE on the previously prepossessed data which might cause some variation in the result 
* The rate of mutation and mating were kept the same 
+ Interpreting the data results:
* The three-object dimension causes difficulty in interpretation and comparison with other models
* Therefore, we reduce the number of dimension to 2. Our results were documented in the below image.
[[files/Image11.png|left]]

Action Items:
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Running Emade on March 1 with other team members  
|Completed
|February 26, 2019
|March 4, 2020
|March 4, 2020
|-
|Fix any errors related to EMADE 
|Completed
|February 26, 2019
|March 4, 2020
|March 4, 2020
|-
|Works on the presentation 
|Completed
|February 26, 2019
|March 4, 2020
|March 4, 2020
|}
== Week 10: March 9, 2020 ==
'''Class Notes:'''

+ Presenting our results on Monday for everybody

+ Listening to sub-teams presentation

== Week 11: March 16, 2020 ==
'''Class Notes:'''

+ Spring break - no meeting 

+ <u>First year students task</u>: Send a message to Dr.Jason via Canvas a list rank sub-teams in which you want to join. 

== Week 12: March 23, 2020 ==
'''Class Notes:'''

+ First Semester joins their sub-team

+ I was assigned into the Research Fundamental Teams. 

+ Dr. Jason explained the new format of the classes (online class) due to Corona Virus situation 

'''Team Meeting Notes:'''

+ Josh and Eric assigned me to read the neat-GP paper first to better understand their approach towards bloat removal 

+ They outlined the speciation threshold to be tested at 0.15, 0.3, and 0.6

+ Main objective: Look at how species change over time 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read Neat-GP   
|In Progress 
|March 23, 2020
|March 27, 2020
|
|-
|Git check out Fitness-sharing branch 
|In Progress 
|March 23, 2020
|March 27, 2020
|
|}

== Week 13: March 30, 2020 ==
'''Team Meeting Notes:'''

+ Eric checked if everyone finished reading about neat-GP paper 

+ Common installation issues related to EMADE on laptops 

+ Everyone should fork Josh's fork of EMADE (fitness-sharing  

'''Individual Notes:''' 

+ Successfully using Josh's fork of EMADE 

+ I was given the task of 5 runs/unrestricted mating/distance threshold of 0.3/50 gens

+ Things I learn from reading neat-GP
* Crossover Bias Theory -  program size during evolution skewed → causing bloat to appear (punishing small individuals, favoring large individuals)
* Multiple bloat control method: one of them is neat GP
+ 2 key components in neat-GP:
* EAT (NeuroEvolution of Augmenting Topologies algorithm) -- originally used to evolve neural networks.
* Flat Operator Equalization bloat control method → shape program size into a uniform, flat distribution
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read Neat-GP   
|Completed
|March 23, 2020
|March 27, 2020
|March 26, 2020
|-
|Git check out Fitness-sharing branch 
|Completed
|March 23, 2020
|March 27, 2020
|March 26, 2020
|-
|Fixing EMADE's issue on my computer 
|In Progress
|March 30, 2020
|April 6, 2020
|
|-
|Finish test run for unrestricted mating/distance threshold of 0.3/50 gens
|In Progress
|March 30, 2020
|April 6, 2020
|
|}

== Week 14: April 6, 2020 ==
'''Team meeting notes:'''

+ Multiple students encountered multiple issue with EMADE's running on their laptops

+ Different modules are missing during the installation such as: lightgbm, hmmlearn, sep, etc.

+ Eric assigned me to conduct 5 runs, speciation threshold: 0.3, unrestricted mating

'''Individual notes:'''

+ I tried to use the command: pip install <the modules> to fix the issue

+ I ran multiple test run on unrestricted mating, however, when I reached 18 to 20 generations, an error occurs causing the termination of EMADE called "Abort Control C". I am certain that I did not intentionally press control C. This errors occurs during my two test run.

+ I conferred this problem with Josh and Eric, and they suggested me that this might be a "window" error 

+ Furthermore, I updated my python version from 3.6.4 to 3.7.1

[[files/Git pull .png|691x691px]]

+ I successfully pull, reinstall, and run EMADE again

+ I ensure that whenever I make a new run, I create a new MySQL database, such as "titanic_experiment_7" to keep track of my progress and upload the master output, error files with exporting csv of individuals, Pareto front and bloat table to the team's google drive.

+ During the third test run, I solved the issue of "Module not found: sep" by installing Visual Studio Code on Microsoft and pip install sep 1.0.3 into my virtual environment in Anaconda. Then I ran reinstall command. 

[[files/Sep module .png|832x832px]]

[[files/Reinstall module.png]]

On my fourth run, I was able to reach generation 30, exporting my results in csv files and uploaded these files into the team's google drive. 

[[files/Result of first run.png]]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Fix issues related to EMADE (modules not found, database, etc) 
|Completed
|March 30, 2020
|April 6, 2020
|April 5, 2020
|-
|Completed two test run (error explanation above) 
|Completed
|March 30, 2020
|April 6, 2020
|April 5, 2020
|-
|Complete one run of unrestricted mating/distance threshold of 0.3/30 gens
|Completed
|March 30, 2020
|April 6, 2020
|April 6, 2020
|-
|Continue to finish 2 more run of unrestricted mating and threshold of 0.3
|In Progress
|April 8, 2020
|April 13, 2020
|
|}

== Week 15: April 10, 2020 ==
'''Team Meeting Notes'''

+ Most of the first semester students were able to fix installation issue with EMADE

+ Sam was having persistent problems getting set up, so Eric decided to get him work on PACE with Chris to keep the process going. 

+ Our team decided to reduce the runs from 50 to 30 gens in order to get sufficient runs in a limited amount of time before the final presentation.

'''Individual notes:'''

+ I uploaded another run of EMADE with required mating and distance threshold of 0.3/30 gens into the shared folder created by Eric and Josh.

+ During the run, I noticed some individuals got stuck that caused 3-4 hours for a generation to be evaluated (queue size approximately 400). Multiple member of the team encountered the same circumstances. Thus, Josh and Eric pushed an update to fitness_sharing that should fix the problem of a single individual causing a run to hang for a long time.

+ After a discussion with ADF team, Josh and Eric decided to set the time out after 2 hours to reduce the amount of time taking for an individual

+ I helped Max with the installation problem with EMADE such as missing GP Framework through slack, and he was able to run EMADE locally. 
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Continue to finish 2 more run of unrestricted mating and threshold of 0.3
|Completed
|April 8, 2020
|April 13, 2020
|April 10, 2020
|-
|Pull Eric's new code  
|Completed
|April 10, 2020
|April 13, 2020
|April 10, 2020
|-
|Complete 3 more run before the final presentation 
|In Progress
|April 11, 2020
|April 15, 2020
|
|}

== Week 15: April 13, 2020 ==
'''Team Meeting Notes'''

The current progress of every member in the group prior to the last team meeting

+ Sam was able to start working on PACE

+ Varun was currently on his second run

+ Shreyas provided data related to the timeout fix --> Thus, we will be able to finish our runs on time.

+ Kartik completed 4 runs

+ Tri and Max completed 2 runs

+ Rohith was given tasks of running another runs

+ The PACE team tried to run on PACE with a local master

+ Chris was making progress on PACE

+ Josh completed 2 runs and currently working on his third run.

'''Individual notes:'''

+ I completed two runs  unrestricted mating and threshold of 0.3/30 gens 

+ I exported my data from MySQL to csv, uploaded the following files to the team google drives for each of my run:
# Master output files
# Master error files
# Individuals csv
# Pareto front csv
# Bloat csv 
# History csv
+ All of my files are located in the following link: 
# Run 1: https://drive.google.com/drive/folders/1-wVaFpAtkumi8pEaSdAdTLQgTbHw_4uN
# Run 2: https://drive.google.com/drive/folders/1-wVaFpAtkumi8pEaSdAdTLQgTbHw_4uN
# Team's Google Drive: https://drive.google.com/drive/folders/1y1EQwaHWMCKDlMOVALpo6ZztLyOYWmW3
+ The images below are my output data:
* Bloat csv
[[files/Image1111.png|border]]
* Individual csv 
[[files/Image1111111.png|border|1000x1000px]]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Continue to finish 2 more run of unrestricted mating and threshold of 0.3
|Completed
|April 8, 2020
|April 13, 2020
|April 10, 2020
|-
|Pull Eric's new code  
|Completed
|April 10, 2020
|April 13, 2020
|April 10, 2020
|-
|Complete 3 more run before the final presentation 
|In Progress
|April 11, 2020
|April 17, 2020
|
|}

== Week 16: April 17, 2020 ==
'''Team Meeting Notes'''

+ Varun completed 3 runs done for the .15 distance threshold

+ Shreyas completed 8 runs at .6 distance threshold

+ Kartik completed all 10 baseline runs

+ Tri completed 5 runs for .3 distance threshold

+ Max completed 5 runs for .6 distance threshold

+ Chris completed 3 runs at .3 distance threshold, in addition to his work with PACE

+ Animesh completed 9 runs for neat-CX

+ Josh completed 4 runs measuring the effect of varying crossover parameters

+ Overall: The team was doing a great job of getting runs done, which will provide enough data for the analysis prior to the final presentation

'''Individual Notes'''

+ I completed a total of 5 runs which Eric assigned to me.

+ I began to work on exporting data and uploading necessary files to the team google drive for analysis

'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Complete 3 more run before the final presentation
|Completed
|April 11, 2020
|April 17, 2020
|April 16, 2020
|-
|Export and upload all data 
|In Progress
|April 13, 2020
|April 20, 2020
|
|-
|Final Presentation Prepare 
|In Progress
|April 13, 2020
|April 20, 2020
|
|}

== Week 16: April 19, 2020 ==
'''Team Meeting Notes'''

+ Our team presented our draft presentation to Dr. Rohling and Dr. Zutty today, and got a lot of helpful feedback. 

+ Our entire team member were able to attend the practice presentation. 

<u>Notes and feedback from the practice presentation:</u>

+ Dr. Zutty suggested that we should explain how our fitness sharing fits in with the overall selection process. He further addressed the question of how do the weights that we apply make it into the NSGAII algorithm?

+ Dr. Zutty also suggested an addition of a motivation slide

+ We should clearly explain more of the “why” in background slides which connects with the motivation slide

+ Analysis Recommendation: utilize the semi log scale for hypervolume graphs

+ Include experimental setup slides

+ Better clarification on the crossover slide - distinguish the differences between our the experiments and in neat crossover

+ Truncate plots at max #gens, and add bloat metric slide

+ Consider adding more texts on the slides

+ <u>Important feedback</u>: It's okay to have negative results as research does not always work out the way we want 

+ Add a summary slide and connect to motivation

+ Consider discussing the big picture (overall results) before going into the details

---> We incorporated many of these feedback into our final presentation to improve it with the entire team

'''Individual Notes:'''

+ For my slide, I found the following useful details:
# Average hypervolume decreases over time for the base line and 0.3 speciation
# Average bloat by generation also decreases, but the baseline seems to do a better job
# The red-shaded region represent one standard deviation above and below the mean for the experiment data, not baseline
# p-value is calculated using a t-test, it is the probability that the observed difference between the two groups of samples (baseline and fitness sharing) was due to random chance
# Statistically significant, in our case, means that p < 0.05, which means there is a less than 5% chance that the observed difference between the two groups was due to randomness in the data
# One possible explanation that it could be so close to the baseline is that with that speciation threshold, the number of individuals per species is close to 1, so the weighting that we applied during fitness sharing has very little effect
# The only problem with this explanation is that it turned out that a speciation threshold of 0.3 had a similar number of individuals per species however we got different results
[[files/Image1212.png]]
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Practice for the final presentation (Slide 11 - 0.3 threshold results)
|Completed
|April 19, 2020
|April 19, 2020
|April 19, 2020
|}

== Week 17: April 20, 2020 ==
'''Team Meeting Notes'''
* We successfully delivered our final presentation
* Our presentation can be found [https://docs.google.com/presentation/d/1mmyBsT76iPt4N7pM0oUf7c2qlhh34gBle978DpOBPrE/edit?usp=sharing here].
* Some notes from the other subteams' presentations:
** ADFs
*** Motivation: reuse useful subtrees
*** Their goal: to improve upon intelligent ADFs with differential ADFs
*** How: They use 4 step process to insert ADFs into the population