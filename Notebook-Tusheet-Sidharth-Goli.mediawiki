== Team Member ==
'''Team Member:''' Tusheet Sidharth Goli

'''Major:''' Computer Science

'''Class:''' Junior (3rd Year)

'''Email:''' tgoli3@gatech.edu

'''Cell Phone:''' 470-350-4410

'''Interests:''' Computer Vision, Machine Learning, Artificial Intelligence

'''Sub-Team:''' NLP (Been in the NLP team for the last 3 semesters)

'''Team Members:''' Anuraag Govindarajan, Cameron White, Alex Liu, Anish Thite, 

Anshul Agarwal, Anshul Tusnial, Pulak Agarwal, Sanket Manjesh, Shreyas Casturi,

Sumit Choudhury, Tejas Pradeep, Tushna Eduljee, Vietfu Tang

'''Self Notebook Evaluation Fall 2020:'''
[[files/Tusheet Notebook Grading Rubric.png|alt=Tusheet Notebook Grading Rubric|center|thumb|386x386px|Tusheet Notebook Grading Rubric]]
[[files/Tusheet.jpg|center|thumb|387x387px]]

== December 2, 2020 ==

=== '''General Information''' ===
* Day of Final Presentation for Fall 2020 semester
* Complete final notebooks
** Some rules to keep in mind for final notebook submission
*** Every entry should have to-do items. To-do's should be specific enough that a single item shouldn't span multiple weeks, i.e. break things down into actionable tasks!
*** Your notebook should include code, results, analysis, and thoughts, that reflect your sub-team progress AND your individual contributions.
*** Your notebook should be written with enough detail that any other course member should be able to learn from and reproduce your efforts.
*** Take notes on your peer's presentations. Include your own thoughts.
*** And as always, "if you didn't document it, you didn't do it!"
* NLP-NN Final Presentation Link - https://docs.google.com/presentation/d/1Z8PjzaP_LjhyycpGSeXX7rIHdVYkxHzqg8vaKVEYhdU/edit#slide=id.gaec8ee0d3b_1_3

=== '''Team Meeting Notes''' ===
* My summaries from the final presentations of the various sub-teams
** Stocks (Market Analysis and Portfolio Optimization)
*** Inconsistencies with the base research paper
**** The way the trading signal was calculated and its rules were inconsistent in the paper
***** Affected the results a lot and was very critical
***** Solution: Expanded upon other training methods - Genetic Labeling
****** It is an "Oracle"
****** This method depended heavily upon history of past actions related to buying and selling the shares by an individual
**** Created a fitness function (window based fitness function)
***** Reduced heavy dependence on the history of past actions
*** Created new Technical Indicator Primitives in EMADE
**** Indicator Primitives that were implemented in the paper
***** Simple Moving Average
***** Exponential Moving Average
***** Moving Average Convergence and Divergence
***** Stochastic Oscillator
***** Relative Strength Indicator
***** William's R%
***** Ease of Movement
****** Distance Moved
****** Box Ratio
**** What the team implemented
***** On-Balance Volume (OBV)
****** If price is up intra-day
******* Add volume to OBV
****** If price is down intra-day
******* Subtract volume to OBV
****** It is a cumulative value calculated over time
******* Cumulative Balance volumes over 3 to 14 days
******* The more days its tracks the better it becomes
***** Bollinger Bands
****** Movement indicator
***** Commodity Channel Indicator (CCI)
****** Trend price level vs relative average price level over a period of time
****** Can be used to identify areas where stocks are over bought or over sold
***** Money Flow Index (MFI)
****** Focuses more on the volume
*** Compared the results of the paper vs EMADE run
**** They think that the paper's prediction was a fluke that they happend to get such a good prediction
**** Paper Results
***** Truth Value - 8.647%
***** Predicted Value - 24.287%
**** EMADE Results
***** Truth Value - 12.314%
***** Predicted Value - 5.053%
*****[[files/Stocks Results.png|alt=Stocks Results|center|thumb|383x383px|Stocks Results]]
**** Seeded run with the Technical Indicator Stream vs Feature Data
***** Run with the Technical Indicators provided better results for optimal method and buying and selling the stocks
***** Ran into the issue of running out of money and could not actually implement the calculated prediction
*** Future Work
**** Test more granular data
**** Increased genetic labeling
**** Run steam_to_feature() on normalized data
**** Test larger test ranges
** EzCGP
*** Preprocessing with OpenCV primitives
**** 4 Types of primitives incorporated
***** Thresholding
***** Normalize
***** Blurring
***** Filtering
*** Objective Scores
**** Focus is now shifted to precision
***** Previously used accuracy and the F1 score
*** PACE-ICE vs PACE-ICE GPU
**** Link - https://www.notion.so/PACE-ICE-GPU-for-Ez-CGP-8be7a2e57c6649229f36505d093952dd
**** Tensorflow-gpu
**** Conda install vs Pip install tensorflow
***** Use pip install as they though this was better (at least for tensorflow)
***** This is where I had question as to why they preferred pip installs compared to conda installs?
*** Genome Seeding
**** After each generation, save 20 best individuals as a pickle file
***** They save the state of the current run
*** Benchmark EzCGP results against the CIFAR10 dataset
**** CIFAR10 - 60% training, 20% validation, 20% testing
*** Initial run results
**** Hours run: ~53 hours
***** 9 generations each averaging about 6 hours
***** Best Individual stats
****** Precision - 0.98
****** Recall - 0.97
****** F1 Value - 0.97
*****AUC generation 1 - 0.92088
*****AUC generation 9 - 0.98191 (big notable jump in the AUC values)[[files/EzCGP Results.png|alt=EzCGP Results|center|thumb|406x406px|EzCGP Results]]
***** Their team spoke about a potential run to remove transfer learning models? I was wondering why they though this would change anything?
****** Their answer: They thought that they got good results because of their transfer learning layers and that their model heavily relied upon this layer. They wanted to measure the core performance of EzCGP without the transfer learning model in their architecture and see how well their model now performs.
*** Research sub-team of EzCGP
**** NAS Research Code
***** Aging Evolution
****** Prune old individuals to simulate "dying by old age"
******* Helps increase diversity in the individuals
****** Two ways to execute it:
******* Early termination
******* Luck
***** Construct reference curves from previously produced curves
**** Experiment on Block Structure
***** Hypothesis: "Blocks" will accelerate the convergence of a population to competitive fitness values
***** Use MNIST instead
*** Future Goals
**** Perform more experiments on block structure
**** Perform more experiments on MNIST dataset
**** Continue neural architecture search experiment
**** "Marry" ezcgp with EMADE
***** This raise a couple interesting questions and Mr. Rodd and Dr. Zutty answered them to the best and most understandable level possible
**** Research new mating methods
** NLP-NN
*** Presentation Link - https://docs.google.com/presentation/d/1Z8PjzaP_LjhyycpGSeXX7rIHdVYkxHzqg8vaKVEYhdU/edit#slide=id.gaec8ee0d3b_1_3
*** These are all the slides that I presented for the final presentation:
****Motivations and Goals for the Fall 2020 semester
*****Slide 1: Apply evolutionary approach to neural architecture search using EMADE
*****Minimize our objectives of Performance and Complexity[[files/Motivations and Goals.png|alt=Motivations and Goals|center|thumb|445x445px|Motivations and Goals]]
****Slide 2: Comparison to paper - "Evolutionary Neural AutoML for Deep Learning"
*****This slide showcases our primary motivation that help us set the goal to improve the performance on this paper using EMADE
*****Stated the differences in objectives between the paper and our implementation of it
*****Mentioned our novelty with comparison to this paper[[files/Comparison to paper - "Evolutionary Neural AutoML for Deep Learning".png|alt=Comparison to paper - "Evolutionary Neural AutoML for Deep Learning"|center|thumb|444x444px|Comparison to paper - "Evolutionary Neural AutoML for Deep Learning"]]
****Slide 3: Otsu's Binarization Primitive Slide 1 (Introduction)
*****Explained the primitive that I coded and added to EMADE spatial_methods.py
*****Explained how Otsu's Binarization works and gave more insight about how it is better at calculating threshold values in image segmentation problems[[files/Otsu's Binarization Primitive Slide 1 (Introduction).png|alt=Otsu's Binarization Primitive Slide 1 (Introduction)|center|thumb|454x454px|Otsu's Binarization Primitive Slide 1 (Introduction)]]
****Slide 4: Otsu's Binarization Primitive Slide 2 (2D Implementation)
*****Showed why we need a new two-dimensional implementation of Otsu's Binarization in EMADE
******Two-dimensional (2D) version of Otsu’s Binarization combines Otsu with the newly added Adaptive Thresholding methods (adaptive mean thresholding and adaptive gaussian thresholding) and performs better than the original one in segmenting images that may be corrupted by noise[[files/Otsu's Binarization Primitive Slide 2 (2D Implementation).png|alt=Otsu's Binarization Primitive Slide 2 (2D Implementation)|center|thumb|470x470px|Otsu's Binarization Primitive Slide 2 (2D Implementation)]]
****Other important results slides
*****Results on Chest X-Ray baseline run
******For 665 generations (Horrendous Accuracy/AUROC)
******Hypervolume: 463342905.27604353
******[[files/Chest XRay Baseline Results.png|alt=Chest XRay Baseline Results|center|thumb|464x464px|Chest XRay Baseline Results]]
****Chest X-Ray Analysis - small size performance vs large size performance
*****Small
******1 - Multilabel Accuracy: 0.46334284694969674
******AUROC: 0.5 
*****Large
******1 - Multilabel Accuracy: 0.8144844809133072
******AUROC: 0.5928323820989334
****Small only predicts one class (usually 10, sometimes a different class). Large model actually tries but results in worse accuracy but better AUROC compared to small size[[files/Chest X-Ray Small vs Large Analysis.png|alt=Chest X-Ray Small vs Large Analysis|center|thumb|457x457px|Chest X-Ray Small vs Large Analysis]]
****Chest X-Ray Overall Analysis
*****[[files/Chest X-Ray Overall Analysis.png|alt=Chest X-Ray Overall Analysis|center|thumb|466x466px|Chest X-Ray Overall Analysis]]
**Modularity
***Abstract primitives by grouping primitives together as "building blocks" to use in later generations for evaluations
****ARL - Abstract combinations into a single node in the individuals
*****Individual broken down into possible candidates and then abstract those components into a single node which is now known as an ARL
******Select some combinations of nodes based on their cumulative distribution function created from their frequency and fitness
*****ARLs are selected based on frequency and distribution
***Experiment Setup
****Run on Titanic Dataset
*****Discussed a bit about  future plans to use the MNIST dataset
****Objectives
*****Minimize False Positive
*****Minimize False Negatives
****Seeded runs with 5 starting individuals
****Cap it at a maximum of 40 generations
****Differential fitness is used as a heuristic
***Differential Fitness (Experiment 1)
****Difference as the fitness of itself and its most fit parent
*****Positive value means a good child
*****Favors higher differential fitness
****Results
*****Statistical significance can be obtained/noticed in generation 16-19
******Do not know the exact reason behind this behavior
*****Converged with the baseline at higher generations
***Alternate Selection Method (Experiment 2)
****Linearly scaled getting selected for a tournament with the number of ARLs it has
*****Increases the number of ARLs
****Results
*****Statistical significance can be obtained/noticed in generation 11-19
*****Values converged with the baseline at later generations
***Data Pair Restriction (Experiment 3)
****ARLs are created only through the datapair fix
*****If they don't take in a data pair (the split components of the individuals), then they are not a valid ARL
****Results
*****No statistical significance was found
*****Did not converge with the baseline at a later generation
***Alternate Selection Updated (Experiment 4)
****Combination of Experiment 2 and Experiment 3
*****Added data pair restrictions
*****Targetted to reduce bloat
****Results
*****Individuals do not have bloat, because most individuals have 0, 1, or 2 ARLs
*****Performs worse compared to most other experiments
******Low sample size may have lead to bad results
***Future Work
****MNIST dataset experiments
*****They want to see how ARLs perform on non-trivial datasets like the MNIST dataset
******Ran for 49 generations
******Slower run compared to the titanic dataset
******Results:
*******They claim that the results are "too good to believe" and say that this overly good result is due to potential over training
*******I had a question about how they were able to move from a binary dataset like Titanic to a 0-9 values of the MNIST dataset?[[files/Modularity MNIST Results.png|alt=Modularity MNIST Results|center|thumb|376x376px|Modularity MNIST Results]]
*****Titanic dataset feels too trivial
****Integrating both ARLs and ADFs
*****ARL - Adaptive Representation through Learning
*****ADF - Automatically Defined Functions
*****This has great potentially undiscovered benefits
******But on the other hand, it does seem like a very difficult and time intensive task
****Modifying creation method of ARLs
*****Rethink the way they currently make ARLs
******Right now, their approach is too simple
******Abstract larger trees or allow ARLs to evolve as well
*****I asked a question about how they would potentially achieve this new method of creating these ARLs and why they think this might be a better and more useful version of ARLs?
=== '''Sub-Team Notes''' ===
* End of semester recap of what we had accomplished this semester
* Figure out our future goals
** Unit testing our new primitives and perform baseline runs with them
** Documented out new primitive that we can add to work along with the latest additions to the primitives
*** Otsu's Binarization, Adaptive Mean Thresholding, Adaptive Gaussian Thresholding
** New Discovery: Multi Task Learning - good for multi-label problems
** Making BERT layer valid at any position in the tree, not just as Input Layer
** More datasets to be tested on
** Implement more complex adaptive mutation scheme
** Trying out co-evolution

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete weekly notebook update
|Completed
|November 30, 2020
|December 2, 2020
|December 2, 2020
|-
|Complete finals peer evaluations
|Completed
|November 23, 2020
|December 2, 2020
|November 23, 2020
|-
|Complete VIP notebook for finals submission
|Completed
|November 30, 2020
|December 3, 2020
|December 3, 2020
|-
|Review our achievements this semester as a team
|Completed
|November 30, 2020
|December 2, 2020
|December 1, 2020
|-
|Establish some goals and tasks as a starting point for next semester
|Completed
|November 30, 2020
|December 2, 2020
|December 1, 2020
|}

=== '''Conclusions''' ===
*Link to our sub-team (NLP-NN) final presentation - https://docs.google.com/presentation/d/1Z8PjzaP_LjhyycpGSeXX7rIHdVYkxHzqg8vaKVEYhdU/edit#slide=id.gaec8ee0d3b_1_3
*Completed finals Peer Evals and submitted the final version of my notebook for Fall 2020 semester
*Reviewed what we had accomplished this semester and how much progress we had made in terms of achieving our goals
*Established some goals and tasks as a starting point for next semester

== November 30, 2020 ==

=== '''General Information''' ===
* Peer evaluations for finals are open. Complete it.
* Dr. Zutty spoke briefly about the final notebook submissions.
** Notebooks will be due on December 3rd, 11:59pm
* Final presentation for Fall 2020 date and time finalized
** December 2nd 2020 - from 6pm to 9pm (approx.)

=== '''Team Meeting Notes''' ===
* Today's meeting is for final touch-ups and help with the final presentations
** Modularity already performed a dry run with Dr. Zutty and Dr. Rohling
* The general meeting was very short and teams preferred to work in their own Bluejeans calls to finishing up their presentations and complete their dry runs
* General sub-teams updates
** Stocks
*** Performed a final review of the results obtained from the EMADE runs
**** Filtering out results and deciding which ones to present during the final presentation
*** Decided to jump back into their sub call and practice for their presentation
** EzCGP
*** Still working on their runs and obtain results
**** Completed some baseline runs
**** Still working on getting more results to add to their final presentation
** NLP
*** Doing final touches and assigning slides to people for the final presentation
**** Link - https://docs.google.com/presentation/d/1Z8PjzaP_LjhyycpGSeXX7rIHdVYkxHzqg8vaKVEYhdU/edit#slide=id.p
**** I'm presenting two intro slides (slide 3 and 4) and two more slides on the primitives that I had coded up (Otsu's Binarization)
*** Some issues that we are running into
**** PACE and ICE HAMMER issues
***** Conda env issues
****** Unable to use any conda commands
******* Solution: just using pip installs instead
****** No admin access for setting up conda environment
******* Solution: remove the conda environment and reinstall the conda environment on PACE
******* This solution worked for me and I was able to perform my baseline runs on PACE
*******PACE Admin Permission Error[[files/PACE Admin Permisson Error.png|alt=PACE Admin Permisson Error|center|thumb|526x526px|PACE Admin Permisson Error]]
******* Database connection Error
*******[[files/Database Time Out Error.png|alt=Database Time Out Error|center|thumb|524x524px|Database Time Out Error]]
***** Out of memory issues
****** Deleted irrelevant datasets and other files from EMADE
****** Deleted the .git files (~5-6 GB of unused files)
****** Deleted some input dataset that are not needed
**Modularity
***Completed their runs, results, analysis and added them to the presentation
***Completed their presentation
****Presented a dry run with Dr. Zutty and Dr. Rohling

=== '''Sub-Team Notes''' ===
*We completed our runs and results and are primarily focusing on getting our presentation together
*We went back to mini-team meeting and were performed a couple dry runs and made some edits to our presentation
**We also split up the intro and conclusion slides so that every slide is taken by someone and everyone has at least one slide to present
**NLP-NN Final Presentation Link - https://docs.google.com/presentation/d/1Z8PjzaP_LjhyycpGSeXX7rIHdVYkxHzqg8vaKVEYhdU/edit#slide=id.gaec8ee0d3b_1_3
*I have completed my tasks for the final presentation (can see from my November 23 notebook entry) and I was working on preparing my slides for the final presentation

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete weekly notebook update
|Completed
|November 30, 2020
|December 2, 2020
|December 1, 2020
|-
|Complete finals peer evaluations
|Completed
|November 23, 2020
|December 2, 2020
|November 23, 2020
|-
|Complete my presentation slides
|Completed
|November 23, 2020
|November 30, 2020
|November 29, 2020
|-
|Script out what I'm going to speak for my slides
|Completed
|November 23, 2020
|November 30, 2020
|November 29, 2020
|}

=== '''Conclusions''' ===
*NLP-NN Final Presentation Link - https://docs.google.com/presentation/d/1Z8PjzaP_LjhyycpGSeXX7rIHdVYkxHzqg8vaKVEYhdU/edit#slide=id.gaec8ee0d3b_1_3
*Our team finished getting all the results, analysis etc. required for the final presentation
**Wrapping up the presentation and split up the intro and conclusion slides so that every slide is taken by someone and everyone has at least one slide to present
**Performed a couple dry runs and made some edits to our presentation in the sub-team meeting
*I completed writing out my slides and scripted out what I'm going to speak for each of my slides

== November 23, 2020 ==

=== '''General Information''' ===
* Dr. Zutty transferred all the midterm grades on to Canvas
* Peer evaluations for finals are open. Complete it.
* Dr. Zutty spoke briefly about the final notebook submissons.
* Will be scheduling the time for the final presentations to fall during the finals week
** December 2nd 2020 (tentatively)

=== '''Team Meeting Notes''' ===
* General sub-teams updates
** Stocks
*** Finish writing the TI primitives
**** Plan on running EMADE with Technical Indicator Primitives
*** Figure out the formula used by the paper to calculate the trend score
*** Results of Genetic Labeling look promising
**** Comparing the method with that of the paper in terms of the prices data and Technical Indicators
*** Ran EMADE using S&P 500 data (with pre-calculated Technical Indicators)
**** Best individual produced 6% profit in 60 testing window
**** Created normalization primitives for dataset normalization ([https://github.gatech.edu/rbhatnager3/emade/tree/668e327aebfd5f9fba4ff584547f68c24a1fd15f Commit])
*** Plan is to run EMADE with new primitives before the final presentation
** EzCGP
*** Focusing on baseline runs. This is the main priority
**** Boosted to 128 GB of RAM and running with 2 GPU's
*** Found a big bug - evolution being greedy
**** Going from 20 individuals to 400+ individuals each generation
**** Allowed for each block to produce children through mating + mutating
*** Working and trying to stick to the Finals timeline discussed in the sub-team meeting.
**** November 19th - build out a skeleton/outline
***** Over the weekend, fill in individual slides
**** November 23rd - have a rough draft ready and finish individual slides
**** November 30th - through final draft and make sure we are presentation ready
**** December 2nd - final presentation
** NLP
*** Making sure we have trial runs on both datasets and get results
**** Runs split between ICEHAMMER and PACE-ICE
**** Planned runs for the final presentation
***** 2 baseline runs - for both toxicity and chest xray datasets each,
***** 2 runs - with neural networks + all primitives enabled
***** 2 runs - with all mating and mutation functions activated in addition to ours
***** 2 runs - with larger queue size and population
*** Analyze the outcome of the chest xray runs
****Calculate the AUROC, and compare it with that of the LEAF paper
***Plan on completing trial runs with Novelty Change enabled as well as on the Amazon product review dataset
*** The CV team created documentation on the CV Primitives in EMADE
**** Link - https://www.notion.so/Computer-Vision-Primitives-6f160347b15c4f3e8c0ccac10b9bc749
*** Tasking is mostly based on completing runs and reporting results
**** Repository for organizing results - https://github.gatech.edu/pagarwal80/EMADEResults
**Modularity
***DataPair Limit
**** Continunig to do runs
***** Using ICEHAMMER to speed up runs
***** Analysis on sample size of 4
**** Promising results. Expecting significance once more samples are collected
***** So far seeing more of an impact on later generations compared to other experiments
***** ARLs are acting as expected and are more "useful"
***MNIST Dataset
**** Can be loaded into EMADE
***** But individuals are having issues evaluating
***** error(**********Found array with 0 feature(s) […])
***Preparation for final presentation
****Schedule a time for a mock run with Dr. Zutty for the final presentation
**** Working on creating more documentation
***** Prepare a more formal write up
**** Refactoring code base to make it cleaner and more understandable
**** Better integration with some visualization and analysis tools

=== '''Sub-Team Notes''' ===
*In addition to working on making new primitives and wrapper for the CV datasets, I have been tasked with performing some baseline runs with EMADE on PACE-ICE
**Earlier this semester, I ran into a lot of issues with the conda environment and paths (after the PACE update at the beginning of the semester) on PACE-ICE
**I will be working on resolving the issues during the thanksgiving break and get a couple runs going on PACE
***Baseline runs for Chest X-Ray dataset
***Results:
****Ran for 665 generations
****Hypervolume: 463342905.27604353
****Best Individual:
*****"NNLearner(ARG0, OutputLayer(ARG0, GlobalAveragePoolingLayer2D(MaxPoolingLayer2D(2, Conv2DLayer(32, defaultActivation, 3, 3, trueBool, 1, InputLayer(ARG0))))), 95, NadamOptimizer)"
******1 - Accuracy: 0.46334284694969674
******Number of Parameters: 815.0
****Worst Individual:
*****"NNLearner(ARG0, OutputLayer(ARG0, GlobalAveragePoolingLayer2D(DropoutLayer(1.0, InputLayer(ARG0)))), 8, FtrlOptimizer)"
******1 - Accuracy: 0.7036211202283268
******Number of Parameters: 30.0 [[files/Chest X-Ray Baseline Run.png|alt=Chest X-Ray Baseline Run|center|thumb|383x383px]]
*****Code snippet from the Visualization Notebook that was used to generate the above graphs
******[[files/Code snippet from the Visualization Notebook that was used to generate the above graphs.png|alt=Code snippet from the Visualization Notebook that was used to generate the above graphs|center|thumb|450x450px|Code snippet from the Visualization Notebook that was used to generate the above graphs]]
*****Another script to visualize what individuals were being received at each generations
******Understand which individuals were appearing on the Pareto Front
******Identify generational trends in hypervolume and test accuracy
******Gain better insight on issues such as why individuals were failing to evaluate and returning fitness scores of INF
******Learn more about why individuals that are and are not appearing on the Pareto Front
******[[files/Another script to visualize what individuals were being received at each generations.png|alt=Another script to visualize what individuals were being received at each generations|center|thumb|446x446px|Another script to visualize what individuals were being received at each generations]]
*This is the Google Doc for brainstorming new primitives + keeping track of preexisting ones + various function wrappers we have
**Link - https://docs.google.com/document/d/1mOr7D0yCq0v51za8k7MIaVC_EC-6tPOsOEAZgEw9YgM/edit?usp=sharing
**Plan is to have all of the primitives for our tasks inside signal, spatial, and feature extraction files
***Implemented Primitives
****Primitive 1: Adaptive Thresholding
*****Adaptive Mean Thresholding
******Link - https://www.tutorialspoint.com/opencv/opencv_adaptive_threshold.htm
******Implemented primitive on Github[[files/Adaptive Mean Thresholding.png|alt=Adaptive Mean Thresholding|center|thumb|518x518px|Adaptive Mean Thresholding]]
*****Adaptive Gaussian Thresholding
******Link - https://docs.opencv.org/3.4/d7/d4d/tutorial_py_thresholding.html
******Implemented primitive on Github
******Github commit link - https://github.gatech.edu/emade/emade/commit/640b591ef16fe4caeb7208bc2ac5909e61123f47[[files/Adaptive Gaussian Thresholding.png|alt=Adaptive Gaussian Thresholding|center|thumb|520x520px|Adaptive Gaussian Thresholding]]
****Primitive 2: Otsu's Binarization
*****Link - https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html
*****Link - https://www.bogotobogo.com/python/OpenCV_Python/python_opencv3_Image_Global_Thresholding_Adaptive_Thresholding_Otsus_Binarization_Segmentations.php
*****Research Paper 1 - https://ieeexplore.ieee.org/document/5344078
*****Research Paper 2 - https://www.researchgate.net/publication/309543000_A_Robust_2D_Otsu%27s_Thresholding_Method_in_Image_Segmentation
*****Implemented primitive on Github (I coded this primitive and ran a couple of small unit tests [mainly for sanity checks] with this primitive on PACE)
*****Github commit link - https://github.gatech.edu/tgoli3/emade/commit/03164e5bbd21d477f5fc95d2eaa1c6e456b1a025#diff-021b05f8d8765cb9660464e3de776995[[files/Otsu Binarization.png|alt=Otsu Binarization|center|thumb|505x505px|Otsu Binarization]]
*****Graphical representation of Otsu's Binarization
******Image 1[[files/Otsu's Binarization 1.png|alt=Otsu's Binarization Image 1|center|thumb|299x299px|Otsu's Binarization Image 1]]
******Image 2[[files/Otsu's Binarization Image 2.png|alt=Otsu's Binarization Image 2|center|thumb|381x381px|Otsu's Binarization Image 2]]
*****The math behind Otsu's Binarization
******[[files/Otsu Binarization Math.png|alt=Otsu Binarization Math|center|thumb|456x456px|Otsu Binarization Math]]
*Other team members provided their updates. We have performed some baseline runs already and pushed our stuff to GitHub repository to store our results data
*I pushed my baseline runs to Github
**Repository for organizing results - https://github.gatech.edu/pagarwal80/EMADEResults
*The CV team created documentation on the CV Primitives in EMADE
** Link - https://www.notion.so/Computer-Vision-Primitives-6f160347b15c4f3e8c0ccac10b9bc749
* Chest X-Ray dataset
** All the setup for this dataset is complete
** Right now, we are doing baseline runs on Chest X-Ray dataset on ICEHAMMER
* Amazon dataset
** The progress on this dataset is almost complete
** Just awaiting on performing the baseline runs
*** They will get done over the thanksgiving break and will be ready before the final presentation

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete weekly notebook update
|Completed
|November 23, 2020
|November 30, 2020
|November 30, 2020
|-
|Complete finals peer evaluations
|Completed
|November 23, 2020
|December 2, 2020
|November 23, 2020
|-
|Need to setup up PACE to help with some baseline runs
|Completed
|November 23, 2020
|November 30, 2020
|November 26, 2020
|-
|Fix conda environment issues on PACE
|Completed
|November 23, 2020
|November 30, 2020
|November 26, 2020
|-
|Fix path issues on PACE (after the PACE update)
|Completed
|November 23, 2020
|November 30, 2020
|November 26, 2020
|-
|Finish implementing the primitives and wrapper functions finalized (in the Google doc link)
|Completed
|November 23, 2020
|November 30, 2020
|November 28, 2020
|-
|Push the new primitives to Github
|Completed
|November 23, 2020
|November 30, 2020
|November 28, 2020
|}

=== '''Conclusions''' ===
*Performed baseline run on Chest X-Ray dataset and the results we presented
**Ran for 665 generations
**Hypervolume: 463342905.27604353
*Completed coding the new CV primitives and pushed to Github
**Adaptive Mean Thresholding
**Adaptive Gaussian Thresholding
**Otsu's Binarization
*I completed my stuff for the final presentation. I have been helping other teammates with running baseline runs and getting other results for the final presentation.

== November 16, 2020 ==

=== '''General Information''' ===
* Noticed that students cannot view their midterm grades on the old VIP website
** Dr. Zutty will be transferring the grades to Canvas
* Will be scheduling the time for the final presentations to fall during the finals week
** December 2nd 2020 (tentatively)

=== '''Team Meeting Notes''' ===
* General sub-teams updates
** Stocks
*** Performing sanity checks on the data to understand anomalies in the results
*** Develop the genetic labeling notebook
**** Explore taking an unsupervised learning approach
*** Tried making an LSTM but its performance has not been too great
*** Made updates to the genetic labeling notebook
**** Link - https://colab.research.google.com/drive/1lptoCb1uDJEbklWqPxuZQjh22XZIuHwj?usp=sharing
*** Main issue is that they still can’t figure out calculation for trend signal (gotten everything else to line up with the paper)
** EzCGP
*** Research Team
**** No individual updates. Working on getting the baseline runs working
*** Implementation Team
**** Baseline Runs
***** Seeding Runs from previous runs with a 10hr runtime on PACE
****** Making a script to get around this 10hr single time runtime on PACE
****** Dr. Zutty offered a few ways to work around this problem and offered to hop on to EzCGP subteam meeting
***** Ensure enough RAM
***** Good GPU/CPU to run
*** Established a timeline for team final presentation
**** November 19th - build out a skeleton/outline
***** Over the weekend, fill in individual slides
**** November 23rd - have a rough draft ready and finish individual slides
**** November 30th - through final draft and make sure we are presentation ready
**** December 2nd - final presentation
** NLP
*** Somewhat a slow week
*** Team created a documentation for PACE ICE
**** Documentation Link: https://www.notion.so/maximgeller/Configuring-EMADE-on-PACE-60aedf065abc445096617c3cec875a11
*** Working on some of the coding portions to get in the features that we have been talking about
**** No major blockers so far
*** Rest of the team is putting in efforts to perform runs via ICEHAMMER, PACE, and Google Colab
**** Goal is to get a good number of runs for results
*** Problems encountered (no solution found yet)
**** We are still figuring out the issue with the GPU (same one from last week)
*** Additional dataset that we plan on using (was discussed last week)
**** Amazon product review dataset - https://www.kaggle.com/bittlingmayer/amazonreviews
**Modularity
***Somewhat a slow week
***Google Colab runtime limit - 12hrs runtime
***DataPair Limit - Continue doing runs
*** Arguments Refactor/Edge cases - Currently in progress
*** MNIST Dataset - Testing phase

=== '''Sub-Team Notes''' ===
*Working on making new primitives that will be used in the chest x-ray dataset
*This is a Google Doc for brainstorming new primitives + keeping track of preexisting ones + various function wrappers we have
**Link - https://docs.google.com/document/d/1mOr7D0yCq0v51za8k7MIaVC_EC-6tPOsOEAZgEw9YgM/edit?usp=sharing
**Plan is to have all of the primitives for our tasks inside signal, spatial, and feature extraction files
**Base on our research on computer vision primitives, we assembled this document
***Link - https://www.notion.so/Computer-Vision-Primitives-1d6225122e0c4d6b9abe57ab005e5cf1
**Primitives currently in EMADE:
***Filters (performed on a signal with hyper parameter alpha & epsilon)
****Hann Window (aka raised cosine)
****Tukey Window (aka tapered cosine)
****Lanczos Window (scaled central sinc lobe)
****Triangular Window
****Bartlett Window
****Gaussian Window
****Blackman Window
****Kaiser Window
****Planck-Taper Window
****Nuttall Window
***CV2 function wrappers
****CV2.MORPH_BLACKHAT
****CV2.add
****CV2.subtract
****CV2.bitwise_xor
****CV2.addWeighted
***Potential next step: adding more primitives
****Various CV2 edge detectors (ie. Canny Edge)
****Image thresholding filters + non maximal suppression
*****Primitive 1: Adaptive Thresholding
******Adaptive Mean Thresholding
*******Link - https://www.tutorialspoint.com/opencv/opencv_adaptive_threshold.htm
******Adaptive Gaussian Thresholding
*******Link - https://docs.opencv.org/3.4/d7/d4d/tutorial_py_thresholding.html
*****Primitive 2: Otsu's Binarization
******Link - https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html
******Link - https://www.bogotobogo.com/python/OpenCV_Python/python_opencv3_Image_Global_Thresholding_Adaptive_Thresholding_Otsus_Binarization_Segmentations.php
****Canny
****Sobel
*Split up runs to perform on PACE, ICEHAMMER, and (maybe) Colab

* We have a total of 10 runs to perform
**Alex, Pulak, Anish, Tusheet and Anuraag - we five will be performing the runs for the NLP-NN team
***Alex, Pulak, Anish, Tusheet - using PACE
***Anuraag - using ICEHAMMER
*First priority is to get the two baseline runs
**Baseline runs need to be performed for:
***Toxicity - Anish
***Chest X-Ray - Maxim

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete weekly notebook update
|Completed
|November 16, 2020
|November 23, 2020
|November 20, 2020
|-
|Finalize the primitives and wrapper functions we will be implementing
|Completed
|November 16, 2020
|November 23, 2020
|November 21, 2020
|-
|Double check with Dr. Zutty on the primitives and wrapper functions we will be implemeting
|Completed
|November 16, 2020
|November 23, 2020
|November 16, 2020
|}

=== '''Conclusions''' ===
*Researched about potential CV primitives for EMADE and collaborated on this Document
**Link - https://www.notion.so/Computer-Vision-Primitives-1d6225122e0c4d6b9abe57ab005e5cf1
**More fine-tuned version of the new primitives + keeping track of preexisting ones + various function wrappers we have
***Link - https://docs.google.com/document/d/1mOr7D0yCq0v51za8k7MIaVC_EC-6tPOsOEAZgEw9YgM/edit?usp=sharing
*Finalized on 3 potential primitives to add
**Adaptive Mean Thresholding
**Adaptive Gaussian Thresholding
**Otsu's Binarization
*Split up runs to perform on PACE, ICEHAMMER, and (maybe) Colab for our final presentation results
**We have a total of 10 runs to perform
***Alex, Pulak, Anish, Tusheet and Anuraag - we five will be performing the runs for the NLP-NN team
**Baseline runs need to be performed for:
***Toxicity - Anish
***Chest X-Ray - Maxim

== November 9, 2020 ==

=== '''General Information''' ===
* None

=== '''Team Meeting Notes''' ===
* General sub-teams updates
** Stocks
*** Performing sanity checks on the data to understand anomalies in the results
****Trading signal formula and had a disparity with the paper's examples
*****Genetically labelled data: https://github.gatech.edu/rbhatnager3/emade/blob/stocks-base/testCode-stocks/genetic_labeling.ipynb
*****This will help in performing supervised learning
**** Check on our TI functions
***** Plan on implementing more TIs in EMADE
** EzCGP
*** Research Team
**** No individual updates. Working on getting the baseline runs working
*** Implementation Team
**** No individual updates. Working on getting the baseline runs working
*** Setting up PACE
**** Ran into issues and ended up fixing them
**** Every team member has PACE environment setup
** NLP
*** CV team goal: Run on the chest-xray dataset using YOLO this week
**** Bounding boxes doesn't seem to work chest x-rays dataset
***** There are only 8 classes that have been defined in the training set with bounding boxes, but there are 15 classes to predict
***** Trying with only those 8 classes also didn't give good results
***** Moving Forth: Next steps are to just simply try VGGNet as a pretrained model
***Found a dataset on Amazon product review for sentiment analysis dataset on Kaggle
****Explore a novel problem, experimenting with the dataset and seeing what we can get out of it
**** Dataset Link: https://www.kaggle.com/bittlingmayer/amazonreviews
**Modularity
***DataPair Limit Problem
****Performing more runs
*** Arguments Refactor/Edge cases
*** MNIST Dataset
**** Using the npz format
*** Selection Method
**** Performed a run and got results for it
**** Learners are never the most frequently ARLs at generation 40

=== '''Sub-Team Notes''' ===
*Sentiment analysis, new dataset found (Amazon Dataset)
**Dataset Link - https://www.kaggle.com/bittlingmayer/amazonreviews
**Another dataset - https://www.kaggle.com/ejlok1/fasttext-model-91-7
*New documentation for using PACE
**Documentation Link: https://www.notion.so/maximgeller/Configuring-EMADE-on-PACE-60aedf065abc445096617c3cec875a11
**This is a more updated and better formatted documentation that what I had created last semester when I used PACE
**This has become a collaborative project for the members of the NN team (including me) who have prior experience with PACE and keeping this document up to date
***I added a bunch of errors that I got while trying to set up PACE and added my solutions to those problems that worked for me
*CV Team Updates and progress tracking
**I was looking for other ways to run the Chest X-Ray dataset and thinking away from the bounded box and YOLO approach
**This week was a slower week and we were busy doing more research work then trying to perform runs
*I was tasked (along with Tushna and Jon) to research about the CV primitives in EMADE and what additional ones we can add to improve our accuracy
**Link to our brainstorming Google Doc - https://docs.google.com/document/d/1mOr7D0yCq0v51za8k7MIaVC_EC-6tPOsOEAZgEw9YgM/edit
*Discussed yet another paper during the Friday sub-team meeting
**An Approximation Algorithm for Optimal Subarchitecture Extraction - https://arxiv.org/abs/2010.08512
***Talked about the ill-effect of over parameterized models (even though they train better)
****Recently it has been shown that that it is possible to remove several neurons for a deep trained neural network and it still remains good.
****From a computational point of view, for a trained architecture, there exists a smaller version with a weight configuration that works just as well as its larger counterpart OSE problem is the task of selecting the best non-trainable parameters for a neural network, such that it is optimal in the sense that it minimizes parameter size, inference speed, and error rate.
****Intuitively, an architectural parameter is different from a trainable parameter because it is a variable which is assigned a value when the architecture is instantiated, likewise remaining unchanged  for the lifetime of this function.
****A change on the value assignment of said variable is capable of effect change on the three functions we are optimizing over, even when utilizing the same training procedure.
***This paper was more theory and proof based (proving that the problem/algorithm was NP-hard) and was not essentially useful for our purposes

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete weekly notebook update
|Completed
|November 9, 2020
|November 16, 2020
|November 13, 2020
|-
|List out the preexisting primitives for the CV task
|Completed
|November 9, 2020
|November 16, 2020
|November 12, 2020
|-
|List out the potential new primitives to add for the CV task
|Completed
|November 9, 2020
|November 16, 2020
|November 12, 2020
|-
|Check the various function wrappers we have
|Completed
|November 9, 2020
|November 16, 2020
|November 12, 2020
|}

=== '''Conclusions''' ===
*CV Team (Chest X-Ray)
**I was looking for other ways to run the Chest X-Ray dataset and thinking away from the bounded box and YOLO approach
*This is a Google Doc for brainstorming new primitives + keeping track of preexisting ones + various function wrappers we have
**Link - https://docs.google.com/document/d/1mOr7D0yCq0v51za8k7MIaVC_EC-6tPOsOEAZgEw9YgM/edit?usp=sharing
*New collaborative documentation for using PACE
**Documentation Link: https://www.notion.so/maximgeller/Configuring-EMADE-on-PACE-60aedf065abc445096617c3cec875a11

== November 2, 2020 ==

=== '''General Information''' ===
* Will finalize the date and time for the final team presentation and get back to us on it
* Remember to update your notebooks regularly

=== '''Team Meeting Notes''' ===
* General sub-teams updates
** Stocks
*** Somewhat slower week
**** Helped on boarding the first semester students integrated into the team and code base
*** Might need some help with the data obtained from some specific runs
**** Will speak to Dr. Zutty after class to verify their findings from the runs
** EzCGP
*** Research Team
**** Performed code review with Rodd
**** Currently working on implementation
*** Implementation Team
**** Fixing issues for baselines
*** Tasked first semester students in the sub-team meeting
** NLP
*** CV team goal: Run on the chest x-ray dataset using YOLO this week
**** CV team focusing on using YOLO architecture with bounding boxes on the chest x-ray dataset, and additionally adding primitives for edge detection, etc
*** Adaptive Mutation team
**** Finished finalizing the things they want to implement
**** Will be moving into implementing phase moving forth
**** Getting BERT in is still a work in progress
**** We found some interesting papers about optimal sub-architecture extraction from BERT
*** NLP-NN Team Goal
**** We aim to finish our implementation and runs by November 16th
**** We want to give ourselves a couple weeks to verify the correctness of our results before the final presentation
**Modularity
***Onboarding the first semester students
**** Gave lectures on EMADE and ARLs/ADFs
**** Tasked with cloning our fork and running a seeded local run
**** Will hopefully start helping with other runs on colab this week
*** Presented graphs from their runs
**** No ARL vs Alternative Selection AUC
**** P-values between No ARL and Alternative Selection over generations
*** MNIST Dataset
**** Goal is to set up a work session this week
*** DataPair Limit
**** Continue doing runs
*** Arguments Refactor/Edge cases
**** Currently in progress

=== '''Sub-Team Notes''' ===
*Find a new dataset on Kaggle for sentiment analysis
**Dataset Link: https://www.kaggle.com/bittlingmayer/amazonreviews
**Cleaning the Dataset: https://www.kaggle.com/ejlok1/fasttext-model-91-7
*Discussed this paper (very briefly) 
**An Approximation Algorithm for Optimal Subarchitecture Extraction - https://arxiv.org/abs/2010.08512
***To be continued next week as we wanted to discuss more about our bounded box YOLO runs on the Chest X-Ray dataset
*CV Team Chest X-Ray dataset updates
**Completed writing a script to pull all the images needed by the bounded box problem
**All the images were distributed into train, test, validation datasets
**Converted image into text script (text file)
***Text representation of the image: '''[label, normalized x, normalized y, normalized width, normalize height]'''
**Created a .names file
***Contains all of the disease labels line by line
**Trained using a different GitHub repository for 150 epochs
**Results:
***[[files/Bounded Box YOLO run.png|alt=Bounded Box YOLO run|center|thumb|622x622px|Bounded Box YOLO run]]
*[[files/Scan.png|alt=Scan|center|thumb|309x309px|Scan]]
*Problems encountered
**Bounding boxes doesn't seem to work chest x-rays dataset
***For one, only about 1000 of the 100,000+ images had bounded box data available
***Another issue is that many of the diseases are not localizable to one particular region, so those 1000 images only contain 8 of the 15 diseases. Furthermore, even the ones that are localizable are not always “objects”, which is what YOLO specializes in
***YOLO is a single-stage detector, which means it sometimes sacrifices some accuracy for speed.
****Solution: Perhaps, it would be more effective to utilize a two-stage detector for this particular dataset.
*** There are only 8 classes that have been defined in the training set with bounding boxes, but there are 15 classes to predict
**** Only 8 diseases that can be pinpointed
**** Trying with only those 8 classes also didn't give good results
*** Detection rate was really bad and it was not able to detect most diseases
*** Moving Forth: Next steps are to just simply try VGGNet as a pretrained model instead of a bounded box approach

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete weekly notebook update
|Completed
|November 2, 2020
|November 9, 2020
|November 6, 2020
|-
|Generate the YOLO model for the chest x-ray dataset on the bounded box data
|Completed
|October 26, 2020
|November 9, 2020
|November 8, 2020
|-
|Write a script that puts all the images that are referenced in the csv file
|Completed
|October 26, 2020
|November 9, 2020
|November 7, 2020
|}

=== '''Conclusions''' ===
*Bounded box approach was not effective with our chest x-ray dataset
**Noted down why the bounded box problem using YOLO architecture did not give us good results
***Started looking for potential fixes or maybe look for yet another way to solve the problem
**Try VGGNet as a pretrained model instead of a bounded box approach

== October 26, 2020 ==

=== '''General Information''' ===
* Distributing the first years (new members) to their new subteams.
* Post midterm updates.

=== '''Team Meeting Notes''' ===
* General sub-teams updates.
** Stocks
*** Truth data produced a negative profit percentage
*** Finished writing new functions to evaluate Technical Indicators
*** Profit percentage calculation was reversed, resulting in the function buying at high and selling at low
**** Reversing improved the profit percentage from -11% on test data to 130%
*** Delegating work for the first semester students
** EzCGP
*** Research Team
**** Review code and begin implementing research paper (deadline of 2 weeks)
*** Implementation Team
**** Updated branch to the newest feature branch
**** There are quite a few bugs and they are working on fixing issues for baselines
*** Delegating work for the first semester students
** NLP
*** CV team goal: Run on the chest x-ray dataset using YOLO this week
*** Novelty (2 approaches)
**** Getting better results than the CoDEEPNEAT paper does on the same datasets
**** Exploring a new problem that hasn't been focused on before and showing how EMADE gets great results on it.
***** We spent some time brainstorming a significant problem to this effect in the sub-team meeting.
**Modularity
***Slow week and nothing new to report
***Will be distributing work to the new students
****Give them some runs to perform

=== '''Sub-Team Notes''' ===
*Dr. Zutty asked us a few questions in our Monday sub-team meeting regarding our midterm presentation
**Introduced the idea of "Stacking" and "Stacked Learners"
*This week, I was researching more about the bounded box approach and how to generate a YOLO (You Only Look Once) model for the Chest X-Ray dataset
**Bounded Box problem resources
***Bounded box for weakly supervised segmentation - https://arxiv.org/abs/2004.06816
***Density Based Object Detection - https://arxiv.org/abs/1911.12721
***OpenCV approaches to bounded box problems - https://docs.opencv.org/master/dd/d49/tutorial_py_contour_features.html
**YOLO (You Only Look Once) resources
***Unified Real-Time object detection - https://arxiv.org/abs/1506.02640
***A more casual read to understand YOLO - https://pjreddie.com/darknet/yolo/
****"We apply a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities." (quoted from the website)
**Chest X-Ray Dataset
*** 112,120 NIH Chest X-rays with Disease labels
*** Multi-label Classification with 14 possible diseases meaning there are 15 classes if we included the label "no disease"
*** For our purpose, the images are converter to 224x224 grayscale images where some of them have annotations.
*** Splits: Train: 70%, Validation: 10%, Test: 20%
**** Example pre-processes 224x224 Chest X-Ray Dataset[[files/Example pre-processed 224x224 Chest X-Ray Will be used as the input data for our EMADE runs.png|alt=Example pre-processed 224x224 Chest X-Ray Will be used as the input data for our EMADE runs|center|thumb|Example pre-processed 224x224 Chest X-Ray Will be used as the input data for our EMADE runs ]]
*** Snippet of example data with labels from the NIH dataset description
**** This is what we want EMADE to essentially do
**** [[files/Snippet of example data with labels from the NIH dataset description.png|alt=Snippet of example data with labels from the NIH dataset description|center|thumb|375x375px|Snippet of example data with labels from the NIH dataset description]]

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete weekly notebook update
|Completed
|October 26, 2020
|November 2, 2020
|October 30, 2020
|-
|Research more about the YOLO architecture
|Completed
|October 19, 2020
|November 9, 2020
|November 1, 2020
|-
|Research more about the Bounded Box problem approach
|Completed
|October 19, 2020
|November 9, 2020
|November 1, 2020
|-
|Generate the YOLO model for the chest x-ray dataset on the bounded box data
|In Progress
|October 26, 2020
|November 9, 2020
|
|-
|Write a script that puts all the images that are referenced in the csv file
|In Progress
|October 26, 2020
|November 9, 2020
|
|}

=== '''Conclusions''' ===
*Read and researched more about about the bounded box problem and YOLO architecture
**Linked several useful resources for YOLO architecture and bounded box problem approach
**Trying to visualize how I can apply these approaches to the Chest X-Ray dataset
*Made some progress with the script to pull the images correctly
*Working on isolating ~1000 images in the bounded box csv file

== October 19, 2020 ==

=== '''General Information''' ===
* Midterm Presentation Day
** NLP-NN Subteam Presentation Link: https://docs.google.com/presentation/d/1Z8PjzaP_LjhyycpGSeXX7rIHdVYkxHzqg8vaKVEYhdU/edit#slide=id.ga3dcb7a2bf_6_2

=== '''Team Meeting Notes''' ===
* Summaries from the midterm presentations of the various sub-teams
** Stocks (Market Analysis and Portfolio Optimization)
*** Objectives
**** EMADE for regression on time series data.
**** EMADE to optimize market trading algorithms.
*** Research
**** Create CERFLANN Architecture (base off of a paper)
**** Keras Neural Networks in EMADE
*** Implementation
**** Run EMADE with regression
**** Run EMADE with Colab
** EzCGP
** NLP
*** Presentation Link: https://docs.google.com/presentation/d/1Z8PjzaP_LjhyycpGSeXX7rIHdVYkxHzqg8vaKVEYhdU/edit#slide=id.ga3dcb7a2bf_6_2
*** Since I'm in the CV sub-team, here are our slides that I presented
**** Explaining our NIH Chest X-Ray Dataset
*****Chest X-Ray dataset description[[files/TG Midterm 1-1.png|center|thumb|376x376px|Chest X-Ray dataset description]]
*****Our motivation for using this dataset[[files/TG Midterm 1-2.png|center|thumb|380x380px|Our motivation for using this dataset]]
**** Primitives used
*****Primitives used for the Chest X-Ray dataset 1[[files/TG Midterm 1-3.2.png|center|thumb|376x376px|Primitives 1]]
*****Primitives used for the Chest X-Ray dataset 2[[files/TG Midterm 1-4.png|center|thumb|290x290px|Primitives 2]]
**** Problems encountered while running the dataset on EMADE
*****Problems encountered[[files/TG Midterm 1-5.png|center|thumb|384x384px|Problems encountered while running]]
**Modularity
***Koza (ADF: Automatically Defined Functions)
***Angeline (ARL: Adaptive Representation Through Learning)
***Rosca
***Runs
****Used Titanic Dataset
****~40 Generations
***Dataset
****Adding the MNIST Dataset
*****For checking the performance of ARLs on non-trivial datasets
**First Years
***Overall synopsis from the 4 first year teams
****Techniques used to solve the Titanic Problem
*****Machine Learning - 80% accuracy
*****Genetic Programming (using DEAP) - 81% accuracy
*****EMADE - 96.5% accuracy
****Some models used for mating and mutations
*****Applied cxOnePoint Function for mating
*****Used mutUniform Function for mutation
*****Analyzed evaluation time

=== '''Sub-Team Notes''' ===
* Talked about a new/alternate approach to the Chest X-Ray problem
** Idea: Model the chest x-ray dataset as a bounded box problem
** The bounded box csv file (found on kaggle) has individual diseases for each bounded box
*** Train a YOLO model to detect diseases in images using bounded boxes
**** This would also allow for the images to have multiple disease detection
** We have distributed our tasks for the CV team on how to implement these ideas
* Plan on the adaptive mutations team to start implement adaptive mutations functions in EMADE
* For novelty, we have two main approaches to chose from - 
** Getting better results than the CoDEEPNEAT paper does on the same datasets
*** For this, each member is exploring different avenues as brought up before. We don't have the attention layers, adaptive mutation, word embedding working yet, but we are working on them
** Exploring a new problem that hasn't been focused on before and showing how EMADE gets great results on it
*** We spent some time brainstorming a significant problem to this effect

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete weekly notebook update
|Completed
|October 19, 2020
|October 26, 2020
|October 23, 2020
|-
|Presented Midterm Presentation
|Completed
|October 19, 2020
|October 26, 2020
|October 19, 2020
|-
|Research more about the YOLO Architecture
|In Progress
|October 19, 2020
|November 9, 2020
|
|-
|Research more about the Bounded Box problem approach
|In Progress
|October 19, 2020
|November 9, 2020
|
|}

=== '''Conclusions''' ===
* Midterm presentation were completed by all the sub-teams and the first years
** NLP-NN Presentation Link: https://docs.google.com/presentation/d/1Z8PjzaP_LjhyycpGSeXX7rIHdVYkxHzqg8vaKVEYhdU/edit#slide=id.ga3dcb7a2bf_6_2
* Got new ideas to model the chest x-ray dataset in YOLO as a bounded box problem
** Distributed tasks for the CV team on how to implement these new ideas

== October 12, 2020 ==

=== '''General Information''' ===
* Midterm Presentation - Monday 19th October 2020 from 5pm onward.

=== '''Team Meeting Notes''' ===
* General sub-teams updates.
** Stocks
*** Performed a big run on EMADE with the data.
**** Ran 52 generations of EMADE with S&P 500 dataset and found a minimum standard error of 10.8387 for a few models (27.2492 was best of seed individuals).
*** Have not really check on the stats behind the results and findings.
**** This will be a goal for the midterm presentation.
** EzCGP
*** Research Team
**** Presentation getting ready.
**** Writeups and summarizing the papers worked on.
*** Implementation Team
**** Perfrom baseline runs, set up metrics and analyze the results.
**** Define what to expect from the EMADE runs in case they cannot get the baseline runs done in time.
** NLP
*** Stats notebook after our cumulative run
**** https://colab.research.google.com/drive/17vC-WvvFMBhG3y8yROE8qSIwhjMEWrdM?usp=sharing
*** Adaptive Mutation, Attention, Shuffle Layers are works in progress.
*** We are trying to see what a "novel" or "satisfactory" result might be. We are looking into this with the current results we have gotten from the EMADE runs.
**Modularity
***Fixed the arg issues from last week.
****Can now properly create ARLs that have ARGs
***Perform runs with the new system that we have.
****Tasking out responsibilities to perform EMADE runs now.

=== '''Sub-Team Notes''' ===
* Set up Google Colab for runs (with EMADE, conda env, all dependencies, port forwarding etc.)
** Link: https://colab.research.google.com/drive/1bhRodLmoobRtAJFtrKLkGtR__wlHbB1Q
** Google Colab setup is now complete with whatever we will be needing for the EMADE runs
** Fixed the MySQL Database error on my Colab notebook and it is all good to run EMADE on it
* Performed EMADE run on Google Colab and here are the results. (Stats Notebook)
** https://colab.research.google.com/drive/17vC-WvvFMBhG3y8yROE8qSIwhjMEWrdM?usp=sharing
* This week, we prioritized more on getting out presentation, analysis, and results together for the midterm presentation
** I was assigned slides to speak on the Chest X-Ray dataset that I had been working on, as well as a slide that lays out the issues we encountered on PACE (which eventually led us to using Google Colab for our runs instead) as I was the person who had worked extensively on PACE for the last couple semesters

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete weekly notebook update
|Completed
|October 12, 2020
|October 19, 2020
|October 16, 2020
|-
|MySQL bug fix on Google Colab
|Completed
|October 12, 2020
|October 19, 2020
|October 15, 2020
|-
|Generate the model for chest X-Ray dataset
|Completed
|October 12, 2020
|October 19, 2020
|October 15, 2020
|-
|Complete my slides for the midterm presentation
|Completed
|October 12, 2020
|October 19, 2020
|October 17, 2020
|}

=== '''Conclusions''' ===
* Google Colab setup is completed and ready to perform runs. (even with the capabilities of port forwarding)
** Link: https://colab.research.google.com/drive/1bhRodLmoobRtAJFtrKLkGtR__wlHbB1Q
* Performed EMADE run on Google Colab and here are the results. (Stats Notebook)
** https://colab.research.google.com/drive/17vC-WvvFMBhG3y8yROE8qSIwhjMEWrdM?usp=sharing

== October 5, 2020 ==

=== '''General Information''' ===
* Update notebooks for midterm evaluation - due October 5th 2020 at 11:59pm.

=== '''Team Meeting Notes''' ===
* General sub-teams updates.
** Stocks
*** Added more SciKit regression functions.
*** Research on the CEFLANN architecture and how feasible it is to implement into EMADE.
**** It is very much doable.
*** Added some Neural Networks using Keras.
*** Were able to run an EMADE regression problem on Google Colab.
*** Nearly finished getting usable S&P 500 data from the AlphaVantage API.
** EzCGP
*** New Augmentor pipeline architecture documentation.
*** Research Team on PACE
**** Get the conda environment working on PACE.
**** Running into issue where it says "Disk Quote exceeded".
*** Implementation Team
**** Debugging the evaluation of randomly generated networks.
***** With a small dataset and small training step (~30 images, batches of 5, 2 epochs).
***** Loading CIFAR-10 into the data loader.
***** Adding more primitives.
** NLP
*** This entails finding the problematic individuals (evaluating to infinite values and becoming stale).
**** First Approach - Abort those individuals so that they're not evaluated in the first place.
**** Second Approach - Genomic healing - Develop a set if rules according to which we can change the representation of the fatal instances.
*** Disussed a research paper in good depth and formulated what to implement from it.
**** Possibility of implementing the "codominance" as mentioned in the research paper.
*** The CV team ran into a lot of PACE issues.
**** We are migrating to a mix of Google Colab and Ice Hammer to perform runs.
*** Current focus:
**** Testing the different mating functions (two point crossover).
**** Using our old primitives.
**** Adaptive mutation implementation (simple thresholding to begin with).
**** Further word embeddings.
**** Shuffle layers mutation functions.
**Modularity
***Google Colab
****Set up new selection methods.
****Running experiments/debugging Differential Fitness.
***MNIST Dataset
**** Currently exploring dataset.
**** Writing cleaning script.
*** EmadeDataPair Constraint (feature and not a bug!)
**** New ARLs seem to be more "useful" at first glance.
**** Due to previous design choices from ~2 semesters ago, Arg0 cannot be part of an ARL.
**** Currently working on debugging/refactoring.
**** May introduce "partial" ARLs.

=== '''Sub-Team Notes''' ===
* Set up Google Colab for runs (with EMADE, conda env, all dependencies, port forwarding etc.)
** Link: https://colab.research.google.com/drive/1CTgRr52mTcykxolHUGWYODvbC8gGCZ6N#scrollTo=nKFsz9GLJP-K
** The Colab file now relies less on conda imports for python packages
** Increased stability with some minor changes to how we do imports in Colab in comparison to running on PACE
*** Look at the Colab file to notice the differences
* Ran into some MySQL issues on Google Colab (linking the database to the Colab file)
** Currently working on fixing that bug.
** This is a similar issue I had on PACE last semester with the database timing out and closing on itself.
** I'm still working on resolving this issue
* Read paper on Adaptive Mutation in Genetic Algorithms by Libelli and Alba
** Link - https://link.springer.com/article/10.1007/s005000000042
** We discussed this paper on the Friday subteam meeting
* Anish discussed a couple research papers that he found interesting and that might be useful for us.
** Paper 1: https://arxiv.org/abs/1901.11117
** Paper 2: https://lilianweng.github.io/lil-log/2020/08/06/neural-architecture-search.html
** Paper 3: https://arxiv.org/abs/2003.12056
*** I skimmed through this paper and found that it was not really applicable for our purposes. Here are some reasons why I felt so:
**** Their setup is lot more restrictive than ours
**** The paper is kind of complicated and not really comparable to our goals

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete weekly notebook update
|Completed
|October 5, 2020
|October 12, 2020
|October 9, 2020
|-
|Got port forwarding/sharing set up on Google Colab
|Completed
|October 5, 2020
|October 12, 2020
|October 5, 2020
|-
|Completed setting up Google Colab
|Completed
|October 5, 2020
|October 12, 2020
|October 5, 2020
|-
|MySQL bug fix on Google Colab
|In Progress
|October 5, 2020
|October 12, 2020
|
|-
|Generate the model for chest X-Ray dataset
|In Progress
|October 5, 2020
|October 12, 2020
|
|}

=== '''Conclusions''' ===
* Google Colab setup is completed and ready to perform runs.
** Link: https://colab.research.google.com/drive/1CTgRr52mTcykxolHUGWYODvbC8gGCZ6N#scrollTo=nKFsz9GLJP-K
* Completed the notebook for midterm evaluation.

== September 28, 2020 ==

=== '''General Information''' ===
* Complete Midterm Peer Evaluations - due October 2nd 2020 at 4pm.
* Update notebooks every week.

=== '''Team Meeting Notes''' ===
* General sub-teams updates.
** Stocks
*** Got Colab working.
*** Started implemeing what they found interesting in the research papers.
*** Ran the regression dataset in EMADE.
** EzCGP
*** Figured out how to work with the new framework and outlined some short term goals for the team.
*** Research Team
**** Work on finding seeding high preforming individuals into the new framework.
***** Learn new framework along with Tensorflow.
*** Implementation Team
**** Working on merging [https://github.com/ezCGP/ezCGP/pull/87 PR] for convolution2D primitive and added Conv2D transpose primitives.
**** Testing loading sample data into ezCGP. ([https://github.gatech.edu/emade/ezCGP/blob/master/data/data_tools/data_loader.py data_loader.py])
** NLP
*** Created the mating function and tested it on EMADE.
****Ran two different test runs.
***** 1st run - Best individual had score 0.0358 after 94 generations. Individual: NNLearner(ARG0, OutputLayer(ARG0, GlobalMaxPoolingLayer1D(GRULayer(50, tanhActivation, 32, trueBool, trueBool, EmbeddingLayer(98, ARG0, fasttextWeights, InputLayer(ARG0))))), 0, NadamOptimizer)(0.03565040012552956, 2205701.0)
***** 2nd run - Best individual had score 0.03759 after 65 generations. Individual: NNLearner(ARG0, OutputLayer(ARG0, OutputLayer(ARG0, GRULayer(8, softmaxActivation, 5, trueBool, trueBool, EmbeddingLayer(50, ARG0, fasttextWeights, InputLayer(ARG0))))), 100, NadamOptimizer)
**** The mating function did not increase the score. It was very similar to the original one.
*** Discussed some future plans and goals for the NLP team.
**** Try a run with the mating function and exclude the optimizers added, and then vice versa to isolate and see if there is one feature that doesn't improve our performance.
**** Adaptive mutation is something we can try to incorporate but we need to figure out a good way to implement it.
**** Using pretrained word embeddings like BERT, ELMo.
**** The idea of adverserial regularization was brought up, is this something we can possibly try?
**** Is there scope of adding a batch normalization layer and will that help?
**** Using the primitives developed by the team in previous semesters.
**Modularity
***Colab is up and running.
***Using and setup AWS for Database.
***Ran into PACE issue.
****Importing sep caused issues.
*** EmadeDataPair constraint
**** New ARLs seem to be more useful at first glance.
**** However, currently exploring a bug with how the functions are compiled, ARL string is not being properly read.
*** MNIST Dataset
**** Hoping to run our changes on a new dataset to see if there are any improvements or if we can leverage more primitives.
**** http://yann.lecun.com/exdb/mnist/

=== '''Sub-Team Notes''' ===
* We are planning on pivoting to Google Colab as PACE is giving new issues every week. This is the Colab file that I created and started to get it prepared for running EMADE
** Link: https://colab.research.google.com/drive/1CTgRr52mTcykxolHUGWYODvbC8gGCZ6N#scrollTo=nKFsz9GLJP-K
* Got MySQL working on Google Colab.
** Website Link: https://remotemysql.com/
** Working now on port forwarding.
**Our sub-team's remote mysql database credentials
***It is set up for use and we need to link this (to Colab) in order to actually put it to [[files/Remote MySQL Database.png|alt=Remote MySQL Database|center|thumb|744x744px|Remote MySQL Database]]
* Discussed the following paper
**Link - [[files/MarsiliLibelli-Alba2000 Article AdaptiveMutationInGeneticAlgor.pdf]]
**I skimmed through the paper after our Friday meeting and found it pretty resourceful
*** The paper talks about two different approaches:
**** Parameter Coding
***** Once each parameter is binary encoded, the new mutation strategy requires each parameter can be dealt with separately instead of as a group, hence the need for the unique encoding
***** Crossover and mutations are completely mutually exclusive
***** The crossover operator produces two new individuals whose fitness is to be evaluated before a possible mutation is applied
**** New mutation operator
***** Mutation will be highly depended on how good a current gene (method) is, based on its contribution to the overall fitness
***** Parameters with a high contribution to the fitness shall have a very low changes of mutations, as they are already good
***** On he other hand methods with a lower contribution to the overall fitness shall have a higher probability of mutation
***** The scaling of the mutation probability factor to foster the mutation of lower grade chromosomes
*** The ideas form the paper are very interesting and doable
*** Although it is quite math intensive and might not be the best for us

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete weekly notebook update
|Completed
|September 28, 2020
|October 5, 2020
|October 2, 2020
|-
|Midterm Peer Evaluation
|Completed
|September 28, 2020
|October 5, 2020
|September 28, 2020
|-
|Set up EMADE on Google Colab
|Completed
|September 28, 2020
|October 5, 2020
|October 2, 2020
|-
|Get dependencies and conda environment on Google Colab
|Completed
|September 28, 2020
|October 5, 2020
|October 2, 2020
|-
|MySQL working on Google Colab
|Completed
|September 28, 2020
|October 5, 2020
|October 2, 2020
|-
|Run preliminary tests on chest x-ray dataset
|In Progress
|September 21, 2020
|October 5, 2020
|October 3, 2020
|-
|Generate the model for chest X-Ray dataset
|In Progress
|September 28, 2020
|October 19, 2020
|
|-
|Port Forwarding on Google Colab
|In Progress
|September 28, 2020
|October 5, 2020
|
|}

=== '''Conclusions''' ===
* Completed midterm peer evaluation.
* Transitioned to Google Colab for our runs and tests and got everything set up on it.
** Link: https://colab.research.google.com/drive/1CTgRr52mTcykxolHUGWYODvbC8gGCZ6N#scrollTo=nKFsz9GLJP-K
** TODO: Port Forwarding
* Discussed two papers and its results to formulate our plans and goals for the future.
** Link - [[files/MarsiliLibelli-Alba2000 Article AdaptiveMutationInGeneticAlgor.pdf]]

== September 21, 2020 ==

=== '''General Information''' ===
* None

=== '''Team Meeting Notes''' ===
* General sub-teams updates.
** Stocks
*** Research Team
**** Discussed a couple papers and narrowed down to 1/2 papers
**** Attempt to mirror the study's methodology using EMADE
**** See if EMADE can outperform the paper's results using AAD
**** Plan on performing EMADE runs on Google Colab + AWS
*** Consensus was that paper was interesting and worth replicating in EMADE
** EzCGP
*** Implementation team working on testing stuff on the new EzCGP architecture
*** Testing loading sample data into ezCGP
*** Baseline experiment cifar-10
*** Discussed more ideas from additional research papers discovered
** NLP
*** CV team has finished setting up PACE for EMADE runs
*** New optimizers have been added and pushed to the NLP-NN branch
*** Reviewed paper on adaptive mutation: https://link.springer.com/article/10.1007/s005000000042
**** Not exactly usable for our purpose
*** Results with activation functions and pretrained embeddings mutation functions:
**** Best individual after 100 generations: 0.03555 score, individual: NNLearner(ARG0, OutputLayer(ARG0, GRULayer(55, sigmoidActivation, 10, falseBool, trueBool, EmbeddingLayer(94, ARG0, gloveTwitterWeights, InputLayer(ARG0)))), 100)
**** Best individual after 70 generations: 0.03558 score, individual:NNLearner(ARG0, OutputLayer(ARG0, GRULayer(93, defaultActivation, 150, falseBool, falseBool, EmbeddingLayer(1, ARG0, gloveTwitterWeights, InputLayer(ARG0)))), 95)
**** The validation accuracy remained the same: 0.04027.
*** Main priority is mating functions to enable crossover across various layers
**** Adaptive mutations
**** Word embeddings
**Modularity
*** Need to debug one of our branches
**** Running into "Cannot connect to database during query" MySQL error
**** Not sure if it's a local database issue or a code issue
*** Running into issues with PACE
**** inputSchema.xsd file is running into issues
**** Comparing with the NN branch
*** Colab
**** MySQL database website isn't working well
**** Opting to try to connect to local IP
*** EmadeDataPair constraint
**** Quick runs to see results

=== '''Sub-Team Notes''' ===
* Worked some more on fixing some PACE issues and conda environment stuff
** Disk Quota exceeded error
*** Deleted irrelevant datasets and other files from EMADE
*** Deleted the .git files (~5-6 GB of unused files)
*** Deleted some input dataset that are not needed
** re-loaded anaconda and re-created conda environment
* I found yet another great repository to generate a pre-trained mode and help us with seeding.
** Link - https://github.com/vinaya8/Transfer-Learning-on-Chest-X-Ray-Images
* We are considering dropping the idea of using PACE for our runs and try Google Colab instead
** I was tasked with setting up our Colab notebook and getting EMADE and conda environment on it
** Link - https://colab.research.google.com/drive/1CTgRr52mTcykxolHUGWYODvbC8gGCZ6N#scrollTo=nKFsz9GLJP-K
* Discussed this research paper this week on adaptive mutations
** Link - https://www.researchgate.net/publication/220117106_A_Genetic_Algorithm_with_Adaptive_Mutations_and_Family_Competition_for_Training_Neural_Networks
** The method they use to perform adaptive mutations is not very usable as it is extremely slow
** Performs extensive mathematical calculations in each iteration makes the process too slow
** No really useful for us, but is definitely an interesting read

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete weekly notebook update
|Completed
|September 21, 2020
|September 28, 2020
|September 25, 2020
|-
|Generating a Pre-Trained Model for EMADE runs
|Completed
|September 21, 2020
|September 28, 2020
|September 26, 2020
|-
|Run preliminary tests on chest x-ray dataset
|In Progress
|September 21, 2020
|October 5, 2020
|
|}

=== '''Conclusions''' ===
* Found a way to generate a pre-trained model.
** https://github.com/vinaya8/Transfer-Learning-on-Chest-X-Ray-Images
** I will be working more with this repository the upcoming week and get some test runs.
* Google Colab setup (in progress)
** Link - https://colab.research.google.com/drive/1CTgRr52mTcykxolHUGWYODvbC8gGCZ6N#scrollTo=nKFsz9GLJP-K

== September 14, 2020 ==

=== '''General Information''' ===
* Complete self-notebook evaluation and put it up on your VIP notebooks.

=== '''Team Meeting Notes''' ===
* General sub-teams updates.
** Stocks
*** 3 major subteams formed
**** Research ML used in trading. (Group A)
**** EMADE integration with Pre-Developed Technical Indicators (Group B)
**** Developing Technical Indicators in EMADE (Group C) (Low Priority until research is substantial)
** EzCGP
*** Research Team
**** Discussed papers they had found
***** In depth discussion on one paper each
**** Get papers distilled down to 3-5 by Sep 17 meeting
*** Implementation Team
**** Finished converting primitives
**** Tested run on multi-gaussian test problem
**** Created guidelines for the team's code development workflow
** NLP
*** Reading and finding more academic papers to draw inspiration from
*** Worked on Colab and getting EMADE set up on it
*** CV team resloving issues with PACE
** Modularity
*** Start looking into ways to improve our selection method for individuals and ARLs
**** Improve our tournament select modification from last semester (~1-2 weeks)
***** Potentially conflicting crowding distance and ARLs i.e. may be working against each other
***** After gaining more insights from analysis, find a way to make ARL individuals more prevalent
**** Limiting ARLs to only return an EmadeDataPair (~1-2 weeks)
***** Will hopefully act on more useful primitives that actually modify the data

=== '''Sub-Team Notes''' ===
* My main goals for this week is:
** Finding GitHub repositories for a pre-trained model
*** I did some research and found a really good Github repository
**** This was the best one out of the Github repositories that I found
**** It has a pretrained model on chest xray data that we can use for seeding - https://github.com/paloukari/NIH-Chest-X-rays-Classification
** Running seeding tests on the chest x-ray dataset on PACE
* Updated subteam goals
** https://docs.google.com/document/d/1jrezh0mv2DKAzgtlhbHza7O9h7FKutCCPlP5enfTmP4/edit
* A few additional GitHub repositories I found for a pre trained Chest Xray dataset that can be used for seeding
** https://github.com/rohanpillai20/Image-Classification-by-Keras-and-Tensorflow
** https://github.com/gregwchase/nih-chest-xray
** https://github.com/paloukari/NIH-Chest-X-rays-Classification
* Ran into unexpected conda environment issues on PACE
** Due to the new path changes on PACE, a lot of conda commands are erroring out
** Ran into "disk quota exceeded" errors
*** Deleted unnecessary .git files etc. that were taking up too much space
** Fixed it by deleting the old conda env and re-installed a new one on PACE
** Anuraag got this weird error on PACE
***We were unable to resolve it this week and push it to the next[[files/PACE Error.png|alt=PACE Error|center|thumb|716x716px|PACE Error]]
* Started preliminary work on performing a seeded run on the chest x-ray dataset
* The research sub-team discussed the following paper they found
** Neuroevolutionary learning papers
** Link - https://link.springer.com/article/10.1007/s005000000042

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete weekly notebook update
|Completed
|September 14, 2020
|September 21, 2020
|September 18, 2020
|-
|Find GitHub repositories for a pretrained model
|Completed
|September 14, 2020
|September 21, 2020
|September 20, 2020
|-
|Complete self notebook evaluation
|Completed
|September 14, 2020
|September 21, 2020
|September 19, 2020
|-
|Skim through the following paper: https://link.springer.com/article/10.1007/s005000000042
|Completed
|September 14, 2020
|September 21, 2020
|September 20, 2020
|-
|Conda environment fix on PACE
|Completed
|September 14, 2020
|September 21, 2020
|September 18, 2020
|-
|Run seeding tests on chest x-ray dataset
|In Progress
|September 14, 2020
|September 28, 2020
|
|}

=== '''Conclusions''' ===
* Completed self notebook evaluation
* Found 3 GitHub repositories which can be used as a frame of reference while running tests on the chest x-ray dataset
* Started preliminary work on performing a seeded run on the chest x-ray dataset

== September 7, 2020 ==

=== '''General Information''' ===
* None

=== '''Team Meeting Notes''' ===
* None - Labor Day Holiday

=== '''Sub-Team Notes''' ===
* Switched to NLP-NN branch, re-cloned it and set it up on PACE
*Ran into some SQL errors involving privileges
** The new paths messed up the MySQL stuff and it was constantly erroring out
* Uploaded a smaller amount of the Chest X-Ray CV dataset onto PACE
** Did not modify .cnf or .pbs files, but changed the paths to the log and pid files
** Ran initial test on 2500 images only as a preliminary test
** Script file used to take a fraction of the data and create a new csv file with a fraction of the data
***I used this script to reduce the large amount of data into a smaller fraction to perform a preliminary run on EMADE[[files/Fractioning Script File.png|alt=Fractioning Script File|center|thumb|424x424px|Fractioning Script File]]
* Finding GitHub Repositories for a pretrained model
* I will be working more on seeding individuals into the dataset before I perform my next run
* I also looked into the transfer learning concept
** I will be on the lookout for github repositories that contain pretrained models with which we can seed our model
** This is to get better results and have a better sense of how we want to implement our CV applications

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete weekly notebook update
|Completed
|September 7, 2020
|September 14, 2020
|September 11, 2020
|-
|Resolved the new MySQL errors
|Completed
|September 7, 2020
|September 14, 2020
|September 11, 2020
|-
|Do preliminary run on chest x-ray dataset (on 2500 images)
|Completed
|September 7, 2020
|September 14, 2020
|September 12, 2020
|-
|Find GitHub Repositories for a pretrained model
|In Progress
|September 7, 2020
|September 14, 2020
|
|}

=== '''Conclusions''' ===
* Ran initial preliminary test on 2500 images of the chest x-ray dataset
* Resolved some other MySQL errors on PACE

== August 31, 2020 ==

=== '''General Information''' ===
* None

=== '''Team Meeting Notes''' ===
* General sub-teams updates.
** Stocks
*** 3 major subteams formed
**** Research ML used in trading. (Group A)
**** EMADE integration with Pre-Developed Technical Indicators (Group B)
**** Developing Technical Indicators in EMADE (Group C) (Low Priority until research is substantial)
** EzCGP
*** Splitting into 2 subgroups, currently 2 people per group,
**** Research and new features sub-team: focuses on researching ideas to implement into ezCGP
***** Each member is finding 15-20 papers each by next meeting, and then be cut down to around 3-5 to work on actual implementation.
**** Code maintenance: works to maintain the current code base and establish baseline performance
***** The second group will work on getting the current code base evolving consistently and well to establish a benchmark for how the current framework runs.
** NLP
*** Short Term Goals:
**** Set up Google Colab for short EMADE runs to experiment and test
**** Explore out files from recent EMADE runs on toxicity dataset to see what model structures are on pareto front and are there any types that don't feature and why
**** Adding hyperparameters and optimizers to be evolved
**** Explore new mutation functions that can be added
**** Explore crossing over of layer lists as a mating function
**** Explore the chest x-ray dataset and create potential models as a baseline reference for beginning of semester.
**** Define requirement for functions that need to be added to EMADE to facilitate CV tasks
**** Explore adding new word embedding system like ELMO or BERT
** Modularity
*** Fixing bugs from the previous semesters.
*** Reading literature and papers
**** GECCO papers and with a focus on novelty and modifying the evolutionary process

=== '''Sub-Team Notes''' ===
* Ran into path issues on PACE and .cnf file
** I made the necessary changes to the .cnf file to fit the new format
*** I shared this .cnf file with the other members of the team which they can straight use for their PACE setup
***[[files/PACE new cnf file.png|alt=PACE new cnf file|center|thumb|443x443px|PACE new cnf file]]
** Environment .yml files
***Environment .yml file 1[[files/Environment .yml file 1.png|alt=Environment .yml files 1|center|thumb|318x318px|Environment .yml files 1]]
*** Environment .yml file 2
***[[files/Environment .yml file 2.png|alt=Environment .yml file 2|center|thumb|497x497px|Environment .yml file 2]]
** Ensure PACE is up and running with respect to seeding to run preliminary tests
** Path issues realted to conda environment arising from PACE update
*** Solution: I fixed it by removing and reinstalling conda environment on PACE
*** This method worked for other team members as well
* On the look for some Machine Learning papers and Github repositories for inspiration and direction with our Chest X-Ray CV dataset
** On the look for a pretrained model to run tests
* I found some papers/github repos that may come in handy in improving EMADE performance for our task.
** To be discussed in the next sub-team meeting
* Friday meetings would generally be to update our subgroups (ie. updating the CV group) on our progress
** Decided to hold sessions with the entire NLP subteam in order to share important ML papers and github repos that we researched and found
*** May come in handy when adding certain functionalities and features into EMADE in order to improve our accuracy of our results

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete weekly notebook update
|Completed
|August 31, 2020
|September 7, 2020
|September 4, 2020
|-
|Find New Datasets
|Completed
|August 31, 2020
|September 7, 2020
|September 4, 2020
|-
|Edit .cnf file on PACE and reslove path issues
|Completed
|August 31, 2020
|September 7, 2020
|September 2, 2020
|-
|Finding some papers/github repos that may come in handy in improving EMADE performance for our task
|Completed
|August 31, 2020
|September 7, 2020
|September 2, 2020
|-
|Do preliminary run on chest x-ray dataset
|In Progress
|August 31, 2020
|September 7, 2020
|
|}

=== '''Conclusions''' ===
* Resolved a lot of PACE issues and got it to a point where I need to test it by running preliminary tests on it.
* I found some papers/github repos that may come in handy in improving EMADE performance for our task.
** To be discussed in the next sub-team meeting

== August 24, 2020 ==

=== '''General Information''' ===
* General sub-teams updates.
** Stocks
*** ML used in trading
*** EMADE integration with Pre-Developed indicators
*** Developing original technical indicators in EMADE (put on hold until group is more grounded)
** EzCGP
*** Group that works on maintaining the current repository and improving the work that has been done so far
*** Group for researching and creating new features to incorporate into EzCGP
** NLP
*** Went over what the team (Anish and Pulak) did over the summer with respect to EMADE.
*** CV Dataset
**** Chest XRay dataset (CIFAR-10 and Chest X-Ray)
** Bloat
*** Merged with the Modularity sub-team
** Modularity (AFD)
*** The instructions for setting up PACE to run with EMADE are not exactly working the way that they are currently
*** These issues were faced by everyone on the team
*** Edits must be made to the mycnf file in order to resolve issues in the path

=== '''Team Meeting Notes''' ===
* Subteam formation/selection process.
** I will be continuing with the NLP subteam for this semester.
* Discussed meeting times and received sub-team updates.

=== '''Sub-Team Notes''' ===
* Working on Colab file and solving some issues that came up.
** https://colab.research.google.com/drive/1Hn-nMMNj3R922A_HFelQJwShatdfeONl?usp=sharing
* Received general updates from the various NLP sub-teams.
* Split into a different CV sub-team meeting.
** Train EMADE on the chest X-Ray dataset.
*** Decided on using PACE for training and runs on EMADE.
**** Potentially use Transfer Learning for this.
**** Need to discuss more details with Pulak, Anish, and even Dr. Zutty.
**** The experienced members worked together to introduce the document created last semester for PACE setup and installations
***** Newer members could be caught up to speed with all of the installation and prep work needed in order to run EMADE on PACE
****** Link to the PACE documentation - https://docs.google.com/document/d/1VIv4EM1KhaUToZpEhKNx3lQs-Hu7QSOk4VEqZcx2tIs/edit?usp=sharing
*** Helped some team members set up PACE, EMADE and Anaconda.
**** [https://meet.google.com/linkredirect?authuser=0&dest=https%3A%2F%2Fdocs.google.com%2Fdocument%2Fd%2F1VIv4EM1KhaUToZpEhKNx3lQs-Hu7QSOk4VEqZcx2tIs%2Fedit https://docs.google.com/document/d/1VIv4EM1KhaUToZpEhKNx3lQs-Hu7QSOk4VEqZcx2tIs/edit]
*** Familiarize ourself with the Chest X-Ray dataset and Cifar 10 dataset.
*CV Team Notes:
** We decided that Anuraag would be in the best position to head the CV team
*** Responsibilities: Relay information between team members and Pulak and Anish(and the rest of the NLP team)
**** Pulak would then be able to add the CV team updates in with the rest of the NLP team updates when updating Dr. Zutty and other teams in our weekly Monday meetings
** The CV team discussed our to-dos:
*** We decided that we would be using PACE for training and EMADE runs rather than Colab
**** Colab recycles often and therefore we would have to repeatedly run our trials
*** Logging into PACE and ensuring environment setup
*** Training EMADE on chest x-ray dataset
**** Noted that we could potentially make use of Transfer Learning
*** We wanted to share these updates with Dr. Zutty at our next general meeting

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete weekly notebook update
|Completed
|August 24, 2020
|August 31, 2020
|August 28, 2020
|-
|Start setting up EMADE on Colab
|Completed
|August 24, 2020
|August 31, 2020
|August 29, 2020
|-
|Work on the Colab file
|Completed
|August 24, 2020
|August 31, 2020
|August 29, 2020
|-
|Fix some issues on the Colab file
|Completed
|August 24, 2020
|August 31, 2020
|August 29, 2020
|-
|Studied up about transfer learning
|Completed
|August 24, 2020
|August 31, 2020
|August 30, 2020
|-
|Get familiarizing with the Chest X-Ray dataset
|Completed
|August 24, 2020
|August 31, 2020
|August 30, 2020
|-
|Get familiarizing with the Cifar 10 dataset
|Completed
|August 24, 2020
|August 31, 2020
|August 30, 2020
|-
|Finding some papers/github repos that may come in handy in improving EMADE performance for our task
|In Progress
|August 24, 2020
|August 31, 2020
|
|}

=== '''Conclusions''' ===
* Worked on the Colab file and fixed some errors.
* Got familiar with the Chest X-Ray and Cifar 10 datasets.
* Helped some team members to set up PACE, EMADE, Anaconda, SQL, etc.
* Read about transfer learning and other potential methods to train EMADE.

== August 17, 2020 ==

=== '''General Information''' ===
* General course syllabus review.

=== '''Team Meeting Notes''' ===
* Subteam formation/selection process.
** I will be continuing with the NLP subteam for this semester.
** This will be my 3rd semester with the NLP-NN team
** I will be working on CV Sub-team along with Tushna, Anuraag, Sanket and Vietfu.
* Discussing potentially new teams and reforming existing teams.
** Starting the stocks team?

=== '''Sub-Team Notes''' ===
* NLP Sub-Team meeting minutes - https://docs.google.com/document/d/1jrezh0mv2DKAzgtlhbHza7O9h7FKutCCPlP5enfTmP4/edit
* Did team introductions and discussed the progress that occured within NLP over the summer so that the entire team is caught up to speed
* I had proposed ideas for new CV primitives that could be very useful if we wanted to achieve accuracy mentioned in our target paper
** Target Paper - https://arxiv.org/pdf/1902.06827.pdf
** My Ideas:
*** Analyze the spatial_methods, signal_methods, and feature_extraction in EMADE
*** Add more primitives and threshold calculation functions to improve accuracy
*** My idea came from how we improved our NLP performance from last semester with the help of additional primitives that I and the other team members created
* Tasks that NLP team is working on -
** Get Colab working for NN branch
** Finding good individuals
** Neural Network team
*** Elmo
*** Bert
*** GPT2 / GPT3
** Evolutions team
*** Concatenate layers
*** New mutation functions
*** New mating functions
*** Get graphs into EMADE
** CV Dataset
*** Chest Xray dataset - https://www.kaggle.com/nih-chest-xrays/data
*** Cifar 10 / Cifar 100
*** Get a better benchmark dataset
*** Get the dataset integrated into EMADE

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete weekly notebook update
|Completed
|August 17, 2020
|August 24, 2020
|August 21, 2020
|-
|Get PACE up to date and running
|Complete
|August 17, 2020
|August 24, 2020
|August 21, 2020
|-
|General setup for NLP this semester
|Complete
|August 17, 2020
|August 24, 2020
|August 21, 2020
|-
|Getting up to speed with where we left of last semester
|Complete
|August 17, 2020
|August 24, 2020
|August 21, 2020
|-
|Read the CV dataset paper
|Complete
|August 20, 2020
|August 24, 2020
|August 23, 2020
|-
|Glance through the CV X-Ray dataset
|Complete
|August 20, 2020
|August 24, 2020
|August 23, 2020
|}

=== '''Conclusions''' ===
* I will be working on CV Sub-team along with Tushna, Anuraag, Sanket and Vietfu.

== April 20, 2020 ==

=== '''General Information''' ===
* Final Presentation Day
** Presentation Link - https://docs.google.com/presentation/d/1z6_uYlpC92xIy1ODrbQTgLnqIZoJwgYI5h0_WMFlwSk/edit#slide=id.p 

=== '''Team Meeting Notes''' ===
* ADF (Automatically Defined Functions)
** Improve EMADE by reusing useful subtrees of individuals.
** Added an additional ADF process in the regular genetic process.
** Subteam Projects
*** Primitive Analysis
**** How ADF's should find 'useful' components in individuals.
*** ADF Selection
*** Differential Fitness
**** Different methods to optimize the search space in genetic programming.
* Research Fundamentals
** Main Goal: Bloat reduction in individuals.
*** Make it run faster.
*** Easier to interpret the tree.
** Technique used: Neat GP
*** Speciation
**** Different speciation thresholds.
**** Speciation threshold 0.15 - No statistically significant increase in both hypervolume and bloat.
**** Speciation threshold 0.3 - Statistically significant increase in both hypervolume and bloat.
**** Speciation threshold 0.6 - Statistically significant increase in hypervolume, but not much in bloat.
* NLP
** Neural Network Subteam
*** Compare to paper - "Evolutionary Neural AutoML for Deep Learning"
*** Primitives
**** ReluLayer - activation function that outputs the input for positive inputs and 0 for negative inputs.
**** ELU (Exponential Linear Unit)
**** SeLU (Scaled Exponential Linear Unit)
**** Dropout - regularization method
**** GloVe Embedding
*** Datasets worked
**** Toxicity dataset (Multilabel problem)
**** Xray Scan dataset
*** Text Classification
**** Vecotrizers
**** Sentiment Analysis
**** Stemmatizers
* NLP Time-Conflict
** My subteam.
** General Intro Slides
***Introduction Slide[[files/Introduction Final Presentation.png|alt=Introduction Final Presentation|center|thumb|596x596px|Introduction Final Presentation]]
***Team Goals[[files/Goals Final Presentation.png|alt=Goals Final Presentation|center|thumb|596x596px|Goals Final Presentation]]
***Results[[files/Results Final Presentation.png|alt=Results Final Presentation|center|thumb|596x596px|Results Final Presentation]]
* EZCGP
** Evolutionary Parameters
*** Ran for 39 generations for about 41 hours.
*** Got better test accuracies.
** VCG-16
*** 16-layer Convolutional Neural Network
*** 10 epochs
*** Test Accuracy: 66.32%
** LeNet-5
*** 10 epochs
*** Test Accuracy: 62.72%
** Several other architectures and accuracies discussed.

=== '''Sub-Team Notes''' ===
* Final Presentation
** Fixed timeslot for NLP Time-Conflict team presentation.
** Updated my slides with the latest edits of num_named_entities primitive.
** Rehearsed and went over the topics for my presentation slides.

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish the Final Presentation
|Completed
|April 17, 2020
|April 20, 2020
|April 19, 2020
|-
|Present our results on Final Day
|Completed
|April 20, 2020
|April 20, 2020
|April 20, 2020
|-
|Complete VIP notebook
|Completed
|April 20, 2020
|April 21, 2020
|April 24, 2020
|}

=== '''Conclusions''' ===
* Ran EMADE on PACE to get results to present for final presentation.
** Presentation Link - https://docs.google.com/presentation/d/1z6_uYlpC92xIy1ODrbQTgLnqIZoJwgYI5h0_WMFlwSk/edit#slide=id.p
** Some important slides.
***num_named_entities introduction slide
****What the primitive does and explaining general intuition behind the primitive.[[files/Num named entities 1.png|alt=num_named_entities 1|center|thumb|605x605px|num_named_entities 1]]
***num_named_entities primitive[[files/Num named entities 2.png|alt=num_named_entities 2|center|thumb|604x604px|num_named_entities 2]]
***num_named_entities tasks performed this semester.[[files/Num named entities 3.png|alt=num_named_entities 3|center|thumb|602x602px|num_named_entities 3]]
* Ran statistical analysis tests on the obtained data from the EMADE runs.
** Incorporates results from different combinations of primitives used.
** Used to address the use of a primitive and whether it makes the classification any more accurate.
** Results presented.
***Results 1 - Baseline testing data after EMADE runs.[[files/Results 1.png|alt=Results 1|center|thumb|604x604px|Results 1]]
***Results 2 - Accuracy Scores vs Generation graphs for num_named_entities and tfisf primitives.[[files/Results 2.png|alt=Results 2|center|thumb|605x605px|Results 2]]
***Results 3 - Some best performing individuals that we got from the EMADE runs.[[files/Individuals from the primitives.png|alt=Individuals from the primitives|center|thumb|605x605px|Individuals from the primitives]]
***Results 4 - Runtime analysis
****num_named_entities takes approximately 10 minutes to run.
****tfisf takes over 2 hours to run.[[files/Results 3.png|alt=Results 3|center|thumb|611x611px|Results 3]]

== April 17, 2020 ==

=== '''General Information''' ===
* Complete Final Peer evaluation.
* Prepare for Final Presentation.
** Set up a meeting time with Dr. Rohling to go over our final presentation.
** Sunday, 19th April - 5:00pm to 6:00pm 

=== '''Team Meeting Notes''' ===
* Updated Jason and Greg on our progress this week.
** Discussed some potential errors with them and possible resolutions to those errors.
* Finalized discussion regarding the statistical analysis.
** Decided upon what statistical analysis would best represent our work.

=== '''Sub-Team Notes''' ===
* Met with Alex, Anuraag and Zach and worked through some last minute changes.
**Statistical Analysis Method[[files/Stats analysis method.png|alt=stats_analysis method|center|thumb|527x527px|stats_analysis method]]
* Discussed our final plans.
* VIP Wiki guide to using PACE.
** Link - [[Guide to Using PACE]]
* Added (by Alex) a new evaluation method called accuracy_score_multi in eval_methods.py
** Multi-dimensional data-objective.
***Using this to evaluate our accuracy in each EMADE run.[[files/Accuracy score multi.png|alt=accuracy_score_multi|center|thumb|545x545px|accuracy_score_multi]]
**Multi-dimensional data-classifier.
***[[files/SVC Classifier.png|alt=SVC Classifier|center|thumb|542x542px|SVC Classifier]]
* Started working on our final presentation.
* New MySQL I started running into and its relatively easy fixes:
** Error : (1130, "Host '[http://rich133-h35-7-l.pace.gatech.edu/ rich133-h35-7-l.pace.gatech.edu]' is not allowed to connect to this MySQL server")
***[[files/Worker Error File - Permission Denied.png|alt=worker.err file - Permission Denied|center|thumb|554x554px|worker.err file - Permission Denied]]
** Fix: ssh into your MySQL server and run this command.
*** UPDATE mysql.user SET Host='%' WHERE Host='localhost';
***This sets host to whatever node your process have been assigned to.[[files/MySQL permission denied fix.png|alt=MySQL permission denied fix|center|thumb|546x546px|MySQL permission denied fix]]
** Also, always remember to flush privileges after any change to the MySQL server.
***Once you run: flush privileges;
***You can run show grants;
***This image shows that all privileges and access has been given to your root user. If you don't do this, it will result in permission denied errors that can be seen in master.err and worker.err files.[[files/Permission Grants.png|alt=Permission Grants|center|thumb|860x860px|Permission Grants]]
*SCP files after EMADE run to local device[[files/SCP Data-Result Files to Local Device.png|alt=SCP Data/Result Files to Local Device|center|thumb|810x810px|SCP Data/Result Files to Local Device]]

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Peer Evaluation
|Completed
|April 10, 2020
|April 29, 2020
|April 17, 2020
|-
|Accumulate all the results from our individual runs
|Completed
|April 10, 2020
|April 20, 2020
|April 17, 2020
|-
|Get worker.out and master.out files from running num_named_entities
|Completed
|April 10, 2020
|April 20, 2020
|April 18, 2020
|-
|Get other files like paretoFitness, paretoFront, parentSummaries etc.
|Completed
|April 10, 2020
|April 20, 2020
|April 18, 2020
|-
|Generate statistical analysis results from the data obtained
|Completed
|April 10, 2020
|April 20, 2020
|April 19, 2020
|-
|Start working on the Final Presentation
|In Progress
|April 17, 2020
|April 20, 2020
|
|}

=== '''Conclusions''' ===
* Ran EMADE on PACE to get results to present for final presentation.
**master.out file from running num_named_entities[[files/Master.out file.png|alt=master.out file|center|thumb|748x748px|master.out file]]
**worker.out file from running num_named_entities[[files/Worker.out file.png|alt=worker.out file|center|thumb|749x749px|worker.out file]]
* Ran statistical analysis tests on the obtained data from the EMADE runs.
** Incorporates results from different combinations of primitives used.
** Used to address the use of a primitive and whether it makes the classification any more accurate.
**FN, FP, TP, TN, MIN, MAX, AVG values for the primitives[[files/FN, FP, TP, TN, MIN, MAX, AVG values for the primitives.png|alt=FN, FP, TP, TN, MIN, MAX, AVG values for the primitives|center|thumb|654x654px|FN, FP, TP, TN, MIN, MAX, AVG values for the primitives]]
**Accuracy Score vs Generations Graph - for num_named_entities and tfisf primitive[[files/Accuracy Score vs Generations Graph.png|alt=Accuracy Score vs Generations Graph|center|thumb|648x648px|Accuracy Score vs Generations Graph]]
**Some best Individuals from running num_named_entities primitive on EMADE.[[files/Best Individuals.png|alt=Best Individuals|center|thumb|651x651px|Best Individuals]]

== April 10, 2020 ==

=== '''General Information''' ===
* Discussed next steps and future goals.
* Planning what sort of statistical analysis we need to do.
** Discussing on what data we need to suit those statistical analysis needs.
* Start running a combination of our primitives and measure these results.
** To verify if these primitives are yielding beneficial for the selection process.
** Are they helping to get accurate results?

=== '''Team Meeting Notes''' ===
*Alex made Google Doc with instructions on EMADE PACE Setup.
** Link - https://docs.google.com/document/d/1VIv4EM1KhaUToZpEhKNx3lQs-Hu7QSOk4VEqZcx2tIs/edit?usp=sharing
** General Information to start up PACE.[[files/Pace 1.png|alt=Pace 1|center|thumb|613x613px|Pace 1]]
**Starting the MySQL servers, ssh'ing into our specific nodes and setup up the databases[[files/Pace 2.png|alt=Pace 2|center|thumb|629x629px|Pace 2]]
*We also made templates for out two essential pbs scripts that help to get the MySQL servers started and actually qsub our job on EMADE.
**Template for MySQL config file .my.cnf
***[[files/Template .my.cnf.png|alt=Template .my.cnf|center|thumb|446x446px|Template .my.cnf]]
**Template for pbsmysql.pbs (start the MySQL server)
***[[files/Template pbsmysql.pbs.png|alt=Template pbsmysql.pbs|center|thumb|361x361px|Template pbsmysql.pbs]]
**Template for runEmade.pbs
***This is used to qsub the actully job that we want to run after kickstarting the MySQL server.
***[[files/Template runEmade.pbs.png|alt=Template runEmade.pbs|center|thumb|508x508px|Template runEmade.pbs]]

=== '''Sub-Team Notes''' ===
* Finished setting up everything needed for MySQL and EMADE.
* Met with Alex, Anuraag and Tushna and fixed all the issues we had.
* Ran my primitive num_named_entities on PACE and got desired master.out and worker.out files with the data that we need for our statistical analysis.
* Discussed about our final plans regarding the statistical analysis.
* Spoke about our final presentation.
* Some MySQL errors:
** We had to experiment with several SQL commands to make sure EMADE works.
** We found out that multiple people cannot run SQL at the same time on the same port.
*** [[files/MySQL Port Error.png|alt=MySQL Port Error|center|thumb|453x453px|MySQL Port Error]]
** Team members chose their own ports and added them to the .my.cnf file.
** We also had to update the template .xml files accordingly (with new port).
***[[files/Changes Needed.png|alt=Changes Needed|center|thumb|803x803px|Changes Needed]]
** I also ran into 'Access Denied' errors and other errors in relation to MySQL.
*** The user 'root' on my computer did not have a password, which was a problem.
*** To fix this, I had to follow these steps:
*** I ran the command: FLUSH PRIVILEGES;
*** I ran the command: UPDATE USER SET password=password('password') where USER='root';
*** I then ran Flush Privileges again.
*** These steps allowed me to get MySQL properly running with access for the user root with password 'password'.
** We also decided to clear the database between EMADE runs to not pollute it too much.
*** This was done by flushing the database for every new run.
** Changed EMADE.py to use only my primitive num_named_entities.
***Original Unchanged:[[files/Unchanged.png|alt=Unchanged|center|thumb|803x803px|Unchanged]]
*** Changed version:[[files/Changed.png|alt=Changed|center|thumb|801x801px|Changed]]
** Changed input_summaries.xml template file to set the correct host server, node and port being used.
***[[files/Template File - input summaries.xml.png|alt=Template File - input_summaries.xml|center|thumb|807x807px|Template File - input_summaries.xml]]

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Setup MySQL root user and password
|Completed
|April 10, 2020
|April 17, 2020
|April 13, 2020
|-
|Make changes to EMADE.py in GPFramework
|Completed
|April 10, 2020
|April 17, 2020
|April 13, 2020
|-
|Make change to input_summaries.xml template file
|Completed
|April 10, 2020
|April 17, 2020
|April 13, 2020
|-
|Create runEmade.pbs script to run my primitive on EMADE
|Completed
|April 10, 2020
|April 17, 2020
|April 15, 2020
|-
|Run my primitive and get master.out, worker.out and paretodata data
|Completed
|April 10, 2020
|April 17, 2020
|April 16, 2020
|}

=== '''Conclusions''' ===
* Final version of all the pbs script files used.
**pbsmysql.pbs[[files/Final Version pbsmysql.pbs.png|alt=Final Version pbsmysql.pbs|center|thumb|694x694px|Final Version pbsmysql.pbs]]
**runEmade.py[[files/Final Version runEmade.pbs.png|alt=Final Version runEmade.pbs|center|thumb|695x695px|Final Version runEmade.pbs]]
* Proof of tasks submitted on PACE
**[[files/Final qsub.png|alt=Final qsub|center|thumb|691x691px|Final qsub]]

== April 3, 2020 ==

=== '''General Information''' ===
* Distance learning format testing out.
* Discussed next steps and future goals.

=== '''Team Meeting Notes''' ===
* Alex noticed some errors with my primitive num_named_entities.
** Timing out when running (taking too long to run)
** Made some optimizations and reduced the number of times we are accessing the entire EMADE datapair.
** Scipy methods are really time intensive.
*** Replaced the old scipy classification method with a newer version of it which basically does the same thing.
*** Optimized when we are making this method call so that it makes the method call only when needed.
*** This has boosted the runtime of this primitive and doesn't give timeout errors.

=== '''Sub-Team Notes''' ===
* Team has made a lot of progress in the last week with regard to getting EMADE on PACE.
* Discussed splitting up workload and assigned individual responsibilities.
** Group 1 - Some of us run with primitives on EMADE to get results and data.
** Group 2 - Some of us take results and data to perform meaningful statistical analysis.
* Alex made Google Doc with instructions on EMADE PACE Setup.
** Link - https://docs.google.com/document/d/1VIv4EM1KhaUToZpEhKNx3lQs-Hu7QSOk4VEqZcx2tIs/edit?usp=sharing[[files/Pace 1.png|alt=Pace 1|center|thumb|613x613px|Pace 1]]
* PACE documentation to support MySQL.
** Link - https://docs.pace.gatech.edu/software/mysql/

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Debugging num_named_entities to help it spit out data in the desired way
|Completed
|April 3, 2020
|April 10, 2020
|April 7, 2020
|-
|Fix SQL Errors
|Completed
|April 3, 2020
|April 10, 2020
|April 7, 2020
|-
|Start running MySQL queries
|Completed
|April 3, 2020
|April 10, 2020
|April 8, 2020
|}

=== '''Conclusions''' ===
* Ran into a couple of MySQL errors and managed to debug and fix all of them.

* SQL Error 1.
** It can't find mysql.plugin as the version is not upgraded. To fix this issue, I need to run mysql --upgrade. But for this to work, I need the MySQL server started and it won't start without fixing this error.
** So as you can see, this is a cyclic error.
** FIX: https://ma.ttias.be/mysql-table-mysql-plugin-doesnt-exist-after-mysql-upgrade/
*** Used the solution given on this website and this fixed the version error.[[files/MySQL version error.png|alt=MySQL version error|center|thumb|827x827px|MySQL version error]]
* MySQL Error 2.
** Permission denied when tring to enter the MySQL server.
** FIX: You need to run `mysql -u root` or something along those lines to make changes to databases, as you’ll need root privileges[[files/MySQL Error Permission.png|alt=MySQL Error Permission|center|thumb|638x638px|MySQL Error Permission]]
*Proof of MySQL completely setup and working.
**[[files/MySQL Proof.png|alt=MySQL Proof|center|thumb|636x636px|MySQL Proof]]

== March 27, 2020 ==

=== '''General Information''' ===
* Distance learning format testing out.
* Discussed next steps and future goals.

=== '''Team Meeting Notes''' ===
* Resolving technical issue arising form the online format.
** Got AnyConnect VPN working to access pace off campus.
* MySQL errors debugging.
** Fixed all the old errors arising from the config and pbs script files.
** Still new MySQL errors arising that needs to be fixed.

=== '''Sub-Team Notes''' ===
* None

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get VPN connected and working for PACE acces
|Completed
|March 27, 2020
|April 3, 2020
|March 29, 2020
|-
|Fix SQL Errors
|In Progress
|March 27, 2020
|April 3, 2020
|
|}

=== '''Conclusions''' ===
* Ran into this MySQL error.
** It can't find mysql.plugin as the version is not upgraded.
** To fix this issue, I need to run mysql --upgrade.
** But for this to work, I need the MySQL server started and it won't start without fixing this error.
** So as you can see, this is a cyclic error. [[files/MySQL version error.png|alt=MySQL version error|center|thumb|827x827px|MySQL version error]]

== March 10, 2020 - March 26, 2020 ==

=== '''General Information''' ===
* Spring Break (extended spring break)

== March 9, 2020 ==

=== '''General Information''' ===
* Midterm Presentation Day
** Presentation Link - https://docs.google.com/presentation/d/1pHF3fIhblYOS1TLtuORmHh5DDBoqpQEuYQdHitaXcfo/edit#slide=id.p

=== '''Team Meeting Notes''' ===
* None

=== '''Sub-Team Notes''' ===
* Since we were running into several issues with PACE, MySQL and other stuff, we decided to run EMADE locally.
** Ran EMADE locally successfully.
** Based our presentation on these results.

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run EMADE locally to get results
|Completed
|March 6, 2020
|March 9, 2020
|March 7, 2020
|}

=== '''Conclusions''' ===
* Ran EMADE locally to get results to present for midterm presentation.
* Some general information presentation slides.
**[[files/Presentation Slide 1.png|alt=Presentation Slide 1|center|thumb|477x477px|Presentation Slide 1]][[files/Presentation Slide 2.png|alt=Presentation Slide 2|center|thumb|479x479px|Presentation Slide 2]][[files/Presentation Slide 3.png|alt=Presentation Slide 3|center|thumb|479x479px|Presentation Slide 3]]
* My presentation slides.
**[[files/Presentation Slide 4.png|alt=Presentation Slide 4|center|thumb|480x480px|Presentation Slide 4]][[files/Presentation Slide 5.png|alt=Presentation Slide 5|center|thumb|480x480px|Presentation Slide 5]][[files/Presentation Slide 6.png|alt=Presentation Slide 6|center|thumb|484x484px|Presentation Slide 6]][[files/Presentation Slide 7.png|alt=Presentation Slide 7|center|thumb|483x483px|Presentation Slide 7]]

== March 6, 2020 ==

=== '''General Information''' ===
* Worked on team presentation - coming Monday
* Made .my.cnf file for MySQL setup - config file
* Created pbsmysql.pbs file - used to kickstart the MySQL server

=== '''Team Meeting Notes''' ===
* Midterm Presentation
** Fixed timeslot for NLP Time-Conflict team presentation
** Updated my sildes with the latest edits of num_named_entities primitive
** Rehearsed and went over the topics for my presentation slides.

=== '''Sub-Team Notes''' ===
* Made edits to the .my.cnf config file to match with our requirements
**Configuration file for MySQL[[files/.my.cnf MySQL config file.png|alt=.my.cnf MySQL config file|center|thumb|654x654px|.my.cnf MySQL config file]]
* Crated a pbs script called pbsmysql.pbs
** It is used to start the MySQL server up.
**Can ssh into the node and see if the database is loaded correctly and can populate correctly.[[files/Pbsmysql.pbs script file.png|alt=pbsmysql.pbs script file|center|thumb|553x553px|pbsmysql.pbs script file]]

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Configuration file for MySQL - .my.cnf
|Completed
|March 6, 2020
|March 13, 2020
|March 9, 2020
|-
|Create script file to run MySQL server - pbsmysql.pbs
|Completed
|March 6, 2020
|March 13, 2020
|March 9, 2020
|-
|Midterm Presentation
|Completed
|February 21, 2020
|March 9, 2020
|March 7, 2020
|}

=== '''Conclusions''' ===
* Presentation Link - https://docs.google.com/presentation/d/1pHF3fIhblYOS1TLtuORmHh5DDBoqpQEuYQdHitaXcfo/edit#slide=id.p
* Created configuration file for MySQL - .my.cnf
* Created script file to run MySQL server - pbsmysql.pbs

== February 28, 2020 ==

=== '''General Information''' ===
* PACE is still down and we are unable to get data for our statistical analysis.
* Ran into additional MySQL errors.
* Came up with a documentation for operating EMADE on PACE.

=== '''Team Meeting Notes''' ===
* Since PACE is down, we were brainstorming alternate ideas that we can work on and present results for the midterm presentation.
* environment.yml - Environment requirements for setting up EMADE on PACE
**environment.yml template[[files/Environment Template File.png|alt=Environment Template File|center|thumb|Environment Template File]][[files/Environment Template File pip.png|alt=Environment Template File pip|center|thumb|Environment Template File pip]]
** PACE navigation setup guide
***Start up PACE.
***Load conda environment (already setup).
***scp and sftp command - used to transfer files from local device to PACE and even the other way around.
***dos2unix converter - needed to covert dos file to unix files (essential for pbs script files to run)
***vim commands
***submitting, removing and checking the status of jobs (qsub, qstat, qdel)[[files/Pace Navigation Guide.png|alt=Pace Navigation Guide|center|thumb|Pace Navigation Guide]]

=== '''Sub-Team Notes''' ===
* Start running the primitives on EMADE.
* Get pareto fronts from the runs.

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|environment.yml setup
|Completed
|February 28, 2020
|March 6, 2020
|March 3, 2020
|-
|PACE navigation guide
|Completed
|February 28, 2020
|March 6, 2020
|March 3, 2020
|-
|Midterm Presentation
|In Progress
|February 21, 2020
|March 9, 2020
|
|}

=== '''Conclusions''' ===
* Presentation Link - https://docs.google.com/presentation/d/1pHF3fIhblYOS1TLtuORmHh5DDBoqpQEuYQdHitaXcfo/edit#slide=id.p
* Complete PACE navigation document.
* Set up environment.yml

== February 22, 2020 ==

=== '''General Information''' ===
* Midterm Hackathon
** Worked on team presentation.
** Discussed about our future goals for the first semester VIP students.
** PACE was down the whole weekend so we were unable to run any new tests.

=== '''Team Meeting Notes''' ===
* None

=== '''Sub-Team Notes''' ===
* None

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Midterm Presentation
|In Progress
|February 21, 2020
|March 9, 2020
|
|}

=== '''Conclusions''' ===
* Presentation Link - https://docs.google.com/presentation/d/1pHF3fIhblYOS1TLtuORmHh5DDBoqpQEuYQdHitaXcfo/edit#slide=id.p

== February 21, 2020 ==

=== '''General Information''' ===
* Peer-evals are open.
** Completed peer evaluation.
* Complete and document all progress made in the VIP notebooks.
** Notebook completed for Midterm 1 evaluation.

=== '''Team Meeting Notes''' ===
=== '''Sub-Team Notes''' ===
* Conda environment installed and working in PACE.
* MySQL working on PACE.
* PBS Script for running the unit test completed.
* Created a MySQL pbs script that is able to run with qsub command.

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Installed necessary packages on PACE
|Completed
|February 21, 2020
|February 28, 2020
|February 18, 2020
|-
|PBS Script for running the unit test
|Completed
|February 21, 2020
|February 28, 2020
|February 21, 2020
|-
|MySQL working on PACE
|Completed
|February 21, 2020
|February 28, 2020
|February 18, 2020
|-
|Statistical analysis for text classification team
|Under Progress
|February 21, 2020
|February 28, 2020
|
|-
|PACE unit test
|Completed
|February 21, 2020
|February 28, 2020
|February 19, 2020
|}

=== '''Conclusions''' ===
* MySQL working on PACE.
* Conda Environment setup on PACE.
* Installed additional packages on PACE.
** All the packages on the EMADE Read Me.
* Removed useless EMADE package on PACE.
[[files/PBS Image.png|alt=PBS|center|thumb|615x615px|PBS]]
[[files/PACE EMADE Setup.png|alt=PACE EMADE Setup|center|thumb|617x617px|PACE EMADE Setup]]
[[files/Unit Tests Setup.png|alt=Unit Tests Setup|center|thumb|620x620px|Unit Tests Setup]]
[[files/PBS Edited.png|alt=PBS Edited|center|thumb|621x621px|PBS Edited]]
[[files/Job Submitted Qstat.png|alt=Job Submitted Qstat|center|thumb|623x623px|Job Submitted Qstat]]
[[files/Pace Run Results.png|alt=PACE Run Results|center|thumb|622x622px|PACE Run Results]]

== February 14, 2020 ==

=== '''General Information''' ===
* Peer-evals open coming Monday.
** Ensure to complete it.
* Complete and document all progress made in the VIP notebooks.

=== '''Team Meeting Notes''' ===
=== '''Sub-Team Notes''' ===
* Conda environment installed and working in PACE.
* MySQL working on PACE.
* Created a MySQL pbs script that is able to run with qsub command.
* Installed necessary packages on PACE(some still in progress) Links used in process:
** https://docs.pace.gatech.edu/software/mysql/#mysql-on-pace
** https://docs.pace.gatech.edu/software/anacondaEnv/

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Conda environment setup on PACE
|Completed
|February 14, 2020
|February 21, 2020
|February 17, 2020
|-
|Installed necessary packages on PACE
|Completed
|February 14, 2020
|February 21, 2020
|February 18, 2020
|-
|MySQL working on PACE
|Completed
|February 14, 2020
|February 21, 2020
|February 18, 2020
|-
|Complete unit testing
|Completed
|February 14, 2020
|February 21, 2020
|February 15, 2020
|-
|Statistical analysis for text classification team
|Under Progress
|February 14, 2020
|February 21, 2020
|
|-
|EMADE test and update for unit tests
|Completed
|February 14, 2020
|February 21, 2020
|February 19, 2020
|}

=== '''Conclusions''' ===
* MySQL working on PACE.
* Conda Environment setup on PACE.
* Installed additional packages on PACE.
** All the packages on the EMADE Read Me.
* Removed useless EMADE package on PACE.
[[files/EMADE Run.png|alt=EMADE run of unit test|center|thumb|EMADE run of unit test|582x582px]]
[[files/EMADE Run 2.png|alt=EMADE Run Results|center|thumb|583x583px|EMADE Run Results]]

== February 7, 2020 ==

=== '''General Information''' ===
* Notebook evaluation.
* Midterm 1 evaluation.

=== '''Team Meeting Notes''' ===
=== '''Sub-Team Notes''' ===
* Run EMADE using the individual primitives.
* Run EMADE using a combination of primitives.
** Determine pareto fronts for both and compare.
* Hopefully, improvements will show when all primitives are being used.
* Need to get MySQL working on PACE-ICE.
* https://docs.pace.gatech.edu/software/mysql/

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Testing num_named_entities.py primitive using PACE ICE
|Completed
|February 7, 2020
|February 14, 2020
|February 11, 2020
|-
|Complete unit testing
|Completed
|February 7, 2020
|February 14, 2020
|February 9, 2020
|-
|Statistical analysis for text classification team
|Under Progress
|February 7, 2020
|February 14, 2020
|
|-
|Setup MySQL for PACE-ICE
|Completed
|February 7, 2020
|February 14, 2020
|February 9, 2020
|}

=== '''Conclusions''' ===
* Got MySQL working on PACE-ICE.
* Fixed bugs and logical errors.
* Create a unit testing suite.
* Run it on PACE-ICE.
* Unit test commit to GitHub EMADE nlp-app branch.
** https://github.gatech.edu/emade/emade/blob/nlp-app/src/UnitTests/text_processing_methods_unit_test.py [[files/NNE Unit Test.png|alt=num_named_entities unit test|center|thumb|608x608px|num_named_entities unit test]]

== January 31, 2020 ==

=== '''General Information''' ===
* Pace Ice accounts access give to all.
* Google Cloud is up and running until March.

=== '''Team Meeting Notes''' ===
* Created a key in pace and linked it to the gatech Github in order to run EMADE on PACE-ICE.
* Discussed creating unit tests for each of the primitives to make sure they are effective.

=== '''Sub-Team Notes''' ===
* Links we used to get pace-ice working and create/add PBS script:

* https://pace.gatech.edu/sites/default/files/pace-ice_orientation_1.pdf
* http://latisresearch.umn.edu/creating-a-PBS-script
* https://hpcc.usc.edu/support/documentation/running-a-job-on-the-hpcc-cluster-using-pbs/
* https://pace.gatech.edu/sites/default/files/presentation_spring2020_0.pdf
* https://help.github.com/en/enterprise/2.19/user/github/authenticating-to-github/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Create unit tests for num_named_entities.py primitive
|Completed
|January 31, 2020
|February 7, 2020
|February 7, 2020
|-
|Statistical analysis for text classification team
|Under Progress
|January 31, 2020
|February 7, 2020
|
|-
|PACE ICE setup
|Completed
|January 31, 2020
|February 7, 2020
|February 4, 2020
|}

=== '''Conclusions''' ===
* Perform additional testing for the existing EMADE projects.
* Testing primitive num_named_entities.py
** Fixed bugs and logical errors.
** Create a unit testing suite.
** Run it on PACE ICE.
* Got PACE ICE setup complete.
[[files/PACE Start.png|alt=PACE-ICE Setup|center|thumb|530x530px|PACE-ICE Setup]]

== January 24, 2020 ==

=== '''General Information''' ===
* Pace Ice accounts access give to all.
* Google Cloud is up and running until March.

=== '''Team Meeting Notes''' ===
* Statistics review of hypothesis testing.
** How do we prove we are making changes to EMADE?
** Are improvements due to our changes or randomness?
** AUC accuracy?
* Each person runs their own primitive on EMADE to get analytical values.
** Maybe create a batch script instead.
** Make AUCs with each of our vectorizers and compare vs the overall.
*** Check if the performance gets better with future generation.
*** Does it give a better solution with all the primitives together.
**** Why? Why not?
** Is AUC comparison even a good method for comparison.

=== '''Sub-Team Notes''' ===
* Discussed creating unit tests for each of the primitives to make sure they are effective.

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Make hypothesis tests for NLP text summarization
|Under Progress
|January 10, 2020
|January 31, 2020
|
|-
|Statistical analysis for text classification team
|Under Progress
|January 24, 2020
|January 31, 2020
|
|-
|Updated primitive num_named_entities.py
|Completed
|January 24, 2020
|January 31, 2020
|January 24, 2020
|-
|Test primitive num_named_entities.py
|Completed
|January 24, 2020
|January 31, 2020
|January 24, 2020
|}

=== '''Conclusions''' ===
* Perform additional testing for the existing EMADE projects.
* Make primitives for testing purpose.
[[files/Tusheet NNE.png|alt=Updates made to the num_named_entities primitive|center|thumb|466x466px|Updates made to the num_named_entities primitive]]

== January 17, 2020 ==

=== '''General Information''' ===
* Time conflict meeting time - Fridays, 4pm at Van Leer 483B.
* Pace Ice accounts access give to all.
* Google Cloud is up and running until March.

=== '''Team Meeting Notes''' ===
* Going to use t-statistic to test our hypothesis.
* Develop more primitives to help in testing. the hypothesis.
* Python SciPy library allows us to do hypothesis testing.
** Use SciPy. Stats
** Ttest_ind

* Issues
** We don't have a hypothesis.
** Welch t-test: There is a way to compute t-statistic without a population mean and standard deviation.

* Designing the experiments.
** If we want strong results, we wither need differences in sample means that overwhelm the sample variance, or a high sample number to reduce the effect of variance.
** If we can get this, we can assure that we have made significant improvements to NLP using the EMADE framework.

=== '''Sub-Team Notes''' ===
* Decided time conflict meeting time/place.
* Come up with hypothesis tests for NLP.
* Monitor future goals to fit to these hypothesis tests. 

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Make hypothesis tests for NLP text summarization
|Under Progress
|January 10, 2020
|January 24, 2020
|
|-
|Statistical analysis for text classification team (brainstorming ideas)
|Under Progress
|January 17, 2020
|January 24, 2020
|
|}

=== '''Conclusions''' ===
* Perform additional testing for the existing EMADE projects.
* Monitor future goals with these new testing techniques.

== January 10, 2020 ==

=== '''General Information''' ===
* Semester beginning general information.
* Choose sub-team for this semester. (time conflict group)
* Time conflict meeting time - Fridays, 4pm at Van Leer 483B.
* Grade Distribution:
** Documentation and records (33%)
** Personal accomplishments and contributions to your team’s goals (33%)
** Teamwork and interaction (33%)

=== '''Team Meeting Notes''' ===
* Statistics review of hypothesis testing.
** How do we prove we are making changes to EMADE?
** Are improvements due to our changes or randomness?
* Going to use t-statistic to test our hypothesis.
* Python SciPy library allows us to do hypothesis testing.
** Use SciPy. Stats
** Ttest_ind

* Issues
** We don't have a hypothesis.
** Welch t-test: There is a way to compute t-statistic without a population mean and standard deviation.

* Designing the experiments.
** If we want strong results, we wither need differences in sample means that overwhelm the sample variance, or a high sample number to reduce the effect of variance.
** If we can get this, we can assure that we have made significant improvements to NLP using the EMADE framework.

=== '''Sub-Team Notes''' ===
* Decided time conflict meeting time/place.
* Come up with hypothesis tests for NLP.
* Monitor future goals to fit to these hypothesis tests. 

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Select sub-team for this semster
|Completed
|January 10, 2020
|January 17, 2020
|January 10, 2020
|-
|Review sub-team goals for this semester
|Completed
|January 10, 2020
|January 17, 2020
|January 14, 2020
|-
|Make hypothesis tests for NLP text summarization
|Under Progress
|January 10, 2020
|January 17, 2020
|January 17, 2020
|-
|Join Team Slack
|Completed
|January 10, 2020
|January 17, 2020
|January 10, 2020
|}

=== '''Conclusions''' ===
* Joined the NLP-timeconflict-subteam for the Spring 2020 semester.
** Part of the Text Classification NLP team.
** Perform additional testing for the existing EMADE projects.
** Monitor future goals with these new testing techniques.

== December 2, 2019 ==

=== '''General Information''' ===
* Notebooks review dates.
* Complete Peer Evaluation.
* Team presentations on Monday, 2nd December 2019.

=== '''Team Meeting Notes''' ===
* Final Team Presentations
** NLP Team Presentation - https://docs.google.com/presentation/d/1KPcNsmbxPipkDncRDKeScHZCRR71gXoDNyumCGimTVc/edit#slide=id.p

* NLP
** Text Classification
*** Stemming/Lemmatization progress.
** Text Summarization
*** Integrating into EMADE.
*** Created three new primitives to help in classification.
**** num_named_entities - calculate the number of named entities in the given EMADE data pair.
**** text_rank
**** TFISF
** Modified Learner
*** Created our own modified learner.
*** Made new evaluation functions as predicted data is now 2 dimensional.
* Bloat Control
* Preprocessing
* ezCGP
* ADF

=== '''Sub-Team Notes''' ===
* No sub team meeting due to finals week.

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Test the modified primitive on the data set
|Completed
|November 25, 2019
|December 2, 2019
|November 29, 2019
|-
|Team presentation slides
|Completed
|November 25, 2019
|December 2, 2019
|December 1, 2019
|}

=== '''Personal Contributions''' ===
* Read our inspiration paper, Evolutionary Algorithms for Extractive Automatic Text Summarization which was our driving force for out implementation.
**https://www.sciencedirect.com/science/article/pii/S1877050915006869
**Showcases different procedures/methods for Automatic Text Summarization.

* Researched different libraries to implement the number of named entities primitive, mainly SpaCy and NLTK.
** NLTK
*** Cons
**** Longer code and more sub-libraries to implement.
**** Ran much slower compared to SpaCy.
*** Pros
**** Accurately classifies the type of named entity as compared to SpaCy. (We didn't need this as we only needed the number of named entities which was the same in both approaches)
** SpaCy
*** Cons
**** Less accurate classification of the type of the named entity.
*** Pros
**** Shorter code fragments.
**** Well documented and easier to use the existing methods inside SpaCy.
**** Ran significantly faster than NLTK version.
* Considering these pros and cons, we felt like SpaCy suited our application better and so we went ahead with SpaCy classification.
* Vectorized the EMADE data pair which is our data set to enable our classification.
* Helped to form the final EMADE data pair which contained the number of named entities in the original data set.
* Created the presentation slides for our num_named_entities primitive which was used in the final semester presentation.

=== '''Conclusions''' ===
* Presented our final presentations for this semester and proposed our plans and goals for the coming semester.

* Used SpaCy to create a primitive in the text_processing_methods.py within the EMADE framework.
** Created the num_named_entities that helps to calculate the number of named entities in the given EMADE data pair.
[[files/Num named entities slide.png|alt=num_named_entities slide information|center|thumb|552x552px|num_named_entities slide information]]
[[files/Number of Named Entities NLP.png|alt=Number of Named Entities final version|center|thumb|550x550px|Number of Named Entities final version]]

== November 25, 2019 ==

=== '''General Information''' ===
* Notebooks review dates.
* Complete Peer Evaluation.
* Team presentations on Monday, 2nd December 2019.

=== '''Team Meeting Notes''' ===
* Preprocessing
** Added primitives to image preprocessing.
** Rotate, shift etc.
* ezCGP
** Demonstrated the block structure for the testing phase.
* ADF
** ADF inside the individuals not being evaluated. (None type error)
** Trying to debug this case.
* NLP
** Summarization team
*** Testing the primitive - number of named entities.
*** Optimized it by using some numpy and vectorization methods.
*** Not very good values for accuracy.
* Bloat Control
** Fixed initial errors with GCP.
** Getting benchmarks using the titanic data set.
** Fix the NEAT GP bug.

=== '''Sub-Team Notes''' ===
* No sub team meeting due to Thanksgiving break.

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Number of named entity data access optimization
|Completed
|November 25, 2019
|December 2, 2019
|November 29, 2019
|-
|Test the modified primitive on the data set
|Completed
|November 25, 2019
|December 2, 2019
|November 29, 2019
|-
|Complete peer evaluations
|Completed
|November 25, 2019
|December 2, 2019
|November 25, 2019
|-
|Read the paper Evolutionary Algorithms for Extractive Automatic Text Summarization
|Completed
|November 25, 2019
|December 2, 2019
|November 29, 2019
|}

=== '''Conclusions''' ===
Implemented number of named entities on a more complex data set.
* Used SpaCy to create a primitive in the text_processing_methods.py within the EMADE framework.
* Performed optimization to reduce the number of traversals on the data set.
** Merged the computations to reduce the amount of traversals through the data set.
** Testing is completed and the behavior is as expected.
*Evolutionary Algorithms for Extractive Automatic Text Summarization
**https://www.sciencedirect.com/science/article/pii/S1877050915006869
**Showcases different procedures/methods for Automatic Text Summarization

[[files/Code Optimized.png|alt=Optimization on the number of named entities primitive and has been tested.|center|thumb|Optimization on the number of named entities primitive and has been tested.|562x562px]]

== November 18, 2019 ==

=== '''General Information''' ===
* Notebooks review dates.
* Peer Evaluation dates TBA soon (tentatively Monday, 25th November).
* Hackathon the coming Saturday, 23rd November.

=== '''Team Meeting Notes''' ===
* Preprocessing
** Troubles during the testing phase.
* ezCGP
** Run code on Ice-hammer.
** 120 workers but it is still not efficient.
** Fixing the mating in the evolutionary run.
* ADF
** Issues evaluating ADF with individuals.
** Fixing more bugs.
* NLP
** Working on the primitives.
** Multi class problem.
** Text Classification
*** Completed the primitive to extract the sentiment analysis.
* Bloat Control
** Bloat quantification algorithm takes too long to work.
** Integrate NEAT GP code.

=== '''Sub-Team Notes''' ===
* Team Meeting on Friday, 22nd November.
** Number of named entity implementation for a larger data set
*** Implement it for a list of list of sentences.
*** Work with text_processing_methods.py in the EMADE framework.

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Number of named entity implementation for more complex data set
|Completed
|November 18, 2019
|November 25, 2019
|November 24, 2019
|-
|Use EMADE's text_processing_methods.py on the data set
|Completed
|November 18, 2019
|November 25, 2019
|November 23, 2019
|-
|Compare SpaCy vs NLTK implementations
|Completed
|November 18, 2019
|November 25, 2019
|November 23, 2019
|}

=== '''Conclusions''' ===
Implemented number of named entities on a more complex data set.
* Used NLTK and SpaCy to work with text_processing_methods.py in the EMADE framework.
* Created basic primitives for our future tasks.
[[files/Number of Named Entities.png|alt=Number of Named Entities|center|thumb|Number of Named Entities|522x522px]]

== November 11, 2019 ==

=== '''General Information''' ===
* Notebooks review dates.

=== '''Team Meeting Notes''' ===
* Bloat Control
** Collecting more meta data from different data sets like the titanic data set.
** Bench marking these results.

* ezcGP
** Get a full run with a non-trivial population chain.
** New students - visualization of the individuals and mating process.
* ADF
** Visualize the benchmarks.
** Size metric for ADF comparisons.

* NLP
** Find number of named entities
** Adding new primitives
** Classification
*** Sentiment analyzation
* Preprocessing
** Figure out the tasks.

=== '''Sub-Team Notes''' ===
* Team Meeting on Friday, 15th November.
** Joined the Text Classification NLP team.
** Reviewed team goals.
** Number of named entity implementation for a larger data set
*** Implement it for a list of list of sentences.
*** Work with text_processing_methods.py in the EMADE framework.

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Number of named entity implementation for more complex data set
|Completed
|November 11, 2019
|November 18, 2019
|November 15, 2019
|-
|Use EMADE's text_processing_methods.py on the data set
|Completed
|November 11, 2019
|November 18, 2019
|November 15, 2019
|}

=== '''Conclusions''' ===
* Implemented number of named entities on a more complex data set.
** Used NLTK and SpaCy to work with text_processing_methods.py in the EMADE framework.
** Created basic primitives for our future tasks.

== November 4, 2019 ==

=== '''General Information''' ===
* Team selection for the first year VIP students.

=== '''Team Meeting Notes''' ===
* Preprocessing team
** Image processing is the primary goal
* ezcGP
** Parallelization fixed
** Increase speed of the code
** Working on mating between the blocks
** Separate operators
* ADF
** Troubleshooting seeding
* NLP
** Adding new primitives
** Find number of named entities
** Classification
*** Sentiment analyzation
* Bloat control
** Working implementation with NeatGP
** Symbolic regression
** Want to get NeatGP syncing with EMADE
** Benchmark testing

=== '''Sub-Team Notes''' ===
* Team Meeting on Friday, 8th November.
** Joined the Text Classification NLP team.
** Reviewed team goals.
** Number of named entity implementation for a larger data set
*** Implement it for a list of list of sentences.
*** Work with text_processing_methods.py in the EMADE framework.

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get started with NLP
|Completed
|November 4, 2019
|November 11, 2019
|November 6, 2019
|-
|Number of named entity implementation for more complex data set
|Completed
|November 4, 2019
|November 11, 2019
|November 9, 2019
|-
|Use EMADE's text_processing_methods.py on the data set
|Completed
|November 4, 2019
|November 11, 2019
|November 9, 2019
|}

=== '''Conclusions''' ===
* Joined the NLP team for remaining semester.
** Part of the Text Classification NLP team.

* Implemented number of named entities on a more complex data set.
** Used NLTK and SpaCy to work with text_processing_methods.py in the EMADE framework.
** Created basic primitives for our future tasks.

== October 28, 2019 ==

=== '''General Information''' ===
* Team selection for the first year VIP students.

=== '''Team Meeting Notes''' ===
* Update from the ezCGP team.
** Better ways to make the code run more efficiently.
* Bloat Control
* ADF
** Google Cloud testing.
* Preprocessing team
* NLP
** Build basic primitives for text data.

=== '''Sub-Team Notes''' ===
* Team Meeting on Friday, 1st November.
** Joined the Text Classification NLP team.
** Reviewed team goals.
** Number of named entity implementation

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Join NLP team Slack
|Completed
|October 28, 2019
|November 4, 2019
|October 28, 2019
|-
|Get started with NLP
|Completed
|October 28, 2019
|November 4, 2019
|November 1, 2019
|-
|Number of named entity implementation
|Completed
|October 28, 2019
|November 4, 2019
|November 3, 2019
|}

=== '''Conclusions''' ===
* Joined the NLP team for remaining semester.
** Part of the Text Classification NLP team.
* Implemented number of named entities in a simple data set.
** Used NLTK and SpaCy to accomplish the task.
[[files/NLTK Implementation.png|alt=NLTK Implementation|center|thumb|430x430px|NLTK Implementation]]
[[files/SpaCy Implementation.png|alt=SpaCy Implementation|center|thumb|437x437px|SpaCy Implementation]]

== October 21, 2019 ==

=== '''General Information''' ===
* Presentations from First Semester sub-teams on EMADE results w/ comparisons to GP and ML
* Presentations from Returning sub-teams on progress and recruitment.

=== '''Team Meeting Notes''' ===
* First Semester sub-teams compare ML, GP and EMADE on the titanic dataset.
* ADF
* ezCGP - Cartesian Genetic Programming
* NLP  - Natural Language Processing
* Preprocessing
* Bloat Control

* Titanic Example Data Set:
** Team presentations.
** GitHub Repository Link: https://github.gatech.edu/bsu32/emadeGroup
** Our team presentation link: https://docs.google.com/presentation/d/1s0Jzx6FY2tZJA3XuXwQ89gayCjDl8HlSzuksCfltXd4/edit#slide=id.g6408953ec7_1_0

=== '''Sub-Team Notes''' ===
* No sub-team meeting this week.

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review and decide which team to join
|Completed
|October 21, 2019
|October 28, 2019
|October 25, 2019
|}

=== '''Conclusions''' ===
* Decided to join the NLP team for remaining semester.

== October 16, 2019 ==

=== '''General Information''' ===
* In class workshop for sub-team presentation.
* Develop a solution for the Titanic problem using EMADE and MySQL.

=== '''Team Meeting Notes''' ===
* In class workshop for sub-team presentation.
* Connect to the common MySQL server and set up the master and workers.

=== '''Sub-Team Notes''' ===
* No sub-team meeting this week.

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Setup MySQL server with one master and other workers
|Completed
|October 16, 2019
|October 21, 2019
|October 17, 2019
|-
|Setup mySQL Database and input_titanic.xml file
|Completed
|October 16, 2019
|October 21, 2019
|October 17, 2019
|-
|Perform the ML run using EMADE
|Completed
|October 16, 2019
|October 21, 2019
|October 19, 2019
|-
|Presentation for the midterm evaluation
|Completed
|October 16, 2019
|October 21, 2019
|October 19, 2019
|}

=== '''Conclusions''' ===
[[files/3D Pareto Front.png|alt=3D Pareto Front|center|thumb|3D Pareto Front|399x399px]]
[[files/AUC EMADE.png|alt=EMADE AUC: 0.18|center|thumb|397x397px|EMADE AUC - 0.18]]
[[files/AUC Comparison New.png|alt=AUC Comparison|center|thumb|398x398px|AUC Comparison]]

== October 9, 2019 ==

=== '''General Information''' ===
* Machine Learning crash course continuation.
* Learn to use EMADE and MySQL database to perform evolutionary ML algorithm.

=== '''Team Meeting Notes''' ===
* EMADE - Evolutionary Multi-Objective Algorithm Design Engine
* Running EMADE
** Navigate to top level directory
** python src/GRFramework/launchGTMOEP.py templates/input_titanic.xml
* Input file
** Configures all the moving parts in EMADE
** First block - pythonConfig
* MySQL servers
** Configure the MySQL server.
** Requires a username and password.
* Input file datasets
** Data is preprocessed into gzipped csv files.
** It is cross folded 5 times (5 Monte Carlo trials).
** Each train and test file create a DataPair object in EMADE.
* Each row corresponds to an instance (person), each column is a feature, the final column is the truth data.
* Objectives
** Weights specifies if it should be minimized (-1.0) or maximized (1.0).
** The evaluation function specifies the name of a method in src/GPFramework/evalFunctions.py (-w)
*** master tag
*** worker tag
** <workersPerHost> specifies how many evaluations to run in parallel.
*** EMADE is resource intensive, keep this between 2 or 3.
*** How many evaluation per person will each worked do in parallel.
* Magic parameters or hyper parameters that affects the evolutionary process.

=== '''Sub-Team Notes''' ===
* No sub-team meeting this week.

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Explore EMADE functions
|Completed
|October 9, 2019
|October 16, 2019
|October 13, 2019
|-
|Install MySQL
|Completed
|October 9, 2019
|October 16, 2019
|October 13, 2019
|-
|Set up MySQL server
|Completed
|October 9, 2019
|October 16, 2019
|October 10, 2019
|}

=== '''Conclusions''' ===
* Installed EMADE.
* Installed MySQL.
* Installed MySQL Workspace.
* Created a MySQL server.

== October 2, 2019 ==

=== '''General Information''' ===
* Machine Learning crash course continuation.
** Use Multiple objective genetic programming algorithm on the Titanic data set.
* Do peer evaluations (due Friday).
* Bootcamp subteam presentation - [[Bootcamp Sub-team Fall 2019|Bootcamp Sub-Team Fall 2019]] (Team 2)

=== '''Team Meeting Notes''' ===
* Titanic Example Data Set:
** Team presentations.
** GitHub Repository Link: https://github.gatech.edu/bsu32/emadeGroup
** Our team presentation link: https://docs.google.com/presentation/d/e/2PACX-1vQKLpnDdAeP3WDqky0OND8uzZ0FC1F1v6e4UnxV6tYPKySzyYRBEtKXQuJ6MH6wnWxYWCphIKWgivXk/pub?start=false&loop=false&delayms=3000

=== '''Sub-Team Notes''' ===
* Team Members: Brandon (Lead), Nesha, Sanket, Tusheet, Tushna

* Presented our results to the class and got a co-dominant solution to the Titanic Example problem using Multiple Objective Genetic Programming.
* Understood why "Tournament" selection is not suitable for the purpose of this project.
* Used NSGA II instead of Tournament selection which is a better choice for Multiple Objective Genetic Programming.

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Solve the Titanic Example problem using Multiple Objective GP
|Completed
|October 2, 2019
|October 9, 2019
|October 6, 2019
|-
|Peer Evaluation survey
|Completed
|September 30, 2019
|October 4, 2019
|September 30, 2019
|-
|Install EMADE
|Completed
|October 2, 2019
|October 9, 2019
|October 6, 2019
|-
|Install MySQL
|Completed
|October 2, 2019
|October 9, 2019
|October 6, 2019
|}

=== '''Conclusions''' ===
* Understood why Tournament selection is not suitable for Multiple Objective Genetic Programming.
** It only evaluates based on the first parameter and doesn't care about any other parameter passed in for evaluation.
* Come up with our own evolutionary loop and HOF evaluator.
* Video comparison/simulation of the AUC as the generations passed by.
* Use other logical operators like less than, greater than etc.
* Representation of what an individual in the tree looks like.
* Better evolutionary setting to be laid out.

== September 25, 2019 ==

=== '''General Information''' ===
* Machine Learning crash course continuation.
** Use Multiple objective genetic programming algorithm on the Titanic data set.
* Do peer evaluations (due Friday).

=== '''Team Meeting Notes''' ===
* Use Multiple objective genetic programming algorithm on the Titanic data set.
** Use simple primitives - and, or, not, +, -, /, %
** Create the evolutionary loop for the genetic algorithm.
** Get a non-dominating frontier.
* Create non-dominating graph.
* Get area under the curve.
* Decided to use deap.tools.selNSGA2t(individuals, k, fit_attr='fitness') instead of tournament.
** deap.tools.selBest(individuals, k, fit_attr='fitness') : Select the k best individuals among the input individuals. The list returned contains references to the input individuals.
** Tournament : Select the best individual among ''tournsize'' randomly chosen individuals, ''k'' times. The list returned contains references to the input ''individuals''.

=== '''Sub-Team Notes''' ===
* Team Members: Brandon (Lead), Nesha, Sanket, Tusheet, Tushna
* Team Meeting 09/30/2019 - Titanic ML Multiple Objective GP Assignment.
* Team Responsibilities:
** Sanket: Working on redoing our feature set with vectorization and presentation.
** Tusheet and Brandon: Genetic Programming and Evolutionary Algorithm.
** Tushna and Nesha: Working on AUC graph and Riemann sums.
* GitHub Repository Link: https://github.gatech.edu/bsu32/emadeGroup
* Our team presentation link: https://docs.google.com/presentation/d/e/2PACX-1vQKLpnDdAeP3WDqky0OND8uzZ0FC1F1v6e4UnxV6tYPKySzyYRBEtKXQuJ6MH6wnWxYWCphIKWgivXk/pub?start=false&loop=false&delayms=3000
[[files/Tusheet Pset Declare.png|alt=Helped in creating the primitive set tailored to our feature set for the Titanic Assignment.|center|thumb|Helped in creating the primitive set tailored to our feature set for the Titanic Assignment.]]
[[files/Tusheet Pset.png|alt=Implement how to use the primitive set that we had created.|center|thumb|Implement how to use the primitive set that we had created.]]
[[files/Tusheet Eval Function.png|alt=Helped in implementing the evaluation function that calculates the false negative and false positive rates. Also changed the selection method to Select Best from Tournament to suit our data set and purpose.|center|thumb|Helped in implementing the evaluation function that calculates the false negative and false positive rates. Also changed the selection method to Select Best from Tournament to suit our data set and purpose.]]
[[files/Tusheet Evolution Loop.png|alt=Assisted in implement the evolutionary loop to minimize the False Positive vs False Negative values to get the best solution.|center|thumb|Assisted in implement the evolutionary loop to minimize the False Positive vs False Negative values to get the best solution.]]
[[files/Tusheet Pareto Front.png|alt=Implemented the graphing functionality after the evolutionary loop to see the trends in our FP vs FN values as the generations passed by.|center|thumb|Implemented the graphing functionality after the evolutionary loop to see the trends in our FP vs FN values as the generations passed by.]]

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Solve the Titanic Example problem using multiple objective genetic programming
|Completed
|September 25, 2019
|October 2, 2019
|September 30, 2019
|-
|Create non-dominating graph
|Completed
|September 25, 2019
|October 2, 2019
|September 30, 2019
|-
|Create area under graph
|Completed
|September 25, 2019
|October 2, 2019
|September 30, 2019
|-
|Peer Evaluation survey
|Completed
|September 25, 2019
|October 2, 2019
|September 30, 2019
|}

=== '''Conclusions''' ===
* Area Under Curve: 0.12988087232811915
[[files/Tusheet Evolutions.png|alt=Working of our evolutionary algorithm.|center|thumb|Working of our evolutionary algorithm.]]
[[files/Tusheet Trends 2.png|alt=Trends of our best/average/worst individuals over the 50 generations of evolution.|center|thumb|Trends of our best/average/worst individuals over the 50 generations of evolution.]]
[[files/Tusheet Graph 2.png|alt=Our resulting Pareto Front showing codominance. Area under curve: 0.12988087232811915|center|thumb|Our resulting Pareto Front showing codominance. Area under curve: 0.12988087232811915]]

== September 18, 2019 ==

=== '''General Information''' ===
* Machine Learning crash course continuation.
* Bootcamp subteam presentation - [[Bootcamp Sub-team Fall 2019|Bootcamp Sub-Team Fall 2019]] (Team 2)

=== '''Team Meeting Notes''' ===
* Titanic Example Data Set:
** Team presentations.
** GitHub Repository Link: https://github.gatech.edu/bsu32/emadeGroup
** Our team presentation link: https://docs.google.com/presentation/d/e/2PACX-1vSL90uzHtPocLyegASRUGtKyhA5YwrN4W7gR06LEOOYAToNM1FjToTjF0ywVq-2xuU6sJTzKeFalIC3/pub?start=false&loop=false&delayms=3000

=== '''Sub-Team Notes''' ===
* Presented our results to the class and got a co-dominant solution to the Titanic Example problem.
* Understood the term 'Over Training' and why this is not a correct method for getting results.

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Solve the Titanic Example problem
|Completed
|September 18, 2019
|September 25, 2019
|September 23, 2019
|-
|Explore vectorization and whitening
|Completed
|September 18, 2019
|September 25, 2019
|September 23, 2019
|}

=== '''Conclusions''' ===
* Better methods to model the data to better better results.
** Vectorization of the data set.
*** To fix numerical data that doesn't have significant value by itself, but in fact the differences between the numbers affects the ML algorithm.
** Tuning of parameters.
** Usage of booleans.
** Whitening of the data set.
*** Normalize data so that they are on the same scale.
*** Helps to clean up the data.

== September 11, 2019 ==

=== '''General Information''' ===
* Machine Learning crash course.
* Kaggle for data sets to work on.
* Scikit learn to check out various machine learning algorithms. 
* Formed bootcamp subteam - [[Bootcamp Sub-team Fall 2019|Bootcamp Sub-Team Fall 2019]] (Team 2)

=== '''Team Meeting Notes''' ===
* Titanic Example Data Set:
** Each group member must find an algorithm to solve the problem.
** As a team, we would get 5 co-dominant algorithms for predicting the survivors on Titanic.
** Use Scikit learn and train, test, split function to predict the outcome.
** Find False Positive and False Negatives, divide by number of Positives/ Negatives respectively.
** Make a plot of False Positive vs False Negative to graphically demonstrate out co-dominant solution.

=== '''Sub-Team Notes''' ===
* Team Members: Brandon (Lead), Nesha, Sanket, Tusheet, Tushna
* Team Meeting 09/12/2019 - Titanic ML Assignment
** Factors that affected our choice of feature set
***https://www.anesi.com/titanic.htm
***https://www.washingtonpost.com/opinions/women-and-children-did-go-first-on-titanic/2012/04/19/gIQAgSaugT_story.html?noredirect=on
**** “Heroism was exhibited by the men on board across all classes and crew.”
**** “First-class men survived at a higher rate than the third-class children”
**** “Men in first class survived at a lower rate, 32 percent, than did third-class women and children (42 percent)”
**** “The Titanic sank at night, and most third-class passengers were far below in the ship, making such access difficult”
**** “Altogether, survival percentage for all women and children on board was 70 percent, for men it was 19 percent”
**** “third class women were 41% more likely to survive than first class men.”
*** GitHub Repository Link: https://github.gatech.edu/bsu32/emadeGroup
***Presentation Link: https://docs.google.com/presentation/d/e/2PACX-1vSL90uzHtPocLyegASRUGtKyhA5YwrN4W7gR06LEOOYAToNM1FjToTjF0ywVq-2xuU6sJTzKeFalIC3/pub?start=false&loop=false&delayms=3000
[[files/Tusheet Feature Set.png|thumb|This is our Titanic Assignment feature set. We added a new feature set by changing the Pclass to give class 1 a higher number and class 3 a lower one. We also combined this edited Pclass with the Sex class, giving women a higher numeric value then men from historic examples.|center]]
[[files/Tusheet Dropped Features.png|center|thumb|Dropped features - Embarked, Fare, Name, Ticket, Cabin, Parch]]
[[files/Feature Set Table.png|center|thumb|Feature Set Table]]
[[files/List Appends.png|center|thumb|This my personal contribution to implement the co-dominant graphs for our solution for which I used two lists that contain the False Positive and False Negative values used later for the graph.]]
[[files/Graphing.png|center|thumb|Graphing function for the scatter plot.]]
[[files/Tusheet Main Codominance Graph.png|center|thumb|Co-dominant Solution for Titanic Assignment.]]

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Explore Kaggle and Scikit-learn
|Completed
|September 11, 2019
|September 18, 2019
|September 13, 2019
|-
|Sub Team Meeting
|Completed
|September 11, 2019
|September 12, 2019
|September 12, 2019
|-
|Solve the Titanic Example problem
|Completed
|September 11, 2019
|September 18, 2019
|September 13, 2019
|}

=== '''Conclusions''' ===
'''''This is the team solution to solving the Titanic Example problem.'''''
* General Procedure:
*# Import Necessary Libraries
*# Read In and Explore the Data
*# Data Analysis
*# Data Visualization
*# Cleaning Data
*# Choosing the Best Model
*# Creating Submission File
* Feature Set Used:
** Age (Further classified)
** Pclass
** SibSp + Parch
** Sex (Further classified)
* Machine Learning Algorithms Used:
** Decision Tree
** K Neighbors
** Neural Networks
** Random Forest
** Linear Regression
** Gaussian NB
* Co-dominant plot:
** We plotted the False Positive vs False Negative and produced a co-dominant solution to the Titanic Example problem.

== September 4, 2019 ==

=== '''General Information''' ===
* Sub-Team Information
** Automatic defined functions
** Research Fundamentals (Bloat Control)
** Automated Processing (Kaggle and go)
** EzCGP
** Natural Language Processing (NLP)

=== '''Team Meeting Notes''' ===
* Multiple Objective Programming
** Algorithm Performance
*** Space efficiency (Memory usage efficiency)
*** Time efficiency
*** Minimize errors (Misclassification)
*** True positive performance
*** Minimize false positive performance
*** Security
*** Precision of results
*** Usability (Human computer interface)
*** Cost effectiveness
** Gene pool: It is the set of genome to be evaluated during the current generation.
*** Genome: Genotypic description of an individual (DNA, GP, GA).
*** Search Space: Set of all possible genomes.
** Evaluation: Associates a genome/individual (set of parameters for GA or string for GP) with a set of scores.
*** Objectives: The set of measurements against which each individual is scored against
*** Phenotype
** Objective Space: Set of objectives
** Scores
*** TP - True Positive
*** FP - False Positive
** Classification Measures
*** Positive/Negative samples
*** Classifier
** Maximization Measures
*** Sensitive or True Positive Rate(TRP)
**** Hit rate or recall
**** TRP = TP/(TP + FN)
*** Specificity (SPC) or True Negative Rate(TNR)
**** TNR = TN/(TN + FP)
** Minimization Measures
*** False Negative Rate (FNR)
**** FNR = FN/P = FN/(TP + FN) = 1 - TPR
*** Fallout or False Positive Rate (FPR)
**** FPR = FP/N = FP/(TN + FP) = 1 - TNR
** Other Measures
*** (Want to maximize) Precision of Positive Predictive Value (PPV): PPV = TP/(TP + FP)
*** (Want to minimize) False Discovery Rate (FDR): FDR = FP/(TP + FP) = 1 - PPV
*** (Want to maximize) Negative Predictive Value (NPV): NPV = TN/(TN + FN)
*** (Want to maximize) Accuracy (ACC): ACC = (TP + TN)/(P + N) = (TP + TN)/(TP + TN + FP + FN)
** Fitness Computation
*** Objective Space: Each individual is evaluated using objective functions.
*** The Objective score calculated for each individual can be used to map each individual to a point in the Objective Space (Phenotype of the individual).
** Genotype: The actual gene (DNA).
** Phenotype: The function (optimizing phenotypes).

=== '''Sub-Team Notes''' ===
* N/A: No team assigned

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class lecture slides with notes
|Completed
|September 4, 2019
|September 11, 2019
|September 5, 2019
|-
|Finish the second part of the DEAP Lab 2: Multi-Objective Genetic Programming
|Completed
|September 4, 2019
|September 11, 2019
|September 5, 2019
|}

=== '''Conclusions''' ===
[[files/Tree Size vs Mean Squared Error.png|thumb|313x313px|Objective Space|center]]
[[files/Fitness vs Generation.png|thumb|314x314px|Fitness vs Generation|center]]
'''''Our objective is to minimize two objectives, the mean squared error and the size of our tree.'''''
* Process/Steps for the Multi-Objective GP
** Import the required libraries needed for the Multi-Objective GP.
** Create our fitness and individual classes.
** Define our toolbox, individual, population, and compiler.
** Define our evaluation function and register the genetic operations. Made use of DEAP's efficient implementations of pareto dominance and evolutionary algorithms to help us in this accord.
** Program the main evolutionary loop.
** Draw statistical data to measure our findings.
== August 28, 2019 ==

=== '''General Information''' ===
* Save the dates: For project presentations
** '''Monday October 21 - 4:30 to 7:30pm.  Location TBD'''
*** Presentations from First Semester sub-teams on EMADE results w/ comparisons to GP and ML.
*** Presentations from Returning sub-teams on progress, and recruitment.  Time for discussions with groups.
** '''Monday December  2 - 4:30 to 7:30pm. Location TBD'''
*** Final Presentations from each group.

=== '''Team Meeting Notes''' ===
* Genetic Algorithms
** Similar to Genetic Algorithms except mating and mutation are varied due to change in representation of genome of individuals.
** Uses Tree Structure (Lisp Preordered Parse Tree)
*** Functions represent the individuals and we input data into this function/individual.
*** Nodes are called primitives and represent functions. (+, -, *, %)
*** Leaves are called terminals and represent parameters.[[files/Tree Structure.png|thumb|339x339px|Tree Structure [ f(x) = 3*4 + 1 ]]]Instead of evaluating genome, the genome tree itself is the function/evaluation.
**** Function: f(x) = 3*4 + 1
**** Parse Tree: [+, *, 3, 4, 1]
** Crossover/Mating in GP
*** Single Point Crossover
**** Pick a random point in the sub tree and then crossover/mate.
** Mutation in GP
*** Node modification
**** Change a node.
**** Add a node/subtree.
**** Delete a node/subtree.
*** Leaves modification
**** Change a leaf.
** What primitives can make this GP evolution easier
*** Power()
*** Factorial()
*** Sin()
*** Cos()
*** Tan()
* DEAP
** It is a type of primitive function set.
** Arity: Number of inputs to a primitive function.
* Symbolic Regression
** y = sin(x)
** Primitive set: +, -, *, /, !, exp (exponents)
** Terminals: x, other constants.

=== '''Sub-Team Notes''' ===
* N/A: No team assigned

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class lecture slides with notes
|Completed
|August 28, 2019
|September 4, 2019
|August 29, 2019
|-
|Finish the first part of the DEAP Lab 2: Single Symbolic Regression
|Completed
|August 28, 2019
|September 4, 2019
|August 29, 2019
|}
[[files/Gentic Programming.png|alt=Minimize the mean squared error in the calculations|thumb|273x273px|Single Symbolic Regression (Minimize the mean squared error)]]

=== '''Conclusions''' ===
'''''Our objective is to minimize the mean squared error in our calculations.'''''
* Process/Steps for the GP
** Import the required libraries needed for the GP.
** Create our fitness and individual classes.
** Define our toolbox, individual, population, and compiler.
** Define our evaluation function and register the genetic operations.
** Program the main evolutionary loop.
** Draw statistical data to measure our findings.

== August 21, 2019 ==

=== '''General Information''' ===
* Wednesday, 4:30-5:20 pm (New students) at Klaus 1440

* Using EMADE framework.
* Notebooks maintained on Wiki: To track personal progress during the semester.
* Grade Distribution:
** Documentation and records (33%)
** Personal accomplishments and contributions to your team’s goals (33%)
** Teamwork and interaction (33%)

=== '''Team Meeting Notes''' ===
* Genetic Algorithm
** Algorithm to produce the best individual (maximum fitness) by the repetitive process of mating and mutating individuals of the given population based on a certain fitness function to eventually yield the best individual.
** Objective: A value used to characterize individuals that you are trying to maximize or minimize in the algorithm.
** Evaluation: A function that computes the objective of an individual.
** Fitness: A relative comparison of an individuals in the given population.
** Selection: Gives individuals with higher fitness a better chance to pass on their genes. Two forms of selection include:
*** Fitness Proportionate: Probability of mating is proportionate to the individual's fitness value. (not random)
*** Tournament: Conducts tournaments among individuals of a certain tournament size and selects the winners for mating. (random picks)
** Mate/Crossover: Mating between individuals of the population.
** Mutate: Induces random modifications among the individuals with the objective of maintaining diversity.
** General flow of the evolutionary algorithm to create the best individual:
*** 1. Randomly initialize population.
*** 2. Determine fitness level of population.
*** 3. Select parents from population based on fitness values.
*** 4. Perform mating/crossover among selected parents to form next generation population.
*** 5. Perform mutation on the new offsprings (next generation).
*** 6. Repeat steps 2-5 over and over until the best individual of the current population meets the requirements.

=== '''Sub-Team Notes''' ===
* N/A: No team assigned

=== '''Action Items''' ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review class syllabus
|Completed
|August 21, 2019
|August 28, 2019
|August 22, 2019
|-
|Join EMADE Slack
|Completed
|August 21, 2019
|August 28, 2019
|August 21, 2019
|-
|Install and configure Anaconda, GitHub and Jupyter Notebook
|Completed
|August 21, 2019
|August 28, 2019
|August 22, 2019
|-
|Review class lecture slides with notes
|Completed
|August 21, 2019
|August 28, 2019
|August 24, 2019
|-
|Finish the first part of the DEAP Lab 1: One Max Problem
|Completed
|August 21, 2019
|August 28, 2019
|August 24, 2019
|-
|Finish the second part of the DEAP Lab 1: N Queens Problem
|Completed
|August 21, 2019
|August 28, 2019
|August 24, 2019
|}

=== '''Conclusions''' ===
'''''We are trying to solve real life problems of getting ideal situations using a repetitive evolution algorithm that resembles human genetic mating and mutating.'''''

* DEAP Lab 1 (Part 1 - One Max Problem)
# Define Individual and gave a random generated initializer for the individual. Create 300 individuals
# Algorithm runs for 40 generations to observe the population evolution to make progress towards the objective.
# Selection (tournament) - Mate (50%) - Mutate (20%) - replace population.
# Draw statistical data.
# Optimize search space for the next runs.
[[files/N Queens Problem Trends.png|frame|391x391px|'''N Queens Problem Statistical Trends''']]
* DEAP Lab 1 (Part 2 - N Queens Problem)
# Objective is to minimize the interactions between the two queens in a game of chess.
# Define individuals and population.
# Crossover - Mutate - Evolution algorithm loop.
# Draw statistical data.
# Optimize search space for the next runs.