== April 26, 2020 ==

=== Future Works ===
* Migrate to Google Cloud Platform(GCP)
** get multiple GPU to working on PACE, automate setup process either using containers or script
* Finish seeding functionality
** How do I break down a model into components?
* 

== April 23, 2020 ==
[[files/EzCGP Spring 2020.png|thumb|EzCGP configuration of the run]]

=== Final Presentation ===
* New semester students built various CNN architectures using Keras.
* They then compared the performance of manually built models to evolved model from running EzCGP
* The evolved model achieved higher accuracy than architectures that students implemented.

[[files/EzCGP Spring 2020(2).png|thumb|Best individual]]

== April 17, 2020 ==

=== Running PACE ===
* PACE is an ''organization'' on campus that offers high performance computing resources to students and faculties. (pace-ice for students, pace for faculties)
* How to usse PACE?
<pre>
# Instructions provided by Samuel Zhang and Luke Kim
# SSH into PACE
ssh GTusername@pace-ice.pace.gatech.edu

# Setup SSH keys in Github (on PACE):
cat ~/.ssh/id_rsa.pub

# (Copy the ENTIRE THING, should start with ssh-rsa and end with <root something>@pace.gatech.edu)
# Go here: https://github.com/settings/keys
# Click New SSH Key and paste into body (name is up to you). Now back to the PACE:
cd ~
git clone git@github.com:ezCGP/ezCGP.git
cd ezCGP

# Install Anaconda on PACE:
cd ~/
mkdir ~/data
mkdir ~/data/.conda
ln -s ~/data/.conda .conda
module avail anaconda         
module load anaconda3/2019.10    # You will load anaconda every time u use pace to do python related work

# That module is the default, for now. Now create your own environment
conda create -n keras python=3.6 anaconda
conda activate keras            # Always activate ur specific environment. 

# Thats the end of setup, now actually running PACE!
qsub run_gpu_<name>.pbs
# qsub submits the .pbs file to the queue in PACE. Check our repo for how to make a .pbs script!

qstat
# check status of queued jobs

qdel <job ID>
# delete a job process

# Once u successfully submitted ur request, PACE will email u when it is finished.
# Sometimes(actually a lot of times) ur request will have some error, which is logged out on .out file
# These errors are often related with code issues, so review ur code carefully
# If vim is too painful, use gists!
</pre>

=== How to Save Models and Reload Them? ===
* PACE has a maximum time limit of 8 hrs. 
* As an estimate, 8hr == 13 epoch with CIFAR-10 (vgg16 requires 74 epoch)
** Epoch represents an iteration of the whole training dataset. CIFAR-10 contains 50000 training images.
* One way to get around this issue is to save the models and reload them again for next epochs
* Saving model and its weights
<pre>
# ... some code ...
hist = model.fit(trainX, trainY, epoch=20, batch_size=256, ...)
model_json = model.to_json()
with open("ts_model0.json", "w") as json_file:
	json_file.write(model_json)
model.save_weights("ts_model0.h5")
print("saved model to disk")
</pre>
* loading model and its weights
<pre>
# load model from .json file
json_file = open('model.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
# load weights into new model
loaded_model.load_weights("model.h5")
print("Loaded model from disk")

# Add optimizers because they aren't saved in model
from keras.optimizers import Adam, SGD
opt = Adam(lr=0.001)
opt = SGD(lr=0.001, momentum=0.9)
loaded_model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])

# fit the dataset on loaded_model. trainX and trainY are same from initial 0-20 epoch
hist = loaded_model.fit(trainX, trainY, epochs=20, batch_size=64, validation_data=(testX, testY), verbose=1)
</pre>

=== Action Task ===
{| class="wikitable"
!Task
!Current Status
!Whats stopping me
!Date Assigned
!Date Resolved
|-
|Run EzCGP on PACE
|In Progress
|Haven't finished running vgg16
|April 12, 2020
|
|-
|Run vgg16 on PACE
|In Progress
|Have to run multiple rounds of PACE
|April 7, 2020
|
|}
== April 12, 2020 ==

=== Building VGG16 from scratch with Keras ===
* VGG16 is an architecture proposed by Karen Simonyan & Andrew Zisserman. 
* It's architecture contains 5 conv layer with 64, 128, 256, 512, and 512 filters respectively. 
* The last two layer contains 3 conv net while the first 3 has 2.
<pre>
model = Sequential()
model.add(Conv2D(input_shape=(32,32,3),filters=64,kernel_size=(3,3),padding="same", activation="relu"))
model.add(Conv2D(filters=64,kernel_size=(3,3),padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
</pre>
== April 10, 2020 ==
This week I've met up with my subteam of new students and installed EzCGP. Unfortunately we were not able to follow along with Sam's instruction because some people had trouble using the campus VPN. However, from Sam's lecture, I learned about PACE, which is an on-campus organization that offers high performance computing environment. I am extremely excited to reduce my training time with this new tool, but I don't have a full understanding of how to use it yet. 

The new students have been assigned a new task, which is to find an image classification NN architecture and implement it but '''I am not sure if I am expected to implement commonly used [https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/ models] from scratch or if I have to find a new architecture that is not built in Keras'''. Meanwhile, I plan to catch up on CNN terms through CS231n course.

=== Action Task ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Review backpropagation
|In Progress
|March 30, 2020
|
|-
|Read papers from Sam
|Finished
|March 30, 2020
|April 10, 2020
|}
== Mar 30, 2020 ==
[[files/Perceptron (or artificial neuron).png|thumb|A perceptron is an artificial neuron can be thought as a function that outputs a single number from the weighted sum of inputs. These functions are called activation functions. ]]
Got assigned to EZCGP subteam. The purpose of this subteam is to create a lightweight cartesian genetic programming framework.This week's task is to look over the resources that Sam gave the new students (3Blue1Brown videos on NN, CS231n, etc) and understand the theoretical background of deep learning. 

=== Notes from resources ===
A neural network is built up of artificial neurons, or perceptrons. A perceptron takes in a weighted sum of inputs and bias value and outputs a single number. The output is calculated using the activation function. In some literature, this function is also called the score function. But regardless of what they are called, the all follow the structure of f(x, W, b) = Wx + b where W is a matrix of weights, x represents input matrix, and b represents a bias factor. 
[[files/Multiple SVM loss function.png|thumb|A Multiple SVM Loss Function: sj represents the score of jth class. syi represents the score of the class that we are trying to find the loss for. ]]
The neural net tweaks these weights and biases to classify inputs to correct outputs. However, humans do not tweak these parameters manually, but use a loss function (or cost function) to calculate how bad the neural network is performing. One way to calculate a loss is using the multiple SVM loss function, which takes the sum of the difference between the score for incorrect classes and the score for correct class (with a delta value added that which i don't understand yet). This sum represents the loss of the specific cases (e.g. loss of one image out of many training images). The goal is to tweak the parameters (W) so that this loss decreases, which is done through backpropagation. 

=== Action Task ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Date Resolved
|-
|Review perceptrons
|Finished
|March 25, 2020
|March 30, 2020
|-
|Review loss functions
|Finished
|March 25, 2020
|March 30, 2020
|-
|Review backpropagation
|In Progress
|March 30, 2020
|
|-
|Read papers from Sam
|In Progress
|March 30, 2020
|
|} 
== Mar 9, 2020 ==
ADF

Angeline and Rosca's system

What makes an ADF useful?
* imporves a population's overall fitness
* Repeated segments of tree may signify it is useful
Data collected
* Average AUC
* Final AUC
* AUC between baseline and new tree does not seem statistically significant
No significant in AUC -> questions how are we selecting ADFs?

Currently favoring certain primitives over others

Despite of different heuristics, ADFs had similar primitives

Hope to look at primitive distribution across generations

How would caching might affect evaluation times

Might use a different heuristic: compare parent and children fitness

Evolving ADFs 

NLP

Task: Text classification

Vectorizers -> converts text into vectors

Stemmatizer reduces words based on established stemming and lemmatization

Hypothesis: 

== Team Member ==
Team Member: Wooseok "Luke" Kim

Email: wkim330@gatech.edu

Interests: Cooking, Web dev, Bits of Good, Database, Reading, ML

== Feb 20, 2020 ==
[[files/Diagram of an individual in GA.png|thumb|Diagram of an individual in GA, taken from Lecture-2 slides]]

====== Lab 2 ======
(*This entry is a makeup to the missing Lab 2 entry*)

In lab 1, we examined the foundation of genetic programming. In lab 2, we are going to dive into genetic algorithm. Though the two might sound similar, genetic algorithm represents individuals as series of functions and their objective score is the output of the function depending on the inputs while genetic programming represents individuals as an array of values. More specifically, individuals in genetic algorithm can be represented using the tree structure.
* Primitives in the tree represents the functions to operate on the values stored in the terminal.
* Terminal stores the values. They serve the role of variables in the function.

====== Symbolic Regression ======
The first part of the lab is titled Symbolic Regression, which aims to formulate a function that best fits with the data set by formulating new functions using given mathematical expressions. In other words, our goal is to evolve an individual that best resembles a specific function. By examining the evaluation function, we can see that the function that we are trying to get is x^4 + x^3 + x^2 + x.

To create an individual, we first create a primitive set. A primitive set contains all potential values for primitives in the individual tree. The lab requires us to give two more new primitives. Since the goal is to form a mathematical function, we can insert more mathematical operations as primitives such as sin(x) or square(x), which are provided in the numpy module. You can use the line below as an example to add more functions in the future. 
<pre>
# pset.addPrimitive(some_np_function, arity='number of arguments')
pset.addPrimitive(np.floor, arity=1)
pset.addPrimitive(np.square, arity=1)
</pre>
[[files/Best tree individual diagram.png|thumb|Best individual tree representation]]
As you can see in the eval function, we are obtaining the objective score by calculating the mean square error between the correct output and individual's output
<pre>
def evalSymbReg(individual, points, pset):
    func = gp.compile(expr=individual, pset=pset)
    sqerrors = (func(points)-(points**4 + points**3 + points**2 + points))**2
    return (np.sqrt(np.sum(sqerrors) / len(points)),)
</pre>After declaring the eval function and creating the primitives for the individuals, the next step is to run the evolutionary loop. This process is same as the first lab.
<pre>
-- Generation 0 --
  Min 0.4337245151489531
  Max 2.7824689070780626
  Avg 1.0690373726833253
  Std 0.2966919694760924
-- Generation 1 --
  Min 0.4337245151489531
  Max 2.225930565212586
  Avg 0.9359849002404055
  Std 0.2767185123827941
-- Generation 2 --
        .
        .
        .
-- Generation 39 --
  Min 1.0117659235419543e-16
  Max 2.499192532183802
  Avg 0.29716023884670967
  Std 0.4100696478053014
-- End of (successful) evolution --
Best individual is add(add(square(x), multiply(add(x, square(x)), square(x))), x), (1.0117659235419543e-16,)
</pre>Using the pygraphviz module, we can visualize the best individual from this evolutionary loop. See diagram to the left. 

====== Multi-Objective Genetic Programming ======
In this section of lab 2, we are going to aim to minimize two values instead of one as done previously. To specify that we are examining two values, we will be inputting a tuple with two values when we are creating the fitness class.
 creator.create("FitnessMin", base.Fitness, weights=(-1.0,-1.0))
The two objectives that we will be aiming to minimize are mean squared error and the size of our tree. Our evaluation function then returns a tuple of mean squared error and the size of the tree.
[[files/Pareto1.png|thumb]]
<pre>
def evalSymbReg(individual, points, pset):
    func = gp.compile(expr=individual, pset=pset)
    sqerrors = (func(points)-(np.negative(points) + np.sin(points**2) + np.tan(points**3) - np.cos(points)))**2
    print(print((np.negative(points) + np.sin(points**2) + np.tan(points**3) - np.cos(points))))
    
    return (np.sqrt(np.sum(sqerrors) / len(points)), len(individual))
</pre>
[[files/Pareto 2.png|thumb]]
Despite of many attempts to reduce the AUC of the pareto individuals, I could not figure it out. I hypothesized that increasing the lambda value, which represents the number of children to produce each generation, would help me to give me more dominant pareto frontier. However, it only increased the AUC by 3 times. Increasing the mutation rate also resulted in a similar output. The only known way to reduce the AUC was to reduce the number of generation by half, which helped me to reduce by almost 0.1, which is nowhere close to 25% reduction. AUC is the indicator of the performance of GP loop. I suspect that making a custom GP loop would help me to solve this issue. I will come back to this stage later in the future. 

====== Action Items ======
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Record Lab 2
|In Progress
|January 15, 2020
|
|February 20, 2020
|-
|Titanic GP Lab
|Complete
|February 10, 2020
|
|February 14, 2020
|}  

== Feb 14, 2020 ==

====== Titanic ML-GP Lab Result ======
* Data Processing
** Cleaned the data like how we did for the previous lab. Used a heat map to identify factors that correlated with survival rate. See diagram on the side.[[files/Survival based on binned ages.png|thumb|Histogram of binned ages vs survival rate]][[files/Feature heat map.png|thumb|Feature heat map]]
*Used 6 ML models to find the Pareto frontier on FN and FP objectives. (ML_model_name [FN, FP]). Models clustered at the end because we have trained to minimize the Euclidean distance from the origin.
**KNN [17, 41]
**MLP Classifier [19, 37]
**Ada Boost [21, 37]
**Random Forest [18, 37], [21, 37]
**Decision Tree [18, 37]
**Linear Support Vector Machine [18, 38][[files/Pareto frontier of ML models.png|center|thumb|Pareto frontier of ML models]]
* Evaluation Function
** Evolutionary loop was similar to the previous lab, with slight changes to the eval_function
** Individuals in this assignments were represented as an array of logical primitives (e.g. or, and, not, etc). 
** The code below outlines the process of creating numpy logical functions to the primitive sets. 
<pre> 
# Define objective
creator.create("FitnessMin", base.Fitness, weights=(-1.0, -1.0)) 

# Create individual classes
creator.create("Individual", gp.PrimitiveTree, fitness=creator.FitnessMin) 

# Line below makes the primitive set. arity=3 implies we are giving three terminals (age, sex, and famsize) 
pset = gp.PrimitiveSet("MAIN", arity=3)

# Following lines creates various functions and adds them to the primitive set (pset)
# arity represents how many arguments the function takes. 
pset.addPrimitive(np.greater, arity=2)
pset.addPrimitive(np.less, arity=2)
pset.addPrimitive(np.equal, arity=2)
pset.addPrimitive(np.logical_and, arity=2)
pset.addPrimitive(np.logical_or, arity=2)
pset.addPrimitive(np.logical_xor, arity=2)
pset.addPrimitive(np.logical_not, arity=1)
pset.addPrimitive(np.less_equal, arity=2)
pset.addPrimitive(np.not_equal, arity=2)          
pset.addPrimitive(np.greater_equal, arity=2)

# We can rename the arguments we passed in when we first made the pset in the order we passed them in.
pset.renameArguments(ARG0='Sex', ARG1='Age', ARG2='family_size')

# We then create an object called toolbox. 
# Think of toolbox as a an actual toolbox of functions and classes that we will use later.
toolbox = base.Toolbox()

# Following lines add classes to the toolbox
toolbox.register("expr", gp.genHalfAndHalf, pset=pset, min_=1, max_=3)
toolbox.register("individual", tools.initIterate, creator.Individual, toolbox.expr)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)
toolbox.register("compile", gp.compile, pset=pset)
                  
</pre>
** After creating the primitive sets, now we can create individuals
** Next step is to create a function to evaluate their objective score (i.e. FN and FP)
<pre>
def eval_ind(individual, points, pset):
    # y_train represents a table with columns of 'passengerId' and 'survived'. 
    # For more detail, look at our team's github repo.
    # You can find it at wiki -> Bootcamp Subteam Spring 2020 -> Group 3 -> github
    y_list = y_train.tolist()

    # Recall that individuals are just functions and their objective scores are 
    # calculated by feeding in the values to the function.
    func = gp.compile(expr=individual, pset=pset)

    # The line below saves the FP and FN values from the confusion_matrix function, which is included in sklearn module
    tn, fp, fn, tp = confusion_matrix(y_list, func(points['Age'], points['Sex'], points['family_size'])).ravel()
    return ((fn+fp)**2, fp, fn,)
</pre>

* Pareto frontier of GP individuals[[files/Pareto frontier of GP individuals.png|thumb|Pareto frontier of GP individuals]]
** The pareto individuals had a score of [17,159], [377, 0], [0, 219], [57, 67]
** On the diagram to the left, the scores are normalized. (MAX_FN: 377, MAX_FP: 219)
** This score is reflective of 10 generations only. We've discovered that increasing the number of generations tends to favor individuals with extreme objective scores (e.g. (MAX_FN, 0) or (0, MAX_FP))
* Comparison of Pareto frontier [[files/Comparison of pareto frontier.png|thumb|Comparison of pareto frontier]]
** The AUC of ML approach was lower than the GP approach, which shows that ML approach was slightly more accurate since it reduced FN and FP. 
** After the presentation, Dr. Rohling mentioned that it is difficult to outperform a ML model using GP approach, which is why EMADE aims to apply GP approach using ML models as primitives.
** In the future, our group would like to change the objectives of ML models. Instead of aiming to minimize the Euclidean distance from the origin, we can try reducing the FN, FP values instead.
====== Action Items ======
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Record Lab 1
|In Progress
|January 8, 2020
|
|
|-
|Record Lab 2
|In Progress
|January 15, 2020
|
|
|-
|Titanic GP Lab
|Complete
|February 10, 2020
|
|February 14, 2020
|}
== Feb 12, 2020 ==

====== Group 4 Notes ======
* Used multilayer perception.
* Unique visualization method.
* Used arithmetic primitives
* gengrow vs genhalfandhalf?
* NSGAII?

====== Group 5 Notes ======
* Used a separate feature title
* Voting classifier, Histogram-based gradient boosting, gradient boosting, stochastic gradient descent, ...
* Tree analysis (include in our future presentation)

====== Group 2 Notes ======
* Generation vs Fitness plot

== Feb 10, 2020 ==

====== Sub-team Meeting ======
* Completed the evolution loop for titanic assignment. Utilized three parameters (FN, FP, FP+FN) as objectives.
* Divided up the roles on who should work on what during the presentation
* Developed a plot with pareto frontier of ML models that we made in the previous lab

====== Action Items ======
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Evolve Models
|In Progress
|February 5, 2020
|
|February 11, 2020
|-
|Record Lab 1
|In Progress
|January 8, 2020
|
|
|-
|Record Lab 2
|In Progress
|January 15, 2020
|
|
|-
|Titanic GP Lab
|In Progress
|Feb 10, 2020
|
|
|}[[files/Pareto Plot of ML models.png|thumb]]

== Feb 8, 2020 ==

====== Sub-team Meeting ======
* Convened with sub-team members to create the evolutionary loop.
* Primitive set included logical primitives instead of numeric operations because unlike lab 2, the task is to predict whether the passenger survived(yes or no result) by examining their features while the other aimed to evolve a mathematical function.
* Evolution is not working properly. Only minimizing one objective and not both.
 -- Generation 0 --
   Min [0. 0.]
   Max [377. 219.]
   Avg [112.9        146.83333333]
   Std [143.60996948  74.76009779]
 -- Generation 1 --
   Min [ 0. 65.]
   Max [359. 219.]
   Avg [ 57.5 170.9]
   Std [105.0605381  62.169848 ]
 -- Generation 2 --
   Min [0. 0.]
   Max [377. 219.]
   Avg [ 50.6        188.93333333]
   Std [117.77792662  63.47646983]
 -- Generation 3 --
   Min [  0. 167.]
   Max [ 61. 219.]
   Avg [  2.03333333 217.26666667]
   Std [10.94983511  9.33428567]

====== Action Items ======
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review GP
|Complete
|February 5, 2020
|Februrary 5, 2020
|Feburary 8, 2020
|-
|Evolve Models
|In Progress
|February 5, 2020
|
|
|-
|Record Lab 1
|In Progress
|January 8, 2020
|
|
|-
|Record Lab 2
|In Progress
|January 15, 2020
|
|
|}

== Feb 6, 2020 ==

====== Lab 1 Notes ======
In One Max Problem, individuals are represented as a set length string of 0 or 1 and the objective is to apply genetic programming principles to evolve an individual made up of only 1s. In this lab, I learned how to use DEAP to implement basic genetic programming principles such as making a population, measuring their fitness, creating a selection function, and looping the population over set amount of generations. 

New things that I learned is that selection function should not place the whole population in a tournament because some individuals who don't survive such competition may offer valuable traits later on in the generation.
* Results from Lab 1
**   -- Generation 0 --   Min 43.0   Max 66.0   Avg 53.486666666666665   Std 4.143648419234261       . . .      -- Generation 39 --   Min 89.0   Max 100.0   Avg 99.05333333333333   Std 2.1534055715442717 -- End of (successful) evolution -- Best individual is [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], (100.0,)

====== '''Action Items''' ======
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review GP
|In Progress
|February 5, 2020
|Februrary 5, 2020
|
|-
|Evolve Models
|In Progress
|February 5, 2020
|
|
|-
|Record Lab 1
|In Progress
|January 8, 2020
|
|
|-
|Record Lab 2
|In Progress
|January 15, 2020
|
|
|}

== Feb 5, 2020 ==

====== Team Meeting Notes: ======
* Use genetic programming principles to evolve algorithms from Titanic Lab
** Due next week as a group project
** Explain the evolutionary loop in your slides
** Do not use built-in algorithms
* Slide presentation
** Have graphs 
** Outline Pareto Frotier

====== Titanic Lab: ======
* Created a RandomForestClassifier with FP: 56 FN: 14
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Review GP
|In Progress
|February 5, 2020
|Februrary 5, 2020
|
|-
|Titanic
|Completed
|January 29, 2020
|February 5, 2020
|Feb 5, 2020
|-
|Evolve Models
|In Progress
|February 5, 2020
|
|
|}

== Feb 3, 2020 - Genetic Algorithm ==
* Genetic algorithm is a practice of applying genetic principles to determine the fittest individual.
* Individuals are represented in a vector form, with each element representing the features of the individual. 
** Ex) A bunny can be represented as (2, 4, 1) with the first element representing the number of ears, second representing the number of legs and third representing the number of noses. 

* A group of individuals is called a population. The population competes to do better at specific objectives.
* An individual competes by aiming to maximize or minimize the objective scores.
* Evaluation is a function that calculates the objective scores of individuals.
* There exist various algorithms that create a random population and produces the best (or good enough) individual.
One Max Problem 
* Individuals are vectors with 100 entries with some populated with 1s.
* We aim to find the best individual, which will be a vector with all 1s.