== Team Member ==
[[files/Picture of me.jpg|thumb|Picture of Xufei Liu]]
Name: Xufei Liu

Email: xliu725@gatech.edu

Interests: Operations research, machine learning, combinatorics, stochastic processes

= Fall 2021 =
Subteam: Modularity 

Members: [https://github.gatech.edu/emade/emade/wiki/Notebook-Vincent-Huang Vincent Huang], [https://github.gatech.edu/emade/emade/wiki/Notebook_Angela_Young Angela Young], [https://github.gatech.edu/emade/emade/wiki/Notebook_Bernadette_Gabrielle_Santiago_Bal Bernadette Bai]

New notebook found here with past semester work: https://github.gatech.edu/emade/emade/wiki/Notebook-2---Xufei-Liu.

== October 15, 2021 ==

====== Lecture Notes ======
* This Saturday, we will have a hackathon
* Modularity
** Squeue error for permission, and squeue is slurm
** Need to use new code from newer emade branch to not get an squeue error.

====== Notes ======
* First run cd/usr
* Then mysqld_safe --datadir='/storage/home/hpaceice1/xliu725/scratch/db'
* New terminal: qsub -I -q pace-ice -l nodes=1:ppn=1,walltime=01:00:00
* mysql -u root

== October 8, 2021 ==

====== Lecture Notes ======
* Hackathon on October 16th to work on the midterm presentation from 1-5 in Klaus
* Stocks team coming to join our team to help wiht stocks runs
* For my error on creating the conda environment...
** remove the .git folder (rm -rf .git) since I'm running out of disk space
* Make sure to use conda activate emade before running the code.

====== Personal Exploration ======
* After getting emade set up:
**ssh into pace-ice and allocate a node/start the database. I found that I can start the database by just running mysqld_safe and NOT cd /usr
** qsub -I -q pace-ice -l nodes=1:ppn=1,walltime=01:00:00
** mysqld_safe --datadir='/storage/home/hpaceice1/xliu725/scratch/db'
** module load anaconda3/2020.02
** module load gcc
** conda activate emade (name of the environment)
** mysql -h atl1-1-02-012-5-l
** Create a database in a new terminal after ssh’ing onto the atl-… address with command CREATE DATABASE <name>;
** Later, you can also delete a database if you type DROP DATABASE <name>;
** exit mysql and find the template file. Then use vim input_titanic or something similar to edit
** When editing, the server is the atl… address, the hostname/password are your information, and the database is the name you used when creating the database in the past
** Unfortunately, running into errors when actually running emade using the following commands:
*** python src/GPFramework/launchEMADE.py templates/<input_file>
*** Make sure you use launchEMADE.py and not launchGTMOEP.py as our codebase is just a little different

====== Action Items ======
{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Uploade new emade-cloud folder to google collab
|Incomplete
|10/8/2021
|10/15/2021
|
|-
|Continue revising Gabriel's paper
|Incomplete
|10/8/2021
|10/15/2021
|
|-
|}

== October 1, 2021 ==

====== Lecture Notes ======
* Peer evaluations due next week and open on Monday
* Modularity
** Depth is increased but Vincent still has to debug
** Having trouble logging into the sql node, but could only sometimes connect
*** Potential check: SQL might not let us connect based on what node we're connecting from, need to change sql settings
*** Check the accounts that we made with wildcard host, we want user@% host.
*** mysql -h nodename -u username -p
*** Want username to be xliu725, but if we go to the node that we see that logging in locally (localhost), we get two users from two nodes
** 'xliu725'@'%'
** https://docs.pace.gatech.edu/interactiveJobs/interactive_cmd/ (may want an interactive job if we can't ssh)
* Stocks
** Team split up
** EMADE full individuals are a length of list 4
** Various crossovers allow you to cross over multiple individuals
*** Can also crossbreed

====== Subteam Meeting 10/7 ======
* Worked on debugging new PACE-ICE issues
* Bernadette had a potential fix although it didn't work for me
** After setting up a database instance, open up a new terminal to run the following commands
*** qsub -I -q pace-ice -l nodes=1:ppn=1,walltime=01:00:00
*** exit
*** mysql -u root
*** DELETE FROM mysql.user WHERE user='';
*** GRANT ALL PRIVILEGES ON *.* TO 'USERNAME'@'%' WITH GRANT OPTION;
*** FLUSH PRIVILEGES;

====== Personal Exploration ======
* Focused mostly on reading the paper that Gabriel linked on overleaf.
* Edited and fixed several grammatical mistakes throughout the paper
* Paper summary
** Looking at AutoML methods that can utilize modularity techniques inspired through genetic programming
** Integrate ARLs (Adaptive Representation through Learning) through EMADE and look at datasets such as MNIST, CIFAR-10, CIFAR-100, SVHN, and stock benchmark
** AutoML will search for the optimal hyper-parameters with little human interaction
* Potential areas of improvement for the paper:
** Improved selection 
*** We weigh individuals with more ARLs as better, but that assumes that ARLs are significantly better. 
***We could try weighing them less and see how little we can weigh them without them disappearing from our individual pool.
** Population Updates
*** Currently talks about introducing new random individuals in generation with genetic duplicates
*** As a note, we may also want to start with a better seeding file as well
*** Why are genetic duplicates needed if we're looking to expand diversity?
* Potential areas to add for the paper:
** Actual depth of ARLs
*** Vincent is currently working on it this semester to have ARLs with more than size 2.
*** Look at how it has different effects on different datasets
** Find the optimal combination of mutation methods, population updates, diversity, etc for the best EMADE ARL model
*** We have many potential avenues to explore and we need to run trials for most of them to determine which perform the best
*** Will different datasets prefer different combinations of the above attributes? And if so, how do we guess which is needed for certain datasets?
** More talk about work done on the titanic dataset? I believe we have a few results in past semesters for that.
*** This could fit under Experiment and also in the introduction to the paper
* Other modifications/potential edits to the paper:
** Need to find old pictures of pareto fronts with super individuals and other things from our past runs for analysis.
*Issues with PACE-ICE
** Currently struggling to get emade installed/set up. It has been ssh'ed over, but I don't have permission to install any packages or create a conda environment.

====== Action Items ======
{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Peer evaluations due
|Complete
|10/1/2021
|10/8/2021
|10/4/2021
|-
|Clean up notebook
|Complete
|10/1/2021
|10/8/2021
|10/8/2021
|-
|Uploade new emade-cloud folder to google collab
|Incomplete
|10/1/2021
|10/8/2021
|Moved to Next Week
|-
|}

== September 24, 2021 ==

====== Subteam Meeting 9/25 ======
* Continued to work to set up PACE
** Found out walltime is 8 hours - worried that we can't get long-enough runs
** May transition back to google collab for now
* Bernadette and I managed to connect to our database for a minute before getting kicked out again. Will continue to work on this issue
** Currently working on fixing the MNIST dataset as well
* Vincent is looking into an error in the adf.py codebase that I may try to help debug as well.
* Bernadette managed to merge the stocks team dataset and evaluation functions with our codebase on Vincent's github branch found here: https://github.gatech.edu/vhuang31/emade

====== Personal Exploration ======
* Currently working on setting up the rest of PACE-ICE
** Managed to start an instance of the database but can't verify that it works
** Keep getting error when I run mysql -h atl1-1-02-012-5-l
* Connected for a moment once more but couldn't get it to function continuously
* Working on getting emade into database as well
** Recloned emade from Vincent's branch using git clone
** Working on using SCP to get emade onto pace.
** Code is: scp -r emade xliu725@pace-ice.pace.gatech.edu:~
* Managed to get PACE-ICE and the database working through the following steps:
* Fixed the .my.cnf file through vim by adding in a port number (I choose 3313)
** Terminal 1: qsub -I -q pace-ice -l nodes=1:ppn=1,walltime=01:00:00
** Terminal 1: mysqld_safe --datadir='/storage/home/hpaceice1/xliu725/scratch/db' (do not cd into /usr)
** Terminal 2: ssh atl1-1-02-012-5-1
** Terminal 2: mysql -u root
** Then I ran the SQL commands found on this page: https://github.gatech.edu/emade/emade/wiki/Guide-to-Using-PACE-ICE

====== Action Items ======
{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Figure out how to connect to the database and verify connection
|Complete
|9/24/2021
|10/1/2021
|9/30/2021
|-
|}


== September 17, 2021 ==

====== Lecture Notes ======
* Things we need to do for the next meeting dealing with images
** Check out our branch
** Make a subfolder for our images
** Change it locally 
** Push changes
* PACE-ICE work
** /storage/home/hpaceice1/shared-classes/materials/vip/AAD
** Numhosts is how many workers are needed to run
** Workers per host is number of subprocesses
* Stocks
** Working on recreating their paper 
* Modularity 
** Currently working on runs with mnist dataset
** Issue with MacBooks trying to unpack files and messing up Google collab
** Look at runs with stocks dataset in the future to see if that works
** Potentially look at Jason’s algorithm when looking at mnist data
** Not enough generations last semester which may have caused our messed up pareto fronts

====== Subteam Meeting 9/23 ======
* Working together to set up PACE-ICE for emade.
** Can't connect to our cluster when we're trying to check the database
** Figured out how to run the database and connect to PACE-ICE

====== Personal Exploration ======
* Working on installing PACE-ICE and getting it set up. Below are the commands that are run and debugging done (link with instructions is at https://github.gatech.edu/emade/emade/wiki/Guide-to-Using-PACE-ICE):
** First I ssh'd into pace from terminal
** Created the scratch folder and db folder within scratch
** Had issues with the .my.cnf file and transferring it to pace using SCP
*** Also needed to change the "USERNAME" to "xliu725".
*** Instead, connected to PACE first and used vim to create the .my.cnf folder in the ~ directory by copying and pasting.
** Ran mysql_install_db --datadir=$HOME/scratch/db
** entered the user folder and started local MySQL instance
*** mysqld_safe --datadir='/storage/home/hpaceice1/xliu725/scratch/db'
* However, got stuck on the step where we're trying to check whether the database is working or not. Unsure why the command of mysql -h atl1-1-02-012-5-l won't work.

====== Action Items: ======

{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Look into PACE-ICE issues with .my.cnf
|Complete
|9/18/2021
|9/23/2021
|9/24/2021
|-
|Find the MNIST error with datasets
|Complete
|9/18/2021
|9/23/2021
|9/24/2021
|-
|}

== September 10, 2021 ==

====== Lecture Notes ======
* Gabe is joining us today!
* Class updates
** In the wiki page, you can link to the files stored otherwise in the notebook.
** Git add/commit/push any images to files under your name and then link to your notebook
** Self-graded notebook rubric is due next week
* Stocks update
** Met to discuss tasking and what the semester will look like, looking at how to write the paper in the future
*** Results from last semester weren't publishable quality yet
*** Uncertain about whether they should build an outline or work on replicating results
*** Jason: Regardless of final results, work is still worth writing up in an article
** Currently thinking about meeting other non-time conflict students to incorporate the stocks team into the paper
** PACE-ICE is up and running once again!
* Modularity
** Contacted Gabe for help (Thanks Gabe :D)
** Need to fork off the code base
** Jason has also streamlined MNIST data if we want to use that
*** Take a look at gen_mnist data set
*** New saved pickle format, with corresponding template file
*** Jason's file uses precision and recall - but we're really far from the original emade branch
** May also need to assess choices we've made when looking for adfs/arls
** These algorithmic decisions could also be changed and experimenced with
*** May want to change hyperparameters or how to use ranking, and how we select arl's could be diversified
** See which parts are arbitrary and can edit in the future
*** Try to make five arl's each generation which can definitely change
** Could also start an exercise of trying to write a paper/potentially have an outline
** Full paper submission date is January 20th for GECCO

====== Subteam Meeting 9/16 ======
* Met up on Thursday to talk about having more runs
** Getting everyone set up on Google Collab again
** Connecting to new database that Bernadette set up for the semester
* Issue with the superindividual last semester
** May need to change our seeding file and find new individuals for it

====== Personal Exploration ======

Notebook Maintenance: 25/25
Meeting Notes: 15/15
Personal Work and Accomplishments: 30/35
Useful Resource: 20/25
Total: 90/100

Comments: Could add more links and write more about personal exploration. Currently haven't contributed as much since I'm working on getting PACE-ICE set up for modularity.

====== Action Items: ======

{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Self-graded notebook rubric
|Complete
|9/10/2021
|9/17/2021
|9/16/2021
|-
|Attempt runs for MNIST
|Complete
|9/10/2021
|9/17/2021
|9/16/2021
|-
|Contact Vincent on arl-depth
|Complete
|9/10/2021
|9/17/2021
|9/15/2021
|-
|}

== September 3, 2021 ==

====== Lecture Notes ======
* Discussing the possibility of working together
** Modularity could take some of the primitives from stocks and change the evaluation functions
** Analyzing the new dataset from stocks
* Directions we could pursue:
** Using the stocks data to test on
** Implementing new primitives, evaluation functions, and thus far
** Looking at how to store primitives in the database
** Have new baseline runs for both mnist and stocks before implementing new primitives

====== Subteam Meeting 9/8/2021 ======
*Potential ideas for things to pursue this semester
**Potential ways to look at data visualizations
**Add/integrate in the stocks subteam
*Currently compiling a list of things we know and things we need to learn for the future
*Potentially have all modularity folks meet on Friday from 3-4
*Created draft of action items and potential paths to pursue here: https://docs.google.com/document/d/1nrIWrMjVsJGYhjUZHZEiTStSvHmNjziNbVNA94ekhBM/edit?usp=sharing
* Keep doing mnist runs for now
** Work on merging the changes with the stocks team

====== Action Items: ======

{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Create new modularity channel
|Complete
|9/3/2021
|9/7/2021
|9/4/2021
|-
|Reach out to stocks to ask about their work
|Incomplete
|9/3/2021
|9/10/2021
|Removed
|-
|Email Zutty about moving the meeting times
|Complete
|9/8/2021
|9/11/2021
|9/9/2021
|-
|}

= Spring 2021 =
Subteam: Modularity 

Members: [https://github.gatech.edu/emade/emade/wiki/Notebook-Vincent-Huang Vincent Huang], [https://vip.gatech.edu/wiki/index.php/Notebook_Angela_Young Angela Young], [https://vip.gatech.edu/wiki/index.php/Notebook_Bernadette_Gabrielle_Santiago_Bal Bernadette Bai]

== April 26, 2021 ==

====== Lecture Notes ======
*Stocks
**Working on makring sure to finish baseline runs
**Seeing how well their individuals are doing through their graphs
**Need to still merge their changes to master now that they have new technical indicators.
**Looking at new decision tree
*ezCGP
**Looking at how new crossovers are doing in terms of visualizing
**So far individuals are doing well
**Using one-point crossover mating methods
*Modularity
**Our subteam has new objectives with three experiments
***See subteam meeting 4/25/2021 for more information
**Looking at precision, recall, and Cohan score
**May need to flatten objective scores to just 2d things, such as precision and recall. 
***May get rid of Cohan Kappa
*NLP
**Currently have 6 folds with 15 generations after a multi-hour run
**Going to review code on Wednesday and run over presentation soon
**Wrapping up the semester

====== Subteam Meeting ======

*Returning students so far are doing well but have two interrupted master process
**I will take over as the new master instead of Vincent to see if it'll work
*New students
**Going to have Gabriel be the master process and have them work
*Kevin is currently looking at code database, changes, etc.

====== Personal Exploration ======

*Added on to the final PowerPoint: https://docs.google.com/presentation/d/1SLLHwjsy-ZHV4OqAXDBclBeTzqrSbyCNCJNRZs0a8Kc/edit#slide=id.g812dce5abf_2_375
**Modified the future work slides
**Took a look at the takeaways slide
***How can we fix super individuals in the future?
***We might want to add/use other objectives that aren't as correlated
***There's the chance that the current F1 and Cohen kappa scores are correlated
**Looked at Pareto front graphs on the PowerPoint for analysis purposes
***Unable to draw conclusions because of the odd shape of the graphs due to super individuals
*Worked on new MNIST runs with old ARL structures
**When I tried to be master, I kept running into a tensorflow error. As a result, Vincent was the master and I was the worker process
**You can see generated Pareto fronts from our baseline runs here: https://drive.google.com/drive/folders/1FqnNg19p_QNYFmbbQAD0vWT0kguwuVoT 
**Currently, on the emade database, we see that databases 6-9 were valid and could be analyzed
***Database schemas earlier were interrupted runs that didn't perform as well
*Analysis for mnist_old_arl_6 database
**The csv file is found here: https://drive.google.com/file/d/15S4SG2DYcbt8HnNNDoL9DhVx36dHh7Sx/view?usp=sharing
**Currently working on code to generate a pareto front for the csv that can be found here: https://drive.google.com/file/d/1uAoayfMn8RRcugqyLm_wvmKT9mX6zhIJ/view?usp=sharing
*From the final pareto fronts generated, you can see that there is a super-individual which dominates the graph
**Unfortunately, this holds true for many individuals
**As a result, we need to balance out individuals in the future to have easier to analyze results
**The new individual below was generated by Cameron Whaley's code
**Analysis of new super-individual vs the one's Angela and I generated before
***First, notice that the new individual is much shorter with only 4 real layers
***The individual generated by Angela and I has depth 7
***Interestingly enough, similarities show that the KNN learner type with K:3 and weight 0 is included. However, ours is a "Grid" while theirs is "Single"
***Pass tri-state is also seen
*The input file used for the new runs are seen here: https://drive.google.com/file/d/1SR9Eq17N5AJhxR3yxcRuelWzFa9rG5GC/view?usp=sharing
**Notice that the new objectives have changed and are based on F1 score and Cohen Kappa
**In addition, the follow code snippets are also changed:
***<maxAdfSize>3</maxAdfSize>
***<shouldUseADFs>true</shouldUseADFs>

[[files/NewInvid.png|A graph of one of the new MNIST super individuals generated through Cameron Whaley's code.]]

====== Final Presentations 4/30/2021 ======

*Stocks
**Objectives
***TA-Lib indicators in emade
***Evolvability of EMADE individuals
***Use larger dataset and take a loot at all sorts of stocks
****Incorporate data analysis and statistical evaluations of individuals 
***Technical indicators and Piecewise Linear Representation 
****Threshold value determines number of piecewise functions 
**Exponential Smoothing
**Removed TriState and Axis parameters to Technical indicator primitives
**Added new Datasets to optimize (Larger Date Range)
**TA-Lib Technical Indicators were redone and Indicators without TA-Lib were calculated manually
**Current results from EMADE
***300+ generations with 4 objectives.
****New objective: Normal CDF on Distribution, correlated with Profit Percentage. AUC of pareto front decreased over the generations
***300+ generations with 3 objectives. 
****Removed Profit Percentage since it was correlated with another objective. 
****Saw an overall decrease in AUC of pareto front, but had a spike from restarting the run in the middle.
**EMADE Analysis
***Monte Carlo Simulations. 
***Calculate profit on stock with buy and sell trades to compare to performance of Individuals. 
****Individuals performed better than randomness.
**Primitives Analysis
***The algorithm uses historical data and technical indicators to predict stock, so bad TIs can mess up the results of this analysis.
**Future work: Comparing levels of generalization of optimal models, statistical analysis of seeding on AUC
***Create bounded objective functions
***Applying fundamental analysis in addition to Technical Analysis, Look at the effectiveness of emade on different intervals of trading, look at another paper to base more research off of.
*ezCGP
**Cartesian block structure very specific to ezCGP
***Some nodes are active while others are inactive to see which works the best
***Stages of blocks, such a preprocessing, data classification, etc are grouped into certain blocks of code that needs to be passed through
**Since the midterm, they’ve removed augmentation and preprocessing
***This resulted in high training accuracy but lower validation accuracy. However, it is much faster
***Unfortunately there were overfitting issues and a lack of connected layers
**Want to replicate with CIFAR-10 without transfer learning
***Also worked on visualizing genomes and researching/testing new mating methods
**However, diversity was not doing well and individuals had few layers so they manually analyzed individuals
***Initial population individuals matched targeted population
***Larger individuals actually did worse, maybe because there were more room for mistakes
***Potentially look at incrementally larger individuals
**Finished inclusion and testing of pooling and drop out for experiments to compare to midterm benchmarks
***With new improvements, they had a 68.5% accuracy which is much more than 56.3% and pooling can improve the evolved architecture
***However, dropout layers did not do well
**Looking at dense layers
***Will adding fully connected layers improve performance?
***However, there was a lower validation and training accuracy. It had low diversity as well and didn’t do as well compared to SOTA or transfer learning.
**WIth visualizations, they improved their tech
***Inactive nodes, layer arguments, and node numbers are added
***Can visualize multiple individuals as needed
***Easy to use command-line interface makes it easy to visualize individuals
**Want to work on better seeding as well
***Looked at online code from TensorFlow’s github
**CGP Paper overview and crossover
***Looked at symbolic regression problems
***Each generation contains offsprings and best individuals from previous generations
**Meta parameter search
***Can get expensive for computational efforts, but fitness is defined as the mean result
**New mating method is through using one-point crossover
***Can get expensive for computational efforts, but fitness is defined as the mean result
***Mating converges faster than runs without mating
**Point mutation - look at percent of parent’s genes to create new child genotype
**Next semester - new mating methods, existing CNN architectures
*NLP
**Take an evolutionary approach to NLP via neural architecture using emade
**Different layer primitives
**In the past:
***Focused on Neural Architecture Search (NAS) and created new primatives for them
***Looking into computer vision applications 
***Too many trivial solutions
**This semester:
***Streamlining how the team ran EMADE and pick better datasets in the future to have better runs.
***Ran emade and examined the shortcomings of their implementation of NAS
**Pretrained embedding layers
***NN layer which input is vector representation of words learned by a predefined vocabulary
**Documented over 50 primatives
**Amazon Product Reviews Dataset
***A binary classification and balanced dataset. 
***Only used half the train data since it was large
**Baseline Models Used
***FastText Model used for benchmarking and achieved 91.73% accuracy
****Seeds are doing really well comparitively
****AUC of results marginally decreased when looking at seeds
** Non-trivial solutions
*** Best individual has a 92.8% accuracy after 22 generations, and this experiment has replicated similar results
**Improvements were very strong at the start but later becomes more marginal after a sharp drop-off
***With the first run, we see there were 17 Pareto optimal individuals, though 7 were seeded
***The elapsed time of individuals was a metric for complexity with an AUC of 0.027
***The second run was 21 generation but only had 4 individuals on pareto front that weren’t seeded, and had an AUC of 0.04.
***Outperformance of seeds became more obvious past generation 20, with best accuracy being 0.9313.
**Takeaways: No discernable pattern in misclassified reviews
***Longer reviews weren’t as good, and dataset could be labeled better
**Future work
***Increase network complexity and decrease failure rate through examining the structure
***Also might want to return to CV and avoiding multilabel datasets
***Improve EMADE’s outlook when seeded poorly
***Look at NNLearners as subtrees
*Modularity
**Questions
**Small selection from MNIST population so that we can get more generations in a small amount of time, but as a result, there's a smaller generation
***This is also because we have a larger seeding file
**We have many individuals on slide 8
***Scalar multiply can help accentuate complexities of the pictures
**We also check for validity of individuals first before looking for ARLs

====== Action Items: ======
{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Finish final PowerPoint
|Complete
|4/26/2021
|4/30/2021
|4/29/2021
|-
|Analyze baseline runs with old architecture
|Complete
|4/26/2021
|4/30/2021
|4/28/2021
|-
|}

== April 19, 2021 ==

====== Lecture Notes ======

*Nearing the end of the semester, with final presentation happening on April 30th from 6-8:50.
*Stocks
**Clarified the main objective of the team
***Working to make software that can predict for any stock after training with specific data.
**Looking into running something not as volatile, such as data with longer time frame
**Currently working on creating new fitness function
*ezCGP
**For visualization, they're adding parameters.
**Currently, best individual is only at 55% accurate
**Difficulty building the individual right now.
*Modularity
**Finally have something running without errors on the depth problem from new database and primative
**Want to see if there are any other issues as well
**Not getting consistently valid individuals due to poor objectives and seeds
**Two objectives getting the same values from when Angela and I ran it
*NLP
**Currently, multiple long hour runs led to over 0.9 accuracy which is great.
**Main categories are debugging, improving evolution, using learners as subtrees, pace-ice things

====== Subteam Meeting ======

*We need to wrap up for the end of the semester.
*Setting first semester students up with figuring out edge cases and running emade
**Also need to code new objective functions for new seeded runs.

====== Subteam Meeting 4/25/2021 ======

*Semester is wrapping up and we need new exploration/analysis
**Returning semester students will be using mnist runs with adf structure
**First-semester students wrote new objective functions and revamped the seeding file for new runs!
**First semesters will be doing runs without adfs
**Kevin and Gabriel will be working on fixing new architecture before trying runs as well
**We'll try to finish around 4 or 5 runs to analyze for our final presentation

====== Personal Exploration ======

*Used git checkout mnist to see changes to our mnist branch
*Our templates file for input_mnist.xml was updated, and I added in our database username, etc as needed
*Changed the following
**<maxAdfSize>3</maxAdfSize>
**<shouldUseADFs>true</shouldUseADFs>
*Ran a worker process for two runs with Vincent as the master process
*First run uses database mnist_old_arl_0
**Had 55 valid individuals but got stuck on generation 12
**As a result, we needed to rerun with new architecture
*Second run uses database mnist_old_arl_1
**Currently only has run for 3 hours with 29 valid individuals
**To find valid individuals I run the SQL query 
***select * from individuals where `FullDataSet F1 Score` is not null;
*I will soon analyze the Pareto front with the new objectives
**Potentially look at just 2 at a time and see which individuals satisfy all of them
**Could also flatten to 2 objectives instead of looking at hypervolume
*From one quick glance at the results, it seems as if one individual is doing much better than some of the other individuals
*Thinking about steps to take for the databases issue for next semester since we won't have time this semester
**Step one: Retrieve individual from database by using pymysql and the primary key for the ARL
**Step two: Place the ARL on the node where it was called/connect it to the individual
**Step three: Expand the ARL by undoing what the other subteam within Modularity has done
**Step four: Close the MySQL connection
*Currently looking within the various files to see where the code might be inserted -> for now, waiting to save writing actual code for this till next semester.

====== Action Items: ======
{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Try new runs on mnist with adfs
|Complete
|4/19/2021
|4/26/2021
|4/25/2021
|-
|Start final presentation to work on
|Complete
|4/19/2021
|4/26/2021
|4/25/2021
|-
|}

== April 12, 2021 ==

====== Lecture Notes ======

*Stocks
**Preparing runs for Thursday
**Complete methods
**Working on seeding and did a previous run
***Focusing on fixing things wrong with their recent run
**What happens when you swap in different spots?
*ezCGP
**Trying out block coding and new changes to see if they're helpful
**Analyzed why some individuals only had 4 or 5 nodes
**Lots of individuals generated but not always chosen, so they changed objective scores
**Visualized individuals to see why certain routes were picked
***Don't have anything that skips
**Currently only have easy primitives added
*Modularity
**Need new objective functions since this is same and not multi-objective
**Having issues generating valid individuals - but Angela and I found several good generations, we need to verify
**Our data also isn't one-hot encoded
***Need better multi-class metrics
**May switch to recall or accuracy

====== Subteam Meeting ======

*Talked with Jason and Gabriel about the mnist run that Angela and I did
**Goal was to minimize F1 accuracy scores
**Difficult to generate a pareto front since the run was more single-objective than multi-objective
**We took a look at some of the valid individuals that did well

====== Subteam Meeting 4/17/2021======

*This subteam meeting is specifically for the databases issue (and is an optional meeting)
**Certain primitives have some issues when converting to database storage
**Currently, three edge cases get lost
**Learners take in learner type, and learner type takes in ARL, but this doesn't get stored
***We want to look into how to better store individuals
*Currently database stores id, input, output, arl expression
**We want to use a more modular design where we can pull arls from the database depending on what the node references
**Currently, the pickle column stores pickle file in the form of "blobs" that we can unpickle using python to get the information back out
***Every individual has its own pickle, which stores individual in its tree form
***code: for node in pickle: print(node.name)
*Goal
**After finding ARLs, store in the database
**While evaluating individuals, unpack ARLs from the pickle
**Example
***Generation 10 finishes evaluating
***Selects individuals
***We create ARLs
***Generation 11 starts
***Now we have new individuals with ARLs in them for evaluation
**Most emade functionality is in EMADE.py through the evaluation() function
***Previous, we just did Learner(ARG, ARL(2)) and run since the ARL was a lambda
***Now, we need to see that if we see an ARL in an individual, then we read from the database and substitute nodes as needed. 
*EMADE originally used ADFs
**We may want Learner(ADF, args) and have it unpack what the ADFs were
**Our population is a list of individuals which is a list of nodes and primitives
**Emade is actually a list of lists where the first index is the individual which might contain ADFs
***Indices after that would be an ADF
**We see that [0] is Learner(ADF, args), [1] is Window filter, [2] is ...
**These ADFs however are tied specifically to the individuals rather than being able to be accessed
*We'll either rewrite evaluate() function or evaluate_individual function
**eg. If ADF/ARL in individual: extract and substitute with a post evaluation function where we re-compress stuff
*We might also want to look at wrapper_methods.py to see how we create primatives, and pre-post primative functions
*Current possible tasking
**ARL/contract Storage in database
**ARL evaluation/expansion where we read from the database
***I have been assigned to this topic with Angela, Rishit, and Gabriel
*Working off of tree_database branch which is old architecture
**Looking at EMADE.py, evaluate() and evaluate_individual() function, maybe wrapper_methods.py (though not preferable)
**Need to communicate with first team to know how to read and write from the database. Maybe look at sql_connection.py

====== Personal Exploration ======

*Angela and I worked on creating another run and set up a work session together
**Unfortunately, we kept getting errors after setting use_adfs to true
**I also looked at cloud copy script but couldn't figure out how to get rid of recursion after several attempts
**At best, we still had to delete the duplicated emade-cloud folder.
**Angela created visualization of an individual
**I graphed the F1 accuracy score against the generations, but couldn't find a trend from our current run
*We tried to seed a run and use new objective functions like false positive and false negative
**Unfortunately, we only got 8 valid individuals
**This is because those only work for binary classification problems
*Gabriel suggested using precision and recall which we might have to code in
*Looked into the emade.py code source repository
**We see that for evaluate_individual on line 1474, currently the arguments are an individual and a dataset.
**Current to-do: If 'adf' is discovered while evaluating, run the expand_adfs() method to expand out the tree again, then recompile the individual as expected
**Idea for writing expand_adfs() -> we need to make sure that we can reference the adfs through the database and insert in the individual as needed. (Line 1547 of the code)
**Look into pymysql and sql alchemy
**Look at adf_update
**We see that to use the database, we need to go to sql_connection_orm_master.py and look from line 94 to line 114.
***You can also see our best individual from the current runs before we moved to new objectives as seen by the visualization we worked on below:
[[files/OldInvid.png|A visualization of our current best individual.]]

====== Action Items: ======
{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Look into CloudCopy.sh
|Complete
|4/12/2021
|4/18/2021
|4/13/2021
|-
|Look up other statistics
|Complete
|4/12/2021
|4/18/2021
|4/17/2021
|-
|Create visualizations of individuals
|Complete
|4/12/2021
|4/17/2021
|4/16/2021
|-
|}

== April 5, 2021 ==

====== Lecture Notes ======

*Stocks
**Look at what our code does and what the purpose of the subteams are
***New first semester students are looking into technical indicators
**Try to create new objective functions
*ezCGP
**Added maxpooling and drop layers
**Ran 50 generations with 8 individuals
**Have an accuracy of 68.4%, but very little diversity
***Mostly one individual with many mutations
**Dropout layer individuals were likey to be dropped at the start.
*Modularity
**Runninig benchmark runs of MNIST and using F1 scores and accuracy
**Trying to work out some bugs
*NLP
**Getting new members set up in PACE to start working
**Got 87% with only 1000 instances so far, can work with a reduced training set.
*Statistics Lecture
**If we get ten times to get results from generations of AUC, we have the following statistics
***Mean
***Variance = E[x^2]-E[x]^2
***We can correct by bias by finding s^2 = n*sigma&2/(n-1)
**Hypothesis testing
***Computing a probability of observing a sample at least as extreme as ours given our assumption of the underlying truth.
***The lower the alpha level, the higher the confidence interval and the less likely you’d have a type 1 error
****The opposite is a type 2 error
***We use a t-table to find the test statistic as needed from the results
**One possibility is we can use Welch’s t-test, or an unequal variance t-test
***We want to see the power we have to reject the null hypothesis from our t statistic
***You can compute how many trials you need to get a rejection of the null hypothesis once you quantify your experiments.

====== Subteam Meeting 4/4/2021 ======

*Updates
**Gabriel has been helping debug
**Kevin finished contract_arls but it doesn’t work.
**Need to be able to access primitives within the individual to analyze it
**Potentially rewrite script to work for mac? So that infinite recursion doesn’t happen
**I can try it but I’m not sure
**Need to get emade-cloud working
*How to do analysis
**Traditionally emade is trained on feature data and make predictions from that
**However, stream data (used in images) is different because images are more complex
**This means we don’t train on images directly unless we use convolutional neural networks - this way models don’t get trained on pixels
**Machine learning is trained on feature extraction where images are converted to feature data first before they get trained on the model
**With MNIST, what happens is there is an additional step needed to make individuals valid.
*Our current data set
**Arg 0 is the data set that we feed in. It might use other primitives such as FFT and so forth.
**This primitive converts stream data into feature data which makes it into a valid individual.
**This extra step may result in less valid individuals

====== Personal Exploration ======

*Helped Krithik Acharya with seeding
**He forgot to update the mnist.xml files
*Finally reuploaded emade-cloud
**Made sure to delete recursive folders within to shorten upload time
**Only need to upload around 201 files
*Ran emade with Angela using google collab, with Angela as the master and me as the worker.
**Completed 1 run with Angela that lasted about 4 hours
**933 individuals in 48 generations
**75 valid individuals, with two individuals that have F1 accuracy scores of 1
**Have multiple individuals with 0.89 or 0.88 scores
*Plan to visualize the individuals soon and analyze them
*Problem: The objective scores are off right now, and we see both objective scores are equal. We may want to modify this.
*Questions:
**How many images are tested on?
**How Why does MyProd and ThresholdBinary doing so well as overall predictors?
**Below is a graph of the overall F1 scores that did the best in a certain generation over multiple generations
***Unfortunately, we can't see much of a pattern here.
**We need to analyze the individuals more on their own and rerun with multi-objectives, since this set of results only has one real objective.
[[files/GenerationF1Score.png|A graph of F1 scores over generations.]]

====== Action Items: ======
{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Look up more possible statistics tests to use for analyzing
|Moved
|4/5/2021
|4/11/2021
|Move to Next Week
|-
|Review statistics notes
|Complete
|4/5/2021
|4/11/2021
|4/7/2021
|-
|Run emade and review valid individuals
|Complete
|4/5/2021
|4/11/2021
|4/10/2021
|-
|}

== March 29, 2021 ==

====== Lecture Notes ======

* First semester students assigned to teams as needed
* 7 students assigned to each team
* Stocks
** Discussed using fitness functions to optimize invidiuals
** How are stronger individuals made? More diverse individuals?
** May use Monte Carlo Method
* ezCGP
** Looking at dense layers
** Continued analyzing runs from the semester
* Modularity
** Looking at how we can proceed in the future
** Looking into using the MNIST dataset for more runs
* NLP
** Wants to get more nontrivial results as needed

====== Subteam Meeting ======

* Sent out form to returning and new subteam members
* Discussed whether to focus on MNIST baseline runs or work on increasing diversity/mutation functions instead
* Went over a powerpoint introducing new members to modularity

====== Subteam Meeting 4/4/2021 ======

*Not much work done, Ivanna is working on the implementation
*Vincent is working on documentation for add_all_subtrees
**Found a bug that needs to be resolved
*Angela and Xufei have been working on getting baseline runs
**Need to rename file
*Some people have made it to 37 generations
*We’re at a good spot to just do some analysis to the database and individuals
**Renamed database to mnist_hoes

====== Personal Exploration ======

*First struggled to read the files as needed
**The solution was to change the directly to emade-cloud rather than emade-datapair
*Could not upload the full emade-cloud folder
**Paused upload and manually uploaded the templates folder as needed
**Ran the code and uploaded other things as needed
**Added in code to update the version of scipy and numpy used
*For some reason can’t get mnist database to run with accuracy 
**Not getting valid individuals
**Even the four seeded individuals are not returning the right things
**Reached out to Gabriel to ask how we can get valid individuals and why our function for F1 score and accuracy aren't working.
*I'm running google collab as master process, Angela Young is the worker
** We created over 800 individuals but we can't get scores for any of them
** We're using the code linked here: https://colab.research.google.com/drive/1i_niAH2dxqdsdA-SMU3tYXCOW0DMRUXK?usp=sharing

====== Action Items: ======
{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Work on getting runs seeded
|Complete
|3/29/2021
|4/4/2021
|4/3/2021
|-
|Run Google Collab with Angela Young as Worker
|Complete
|3/29/2021
|4/4/2021
|4/3/2021
|}

== March 22, 2021 ==

====== Class Presentations: ======
* Stocks team
** Look at how EMADE introduces Stock market trend analysis
** Research step and implementation
*** Picked a new paper that is more consistent and wants to create a model that's better than the one in the paper
*** Writing Technical Indicator functions for data preprocessing
*** Write TIs that actually account for volumetric data
** Scope definition/Literature review
*** Paper uses Piecewise Linear Representation (PLR) that recognizes trends in stock price movement
** Implementation
*** Technical indicators used include simple moving average, bias, relative strength index, moving average, stochastic oscillator, Williams, transaction volume, and single day change for everything
*** Wants to expand technical indicators to match the paper
*** PLR Algorithim: Make trends visible in stock prices
*** Trends convert to trading signals and discuss threshold value using Genetic algorithm
*** Exponential smoothing - uses NN trained with TIs to predict trading signal
**** 15% tolerance to smooth out the predictions of whether to buy or sell
** Current issues
*** Figuring out smaller implementation details
*** How to generate proper thresholds per stock
*** Generating valid individuals in EMADE after seeding individuals
** Results
*** Predicted trading signals using a seeded run with 100 individuals, running it for 77 generations
*** About a 20% profit with tree size of 148 (for the best individual)
*** Does not use TI primitives at all
** Future
*** Look into getting a lot more technical indicators implemented into the run
*** Want to look at different time granularities
*** Look at various stocks like penny stocks, crypto, etc
*** Check out neural network evolution
*** Isolate evolution for technical indicators
* Bootcamp 1
** Data preprocessing - feature selection methods with univariate selection, feature importance, correlationship heatmap
*** Looking at variables that are the most correlated
** Used SGDClassifier, NuSVC, Random Forest, Quadratic Discriminant, AdaBoostClassifier, etc
** MOGP results minimized the FN and FP squared to encourage both of them decreasing
** The MOGP performed much better than ML models except 2
** Methodology: Minimal data cleaning with no parameters removed (they dropped Name, Embarked, and PClass for ML and MOGP)
** Ran for 21 generations and found 36 pareto individuals in final generation
*** Runs faster for cluster run due to shared computer power, and less redundancy
*** In addition, emade allows for more diversity.
*** EMADE has higher accuracy
* ezCGP
** Introduction
*** Uses graph-based structure instead of tree based structure 
*** This encourages custom primitives and data types
*** Uses a block strucure as well to avoid mixing
** Current progress
*** Focusing on Neural Architure search - This way they can recreate results with no transfer learning
*** Checking current assumptions
*** Transformers help with vision and language tasks
*** Began experimenting with genetic algorithms since there wasn't much existing research
*** Untrained model performed with over 10 hours of training
*** Ran experiments on training parameter benchmarking that converges after 20 epochs
**** Currently testing if ezcgp framework would create architecture complex enough without using transfer learning blocks
***** First ran a few generations after removing transfer learning blocks
**** Potentially overfitting
* Bootcamp 2
** Extrapolate title from each passenger's name
*** This way, you can expolate missing ages from title
** Imported fare from PClass
** Did Hot Encoding for Sex to make sure one is not prioritized
** Dropped Cabin, embarked from parameters
** Minimized FNR and FPR by squishing
*** Ran with a population of 300 individuals for 40 generations
*** GP surpassed ML
** Had 25 generations of EMADE
*** EMADE did slightly worse compared to MOGP and ML
*** Did they not use the same feature data preprocessing?
* Modularity
** Our presentation. Questions/Comments are below.
** Are there space complexities since we're running/storing each of the nodes? Should we use some worker process features to help with resolving time/space complexities?
*** Definitely takes up more space compared to before
*** Time complexity could also be an issue since we have to add more processes to EMADE processes but not too big of a concern
* Bootcamp 5
** Preprocessing
*** Made a chart to see which features were most correlated
*** Dropped columns as the chart said.
** GP
*** Fixed/normalized features before passing them in
*** Used NSGA II after trying out multiple selections
** ML
*** Used 1500 generations may have overfitted individuals, so they chose to go with first run of 50 individuals
*** Need to balance between number of generations and runs
** EMADE
*** Changed the dataset in the exact same ways
*** Didn't see significant improvements for EMADE which wasn't significantly better than GP or ML
*** Paired with the longesr running time, this may not be the best
* NLP
** Tried Nerual architecture search to work on EMADE
*** Focused on Kaggle's Amazon dataset.
** Found many trivial solutions and want to figure out why
** PACE-ICE standardizes runs 
** Started documenting NLP Primitives
*** Fully explains 7 implemented primities and a work in progress one
** Checked how to get a dataset up and running in EMADE
** Decided to analyze the  Amazon Product Reviews Dataset
*** Binary Classification and Balanced Dataset
** Worked on Kaggle baseline model but was hard to replicate in EMADE
** May use FastTEXT as primative
** Explored non-seeded runs, and got same results as a seeded run 
*** Need to analyze why individuals are failing
** In the Future
*** Want to expand into PyTorch functionality
*** Work on high compatibility with SOTA attention-based models
*** Look at deeper learning compability
**** Obstacle is refactoring code from Keras to PyTorch, resource prohibitive
** Goals
*** Try exploration more with amazon dataset
*** Look at trivial solutions
*** Identify weaker primatives
*** Look more into PyTorch 
* Bootcamp 3
** Data preprocessing
*** Dropped Name, ticket, and cabin since they either missed information or weren't revelant
*** Filled in missing values such as Age or Fare
*** One-Hot encoded Sex/Embarked, noticed some class imbalances
** MOGP and ML run
*** For MOGP they added 9 primitives to help evole more complex individuals
*** Hyperparameters include 200 generations, 200 selection size
*** Used mutUniform and cxOnePointLeafBiased
*** Used tournament selection with initial population, with NSGA-II to select best offsprings
*** MOGP pareto front is 0.1102.
** EMADE
*** Had 26 generations for about 3 hours, however difficult to get estimate of FPR and FNR
*** Through every generation the pareto front significantly increased
*** Almost all optimal individual has an AdaBoostLearner as the outer primitive (only other different one was myPlanckTaper)
*** Has high phenotypic diversity, but low genotypic diversity
** Comparison
*** The machine learning models are fastest time wise
*** EMADE has less individuals, but will have better AUC over time
*** We see that MOGP is best at individual tuning and # of pareto front individuals. 
* Bootcamp 4
** Data PreProcessing
*** PClass had a low correlation, Names had no value in the string format, both don't really help so were dropped
*** Filled in null values of age with the average
** ML and MOGP models
*** Ran XGBoost, AdaBoost, etc. Also looked at CatBoost.
*** Also looked at K-Nearest Neighbors
*** For Neural network they got 82.7% accuracy
** GP
*** For titanic MOGP, they used mutUniform, mutShrink, and csOnePoint wiht SPEA2 and selBest
*** Machine learning ended up doing better
** EMADE
*** Ran for 20 generations with 12 individuals on the pareto front without changing anything
** In the very end, it seems that genetic programming did the best with ML doing the worst. However, if EMADE ran for longer it may have done better.

====== Subteam Meeting 2/28/2021 ======
* Work session since we're not too sure
** Most people just run emade and don't have too much else
** We need to normally compare against the baseline but we might not have too many results
** Around generation 20, we begin getting smaller standard deviation
*** As a result, all our experiments look like they're significant
** However, we may need to fix that/find a way to make it better
** We could all make baseline runs
* Could potentially look into diversity papers and see if we can make a stand-alone function for improving diversity
** This way other subteams may be able to use them as well.

====== Action Items: ======
{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Try Baseline Runs
|Complete
|3/28/2021
|4/3/2021
|4/2/2021
|-
|Research more topics
|Complete
|3/28/2021
|4/3/2021
|4/1/2021
|}
== March 15, 2021 ==

====== Lecture Notes: ======
* Stocks
** Ran emade using new primatives, got interesting results
*** Not that good - potentially because they didn't run for long enough
*** Lower population back to 60 individuals so we can have crossover mutations
** Need to consider crossover, mutation function differences even with 700 individuals
* ezCGP
** Got benchmark results last week, now working on improving results
** Currently experimenting with individuals
* Modularity
** Now working on pushing code for working to the depth problem
** Want to set up a practice presentation sometime this week
** Still working through errors
* NLP
** Also getting a MySQL error when trying to run it
** Individuals are having issues with generating
** MySQL Operational error
* Note that presentations are next week

====== Subteam Meeting ======
* Working on updating ARL_Update method
* Potentially practice presenting over the weekend
* Vincent is still working on adding all subtrees
** Vincent is working on mapping leaf nodes
* Angela is still struggling to get emade to work.

====== Subteam Meeting 3/21/2021 ======
* Finishing up the PowerPoint slides for the presentation
** Working on adding our own slides and future slides for the powerpoint
* Going to present to the advisors today at 11:00 and get feedback.
* Personal: Added on slides for search_individual, modifying the future work part

====== Personal Exploration ======
* Added slides on to our powerpoint here: [https://docs.google.com/presentation/d/1iaC5dHYX7G-NWuCAFjjVVzKHMm7NUCk_kHP72tQmZc4/edit#slide=id.gc98f9b8f3e_1_16 https://docs.google.com/presentation/d/1iaC5dHYX7G-NWuCAFjjVVzKHMm7NUCk_kHP72tQmZc4]
* Future work: Look at implementing complexity count and adjust for that in the Find_ARLs updated method

====== Action Items: ======
{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Add to PowerPoint
|Complete
|3/15/2021
|3/17/2021
|3/18/2021
|-
|PowerPoint Rehersal
|Complete
|3/15/2021
|3/22/2021
|3/21/2021
|}
== March 8, 2021 ==

====== Lecture Notes: ======
* Stocks
** Working on getting a full run of emade
** Working on primitives still
** Start preparing data sets from template files
** Still figuring out how to find optimal threshold - make sure they're using truth data
* ezCGP
** Not sure if preprocessing is helping or not because it's counterintuitive
** Surprised not adding dense layers
** Working on creating stable evolutionary structure
** Developing new seeds through current population
** Make sure validation set isn't too similar to your training set - high validation score
* Modularity
** People working on depth stuff - have the individual components are done and we just need to combine the code.
** This week - we can begin experiments (hopefully)
* NLP
** Hitting snags with baseline models
*** Posting questions on stackoverflow
** EMADE is now running on the amazon dataset, currently doing another run on generation 24.
* Note: Midterm presentations are coming up! We get new students assigned the next week.

====== Subteam Meeting ======
* Working on pushing code to git
* Make sure I'm using ARLUpdate branch
** Potentially try downloading campus VPN

====== Subteam Meeting 3/14/2021 ======
* Add to the presentation and include all of our updates
* Try to run a practice presentation with the professors to get feedback and fix it
* Finish pushing code.

====== Personal Exploration ======
* Commited my code to the repository
** Looked at intro to github here: https://www.earthdatascience.org/workshops/intro-version-control-git/basic-git-commands/
** Commited my code to the ARL_Update branch after testing it.
** Had merge conflicts when I tried to push it.
** Ran git merge to resolve
***You can see the completed adf.py file here at my point of committing: https://drive.google.com/file/d/1wy-x7xql8ZR-TQE8zjvgvh8orCamEi8Q/view?usp=sharing

====== Action Items: ======
{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Find ARLUpdate branch
|Complete
|3/8/2021
|3/15/2021
|3/8/2021
|-
|Work on pushing new and improved code
|Complete
|3/8/2021
|3/15/2021
|3/9/2021
|}
== March 1, 2021 ==

====== Lecture Notes: ======
* Stocks
** Working on developing volume based indicators
** Currently trying to implement it into emade
** The paper seems to be different this time and they fully understand it
*** This paper is more consistent
** New research paper doesn't contradict itself
** Trying to create volume primitives
* ezCGP
** Fixed past pipeline bugs
** Currently visualizing graphs of the individuals
** Need to look at confusion matrices and their differences
* Modularity
** Currently working on our code base and modifying the search methods
** Just has one more commit left to the documentation
* NLP
** Currently only NSGA II is working and other things are getting weird errors
** Collaborating with stocks team to try and resolve error
** Jon is wrapping up the documentation
** Expect a couple of runs and have set up one instance
** Potentially using wrong deap version

====== Subteam Meeting ======
* New find method by Kevin is described by two different components
* We want to test each individual method before running it in the overall method
* Currently working on implementing changes to the code base
** I've already finished my search_individual method but I still need to test it before submitting it to our github code
** Gabriel is working with Angela and Regina on the database while the rest of us are changing methods within the code
** This session was mostly a work session

====== Subteam Meeting 3/7/2021 ======
* Bernadette made the generate_adf methods
** Still needing to test it
** Same as me!
* This subteam meeting is still a work session.

====== Personal Exploration ======
* Began coding the search_individual method
** Called with Kevin Lu to work on navigating through git so that I can upload my changes onto there
** Still need to test my current code with print statements to make sure it won't break our codebase
** The code I wrote is attached [https://codeshare.io/24ZZv8 here].
* Difficulty in installing the necessary packages for emade
* Found a solution here: https://stackoverflow.com/questions/64963370/error-cannot-install-in-homebrew-on-arm-processor-in-intel-default-prefix-usr
** The reason is because my macbook has a M1 chip
** Code to use is: arch -x86_64 /usr/local/homebrew/bin/brew install <packagename>
* Also needed to create an environment for emady using conda create --env myenv
* Each time from now on, must do conda activate myenv, and then did conda install lightgbm
* Code to run emade
** Just once: conda activate myenv 
** bash reinstall.sh 
** python src/GPFramework/seeding_from_file.py templates/input_titanicADF1.xml seeding_titanic_benchmark 
** python src/GPFramework/launchEMADE.py templates/input_titanicADF1.xml 
* Got new error when trying to run emade
** "Not a gzipped file"
** May be a macOS issue
** Worked when I reinstalled emade with git lfs install.

====== Action Items: ======
{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Test search_individual method
|Complete
|3/1/2021
|3/8/2021
|3/7/2021
|-
|Push method to git branch 
|Complete
|3/1/2021
|3/8/2021
|3/8/2021
|-
|Peer Evaluations
|Complete
|3/2/2021
|3/8/2021
|3/3/2021
|}
== February 22, 2021 ==

====== Lecture Notes: ======
* Stocks
** Working on generating PLR
** Looking at different folds using tech company stocks
*** Apple, Boeing, Verizon
* ezCGP
** Try to get a full run of ezcgp
** Try to initialize individuals
** Continue working on PACE-ICE
* Modularity
** Done with documentation side of things 
** Focusing on depth problem/location ARLs alongside smaller ARLs
* NLP
** Getting infrastructure set up
** Trying to start a run on the primitives 

====== Subteam Meeting ======
* Plans for finding the ARL
** Looking for partial ARLs
** All ARLs are same size before but now they're different sizes. Consider number of nodes in an ARL
*** Are bigger ARLs really better?
** Point of ARL is to minimize chance of destructive properties
** Note that ARLs will begin to have things in common
* Tasks to help find ADF
** Make sure update time works
** Also look at generate ADF

====== Subteam Meeting 2/28/2021 ======
* I will be working on the search_individual method
** Vincent is working on add_all_subtrees and Bernadette is working on generate_adf.
** Kevin assigned the tasks and is working on the find_adf tree.
* This is a work session.
** Finished coding the search individuals method

====== Personal Exploration ======
* Focus on getting Sphinx set up
** Need to download a C complier in order to get everything working. Downloaded X Code from the mac app store.
** Did some research into the way that nodes are stored
** It looks like the current individuals are a list of nodes in order from left to right
*** Notice that search_individual needs to traverse the individual from left to right, so we can just iterate through the codebase
** Reviewed the current find_adfs method listed in the class.

====== Action Items: ======
{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Review the codebase
|Complete
|2/21/2021
|3/1/2021
|2/28/2021
|-
|Finish getting Sphinx set up
|Complete
|2/21/2021
|3/1/2021
|2/28/2021
|}
== February 15, 2021 ==

====== Lecture Notes: ======
* Stocks
** Looked at google scholar to find more research papers that uses genetic programming
** Uses special labeling methodology for piecewise linear algorithms to mark special points and times.
** Currently focusing on plr stuff.
** Focusing on creating a new fitness function.
*** Issue: Focuses on 2008 stock data which happens during the recession.
* ezCGP
** Currently working on using PACE-ICE without it crashing
** Precision/recall is a little difficult
** Working on their branch to see if they can finish their current trials
** Potentially look at CFAR10 since memory might be an issue
* Modularity
** Created new modularity page to update things
** Working on changing architecture after looking into sphinx
** Looking to explore it more to see if we can get a more solid idea
** Need to rewrite how we find our ARLs since the depth issue is from our method of finding
** Trying to store more information in the database
* NLP
** Next week hopefully have more runs in pace
** Still working on getting everything set up

====== Subteam Meeting ======
* Past subteam meeting is recorded and uploaded
* Went over weaknesses of current architecture, had brief introduction to emade
* Add own thoughts to wiki page and potential future goal
* Set up survey to set up a new time to potentially work on sphinx
** Kevin asked if we should try to edit functions
** Mess around with codebase or just with dev?

====== Subteam Meeting 2/21/2021 ======
* Documentation has been assigned to Bernadette and Vincent
* Read documentation
* Tasking for the week
** Generalized depth vs partial ARL
** Potentially work on different methods
** I will work with Kevin on modifying the code base for bettering ARLs.

====== Personal Exploration ======
* Notebook self evaluation
** Name and contact: 5  
** Teammate names: 5 (linked above)  
** Neat, legible: 5  
** Organization: 5  
** Updated weekly: 5  
** Group topics: 5  
** Other individuals: 4  
** To do items: 5  
** To do consistency: 5  
** To do cancellation: 4  
** Level of details: 5  
** References: 4  
** Useful resource: 4

====== Action Items ======
{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Read over articles of other subteam members
|Complete
|2/15/2021
|2/22/2021
|2/21/2021
|-
|Watch recorded modularity meeting
|Complete
|2/15/2021
|2/21/2021
|2/21/2021
|-
|Notebook Self Evaluation
|Complete
|2/15/2021
|3/1/2021
|2/21/2021
|}

== February 8, 2021 ==

====== Lecture Notes: ======
* Market Analysis Team
** Discussed goals of the semester to align with research paper
*** Trying to find another research paper like the one last semester but more consistent
*** See how to use EMADE to implement results from the paper
*** How to improve past primatives 
*** Look at fundamentals such as APIs to use for more data
*** Discuss which stocks to target if it is not specified in the paper
*** Test on multiple stocks
** Future goals
*** Finish selecting a new research paper
*** Figure out actionable changes to make from the research paper
*** Common theme among papers: Look for papers with volume of data to use
* ezCGP Team
** Looked at past research paperes to look at transformeres and hyperparameters with genetic evolution
** Updated their problem file
*** Started working on PACE-ICE
*** Plan to test updated problem file and see the changes
** Looking into minGPT
* Modularity (Our subteam)
** Did literature review to look at papers and digest them
** Currently decided to read each other's papers
** Focus on expanding complexity for ARLs
* NLP
** Focusing solely on NLP to troubleshoot
*** Preprocessing vs unbalanced dataset? Dividing into multiple subproblems
*** Focus on controls while working on Amazon dataset.

====== Subteam Meeting ======
* Focus more on literature review to figure things out
* Try to figure out Sphinx
** Set up documentation for our project
** Automatically pulls from our code base
** Auto module pulls out individuals from the source code directly
** Can also pull out docstrings
* Current [[Modularity|Modularity page]]

====== Action Items: ======
{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Read over articles of other subteam members
|Incomplete
|2/7/2021
|2/15/2021
|Moved to next week
|-
|Summarize current paper on Wiki Page
|Complete
|2/7/2021
|2/15/2021
|2/8/2021
|}

== February 1, 2021 ==

====== Lecture Notes: ======
* Going over subteam progress goals
** Stocks
*** Play with selection methods
*** Check parameters
*** Try to incorporate more emade in the project
*** See how different sorts of data impact the dataset
** Ezcgp
*** Two team members use two separate projects
*** Look at preprocessing and altering data potentially
*** Use transformers to work on image coding
** NLP
*** No new updates for this semester
** Modularity
*** Interest in making deeper ARLs that are more than just one depth
*** Literature review for now for this week and next week, see what we can expand upon
*** Are ARLs always useful?
**** Last semester built upon flawed assumption

====== Subteam Meeting: ======
* Trying to make source code easier to read. Gabriel is going to write source code to make it easier to read.
* Let's work on a literature review this week
** Goal: Bring in one paper to talk about
** Presentation on intro to ARLs, possible resources, etc

====== Subteam Meeting 2/7/2021: ======
* Going over literature review to see what we can improve
** Gabriel - https://link.springer.com/article/10.1007/s10462-019-09706-7
*** A review of modularization techniques in artificial neural networks 
*** See how we can add larger trees to our projects
*** Comparing graphs to trees
** Kevin Lu
*** [https://link.springer.com/chapter/10.1007/978-3-540-88906-9_54 Mutation only genetic algorithms]
*** Brings an idea of each individual mutation probability based on fitness
*** A lot like my paper
** Vincent Huang
*** https://emade-vip.slack.com/archives/CMGTQ5JMS/p1612725361012400
*** Diversity based genetic programming
*** Measures diversity using distance and tree depth on the graph to get the similarity 
*** Also looks at subtree differences, which is how many changes you make from one tree to get to another tree.
*** You can also track generations to see the common parent that led to lots of high fitness individuals
**** Multiple ways to see how "similar" trees are.
** Bernadette
*** Looking at introducing diversity into our individuals as well
*** '''[https://dl.acm.org/doi/pdf/10.1145/3321707.3321718 Convergence and Diversity Analysis of Indicator-based Multi-Objective Evolutionary Algorithms]'''
*** [https://dl.acm.org/doi/pdf/10.1145/3376916 h'''ttps://dl.acm.org/doi/pdf/10.1145/3376916''']
*** '''[https://www.researchgate.net/profile/Michael_Emmerich/publication/235412985_On_Quality_Indicators_for_Black-Box_Level_Set_Approximation/links/0c960514cad7fc4ead000000.pdf On Quality Indicators for Black-Box Level Set Approximation]'''
** Angela
*** Discussing communities in regards to modularity
*** Establishing bounds within networks without having it become too rigid

====== Personal Exploration ======
* Worked on reviewing current literature and research paper
* '''[https://ieeexplore.ieee.org/abstract/document/7748328 A Survey of Modularity in Genetic Programming] by George Gerules, Cezary Janikow'''
** Previous limitations: For the Human Genome Project, there was no intrinsic value of a subroutine, since subroutine's fitness didn't differentiate from other building blocks of code.
** Sometimes, created routines aren't removed which leads to unfit routines
** Rosca and Ballard used subroutines or building blocks with their own fitness functions to identify useful ones and add them to a function set of an evolved genetic programs.
** Ways to keep track of usefulness
*** Structural complexity - number of nodes in a tree for subroutine
*** Evaluation complexity - number of nodes in a tree and number of times a call is made to the routine
*** Evaluation complexity - keeps track of "call hierarchies"
*** Description complexity - uses minimum description length MDL
**** This happens when a problem is coded in a minimal way to describe the overall representation.
**** Still confused, might ask about it at subteam meeting.
** As the GP run happens, we track newly created building blocks that are added to the function set and remove them if they are "unfit".
** Subroutines are subtrees with a depth between 2 and 4
** Methods and heuristics to test existing algorithms currently existing
*** Random method - selects blocks in program randomly
*** Randomfit method - selects blocks using either tournament or fitness proportional selection
*** Wholeprogfitness - selects block according to same fitness function
*** FITNESSBLOCK - selects blocks according to same fitness used for entire program.
*** BLOCKACTIVATION - does selection after crossover. We evaluate the child and determine whether it will replace the parents
*** Frequency method - selects block based on highest number of times it happens in population
*** Frequency Program - selects block based on highest number of times it occurs in single program
*** Schema - selects block according to average fitness of block in relation to average fitness of all programs
*** Correlation - selects blocks according to tournament or fitness proportional. Then a statistical correlation happens in the tree against subprograms in the tree.
*** Saliency - modifies building blocks to look for large scale differences in fitness. 
**** If modification causes large negative change, then subroutine has high semantic relevance to overall fitness.
** Randomness is also introduced
*** Low fitness subroutines are replaced with mutations - etc randomly generated routines
** Ended with mixed results. One reason it might not do better than vanilla GP may be because of the non-commutative nature of functions chosen for the evolutionary target.
* '''[https://bluejeans.com/playback/s/dKmkzdE9KG8o2IX0KjqqpX57A9CTAdntXRw4hdSgEBAd6bsLu6xwiAO1yc68i5zN Intro to Modularity Video]'''
** Made by Gabriel to introduce Angela and me to the topic.
** Presentation is found [https://docs.google.com/presentation/d/1yrkD411TYEVQ8OMiqODLsoXdDiVo43PZBZpW9-1TNlo/edit#slide=id.p here]
** ADFs (Automatically Defined Functions)
*** Created by Kozas. These are subtrees that are tied to an individual and only the individual. They can also grow and evolve.
** Adaptive Representation through Learning (ARLs)
*** Created by Rosca, and once we find a useful subtree, we lock it in.
*** Keeps a global pool of subtrees for any individual to call
*** ARLs can grow through nesting, so new ARL uses old ARL
** The two are not mutually exclusive!!
** Our current fork only has ARLs but we occasionally refer to them as ADFs.
** Our current work
*** Search population for parent and children nodes with 1 depth
*** We choose a combination of nodes from how often they're used
*** Abstract combinations into a single node
*** They can wrap around each other
*** Globally accessible through a primitive set
*** Current process
**** Selection to update_representation to mating to mutation
*** We have find_adfs and generate_adfs (should be arl)
** Future work
*** Diversity so we don't limit search space
*** Selection method to encourage the spread of ARLs
*** Mutation methods to spread ARLs through the population and have a mutation function that replaces nodes with ARLs
*** We can create new individuals with ARLs in every generation

====== Action Items ======
{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Work on literature review this week
|Complete
|2/1/2021
|2/7/2021
|2/6/2021
|-
|Find one paper to talk about by Sunday
|Complete
|2/1/2021
|2/7/2021
|2/6/2021
|-
|Watch intro to modularity video
|Complete
|2/1/2021
|2/7/2021
|2/7/2021
|}

== January 25, 2021 ==

====== '''Lecture Notes:''' ======
* Daniel Martin takes over as leader for ezCGP subteam
* Stocks subteam will be led by the same two members
* Modularity subteam: Still led by Gabriel Wang
* Neural Network/Architecture

====== Subteam Meeting 1/31/2021 ======
* Looking at research topics for the semester
* Talked about increasing diversity in our work
* Review literature, find papers about them
* Can discuss more ideas with Gabriel or Dr. Zutty
* Gabriel will be recording a video recording the work done so far so that we can look at possible things to explore
* I need to do some light research and reading to see what other topics there are.
* Potentially add more depth to our ARLs and get larger subtrees
* Potentially look at GECCO conference and literature

====== Action Items ======
{| class="wikitable"
!Task
!Status
!Assigned Date
!Due Date
!Completed Date
|-
|Create wiki page and set it up for the next semeseter.
|Completed
|1/25/2021
|2/1/2021
|1/26/2021
|-
|Meet with new subteam to go over modularity
|Completed
|1/25/2021
|1/31/2021
|1/31/2021
|}
