== Team Member ==
Team Member: Yash Shah

Email: yshah43@gatech.edu   Cell Phone: 404-909-7535

Interests: Machine Learning, Soccer, Python

= Fall 2019 =

== October 3,2019 ==

== September 27,2019 ==

==== Team Meeting: ====
* SCRUM meeting

==== Sub-Team Meeting: ====
* I was the only member from NLP-NN to show up.
* Talked to Mohan and he said the goal was still to implement the keras layers inside the EMADE primtives.

== September 20,2019 ==

==== Team Meeting: ====
* Couldn't attend the team meeting.

==== Sub-Team Meeting: ====
* Contacted Anish about what was going on for the week.
* The goal is still adding keras layers to EMADE
* We will also try adding a "healing" function after mutation to make sure that layer sizes add up
* AWS credits were assigned. But I already have EMADE up and running on GCP

== September 13,2019 ==

==== Team Meeting: ====
* Conflict students gave updates about their past week of work.

====== Sub-Team Meeting: ======
* I hadn't started reading about DeepNEAT but everyone decided to postpone it.
* Current task is to understand EMADE primitive
* Next task is to implement a keras layer inside the EMADE primitive.
* I had 300$ worth of GCP credits left so I created an EMADE instance.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|EMADE Primitve
|Resolved
|09/13/19
|
|
|-
|Implement a keras layer inside the primitve
|Resolved
|09/13/19
|
|
|-
|Set up a GCP instance
|Resovled
|09/13/19
|
|09/14/19
|}

= September 11, 2019 =
* Genotype is an array of vectors(encoding) and Phenotype(expression) is the string itself.Â 
* NEAT - Neuro Evolution of Augmenting Topologies.
* Topology is how many hidden units, weights we have.
* Augmenting means increasing.
* We start with smallest possible network and then augment it.
* One interesting point is how would you crossover 2 different networks of varying size, layers and nodes.
* This is done by keeping a track of the node's origins. The ones with the same ancestor are elgibile.
* Read - http://nn.cs.utexas.edu/downloads/papers/stanley.cec02.pdf
* Gained a basic understanding of RNN. 
* RNNs are basically NNs but with a feedback lop

== September 6 2019 ==

==== '''Team Meeting:''' ====
* Had the first team meeting of the semester for time conflict students
* Dr Zutty explained the goals of various teams
* I decided to join the NLP team.

==== Sub-Team Meeting: ====
* Specifically the NLP - NN Team. Our goal is to incorporate Neural Nets as a part of the EMADE framework
* We also decided our goals for the first week
* Cloned the NLP - nn repo on locally.
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read DeepNEAT
|Resolved
|09/13/19
|
|
|-
|Read NEAT
|Resolved
|09/06/19
|09/13/19
|09/11/2019
|-
|Install EMADE locally
|Resolved
|09/06/19
|
|09/06/19
|}

= Spring 2019 =

== January 7, 2019 ==
'''Team Meeting Notes:'''
* Professor Greg walked us through the structure of the course.
* Online notebooks are a new feature and apparently better than normal notebooks.
* Monday March 11 4:30 to 7:30 PM will have new students presenting what they learnt and old students will pitch about their respective teams.

'''Bootcamp Notes:'''
* Genetic Algorithms are based on Darwins theory of the the survival of the fittest.
* Genetic Algorithms working is Initialize population, Evaluation, Selection, Crossover/Mutation and repeat until Evaluation shows that the fittest individual has been created.
* Fitness determines the probability that it is selected for mating
* Discussed terms like Evaluation, Crossover/Mating (Single or double point), Mutation, Selection.
*DEAP - Distributed Evolutionary Algorithms in Python
* Lab 1 will familiarize us with it.
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Lab 1
|Completed 
|January 7, 2019
|January 14,2019
|January 13, 2019
|-
|Join Slack Channel
|Completed 
|January 7, 2019
|January 14,2019
|January 7, 2019
|-
|Read about DEAP
|Completed 
|January 7, 2019
|January 14,2019
|January 13, 2019
|}
== January 14, 2019 ==
'''Team Meeting Notes:'''
* All subteams gave a scrum update

'''Bootcamp Notes:'''
* Genetic Algorithm has its individuals represented as lists whereas Genetic Programming uses trees.
* Genetic Programming is an application of GA.
* Nodes in GP are called primitives and each primitive is some sort of 
* y = sin(x) can have sine function as a primitive set. (algebraic functions too)
* Root is the top-most node.
* Terminal (leaves) contains constants or arguments.
* While compiling each individual, just move leaves to root.
'''Lab 2:'''
* Arity is the number of inputs for the node.
* Symbolic Regression - use data to find the best fit.
* Genetic Programming cares a lot less about data and more about objectives.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Lab 2
|Completed
|January 14, 2019
|January 28,2019
|January 26,2019
|}

== January 28, 2019 ==

==== '''Team Meeting Notes:''' ====
* Scrum updates from team meeting notes

==== Bootcamp Notes: ====
* Terms like False Positive, False Negative, True Positive and True Negative were introduced.
* Pareto - an individual better than the rest on all objectives.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Lab 3
|Completed
|January 28, 2019
|February 4,2019
|February 1,2019
|}
[[files/Download.png]]

== February 4, 2019 ==

==== Bootcamp notes: ====
* Learned about the titanic problem
* My group includes me, Animesh, Sruthi and Sean.
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Titanic Lab
|Completed
|February 4, 2019
|February 11, 2019
|February 10, 2019
|}
* Did feature engineering on the columns. Experimented with the dataset
* As I was using random forest, my splitting function of the train dataset didn't split it randomly. First 2/3 portion was training and rest was validation.
* n_estimators(number of tress in the random forest) = 30 as I didn't want to overfit 
Kaggle Score: 0.77033

Confusion Matrix:
{| class="wikitable"
|True Positive (TP): 172
|False Negative (FN): 35
|-
|False Positive (FP): 15
|True Negative (TN): 73
|}
[[Bootcamp Sub-team Spring 2019 - Titanic ML]] (group 6)

== February 11, 2019 ==

==== Bootcamp notes: ====
* Use GP for the titanic problem.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Titanic Lab with GP
|Completed
|February 11, 2019
|February 18, 2019
|February 17, 2019
|}
* Used lab 2 as the starting point
[[Bootcamp Sub-team Spring 2019 - Titanic GP]] (group 6)

== February 18,2019 ==

==== Bootcamp notes: ====
* Installation of EMADE is goal of the week
* Python 3.6 (NOT 3.7) is must as Tensorflow needs to be used.
* Create a python 3.6 virtual environment with anaconda
* Used homebrew to install git lfs
* server is always localhost which points to ip address
* Used sql workbench to create a database schema

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install EMADE
|Completed
|February 18, 2019
|February 25, 2019
|February 22,2019
|}

== February 25,2019 ==

==== Bootcamp notes: ====
* Use Titanic with EMADE.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Connect EMADE to Master
|Completed
|February 18, 2019
|March 11, 2019
|March 12, 2019
|}

== March 4,2019 ==

==== Bootcamp Notes: ====
* Presentation should be 10 minutes long
* Topic is titanic with EMADE vs GP vs sklearn

==== Action Items: ====
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Presentation
|Completed
|March 4, 2019
|March 11, 2019
|March 10, 2019
|}
Connection to EMADE as a worker has been unsuccessful so far.  Getting the SSL connection error:

Installed mysql through homebrew and tried to change the mysql settings but wasn't able to.

While connecting a user to the titanic database changed ssl setting to no, yet to test if that works.

== March 11,2019 ==

==== Team Meeting: ====
* All teams including mine presented their presentations.
* Group 6 - [[Bootcamp Sub-team Spring 2019 - Titanic EMADE|https://vip.gatech.edu/wiki/index.php/Bootcamp_Sub-team_Spring_2019_-_Titanic_EMADE]]

==== '''Action Items:''' ====
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Decide which team to join
|Completed
|March 11, 2019
|March 25, 2019
|March 25, 2019
|}

== Caching ==

== March 25,2019 ==

==== Team Meeting: ====
* Joined the caching team.
* Create a new branch off the grid_slurm_integration branch and merged selection_methods.py and methods.py file.
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Create New Branch
|Completed
|March 25, 2019
|April 1, 2019
|March 31, 2019
|}

== March 31,2019 ==
'''Individual notes:'''
* There weren't really any changes to make to selection_methods.py and methods.py file.
* Also set up reading the EMADE code on pycharm IDE which is much better than reading on github. Also makes merging easier.
* The underlying goal of this exercise was for us to understand the current caching mechanism which isn't really possible from these two files.
* Asked Sam and he told me to read data.py and launchGTMOEP.py. - will do that next week
* Eric sent a pull request to Ben.

== April 1,2019 ==

==== Team Meeting: ====
* Part of the subteam that is supposed to improve the caching mechanism along with Alex Gurung and William Li.
* Have to start by understanding how the current caching mechanism works.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Current Caching mechanism
|Completed
|April 1,2019
|April 5,2019
|April 3,2019
|-
|Run EMADE on GCP
|Completed
|April 1,2019
|
|April 9,2019
|}

== April 3,2019 ==

===== Current Caching Mechanism:  =====
Goal is to understand what the current caching mechanism is from data.py and launchGTMOEP.py

Caching parameters are figured out by sending a query to the sql database to find the Cache Configurations which is returned as dictionary and pickled.

Basic overview is that most functions have an input parameter use_cache which is false by default.

When trying to save data to cache, data is stored in gen_data directory. Sometimes the data is hashed to save space too.

When caching mode is 1, the previous hash is used to query the database. The query will return the data pair or be empty.

If the query returns empty handed:
* Timer is started. 
* Point is that the data is cached only if the time taken to get the data is greater than a certain threshold.
* Training and test data is stored then.

<u>Question:</u> I'm not really sure how what data is kept in the gen_data folder is kept track of. Are we using a LRU (least recently used)  counter or what?
* One of the things that I have looked for and missed is, when the data gets updated does it updated in gen_data folder or the disk. (Are we following the write back or write through caching mechanism?) - Really depends on the systems preference. Code can't really choose that 

'''Ideas on how to improve caching:'''
* While storing data in the cache, create some sort of scoring methodology that will keep in mind time to read the data from disk, size on disk , frequency and its importance which the user can set as an input parameter. (Will be on hold till the benchmarking script is finished)
* Provide the user a choice to cache what he wants and assign a priority # to what he caches.

== April 5,2019 ==
* Caching sub-team meeting to discuss what the sub teams will work on..

* Discussed amongst ourselves our understanding of the current caching mechanism.
* Look for new ideas to improve caching

Caching maintains a current LRU counter to decide what to get rid off. As soon as the cache size exceeds a limit, the FIFO principle kicks out the least recently used data.

(answers my above question - source -https://github.gatech.edu/bchau7/emade/blob/grid_slurm_integration/src/GPFramework/sql_connection_orm.py)

== April 8,2019 ==

==== Team meeting: ====
* Use the knapsack problem to figure how to optimize cache
** Knapsack problem is a optimization problem
** Given a set of weight and their values, goal is to find max possible value for a particular weight limit.
* Current cache is too big and hence time taken is longer to fetch the required data.
* Use dynamic programming to create a more efficient cache.

==== Action Items: ====
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Understand Knapsack Problem
|Finished
|April 8,2019
|
|April 12,2019
|-
|Improve Alex's code
|
|April 8,2019
|
|
|}

== April 12,2019 ==

==== Individual notes: ====
https://www.geeksforgeeks.org/dynamic-programming/
* Used the above website to further understand dynamic programming.
* Discusses Tabulation (Bottom Up) and Memoization (Top Down) dynamic programming approaches.
* For Fibonacci series, DP reduces Big O from n! to linear.
* 0-1 Knapsack Problem - read and now implement it for the cache.

* Another way to improve cache performance is to use cache friendly code in the sense arrays must implemented as caching follows the principle of spatial locality (which is already implemented and kind of common sense too.)
Also, came across this interesting article (https://www.thepythoncorner.com/2018/04/how-to-make-your-code-faster-by-using-a-cache-in-python/?doing_wp_cron=1555888764.7517518997192382812500) which talks about using the cachetools library to speed up your python code and you use LRU caching(current mechanism) or TTL caching. Using this library would certainly get rid of a lot of code that is not needed but before making any conclusions need to more research on it or other such libraries.

== April 15,2019 ==

==== Team meeting: ====
* Continued working on figuring out how to improve caching.
* My GCP setup is working correctly. I used the instructions that Ben shared.

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Do research on existing caching modules in python
|Finished
|April 15,2019
|
|April 17,2019
|}

== April 17,2019 ==

==== Individual notes: ====
Caching library vs Creating our own caching mechanism: (discuss with team members)
* Having a library has its advantage where the user could choose a particular mechanism. This is would be helpful as EMADE will be used in a wide variety of applications with different kinds of data and I have my suspicions whether one caching mechanism would be a good fit for all.
* Could have an input parameter like the reuse option in the xml file as to choose a caching mechanism. Default could be set to LRU or something else.

The main reason I started looking at various caching libraries's source code was to gain inspiration.
* After looking at code for cachetools  (https://github.com/tkem/cachetools/blob/master/cachetools/cache.py) , it seems like the current caching mechanism in emade is based off this library. 
* Now looking at the Beaker library, which has an interesting property of creating separate threads which theoretically should speed up the process.
* Threading is probably the most promising idea I have stumbled upon while researching on how to improve current caching mechanism.
* Definitely one of the things that I'm going to research and maybe try implementing next semester.
* Implemented multithreading in C++. Input argument was a vector with 10000000 doubles as elements and surprisingly multithreading took far longer than a single thread.
*[[files/Screen Shot 2019-04-22 at 6.55.16 PM.png|none|thumb|1264x1264px]]
* Not really sure what to make of the result , but certainly need to do more testing and code in python before making a definite decision. Code - https://github.gatech.edu/yshah43/Multithreading
* Paper on multithreading in caches - http://web.engr.oregonstate.edu/~benl/Publications/Journals/IEEE_ToC99.pdf 
** Basically what it says is multithreading lowers memory latency - memory latency is time lag between data being fetched from memory and it being available to the processor
** lower cache miss rate due to temporal and spatial locality for data
** cache miss rate for instructions increases 
** It was published in 1999, so it is pretty old but it talks about dynamic thread creation and how users wont have to write multithreaded code - certainly something to look into 

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Dynamic Thread creation
|
|April 18,2019
|Fall 2019
|
|-
|Implement multithreading on grid_slurm_integration_branch
|
|April16,2019
|Fall 2019
|
|-
|Final Presentation
|Completed
|April 19,2019
|April 22,2019
|April 20,2019
|}

== April 19,2019 ==

==== Subteam meeting: ====
* Worked out presentation details

== April 22,2019 ==

==== Team meeting: ====
* Presented our final presentation - https://docs.google.com/presentation/d/15m_zXjYzh8NjSt8R-O-rFKncoHjmWP40Cz0Z09ACCn0/edit#slide=id.g569ac99600_10_0

I believe I should deserve an A because after joining the caching team I have done a lot of research on how to improve caching.  I also enjoyed spending a considerable amount of time reading through emade source code to understand the current caching mechanism.While this hasn't resulted in actually implementing any code, we think we know the best way to optimize it and now that benchmarking script is present we will try to figure that out in fall. I didn't know Machine Learning before this class, so it has been a steep learning curve for me and I have risen up to the challenge.

I can do feature engineering, use ml models on a dataset and use GP.

__FORCETOC__