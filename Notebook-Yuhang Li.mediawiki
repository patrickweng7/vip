
== About Me ==
[[files/W.E. in Yunnan.jpg|alt=A shameless selfie of me, my girlfriend and a pagoda in Yunnan, China|thumb|236x236px|Me (right) and my love]]
Name: '''Yuhang Li''', a.k.a '''William'''

Email: williamlee@gatech.edu

Phone: (404) 906 2209

Major: Computer Science (graduating in 2020)

=== VIP ===

VIP team: [[Automated-Algorithm-Design|Automated Algorithm Design]]

Joined in: Spring 2019

GitHub repo: https://github.gatech.edu/yli3048/AAD

Other team members: [[Notebooks_Spring_2019#Individual_Notebooks|Notebooks Spring 2019]]

=== Interests ===

CS: Compiler, Web Development, Game Development, Machine Learning, Deep Learning, Android Development

Non-CS: Geography (including but not limited to staring at maps), World History, Geopolitics, Chinese Calligraphy

<s>Video Games: EU4, BF1, HoI4, Civ5/6</s>

== Spring 2020 (3rd semester) ==
From '''Jan 27''' to '''April 20, 2020''',

Having fun with:
 __/\\\\\\\\\\\\\\\__/\\\\\\\\\\\\\\\________/\\\\\\\\\_____/\\\\\\\\\\\\__/\\\\\\\\\\\\\___        
  _\/\\\///////////__\////////////\\\______/\\\////////____/\\\//////////__\/\\\/////////\\\_       
   _\/\\\_______________________/\\\/_____/\\\/____________/\\\_____________\/\\\_______\/\\\_      
    _\/\\\\\\\\\\\_____________/\\\/______/\\\_____________\/\\\____/\\\\\\\_\/\\\\\\\\\\\\\/__     
     _\/\\\///////____________/\\\/_______\/\\\_____________\/\\\___\/////\\\_\/\\\/////////____    
      _\/\\\_________________/\\\/_________\//\\\____________\/\\\_______\/\\\_\/\\\_____________   
       _\/\\\_______________/\\\/____________\///\\\__________\/\\\_______\/\\\_\/\\\_____________  
        _\/\\\\\\\\\\\\\\\__/\\\\\\\\\\\\\\\____\////\\\\\\\\\_\//\\\\\\\\\\\\/__\/\\\_____________ 
         _\///////////////__\///////////////________\/////////___\////////////____\///______________

== Apr 20, 2020 ==

=== Final Presentation ===

==== ezCGP ====
https://docs.google.com/presentation/d/1TV78U_DNYqzz7cwFAqhuXwjJl6Ou8qVV0f8nkKiARjY/edit#slide=id.p

==== Data Augmentation ====
My slide: https://docs.google.com/presentation/d/1TV78U_DNYqzz7cwFAqhuXwjJl6Ou8qVV0f8nkKiARjY/edit#slide=id.g7459e25a8e_16_8

key points:
* what is data augmentation
** augmenting the dataset by creating new data from altering the existing ones
* why do we do data augmentation: 
** Increase the number of training examples
** Reduces overfitting and improving generalization
* how it is done: Augmentor
* how it is integrated with the new ezCGP architecture
** new Operators, Arguments and Evaluate function and Problem

=== Action Item ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Prepare for the presentation
|Completed
|Apr 17, 2020
| Apr 20, 2020
| Apr 20, 2020
|}
== Apr 17, 2020 ==

=== Meeting with Michael ===
I had a talk with Michael and Henry to finalize our code and make the presentation slides.

=== Action Item ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Add Data Augmentation and Preprocessing Evaluate functions
|Completed
|Mar 22, 2020
|Apr 17, 2020
|Apr 14, 2020
|-
|Add Data Augmentation and Preprocessing Operators
|Completed
|Mar 22, 2020
|Apr 17, 2020
|Apr 14, 2020
|-
|Add Data Augmentation and Preprocessing Problem
|Completed
|Mar 22, 2020
|Apr 17, 2020
|Apr 14, 2020
|-
|Add Data Augmentation and Preprocessing Arguments
|Completed
|Mar 30, 2020
|Apr 17, 2020
|Apr 14, 2020
|-
|Prepare for the presentation
|In Progress
|Apr 17, 2020
| Apr 20, 2020
| 
|}
== Apr 14, 2020 ==

=== Meeting with Michael ===
I had a phone meeting with Michael and Henry to get their opinions on my code.

I was able to finalize my code and made this commit with the help of Michael: https://github.com/ezCGP/ezExperimental/commit/cf8fc3ad27be9953b08409d3d30e8bba6059ea70

However, after the commit, the code ran into an unforeseen bug. This bug was later found to be caused by improper naming of Operators and fixed in this commit: https://github.com/ezCGP/ezExperimental/commit/4ac3c04646c7f9fc9c8360705ae57f2c4a519fb4

During the process, we also discovered that the BlockFactory class seems to be redundant and does not achieve what it was supposed to do (provide an abstract interface for producing different blocks), it turned out we still need to define separate Factory classes for each specification of a block. This class needs to reorganized.

Also, there is a lot of duplicate code in the [https://github.com/ezCGP/ezExperimental/blob/graph/evaluate.py evaluate.py], and should be refactored into a function. It could have been done easily but I did not do it so as to not break the code on other branches and causing confusion for other members. Michael also said he wanted to do the refactoring after all codes are merged in.

=== Action Item ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Add Data Augmentation and Preprocessing Evaluate functions
|Completed
|Mar 22, 2020
|Apr 17, 2020
|Apr 14, 2020
|-
|Add Data Augmentation and Preprocessing Operators
|Completed
|Mar 22, 2020
|Apr 17, 2020
|Apr 14, 2020
|-
|Add Data Augmentation and Preprocessing Problem
|Completed
|Mar 22, 2020
|Apr 17, 2020
|Apr 14, 2020
|-
|Add Data Augmentation and Preprocessing Arguments
|Completed
|Mar 30, 2020
|Apr 17, 2020
|Apr 14, 2020
|-
|Add unit testing for data augmentation and preprocessing problems
|Abandoned
|Apr 4, 2020
| -
| -
|}
== Apr 6, 2020 ==

=== ezCGP Team Meeting ===
* Progress report
* updated task: 
** try to get a few augmentation primitives loaded into the framework using the TensorFlow problem as a model
** the ultimate goal is to get a prototype working
* Michael confirmed with me that the integration of data augmentation and preprocessing primitives is going to be the last task for the semester. He wanted to make sure I take my time to write the code properly and get everything merged in one week before the final presentation.

=== Action Item ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Add Data Augmentation and Preprocessing Evaluate functions
|In Progress
|Mar 22, 2020
|Apr 13, 2020
|
|-
|Add Data Augmentation and Preprocessing Operators
|In Progress
|Mar 22, 2020
|Apr 13, 2020
|
|-
|Add Data Augmentation and Preprocessing Problem
|In Progress
|Mar 22, 2020
|Apr 13, 2020
|
|-
|Add Data Augmentation and Preprocessing Arguments
|In Progress
|Mar 30, 2020
|Apr 13, 2020
|
|-
|Add unit testing for data augmentation and preprocessing problems
|Not Started
|Apr 4, 2020
| -
|
|}
== Apr 4, 2020 ==

=== Meeting with Michael ===
I had a phone meeting with Michael to report my findings about the new codebase and get his opinions on how my code should look like.

Michael provided me with a done Problem class modeled for TensorFlow 2 training as an example: https://github.com/ezCGP/ezExperimental/blob/graph/problem_tensorflow.py

A test file is also written to test out the TensorFlow problem: https://github.com/ezCGP/ezExperimental/blob/graph/unit_tests/test_tensorflow.py

To run the test file: <code>python -m unittest unit_tests/test_[http://tensorflow.py/ tensorflow.py]</code>

To run the evolution: <code>python [http://main.py/ main.py] -p problem_tensorflow -s 1</code>

I may also add my own testing for data augmentation and preprocessing later on.

=== Action Item ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Add Data Augmentation and Preprocessing Evaluate functions
|In Progress
|Mar 22, 2020
|Apr 6, 2020
|
|-
|Add Data Augmentation and Preprocessing Operators
|In Progress
|Mar 22, 2020
|Apr 6, 2020
|
|-
|Add Data Augmentation and Preprocessing Problem
|In Progress
|Mar 22, 2020
|Apr 6, 2020
|
|-
|Add Data Augmentation and Preprocessing Arguments
|In Progress
|Mar 30, 2020
|Apr 6, 2020
|
|-
|Add unit testing for data augmentation and preprocessing problems
|Not Started
|Apr 4, 2020
| -
|
|}
== Mar 30, 2020 ==

=== ezCGP Team Meeting ===
* Progress update: little work done from most members
* Updated team goal by end of semester:
** Instrumentation to collect/gauge evolution, seeding
* new semester students crash course on ezCGP: https://drive.google.com/open?id=1y1Ybczg9sL57SM2E5F5X53FPwOHb-Uc6

=== Individual Notes ===
I was looking at the new architecture of ezCGP and was deeply confused. 

I appreciate the new framework which makes a lot more sense from software engineering point of view:
* the new framework is more OOP-structured, with concepts from the new ezCGP model condensed into abstract base classes and implementing classes inheriting the base classes, forming a clean object hierarchy
But meanwhile I am confused by a lot of details in the new design:
* too many abstract base classes causing confusion on what classes to inherit and what behaviors can be expected from an implementation
* inconsistent naming and packaging renders the code very obscure to read
* lack of typing for arguments and return types makes the code hard to understand and reuse, partly due to not strictly following the typing and documenting convention established by PEP for Python 3
* overall, the current state of codebase seems to me like a mix of overengineering designs and careless development practices.
Despite the difficulties I encountered with the new codebase, I was still trying to make progress on my part, but then I ran into a problem with some missing operators and arguments that were supposed to be there but actually not implemented.

I talked to Michael about this, and he and Sam made the following update: https://github.com/ezCGP/ezExperimental/commit/31318d82db6dfc26a20384202947c69e86702aa4

As a result, I now also need to make my own Argument class for data augmentation and preprocessing.

=== Action Item ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Add Data Augmentation and Preprocessing block prototype to the new framework
|Completed
|Mar 14, 2020
|Mar 28, 2020
|Mar 27, 2020
|-
|Add Data Augmentation and Preprocessing Evaluate functions
|In Progress
|Mar 22, 2020
|Apr 6, 2020
|
|-
|Add Data Augmentation and Preprocessing Operators
|In Progress
|Mar 22, 2020
|Apr 6, 2020
|
|-
|Add Data Augmentation and Preprocessing Problem
|In Progress
|Mar 22, 2020
|Apr 6, 2020
|
|-
|Add Data Augmentation and Preprocessing Arguments
|In Progress
|Mar 30, 2020
|Apr 6, 2020
|
|}
== Mar 25, 2020 ==

=== ezCGP Small Group Meeting ===
This is a special meeting arranged for new students not familiar with ezCGP or the underlying concepts. I wanted to brush up on my fundamentals so I listened in as well.

Michael and Sam gave a crash course on Deep Learning: https://docs.google.com/presentation/d/1NDYt_0MIUn6Qikmn7JFCHi62-tKKHwKSKM1bQwlak3o/edit?usp=sharing

Key points covered:
* What is a Maching Learning problem
* Deep Neural Networks
* Perceptrons
* Activation functions: Sigmoid, ReLU, tanh, maxout, ELU, Softmax
* Optimizers
* Convolution layers
* Loss functions
* Gradient Descent
* Update weights

== Mar 22, 2020 ==

=== ezCGP Team Meeting ===
* Progress update
* New architecture finalized and skeleton code implemented
* Received detailed instructions on how to fit my work into the new architecture:
** I need to add new Evaluate functions for data augmentation and preprocessing blocks
** I need to add new Operators for data augmentation and preprocessing
** I need to add a new Problem to test out if data augmentation and preprocessing blocks work as expected

=== Action Item ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Add Data Augmentation and Preprocessing block prototype to the new framework
|In Progress
|Mar 14, 2020
|Mar 28, 2020
|
|-
|Add Data Augmentation and Preprocessing Evaluate functions
|In Progress
|Mar 22, 2020
|Apr 4, 2020
|
|-
|Add Data Augmentation and Preprocessing Operators
|In Progress
|Mar 22, 2020
|Apr 4, 2020
|
|-
|Add Data Augmentation and Preprocessing Problem
|In Progress
|Mar 22, 2020
|Apr 4, 2020
|
|}
== Mar 14, 2020 ==

=== ezCGP Team Meeting ===
* Summarized what the team has achieved in the first half of semester:
** benchmarking
** seeding
** data augmentation
* New tasks to be picked:
** fill in TensorFlow 2.0 primitives into new framework
** '''add a data Augmentation and Preprocessing block prototype to the new framework (assigned to me)'''
** seeding state of the art individuals

=== Action Item ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Make unit tests for Augmentor-integrated Dataset class
|Completed
|Mar 4, 2020
|Mar 18, 2020
|Mar 15, 2020
|-
|Add Data Augmentation and Preprocessing block prototype to the new framework
|In Progress
|Mar 14, 2020
|Mar 28, 2020
|
|}
== Mar 9, 2020 ==

=== Midterm Presentation ===

==== New ezCGP Architecture ====
[[files/New ezCGP Architecture.png|1189x1189px]]

==== Data Augmentation (my slide) ====
See here: https://docs.google.com/presentation/d/1DaGSf2-x87oNFT5oukKR1jfI0m2wtXs--56K3mf7q38/edit#slide=id.g8126fb0964_0_18

Key points:
* New pipeline: Data Augmentation -> Preprocessing -> Training
* Why data augmentation: 
** Increase the number of training examples
** Reduces overfitting and improving generalization
* Use an Augmentor pipeline
** Allows declaratively adding augmentation operators onto dataset
*** e.g. p = Augmentor.pipeline(); p.rotate(probability=0.5);
* Each DataSet object now has a training pipeline and a testing pipeline
* Better memory efficiency from last semester

=== Action Item ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Make unit tests for Augmentor-integrated Dataset class
|In Progress
|Mar 4, 2020
|Mar 18, 2020
|
|-
|Talk to Michael/Samuel about seeding
|Completed
|Mar 4, 2020
|Mar 11, 2020
|Mar 7, 2020
|-
|Test ezCGP integration with an algorithm
|Postponed
|Mar 4, 2020
| -
|
|}
== Mar 4, 2020 ==

=== Meeting with Jason ===
* Reported to Jason the current progress of the integration of Augmentor into ezCGP
* Discussed the plan for the next week
** Unit testing the Augmentor code with <code>unit_test</code> or <code>pytest</code>
** Seeding
** Testing ezCGP with a simple algorithm, e.g. AlexNet, to see how easily it can be used

=== Action Item ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Make unit tests for Augmentor-integrated Dataset class
|In Progress
|Mar 4, 2020
|Mar 11, 2020
|
|-
|Talk to Michael/Samuel about seeding
|Not started
|Mar 4, 2020
|Mar 11, 2020
|
|-
|Test ezCGP integration with an algorithm
|On Hold
|Mar 4, 2020
| -
|
|}
== Feb 29, 2020 ==

=== AAD hackathon ===

==== Redesign Dataset with Augmentor added in ====
I met with Michael and updated with him our current progress on the incorporation of Augmentor into ezExperimental.

Here is my commit to add the new Dataset class: [https://github.com/ezCGP/ezExperimental/commit/02795d32a6fc4f05f2eba487ec34b3e405dd1a92 dataset.py].

The associated PR is linked here: https://github.com/ezCGP/ezExperimental/pull/1.

==== New Tensorflow Graph Design ====
'''Goal''': refactor the current models with the new [https://www.tensorflow.org/guide/keras/functional Tensorflow Functional API].

The bottom right is how we used to construct a model using Keras Sequential. The left side is how we can construct a model with branches using the new TensorFlow Functional API:

[[files/Tensorflow Functional API.jpg|frameless|900x900px]]

How the model is now incorporated in the new Block object:

[[files/New ezCGP Object Hierarchy.jpg|frameless|900x900px]]

=== Action Item ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Integrate the new Dataset class into ezCGP
|Completed
|Feb 18, 2020
|Mar 2, 2020
|Feb 29, 2020
|}
== Feb 15, 2020 ==

=== ezCGP Team Meeting ===
I talked to Mr. Rodd and he went through the whole architecture with me.

This is the original structure of ezCGP:

[[files/Old ezCGP Structure.jpg|frameless|901x901px]]

This is the current state of ezCGP after we reorganized it this semester:

[[files/New ezCGP Structure.jpg|border|frameless|900x900px]]

The new architecture is much better organized and clearer and makes programming sense to me.

Now that I understand the overall architecture and I need to talk to Michael to find out how he envisions the augmentation fits into the big picture.

=== Action Item ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Talk to Michael about augmentation
|Completed
|Feb 15, 2020
|Feb 22, 2020
|Feb 18, 2020
|-
|Update ezCGP's DataSet class to use Augmentor
|Completed
|Feb 5, 2020
|Feb 14, 2020
|Feb 22, 2020
|}
== Feb 14, 2020 ==

=== Meeting with Michael ===
* The new data-augmentation block structure will produce an Augmentor pipeline object which will be passed to the training block. 
* The training block will use this pipeline object in the next_bach function. 
* The Dataset class can be initialized with a path to the training set and a blank Augmentor pipeline
* Michael will rewrite the blocks class to use the new Dataset class and stop threading the entire dataset through individual
* Then we will combine it and we can move onto testing+benchmarking phase

=== Action Item ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Talk to Mr. Rodd to understand ezCGP architecture
|Completed
|Feb 14, 2020
|Feb 22, 2020
|Feb 15, 2020
|-
|Update ezCGP's DataSet class to use Augmentor
|Completed
|Feb 5, 2020
|Feb 14, 2020
|Feb 22, 2020
|}
== Feb 5, 2020 ==

=== Individual Notes ===
* I read through Augmentor's [https://github.com/mdbloice/Augmentor documentation] and source code.
* I made a [https://github.gatech.edu/yli3048/AAD/blob/master/TeamEzcgp/ResearchAugmentor/augmentor_exercise.py script] that demonstrates the basic usage of the library
** Build a pipeline and specify its data source: <code>p = Augmentor.Pipeline("path/to/data")</code>
** Insert operators into pipeline and specify applying probabilities: <code>p.rotate90(probability=0.5)</code>
** Sample a certain number of images from augmented data (will be stored in separate folder): <code>p.sample(10)</code>
* The library also supports
** multi-mask image augmentation (read [https://github.gatech.edu/yli3048/AAD/blob/master/TeamEzcgp/ResearchAugmentor/augmentor_exercise.py#L22 this script] for a usage example and [https://github.gatech.edu/yli3048/AAD/blob/master/TeamEzcgp/ResearchAugmentor/Multiple-Mask-Augmentation.ipynb this notebook] for detailed explanation)
** parallel augmentation of ground truth data: <code>p.ground_truth("path_to_ground_truth")</code>
** Keras integration as a generator: generator = <code>p.keras_generator(batch_size=128)</code>
** Tensorflow integration: <code>transforms = torchvision.transforms.Compose([p.torch_transform(), torchvision.transforms.ToTensor()])</code>
* Commented on [https://github.com/ezCGP/ezCGP/issues/26#issuecomment-582233166 this issue] about the above findings.

=== Meeting with Jason ===
* Updated the above progress with Jason
* Jason wants us to pivot our focus onto producing some actual stats comparing our model's performance with-augmentation vs without-augmentation.
* Slides about generating stats on Emade: [https://github.gatech.edu/emade/reference_material/blob/master/Lectures/Lecture_6_Stats_For_EMADE/stats_for_emade.pptx download here]

=== Meeting with Michael ===
* Updated the above progress 
* I got assigned to replace/upgrade [https://github.com/ezCGP/ezCGP/blob/master/DataSet.py ezCGP's DataSet class] to use Augmentor.
** Our current dataset class batches the data into a Tensorflow graph in blocks.py. 
** However, dataset actually contains a physical copy of the Dataset.
** We want it to take batches from the cifar-10 dataset file structure. 
** Preferably we want to retain the next_batch syntax.

=== Action Item ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Update ezCGP's DataSet class to use Augmentor
|In Progress
|Feb 5, 2020
|Feb 14, 2020
|
|}
== Feb 1, 2020 ==

=== ezCGP Meeting ===
* I will tentatively join [[Notebook Michael Andrew Jurado|Michael Jurado]]'s augmentation team
* We will be using the [https://github.com/mdbloice/Augmentor Augmentor] library to build our data augmentation pipeline
* Augmentor streamlines data augmentation which is a process that will make our model more robust to data variance

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read the documentation of Augmentor
|Completed
|Feb 1, 2020
|Feb 7, 2020
|Feb 5, 2020
|-
|Write a prototype script for data augmentation
|Completed
|Feb 1, 2020
|Feb 7, 2020
|Feb 5, 2020
|-
|Post the above script to [https://github.com/ezCGP/ezCGP/issues/26 this] Github issue
|Completed
|Feb 1, 2020
|Feb 7, 2020
|Feb 5, 2020
|}
== 2019 (2nd semester) ==
From '''Aug 19, 2019''' to '''Dec 2, 2019''',

Having fun with:
 ╔╗╔┌─┐┌┬┐┬ ┬┬─┐┌─┐┬    ╦  ┌─┐┌┐┌┌─┐┬ ┬┌─┐┌─┐┌─┐  ╔═╗┬─┐┌─┐┌─┐┌─┐┌─┐┌─┐┬┌┐┌┌─┐
 ║║║├─┤ │ │ │├┬┘├─┤│    ║  ├─┤││││ ┬│ │├─┤│ ┬├┤   ╠═╝├┬┘│ ││  ├┤ └─┐└─┐│││││ ┬
 ╝╚╝┴ ┴ ┴ └─┘┴└─┴ ┴┴─┘  ╩═╝┴ ┴┘└┘└─┘└─┘┴ ┴└─┘└─┘  ╩  ┴└─└─┘└─┘└─┘└─┘└─┘┴┘└┘└─┘

== Dec 2, 2019 ==

=== Individual Notes ===

==== Personal Reflection ====
This semester has been quite uneasy for me. I have another course scheduled at the same time as our weekly meeting so I had to abandon my original team Caching and join a new one. This was nothing short of starting over again as I had no knowledge at all about the new team's domain and their progress, and the only thing I could carry over from last semester was my (limited) knowledge of EMADE that I learned from diving into the rabbit hole of caching. I spent the first couple weeks trying to catch up with the new team's work and filling in the holes in my understanding of neural network and natural language processing. I learned a LOT over the weeks but still not fully enough for me to comfortably make contributions on my own. Anish and Yoonwoo provided me with a lot of guidance, and I also learned a lot by picking up dots from their discussions (thank you guys!). I also had a couple of interviews scattered throughout the semester and they drained up a lot of my time. Luckily I won't be having any more of them next semester and I hope I can contribute more!

=== Time Conflict Students Meeting ===

==== Final Presentation ====
Link to our team's slides: https://docs.google.com/presentation/d/1GSIrOEssa06AZDewUNgxEtssS3OQrKnxbpkuIrEwlXY/edit#slide=id.p 

== Nov 22, 2019 ==

=== Individual Notes ===
I had an interview scheduled that afternoon and could not make it to the meeting.

Our team is trying to fix any more bugs that popped up during testing and finalize the slides for next week's presentation.

=== Time Conflict Students Meeting ===

==== Hackathon Session ====
* Added Embedding Layer changes (see Anish's commit [https://github.gatech.edu/athite3/emade/commit/ce3211fbbcc67c787bf2439b651083632db82134 here])
* Tested NNLearner and got a type error due to DEAP code
** Dr. Zutty wrote a passThrough function for our type (str) that fixed it
* Final commit: https://github.gatech.edu/athite3/emade/commit/7479a332600d1f639f3a937631d7c8760b2c4412

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Prepare for the final presentation
|Completed
|Nov 15, 2019
|Dec 2, 2019
|Dec 2, 2019
|}
== Nov 15, 2019 ==
=== Individual Notes ===
* I rewrote the Keras layers definitions in <code>[https://github.gatech.edu/athite3/emade/commit/f4929549a86e9da678ed03e3e00e2e8440f9936a#diff-60731d06a27a485035d070079f42da1a src/GPFramework/neural_network_methods.py]</code> (see the commit [https://github.gatech.edu/athite3/emade/commit/f4929549a86e9da678ed03e3e00e2e8440f9936a here])
** Our goal is to rewrite our representations of Keras layers so they can be serialized by the EMADE engine.
** I deleted the confusing "layer supplies" methods which took in out_dim, model (and sometimes activation_func) and returned a constructed Keras layer object.
** I added in Layer class and its subclasses to represent the different Keras layers in a serializable way (list of strings/lists)
* Correspondingly, the neural network primitives in <code>[https://github.gatech.edu/athite3/emade/blob/master/src/GPFramework/gp_framework_helper.py#L363 src/GPFramework/gp_framework_helper.py]</code> will also have to be changed
** The parameters for adding layer primitives will have to change in response to the new layer constructors

=== Time Conflict Students Meeting ===
* We discussed different ways to implement the objectives we laid down last week
* We decided to rewrite part of <code>src/GPFramework/neural_network_methods.py</code>
* See a detailed explanation of implementation in my individual notes.

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Fix the SQL error
|Completed
|Nov 8, 2019
|Nov 15, 2019
|Nov 15, 2019
|-
|Rewrite the layer definitions to enable serialization
|Completed
|Nov 8, 2019
|Nov 15, 2019
|Nov 15, 2019
|-
|Prepare for the final presentation
|Completed
|Nov 15, 2019
|Dec 2, 2019
|Dec 2, 2019
|}
== Nov 8, 2019 ==
=== Time Conflict Students Meeting ===

==== Notes ====
* Located source of the SQL <code>can't pickle _thread._local objects</code> bug with help from Jason
** The issue was that Keras models can not be pickled
** This can be solved by using serialization wrappers for the Keras layers.

==== Objectives ====
# Redefine initModel -> create empty list
# Create Layer objects (type, out dim)
# Subclass it for Embedding
# Redefine layer type functions to take in list, create Model of type, add it to list, return
# Choose NNlearner to iterate through lists and add stuff

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Fix the SQL error
|Completed
|Nov 8, 2019
|Nov 15, 2019
|Nov 15, 2019
|-
|Rewrite the layer definitions to enable serialization
|Completed
|Nov 8, 2019
|Nov 15, 2019
|Nov 15, 2019
|}
== Nov 1, 2019 ==

=== Individual Notes ===
* I reinstalled another Conda environment and created a new MySQL database to see if the error disappears by itself, but no success, it is still there.
* Anish and Yoonwoo all were able to replicate the error, so root must have been in the code rather than dependencies/environments.
* I am trying to add breakpoints with PyCharm debug to locate the source line for the error.
=== Time Conflict Students Meeting ===
All team members are trying to locate the source of the SQL error, as it is the sole blocker that prevents any further testing on our code.

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Investigate the cause for the SQL error
|Completed
|Oct 18, 2019
|Until it gets fixed
|Nov 8, 2019
|}
== Oct 25, 2019 ==

=== Time Conflict Students Meeting ===
No meeting this Friday because we just had presentation.

Link to the presentation slides: https://docs.google.com/presentation/d/1B63kw5ne58jJ0FhFcM9L7GplOe0Asq5awU27hqRoEp0/edit#slide=id.g64015f6982_0_71

Our goal for this and next week is still fixing the SQL error.

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Investigate the cause for the SQL error
|Completed
|Oct 18, 2019
|Until it gets fixed
|Nov 8, 2019
|}
== Oct 18, 2019 ==
=== Individual Notes ===
I couldn't make it to the Friday meeting because of an interview.

Anish decided to abandon our previous plan to spin up an AWS instance, because we have much more stuff to fix in our current codebase and our laptops work fine to run the tests.

So I put together whatever I could find from my research on creating AWS instances and pushed it to a separate branch.

=== Time Conflict Students Meeting ===
* We decided to pause creating the AWS instance for more important stuff.

==== Hackathon Session ====
* Trained a neural network that outperformed logistic regression benchmark
** Structure: Embedding -> LSTM(32) -> Dense(10, ReLU) -> Dense(1, sigmoid)
** link to the Google Collab instance used to train the model: https://colab.research.google.com/drive/1qKdRNr9onZRyDhWC5oEWAUY5yJxRwis3
* Implemented all of Neural Network Learner
* Added the GRU layer
* Made InitModel into an ephemeral constant
* The implementation of the embedding layer in EMADE was changed to the one in the seed model.
* Tested NNLearner
** Ran into the same SQL issue again
* Final commit: https://github.gatech.edu/athite3/emade/commit/555da6681b1febd9350b2abe904ec1c05a5928a8

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Prepare for presentation
|Completed
|Oct 18, 2019
|Oct 21, 2019
|Oct 21, 2019
|-
|Investigate the cause for the SQL error
|Completed
|Oct 18, 2019
|Until it gets fixed
|Nov 8, 2019
|}
== Oct 11, 2019 ==
=== Individual Notes ===
* I drilled into creating an AWS instance for our team to run EMADE on.
** I had to reorganize the dependencies and fix the docker-compose file.
** For some reason, a SQL error keeps popping up when we run an EMADE instance.

=== Time Conflict Students Meeting ===
* We started writing Keras layers as EMADE primitives 
** Implemented LSTM, Dense layers (see Anish's commit [https://github.gatech.edu/athite3/emade/commit/062266096ef3591cd79d3b6da2757033879f2cbd here])
** Embedding Layer is different from the other layers:
*** Its input should be data
*** It also needs vocabulary size and will have to calculate output dimension
* We decided to give up fixing the objective function, since the EMADE evaluation metrics should work. We can use the false positive and false negative evaluation functions.

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Create an AWS instance to run EMADE and test our changes on
|Abandoned
|Oct 11, 2019
|Oct 18, 2019
|N/A
|}
== Oct 4, 2019 ==
=== Individual Notes ===
* I tried to look into emade's code to see where I can put in my healing function.
* I found the script that is responsible for running the main learning logics: [https://github.gatech.edu/yli3048/emade/blob/detection_processing/src/GPFramework/learner_methods.py learner_methods.py]
* I also located where the learner parameters are set: [https://github.gatech.edu/yli3048/emade/blob/detection_processing/src/GPFramework/gp_framework_helper.py gp_framework_helper.py]
* And where the mutation methods are registered: [https://github.gatech.edu/yli3048/emade/blob/detection_processing/src/GPFramework/EMADE.py#L278 EMADE.py]
* Instead of doing healing after mutation, I can prevent mutants that violate layer size constraints by giving them fitness value of 0.
* I am trying to change the objective function to achieve the above goal.

=== Time Conflict Students Meeting ===
* I talked to Jason about deployment of EMADE using an image with slurm

==== SCRUM Reports ====
* Jason said branch [https://github.gatech.edu/yli3048/emade/tree/detection_processing/src/GPFramework detection-processing] has what we need to further our work on EMADE primitives.
* We asked Jason to clarify a bunch of questions relating to how EMADE works.
* Anish pointed out we also need a way to store model weights in addition to their structures, otherwise we would have to recompute the weights for the best individuals.
* Anish made a [https://github.gatech.edu/athite3/emade/blob/master/emade_spin_up.md writeup] as to how EMADE works at source code level.

==== Objectives ====
[[files/Descriptive name.jpg|thumb|267x267px|Objectives for this week]]
* Try to store model weights
* Create new learner type for Keras layers
* Figure out how data is inputted
* Change the objective function to prevent mutation from altering layer size

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Figure out how to implement Keras layers as EMADE primitives
|Completed
|Sep 13, 2019
|Oct 11, 2019
|Oct 11, 2019
|-
|Change the objective function to limit layer size mutations.
|Abandoned
|Oct 4, 2019
|Oct 11, 2019
|N/A
|}
== Sep 27, 2019 ==
=== Time Conflict Students Meeting ===
* I requested absence because of the career fair this Friday, and did not participate in the meeting.
==== SCRUM Reports ====
See NLP team report [[Natural Language Processing#September_30.2C_2019|here]]

=== Group Meeting ===

==== NLP Team ====
* Text Summarization subteam could not find a dataset for their specific text summarization method
* They decided to work on making their own sentence based extractive summarization method summarization dataset using dynamic programming
** Get news article for CNN dataset, parse it sentence level, perform evaluation functions on it sentence by sentence, use dynamic programming to utilize score of sentences before to the next sentence. In the end, you get a score for the whole document.
** Alex working on evens and Mohan is working on odd by end of this week.

==== NLP-NN Subteam ====
Since our group didn't get to meet this week, our goals will still be the same as last week.

Objectives:
* Add Keras layers as EMADE primitives
* Add healing function after mutation

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Figure out how to implement Keras layers as EMADE primitives
|Completed
|Sep 13, 2019
|Oct 11, 2019
|Oct 11, 2019
|-
|Try and test adding a healing function after mutation
|Completed (workaround found)
|Sep 13, 2019
|Oct 11, 2019
|Oct 4, 2019
|}
== Sep 20, 2019 ==

=== Individual Notes ===
* I learned from Mohan and Jiseok about how EMADE primitives work.
* My subteam created the [https://github.gatech.edu/emade/emade/tree/nlp-nn nlp-nn] branch on the [https://github.gatech.edu/emade/emade/ emade/emade] repo.
* We have got our Amazon credits (registration link: https://www.awseducate.com/Registration?apptype=student&courseview=true#INFO-Student).
* My team set up the AWS emade instance. Though I already have one running on GCP, I will test the AWS one to see if it works identically.
* I started to read [[files/Evolving Deep Neural Networks.pdf|the paper]] that introduces DeepNEAT
** It seems too complicated to be implemented any time soon
** This route is put on pause by the team

=== Time Conflict Students Meeting ===

==== SCRUM Reports ====
See NLP team report [[Natural Language Processing#September_20.2C_2019|here]].

See NLP-NN team report [[Natural Language Processing Neural Network#Tasks for 09/21|here]].

=== Group Meeting ===

==== NLP team ====
* Reagan and Bek met and went over various stemming methods and a strategy for lemmitization
** Reagan caught Bek up with his implementations on the Jupyter notebook
*** He implemented several different stemmers
*** Created a lookup table to match the POS coming from the tagger to the input that's required for lemmatizer
** Discussion of possible testing of effectiveness of the methods above by creating a primitive
* Mohan and Alex met and planned out the work needed to get done over the course of the semester
** We settled on approaching the problem as a supervised-with-dataset problem, and visualized inputs as lists of numerical values representing sentences

==== NLP-NN subteam ====
*We have got our Amazon credits (registration link: https://www.awseducate.com/Registration?apptype=student&courseview=true#INFO-Student).
*Thus we were able to set up an emade instance on AWS.
*We discussed how to implement Keras layers as primitives.
*We decided to try adding a healing function after the mutation step to make sure that layer sizes add up.

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Figure out how to implement Keras layers as EMADE primitives
|Completed
|Sep 13, 2019
|Oct 11, 2019
|Oct 11, 2019
|-
|Try and test adding a healing function after mutation
|Completed (workaround found)
|Sep 13, 2019
|Oct 11, 2019
|Oct 4, 2019
|}

== Sep 13, 2019 ==

=== Individual Notes ===

==== Natural Language Processing ====
Study of interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.

===== Key Concepts =====
* Syntax
** Lemmatization: It entails reducing the various inflected forms of a word into a single form for easy analysis.
** Morphological segmentation: It involves dividing words into individual units called morphemes.
** Word segmentation: It involves dividing a large piece of continuous text into distinct units.
** Part-of-speech tagging: It involves identifying the part of speech for every word.
** Parsing: It involves undertaking grammatical analysis for the provided sentence.
** Sentence breaking: It involves placing sentence boundaries on a large piece of text.
** Stemming: It involves cutting the inflected words to their root form.
* Semantics
** Named entity recognition (NER): It involves determining the parts of a text that can be identified and categorized into preset groups. Examples of such groups include names of people and names of places.
** Word sense disambiguation: It involves giving meaning to a word based on the context.
** Natural language generation: It involves using databases to derive semantic intentions and convert them into human language.

===== Techniques =====
Just as how '''C'''onvolutional '''N'''eural '''N'''etworks are frequently used in the field of computer vision to deal with images, '''R'''ecurrent '''N'''eural '''N'''etworks are widely used in NLP to process sequences of data.
[[files/RNN.jpg|thumb|Structure of a Recurrent Neural Network]]

==== Recurrent Neural Networks ====
A recurrent neural network ('''RNN''') is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior. Unlike feedforward neural networks, RNNs can use their internal state (memory) to process sequences of inputs. This makes them applicable to tasks such as unsegmented, connected handwriting recognition or speech recognition.

A very important and useful architecture of RNN is called '''Long short-term memory''' ('''LSTM'''). LSTM has feedback connections. It can not only process single data points (such as images), but also entire sequences of data (such as speech or video). The key difference between LSTM and classic RNN lies in that:<blockquote>Classic RNNs can keep track of arbitrary long-term dependencies in the input sequences. The problem of vanilla RNNs is computational (or practical) in nature: when training a vanilla RNN using back-propagation, the gradients which are back-propagated can "vanish" (that is, they can tend to zero) or "explode" (that is, they can tend to infinity), because of the computations involved in the process, which use finite-precision numbers. RNNs using LSTM units partially solve the vanishing gradient problem, because LSTM units allow gradients to also flow ''unchanged''. However, LSTM networks can still suffer from the exploding gradient problem.</blockquote>There are several architectures of LSTM units. A common architecture is composed of a '''cell''' (the memory part of the LSTM unit) and three "regulators", usually called gates, of the flow of information inside the LSTM unit: an '''input gate''', an '''output gate''' and a '''forget gate'''. Some variations of the LSTM unit do not have one or more of these gates or maybe have other gates. For example, gated recurrent units (GRUs) do not have an output gate. Intuitively, the cell is responsible for keeping track of the dependencies between the elements in the input sequence. The input gate controls the extent to which a new value flows into the cell, the forget gate controls the extent to which a value remains in the cell and the output gate controls the extent to which the value in the cell is used to compute the output activation of the LSTM unit. The activation function of the LSTM gates is often the logistic sigmoid function. There are connections into and out of the LSTM gates, a few of which are recurrent. The weights of these connections, which need to be learned during training, determine how the gates operate.

Here is a link to a really informative Youtube video explaining how RNN and LSTM work: https://www.youtube.com/watch?v=WCUNPb-5EYI

And an example of using RNN to train an AI to play Mario Kart: https://www.youtube.com/watch?v=Ipi40cb_RsI

==== NeuroEvolution of Augmenting Topologies Library ====
'''NEAT''' is an evolutionary algorithm that creates artificial neural networks. The [[files/Stanley.cec02.pdf|original NEAT paper]] gives a pretty good high-level explanation of how NEAT works.

In NEAT, a population of individual '''genomes''' is maintained. Each genome contains two sets of '''genes''' that describe how to build an artificial neural network:
* '''Node genes''', each of which specifies a single neuron.
* '''Connection genes''', each of which specifies a single connection between neurons.
The fitness functions, reproduction and mutation are similar to those that we have seen in regular evolutionary programming.

'''Crossover''' between two networks is achieved by keeping track of the origins of the nodes, with an '''identifying number'''. Those derived from a common ancestor (that are homologous) are matched up for crossover, and connections are matched if the nodes they connect have a common ancestry.

A '''structural mutation''', such as the addition of a node or connection can, while being promising for the future, be disruptive in the short-term (until it has been fine-tuned by less-disruptive mutations). This is dealt with in NEAT by dividing genomes into species, which have a close genomic distance due to similarity, then having competition most intense within species, not between species (fitness sharing).

A potential problem with NEAT is that it is hard to generate larger neural networks with it. This is addressed by '''HyperNEAT''' and '''CoDeepNEAT'''.

Here is an example of using NEAT to train an AI to play Super Mario: https://www.youtube.com/watch?v=qv6UVOQ0F44

=== Time Conflict Students Meeting ===
==== SCRUM Reports ====
See NLP team report [[Natural Language Processing#September_13.2C_2019|here]]
=== Group Meeting ===
I decided to join the NEAT subteam (subteam notebook [[Natural Language Processing Neural Network|here]]) under the NLP team (team notebook [[Natural Language Processing|here]]).

==== Team members ====
[[Notebook Jiseok Choi|Jiseok Choi]]

Yuhang Li (me)

[[Notebook Yoonwoo Kim|Yoonwoo Kim]]

[[Notebook Yash Jignesh Shah|Yash Shah]]

[[Notebook Anish Mahesh Thite|Anish Thite]]
==== Objectives ====
* Read about DeepNEAT
* Figure out the layer size

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read about DeepNEAT
|On Pause
|Sep 13, 2019
|Postponed
|
|-
|Learn about how EMADE primitives work
|Completed
|Sep 13, 2019
|Sep 20, 2019
|Sep 14, 2019
|-
|Set up cloud instance (waiting for credits)
|Completed
|Sep 13, 2019
|until we receive credits
|Sep 19, 2019
|}

== Sep 6, 2019 ==
* Missed two previous weekly meetings due to time conflict with the main session since this semester
=== Time Conflict Students Meeting ===
* Presented with available groups to join
** Research Fundamentals
** NLP
** Automated Preprocessing
** EzCGP (too big to join)
* I am more interested in NLP and Automated Preprocessing, will stay with the teams to figure out my role.
=== Group Meeting ===

==== NLP team ====
See NLP team report [[Natural Language Processing#September_4th.2C_2019|here]]

==== NLP-NEAT team ====

===== Objectives =====
* Install EMADE
* Read NEAT docs
* Read about NLP

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install EMADE on my local computer
|Completed
|Sep 6, 2019
|Sep 13, 2019
|Sep 6, 2019
|-
|Learn about [https://neat-python.readthedocs.io/en/latest/ NEAT]
|Completed
|Sep 6, 2019
|Sep 20, 2019
|Sep 16, 2019
|-
|Research how do NLP and RNN work together
|Completed
|Sep 6, 2019
|Sep 20, 2019
|Sep 10, 2019
|}

== Aug 26, 2019 ==
=== Team Meeting ===

==== SCRUM Reports ====
See all teams' reports [[Fall 2019 Sub-team Weekly Reports#Monday_Aug_26_2019|here]].

I did not personally participate due to time conflict.

=== Time-Conflict students ===
I created a private channel on Slack for all the students with time conflicts to discuss an appropriate time to meet.

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Settle a meeting time with other time-conflict students
|Completed
|Aug 19, 2019
|Sep 6, 2019
|Sep 2, 2019
|}

== Aug 19, 2019 ==
=== Team Meeting ===
I had to leave the meeting early because I had another class which was scheduled at the same time as the meeting. I talked to Prof. Jason and Prof. Rohling, and received their permission for not coming to the team meeting (for the first couple of weeks) until an alternative schedule for all the students with time conflicts could be found.

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Settle a meeting time with other time-conflict students
|Completed
|Aug 19, 2019
|Sep 6, 2019
|Sep 2, 2019
|}

== Spring 2019 ==
From '''Jan 7, 2019''' to '''Apr 22, 2019''',

Start hacking with:
 EEEEEEEEEEEEEEEEEEEEEEMMMMMMMM               MMMMMMMM               AAA               DDDDDDDDDDDDD      EEEEEEEEEEEEEEEEEEEEEE
 E::::::::::::::::::::EM:::::::M             M:::::::M              A:::A              D::::::::::::DDD   E::::::::::::::::::::E
 E::::::::::::::::::::EM::::::::M           M::::::::M             A:::::A             D:::::::::::::::DD E::::::::::::::::::::E
 EE::::::EEEEEEEEE::::EM:::::::::M         M:::::::::M            A:::::::A            DDD:::::DDDDD:::::DEE::::::EEEEEEEEE::::E
   E:::::E       EEEEEEM::::::::::M       M::::::::::M           A:::::::::A             D:::::D    D:::::D E:::::E       EEEEEE
   E:::::E             M:::::::::::M     M:::::::::::M          A:::::A:::::A            D:::::D     D:::::DE:::::E             
   E::::::EEEEEEEEEE   M:::::::M::::M   M::::M:::::::M         A:::::A A:::::A           D:::::D     D:::::DE::::::EEEEEEEEEE   
   E:::::::::::::::E   M::::::M M::::M M::::M M::::::M        A:::::A   A:::::A          D:::::D     D:::::DE:::::::::::::::E   
   E:::::::::::::::E   M::::::M  M::::M::::M  M::::::M       A:::::A     A:::::A         D:::::D     D:::::DE:::::::::::::::E   
   E::::::EEEEEEEEEE   M::::::M   M:::::::M   M::::::M      A:::::AAAAAAAAA:::::A        D:::::D     D:::::DE::::::EEEEEEEEEE   
   E:::::E             M::::::M    M:::::M    M::::::M     A:::::::::::::::::::::A       D:::::D     D:::::DE:::::E             
   E:::::E       EEEEEEM::::::M     MMMMM     M::::::M    A:::::AAAAAAAAAAAAA:::::A      D:::::D    D:::::D E:::::E       EEEEEE
 EE::::::EEEEEEEE:::::EM::::::M               M::::::M   A:::::A             A:::::A   DDD:::::DDDDD:::::DEE::::::EEEEEEEE:::::E
 E::::::::::::::::::::EM::::::M               M::::::M  A:::::A               A:::::A  D:::::::::::::::DD E::::::::::::::::::::E
 E::::::::::::::::::::EM::::::M               M::::::M A:::::A                 A:::::A D::::::::::::DDD   E::::::::::::::::::::E
 EEEEEEEEEEEEEEEEEEEEEEMMMMMMMM               MMMMMMMMAAAAAAA                   AAAAAAADDDDDDDDDDDDD      EEEEEEEEEEEEEEEEEEEEEE

== Apr 22, 2019 ==
=== Team Meeting ===
==== Final Presentation ====
[https://docs.google.com/presentation/d/15m_zXjYzh8NjSt8R-O-rFKncoHjmWP40Cz0Z09ACCn0/edit#slide=id.p Link to Cache Subteam's presentation]

== Apr 15, 2019 ==
=== Team Meeting ===
==== Weekly Sub-team Progress Report ====
'''All subteams reports''': [[Sub-team Weekly Reports#April_15.2C_2019_Reports|see here]]

'''Cache subteam report''': [[Sub-team Weekly Reports#Caching_Sub-team_Report_9|see here]]
=== Subteam Meeting ===
==== Cache Validation Subgroup ====
* Did research on a variety of algorithms to solve the Knapsack problem
** Two main schools of thoughts:
*** Hardware limited: tradeoff between performance and precision
**** Minor imprecision in cached object selecting is tolerable
**** Should be able to sacrifice some precision for gain in performance
**** '''Approximation Algorithms'''
***** Greedy: sorting objects by their benefits/weights, and selecting the largest if there is any space left
***** Scaling: multiplying weights by a fixed factor and rounding, thus reducing work required
***** Buckets: grouping similar objects and reducing steps required to calculate
*** Hardware extensible: adding additional computing power
**** Parallelism
***** Reducing time complexity significantly
***** Causing additional software complexity for cooperating between processors
***** Parallel algorithms:
****** Paper found: [https://github.gatech.edu/yli3048/AAD/blob/master/TeamCache/Knapsack/An%20efficient%20parallel%20algorithm%20for%20solving%20the%20Knapsack%20problem%20on%20hypercubes.pdf An efficient parallel algorithm for solving the Knapsack problem on hypercubes]
* Alex implemented and optimized some algorithms for benchmarking:
** Results (from [[Notebook_Alexander_Ackerman_Gurung#April_10th.2C_2019|Alex's notebook]]):
***Optimal solution for weight 40000 took time 9.66s and has value 18306
***1% of weight bucket solution for weight 40000 took time 0.01s and has value 12854
***Fixed 100 bucket solution for weight 40000 took time 0.03s and has value 16159
***Square bucket solution for weight 40000 took time 0.05s and has value 17532
***Heap solution for weight 40000 took time 0.00s and has value 8195

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Summarize knapsack resources gathered and work with Alex to implement the approximation algorithm
|Completed
|Apr 15, 2019
|Apr 22, 2019
|Apr 19, 2019
|-
|Prepare for the final presentation
|Completed
|Apr 15, 2019
|Apr 22, 2019
|Apr 21, 2019
|}

== Apr 8, 2019 ==
=== Team Meeting ===
==== Weekly Sub-team Progress Report ====
'''All subteams reports''': [[Sub-team Weekly Reports#April_8.2C_2019_Reports|see here]]

'''Cache subteam report''': [[Sub-team Weekly Reports#Caching_Sub-team_Report_8|see here]]
=== Subteam Meeting ===
Each subteam continues working on their tasks.
==== Validation Method Subteam ====
* Alex shared his research and work so far
** New algorithm: knapsack with bucket
* Finish setting up GCP
** James shared a [https://github.gatech.edu/yli3048/AAD/blob/master/TeamCache/guides/install_emade_debian.sh script] that sets up everything in a Debian system (not including anaconda)
** Another GCP setup [https://github.gatech.edu/yli3048/AAD/blob/master/TeamCache/guides/SetupGuideWithGoogleInstances.txt guide]

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Find ways to improve cache validating
|Completed
|Apr 8, 2019
|Apr 22, 2019
|Apr 14, 2019
|}

== Apr 1, 2019 ==
=== Team Meeting ===
==== Weekly Sub-team Progress Report ====
'''All subteams reports''': [[Sub-team Weekly Reports#April_1.2C_2019_Reports|see here]]

'''Cache subteam report''': [[Sub-team Weekly Reports#Caching_Sub-team_Report_7|see here]]
=== Subteam Meeting ===

==== Notes ====
Members will be split into three subteams:
*Fixing Image Team (Sam, Ben):
**Look at the old commits that causes "c" (error in terms of saving image cache)
**Revert the error and find other bugs
*Bash Team (Eric, Anish):
**Broken down into two stages, first stage looks at creating the script needed for stats on a single instance
**Next stage looks at creating the script for multiple instances
**This week we're expecting the first stage
*New Cache Invalidation Methods Team (Alex, '''William''', Yash):
**Document and understand the current caching mechanism
**Summarize our understanding in notebooks
**Start researching new methods to implement for better caching implementations

==== Team Goals for the Following Week ====
*Add more documentation, as per usual.
*Get new members to read data.py and launchGTMOEP.py to better understand cache (continuation from last week).
*Finish merging master into the cache branch.
*Start looking at getting the new members involved in fixing image data.

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Start working with GCP
|Completed
|Mar 25, 2019
|Apr 8, 2019
|Apr 6, 2019
|-
|Read [https://github.gatech.edu/emade/emade/blob/master/src/GPFramework/data.py data.py] and [https://github.gatech.edu/bchau7/emade/blob/master/src/GPFramework/launchGTMOEP.py launchGTMOEP.py]
to understand how caching code works
|Completed
|Mar 25, 2019
|Apr 8, 2019
|Apr 5, 2019
|}

== Mar 25, 2019 ==
=== Team Meeting ===
This is when my bootcamp ends.

Today new recruits decide which team they want to join.

From now onwards I will be working with the '''Cache''' subteam.

=== Subteam Meeting ===
==== Team Cache ====
* Members:
** [[Notebook I-Ping Huang|Samuel Huang]] (3rd semester)
** [[Notebook Benson Chau|Benson Chau]] (2nd)
** [[Notebook Eric Frankel|Eric Frankel]] (1st)
** [[Notebook Alexander Ackerman Gurung|Alex Gurung]] (1st)
** [[Notebook Yuhang Li|'''Yuhang Li''']] (1st)
** [[Notebook Yash Jignesh Shah|Yash Shah]] (1st)
** [[Notebook Anish Mahesh Thite|Anish Thite]] (1st)

=== Action Items ===
{|class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Start working with GCP
|Completed
|Mar 25, 2019
|Apr 8, 2019
|Apr 6, 2019
|-
|Read [https://github.gatech.edu/emade/emade/blob/master/src/GPFramework/data.py data.py] and [https://github.gatech.edu/emade/emade/blob/master/src/GPFramework/didLaunch.py didLaunch.py]
|Completed
|Mar 25, 2019
|Apr 1, 2019
|Mar 31, 2019
|-
|Document and merge [https://github.gatech.edu/emade/emade/tree/master emade/master] into [https://github.gatech.edu/bchau7/emade/tree/grid_slurm_integration bchau7/grid_slurm_integration]
|Completed
|Mar 25, 2019
|Apr 1, 2019
|Mar 31, 2019
|}

=== Progress Notes ===
'''Mar 31, 2019'''
* I worked with Sam to merge two files ([https://github.gatech.edu/bchau7/emade/blob/grid_slurm_integration/src/GPFramework/didLaunch.py didLaunch.py] and [https://github.gatech.edu/bchau7/emade/blob/grid_slurm_integration/src/GPFramework/database_tree_evaluator.py database_tree_evaluator.py]) from [https://github.gatech.edu/emade/emade/tree/master emade/master] into [https://github.gatech.edu/bchau7/emade/tree/grid_slurm_integration bchau7/grid_slurm_integration].

== Bootcamp Calendar - Spring 2019 ==
{| class="wikitable"
!Week No.
!Date
!Class
!Assignment
|-
|1
|[[#Jan 7, 2019|Jan 7]]
|What is EMADE?Intro #1 Evolutionary Algorithms 
[[files/Part 1 (Genetic Algorithm).pptx|thumb|Intro #1 Evolutionary Algorithms]]
|<nowiki>#</nowiki>1 DEAP on Simple Problem
[https://github.gatech.edu/emade/emade/blob/master/notebooks/Lab%201%20-%20Genetic%20Algorithms%20with%20DEAP.ipynb Python Notebook Here]
|-
|2
|[[#Jan 14, 2019|Jan 14]]
|Intro #2 Evolutionary Programming 
|#2 GP for regression problem
|-
|3
|[[#Jan 21, 2019|Jan 21]]
| colspan="2" |MLK Day .... No class
|-
|4
|[[#Jan 28, 2019|Jan 28]]
|Intro #3 Multiple Objectives
[[files/Lecture 3 - Multiple Objectives.pdf|thumb|Lecture 3 - Multiple Objectives]]
|#3 GP Part II
|-
|5
|[[#Feb 4, 2019|Feb 4]]
|Intro #4 Machine Learning
|#4 Titantic data set with sci-kit-learn
|-
|6
|[[#Feb 11, 2019|Feb 11]]
|Intro #5 Titantic w/ GP
|<nowiki>#</nowiki>5 GP Titanic Classifier with DEAP
|-
|7
|[[#Feb 18, 2019|Feb 18]]
|Intro #6 EMADE
|#6 Installation of EMADE
|-
|8
|[[#Feb 25, 2019|Feb 25]]
|Working Session with EMADE
|#6 GP Using EMADE 
|-
|9
|[[#Mar 4, 2019|Mar 4]]
|Reserved Week
|
|-
|10
|[[#Mar 11, 2019|Mar 11]]
|Presentation Evening 4:30 to 7:30 P.M.
|
|}

== Mar 11, 2019 ==
=== Team Meeting ===
==== Group Presentation ====
'''See my team's progress report here:'''
[[Bootcamp_Sub-team_Spring_2019_-_Titanic_EMADE#Group_2|Team Progress Report]]

'''See my team's presentation slides here:'''
[https://docs.google.com/presentation/d/1nsDUYcjShJMIMMnyGR9dozrdc2yt6r2tM8egJogN0dY/edit#slide=id.p Team 2 Presentation]

=== Progress Notes ===
==== Working on EMADE itself ====
* Managed to push my own [https://github.gatech.edu/yli3048/emade/tree/lyh branch lyh] to [https://github.gatech.edu/yli3048/emade my forked repo] of EMADE
** Resolved the lfs issue that previously prevented me from pushing by:
*** Refetched lfs files from upstream (original EMADE repo) by running: <code>git lfs fetch --all upstream</code>

== Mar 4, 2019 ==
=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Work with Titanic using Emade
|Completed
|Feb 25, 2019
|Mar 11, 2019
|Mar 8, 2019
|}
=== Progress Notes ===
==== Working on EMADE itself ====
* Added EMADE as a git submodule within my own AAD repository
* Created my own development branch of EMADE, [https://github.gatech.edu/yli3048/emade/tree/lyh '''lyh''']
** Tried to circumvent hypervolume issue by commeting out [https://github.gatech.edu/yli3048/emade/blob/lyh/src/GPFramework/gtMOEP.py#L1156 line 1156 in emade/src/GPFramework/gtMOEP.py]
** Attempted to gather all output files in an output directory
* '''Issues encountered:''' [[files/Python_processes_do_not_terminate.png|thumb|400x222px|Python process wouldn't terminate]]
** Python constantly quits during the course of running EMADE
*** See the debug message generated: [[files/Python_quitted_unexpectedly.txt|alt=Python quitted unexpectedly.txt]]
** Python processes won't terminate after EMADE is stopped, taking up 100% of CPU
*** See thumbnail image to the right for a sample of the process

==== Titanic with EMADE ====
* Ran EMADE server on my computer for several nights
* Teammates ([[Notebook_Eric_Frankel#March_11.2C_2019|Eric]], [[Notebook_Oscar_Thomas_Aguilar#3.2F11.2F19|Oscar]]) were able to join in as workers to contribute processing power
** [[Notebook_Zachary_Robert_Butler#March_3.2C_2019|Zack]] had trouble connecting to the server due to VPN
* Obtained 4 paretoFitnessTitanic files and 48 generations of fitness values in total
** Generation counter was reset every run
*** Had to combine generations manually (and increment generation numbers) with [https://github.gatech.edu/yli3048/AAD/blob/master/Bootcamp/Emade_Titanic/avg_over_time.py this script]
* Analysis of results:
** Area under curve of Pareto fronts increased over time (against expectation):<br />[[files/Graph_of_AUC_Over_Time.png|frameless|border|Area under curve over time]]
*** Probably due to appearance of individuals at the edges (to the extreme of one axis) and them not being replaced often
** Best individuals move closer to the origin over time (expected)<br />[[files/Graph_of_Minimum_Euclidean_Distance_Over_Time.png|frameless|border|Minimum Euclidean distance over time]]
** Final generation:<br />[[files/Pareto_Front_for_Last_Generation.png|frameless|border|Pareto front for the last generation]]

== Feb 25, 2019 ==
=== Team Meeting ===
==== Weekly Sub-team Progress Report ====
([[Sub-team Weekly Reports#February_25.2C_2019_Reports|See full report here]])
==== Bootcamp ====
Working session with [https://github.gatech.edu/emade/emade EMADE]

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Work with Titanic using Emade
|Completed
|Feb 25, 2019
|Mar 11, 2019
|Mar 8, 2019
|}

=== Progress Notes ===
==== Learn to use EMADE ====

Please read the [https://github.gatech.edu/emade/emade/blob/master/README.md README.md] file in the EMADE repository first.

'''To run EMADE:'''
<ol>
<li> Populate the input_file (e.g. input_titanic.xml) with database info:</li>
<pre><dbConfig>
    <server>localhost</server>           <!-- set to IP address of server (localhost if run locally) -->
    <username>emade</username>           <!-- set to mysql user -->
    <password>emade</password>           <!-- set to mysql user's password -->
    <database>emade_titanic</database>   <!-- set to mysql database -->
    <reuse>1</reuse>                     <!-- set to 1 to reuse data from database -->
</dbConfig></pre>
<li> Run <code>python src/GPFramework/launchGTMOEP.py templates/<input-file></code> (adjust path to the files if needed) <br />
'''Note:''' If running as worker, append <code>-w</code> flag to the end: <code>python src/GPFramework/launchGTMOEP.py templates/<input-file> -w</code>
</li>
<li> Check "masterXXXXX.out/.err" and "workerXXXXX.out/.err" to see if EMADE is running properly (replace XXXXX with corresponding process ID) </li>
</ol>

'''Troubleshooting'''
* If encountered issues related to "import subprocess":
** Try to pull the [https://github.gatech.edu/emade/emade/tree/dev <code>dev</code>] branch first (some bugs fixed in that branch)

== Feb 18, 2019 ==
=== Team Meeting ===
==== Weekly Sub-team Progress Report ====
([[Sub-team Weekly Reports#February_18.2C_2019_Reports|See full report here]])
==== Bootcamp ====
Introduction to [https://github.gatech.edu/emade/emade EMADE]
=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Install EMADE
|Completed
|Feb 18, 2019
|Feb 25, 2019
|Feb 18, 2019
|-
|Complete [http://www.vip.gatech.edu/peer-evaluations Peer Evaluation]
|Completed
|Feb 15, 2019
|Feb 22, 2019
|Feb 19, 2019
|}
=== Progress Notes ===
==== Installing EMADE and Troubleshooting ====
I followed the [https://github.gatech.edu/emade/emade#installation installation] section in the README file of the EMADE repository to install EMADE.

I did not install anaconda as the instructions asked though. I have been using pip and virtualenv and would like to maintain the consistency of using these managing tools. I managed to install all the packages that are required to be installed with conda in the instructions with pip.

I have previously installed mysql server and MySQLWorkbench (downloaded from the official website) on my Mac, but when running EMADE I encountered a lot of connection errors, indicating that I the Emade process was not able to connect to the database. I eventually resolved this issue by uninstalling the mysql downloaded from the official website and reinstalling it through Homebrew by:
 brew install mysqlclient
It removed the mysql setting panel from System Preferences, thus I would have to start and stop the mysql server through brew services (which has to be installed separately):
 brew services start mysql
 brew services stop mysql

Apart from reinstalling mysql, I also had to setup a root user and mysql user and grant them corresponding privileges. The authentication type also had to be set to Standard instead of caching_sha2_password or else.
 # Reset password for root
 $(brew --prefix mysql)/bin/mysqladmin -u root password [new password for root]
 
 # Create a user for exclusive use of emade
 mysql -u root -p
 create user "emade"@"%" identified by "password";
 create database emade_db;
 grant all privileges on emade_db.* to "emade"@"%";

To solve the connection issue:
 # Add this line into /etc/hosts:
 127.0.0.1 [Your computer's hostname].local
and
 # Comment the bind-address line out from /etc/my.cnf:
 # Default Homebrew MySQL server config
 [mysqld]
 
 # Only allow connections from localhost
 # Allowing connections from all IPs by commenting this out
 # bind-address = 127.0.0.1

== Feb 11, 2019 ==
=== Team Meeting ===
==== Weekly Sub-team Progress Report ====
([[Sub-team Weekly Reports#February_11.2C_2019_Reports|See full report here]])
==== Bootcamp ====
* Use GP to make predictions for the dataset
* Goal: implementation the prediction model with GP (primitive tree)
=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|[https://www.kaggle.com/c/titanic/ Kaggle Titanic Dataset] prediction with GP
|Completed
|Feb 11, 2019
|Feb 18, 2019
|Feb 17, 2019
|-
|Complete [http://www.vip.gatech.edu/peer-evaluations Peer Evaluation]
|Completed
|Feb 15, 2019
|Feb 22, 2019
|Feb 19, 2019
|}

=== Progress Notes ===
==== Kaggle Titanic Dataset Prediction with DEAP ====

'''Goal''': use genetic programming with DEAP to perform classification on the survivability of the passengers on Titanic.

'''Our team's report''': [[Bootcamp Sub-team Spring 2019 - Titanic GP#Group_2|Group 2 Report - Titanic GP]]

'''My solution''': ([https://github.gatech.edu/yli3048/AAD/blob/master/Bootcamp/Titanic/predict_with_deap.py see python script here])

* Perform data preprocessing with Pandas
** Dropped columns "Name", "Ticket", "Cabin" that are hard to generate quantifiable data for now
** Designated column "PassengerId" as primary key
** Replaced string values in columns "Embarked", "Sex" with integer values
** Filled missing data in columns "Age", "Fare", "Embarked" with the average value of the column
** Separated X and y ("Survived") columns
** Split 1/5 of data as validation set
* Train prediction model with DEAP
** Used weakly typed genetic programming
** Used primitive trees as individuals in evolution
*** Primitives selected: add, subtract, multiply, negative, square
*** Used genHalfAndHalf to produce primitive trees with min height of 1 and max of 5
*** Used mutUniform to randomly pick a node in the tree to be replaced with a newly generated full subtree of height 0-2
*** Static height limit: 20
** Evaluation of individuals:
*** Compile each individual into an executable function
*** Run function on all passengers' data
*** Thresholds: -10 <= Result <= 10 means survived, not otherwise
*** Use Euclidean distance from (FPR, FNR) to origin (i.e. FPR^2 + FNR^2), and FPR, FNR as three objectives to minimize
** Evolutional parameters:
*** NGEN (number of generations): 50
*** MU (size of population): 50
*** LAMBDA (number of children to produce at each generation): 100
*** CXPB (probability that an offspring is produced by crossover): 0.5
*** MUTPB (probability that an offspring is produced by mutation): 0.2
* Trained model
** Evolution graph: <br />[[files/predict_with_deap_evolution_history.png|frameless|border|Evolution History]]
** Pareto front of dominating individuals: <br />[[files/predict_with_deap_pareto_front.png|frameless|border|Pareto Front]]
** Best individual:
*** '''Primitive Tree''': multiply(add(multiply(Pclass, add(multiply(Sex, Embarked), negative(Embarked))), negative(Embarked)), square(negative(Pclass)))
*** '''Fitnesses''': 0.13213734567901236, 0.2638888888888889, 0.25 (FPR^2 + FNR^2, FPR, FNR respectively)
*** '''Confusion matrix''':
**** TPR: 0.7580645161290323
**** TNR: 0.7435897435897436
**** FPR: 0.2564102564102564
**** FNR: 0.24193548387096775

== Feb 4, 2019 ==
=== Team Meeting ===
==== Weekly Sub-team Progress Report ====
([[Sub-team Weekly Reports#February_4.2C_2019_Reports|See full report here]])
* Teams:
:- Stock
:- EEG
:- Deep
:- Caching
:- Visualization

==== Bootcamp ====
* [https://www.kaggle.com/c/titanic/ '''Kaggle Titanic Dataset''']
** Contains data of the passengers on Titanic (their attributes and whether survived)
** Provides training data and testing data
** Goal: train prediction models to predict the survivability of the passengers
* Teaming Up
** Select team members from a pareto front (of their python and ML savviness)
** My team: see below

==== My team ====
'''Team 2''' ([https://vip.gatech.edu/wiki/index.php/Bootcamp_Sub-team_Spring_2019#Group_2 team page here])

Members: [[Notebook_Oscar_Thomas_Aguilar|Oscar Aguilar]], [[Notebook_Zachary_Robert_Butler|Zack Butler]], [[Notebook_Eric_Frankel|Eric Frankel]] ([https://github.gatech.edu/efrankel6 github page]), [[Notebook_Yuhang_Li|William Li]] (me)

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|[https://www.kaggle.com/c/titanic/ Kaggle Titanic Dataset] prediction
|Completed
|Feb 4, 2019
|Feb 11, 2019
|Feb 10, 2019
|}

=== Progress Notes ===
==== Kaggle Titanic Dataset Prediction ====
* See [https://github.gatech.edu/yli3048/AAD/tree/master/Bootcamp/Titanic '''my GitHub repo'''] for this project
* My prediction model ([https://github.gatech.edu/yli3048/AAD/blob/master/Bootcamp/Titanic/predict_with_sklearn.py see python script here]):
** C-Support Vector Classification
*** Detected and dropped outliers that have more than 2 abnormal values using Tukey method (mostly from "Age", "SibSp", "Parch")
*** Filled missing data with average value of the category
*** Used GridSearch to select the best parameters (kernel, C, gamma)
*** Best parameters selected: kernel: "linear", C: 0.01
*** Result accuracy: 81.7% (Kaggle score: 75.1%), FPR: 4.2%, FNR: 44.2%
*** Confusion Matrix:
{|class=wikitable
|
! Predicted Positve
! Predicted Negative
|- 
! Actual Positive (P)
| TP = 58
| FN = 46
|-
! Actual Negative (N)
| FP = 8
| TN = 183
|}
* Team Result ([https://vip.gatech.edu/wiki/index.php/Bootcamp_Sub-team_Spring_2019#Group_2 see team page here])
** Pareto Front of team members' FPs and FNs
*** [[files/Group 2 Pareto Front Bootcamp Spring 19.png|thumb|Our FPs and FNs on a Pareto front|none]]

== Jan 28, 2019 ==
=== Team Meeting ===
==== Weekly Sub-team Progress Report ====
([[Sub-team Weekly Reports#Jan_28.2C_2019_Reports|See full report here]])

==== Bootcamp Lecture ====
([https://vip.gatech.edu/wiki/images/4/4f/Lecture_3_-_Multiple_Objectives.pdf '''download lecture slides here'''])
* Today's scope:
** Genes with Scores '''=>''' Fitness Computation '''=>''' Genes with Fitness

* Gene Pool: the set of genomes to be evaluated during the current generation
** Genome: DNA/Genotypic description of an individual
** Search Space: Set of all possible genome

* Evaluation: Maps a genome/individual
** from a location in search space
*** Genotypic description 
** to a location in objective space
*** Phenotype description

* Classification
** Confusion Matrix:
*** TPR = TP/P=TP/(TP+FN)
*** TNR=TN/N=TN/(TN+FP)
*** FNR=FN/P=FN/(TP+FN)
*** FPR=FP/N=FP/(FP+TN)
{|class=wikitable
|
! Predicted Positve
! Predicted Negative
|- 
! Actual Positive (P)
| True Positive (TP)
| False Negative (FN)
|-
! Actual Negative (N)
| False Positive (FP)
| True Negative (TN)
|}

* Objective Space: Set of objectives
** Each individual is evaluated using objective functions
** Objective scores give each individual a point in objective space
** '''Phenotype'''

* ''' Pareto Optimality '''
** An individual is '''Pareto''' if there is no other individual in the population that outperforms the individual on all objectives
** The set of all Pareto individuals is known as the '''Pareto frontier'''

* Nondominated Sorting Genetic Algorithm II (NSGA II)
** Population is separated into nondomination ranks
** Individuals are selected using a binary tournament
** Lower Pareto ranks beat higher Pareto ranks
** Ties on the same front are broken by '''crowding distance'''

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Multi-objective part of [https://github.gatech.edu/emade/emade/blob/master/notebooks/Lab%202%20-%20Genetic%20Programming%20and%20Multi-Objective%20Optimization.ipynb Lab 2]
|Completed
|Jan 28, 2019
|Feb 4, 2019
|Feb 3, 2019
|}

=== Progress Notes ===
* Completed Lab 2, part 2 ([https://github.gatech.edu/yli3048/AAD/tree/master/Bootcamp/Lab2 view this lab on my GitHub repo])
==== Multi-objective GP ====
([https://github.gatech.edu/yli3048/AAD/blob/master/Bootcamp/Lab2/multisymreg.py '''view python script here'''])

* Multiple objectives instead of just one
* Evaluation function needs to take into account multiple fitness points
* '''Pareto dominance'''
** Dominated
** Dominators
** Implementation:
 # Returns true if the first individual dominates the second individual
 def pareto_dominance(ind1, ind2):
     not_equal = False
     for value1, value2 in zip(ind1.fitness.values, ind2.fitness.values):
         if value1 > value2:
             return False
         elif value1 < value2:
             not_equal = True
     return not_equal

== Jan 14, 2019 ==
=== Team Meeting ===
==== Weekly Sub-team Progress Report ====
([[Sub-team Weekly Reports#Jan_14.2C_2019_Reports|See full report here]])

==== Bootcamp Lecture ====
<u>'''GP: Genetic Programming'''</u>
* Basic stages of GP:
** Evolution
** Fitness Computation
** Selection
** Mating
** Mutation

* Alternative structures for '''genomes''' of individuals:
** List (used in GA as in Lab 1)
** Tree (used in GP)
*** Nodes: called "primitives", contain operators
*** Leaves (external nodes): called "terminals", 
*** Crossover: swap subtrees
**** Strongly-Typed Crossover: two subtrees must be of the same output type
**** Unlike GA, crossovers are restricted to single-point crossovers
*** Mutation
**** Insertion: insert a randomly generated subtree
**** Shrinking: delete a subtree
*** Trees can be simplified by introducing more complex operators (e.g. use <code>2 ^ 3</code> instead of <code>2 * 2 * 2</code>)
* Symbolic Regression
=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Symbolic Regression part of [https://github.gatech.edu/emade/emade/blob/master/notebooks/Lab%202%20-%20Genetic%20Programming%20and%20Multi-Objective%20Optimization.ipynb Lab 2]
|Completed
|Jan 14, 2019
|Jan 28, 2019
|Jan 24, 2019
|}

=== Progress Notes ===
<u>'''Working through Lab2'''</u> ([https://github.gatech.edu/yli3048/AAD/tree/master/Bootcamp/Lab2 view this lab on my GitHub repo])
==== Symbolic Regression ====
([https://github.gatech.edu/yli3048/AAD/blob/master/Bootcamp/Lab2/symreg.py '''view python script here'''])
* Create a primitive set that contains all the primitives (operators) that we can use:
 pset = gp.PrimitiveSet("Main", arity=1) # arity = amount of arguments each primitive takes<br>
 pset.addPrimitive(np.add, arity=2)
* Individuals are made of trees instead of parameters now:
 creator.create("Individual", gp.PrimitiveTree, fitness=creator.FitnessMin)
* Each tree consists of internal nodes that are primitives and leaf nodes that are operands
* Individuals are evaluated using sandard errors:
 def evalSymReg(individual, points, pset):
    # Compile the tree into a function
    func = gp.compile(expr=individual, pset=pset)
    # Calculate main squared error between this function and the target function
    sqerrors = (func(points) - (points ** 4 + points ** 3 + points ** 2 + points)) ** 2
    return (np.sqrt(np.sum(sqerrors) / len(points)),)
* The rest of the steps are the same as in Lab 1

== Jan 7, 2019 ==
=== Team Meeting Notes ===

==== Lecture: Introduction to Genetic Algorithm ====
([https://github.gatech.edu/emade/reference_material/blob/master/Lectures/Lecture_1_GA/Part%201%20(Genetic%20Algorithm).pptx?raw=true '''download lecture slides'''])

* Initialization stage
:- Create a population of solutions, called "individuals", each storing a list of random parameters. 

* Evaluation stage
:- Assign each individual with a "fitness value" according to our expectations. 

* Selection stage
:- Individuals with higher fitness values will have a higher chance of getting mated. 

* Mating stage
:- Individuals are matched at random (with mating chance taken into account) and exchange genes (information/parameters) with their match. 

* Mutation stage
:- A randomly selected parameter will mutate (change).

==== New entries to my AAD Glossary ====
* [[#Population|Population]]
* [[#Individual|Individual]]
* [[#Objective|Objective]]
* [[#Fitness|Fitness]]
* [[#Evaluate|Evaluate]]
* [[#Selection|Selection]]
* [[#Mate|Mate/Crossover]]
* [[#Mutate|Mutate]]

=== Action Items ===
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Start notebook
|Completed
|Jan 7, 2019
|Jan 14, 2019
|Jan 11, 2019
|-
|Join Slack
|Completed 
|Jan 7, 2019
|Jan 14, 2019
|Jan 9, 2019
|-
|Complete [https://github.gatech.edu/emade/emade/blob/master/notebooks/Lab%201%20-%20Genetic%20Algorithms%20with%20DEAP.ipynb Lab 1]
|Completed
|Jan 7, 2019
|Jan 14, 2019
|Jan 13, 2019
|-
|Setup [https://jupyter.org/install Jupyter Notebook] and [https://deap.readthedocs.io/en/master/installation.html DEAP]
|Completed
|Jan 11, 2019
|Jan 14, 2019
|Jan 12, 2019
|-
|[[#Jupyter Notebook Tutorial Video|Learn how to use Jupyter Notebook]]
|Completed
|Jan 12, 2019
|Jan 14, 2019
|Jan 12, 2019
|}

=== Progress notes ===
* Installed Jupyter and DEAP
* <span id="Jupyter Notebook Tutorial Video">Watched a super useful Jupyter Notebook tutorial video [https://www.youtube.com/watch?v=HW29067qVWk here]</span>
* Completed Lab 1 ([https://github.gatech.edu/yli3048/AAD/tree/master/Bootcamp/Lab1 view this lab on my GitHub repo])
==== One Max Problem ==== 
([https://github.gatech.edu/yli3048/AAD/blob/master/Bootcamp/Lab1/lab1_one_max.py '''view python script here'''])
[[files/TwoPointCrossover.png|thumb|alt=An illustration of a two-point crossover|Two Point Crossover]]
* A simple example of how to write a Genetic Algorithm using DEAP with one attribute (fitness value)
* First define classes (attribute, individual) and setup toolbox with commonly used functions
* GA stages:
** Initialization: initialize a population with random parameters (0 or 1 bits in this case)
** Evaluation: calculate the fitness value for each individual (sum of all bits in this case)
** Selection: use a tournament between several individuals to select a best one among them, then repeat to select a new generation
** Crossover: use a two-point crossover (two points are randomly selected and bits between the two points are swapped)
** Mutation: randomly selected bits are flipped
** Propagation: jump back to Evaluation stage to repeat
==== N Queens Problem ====
([https://github.gatech.edu/yli3048/AAD/blob/master/Bootcamp/Lab1/lab1_nqueens.py '''view python script here'''])
[[files/PMX.png|thumb|alt=An illustration of Partially Matched Crossover|Partially Matched Crossover]]
* An more complex example of how a Genetic Algorithm solves a problem with constraints
* Similar process as above. Some differences:
** Evaluation: count the number of conflicts on the diagonals (since it's guaranteed each line and row only has one queen)
** Crossover: use a [http://www.wardsystems.com/manuals/genehunter/crossover_of_enumerated_chromosomes.htm Partially Matched Crossover] (PMX) algorithm to preserve the ordering property of individuals (thus not breaking the constraints of the problem)
** Mutation: shuffle the individual's list instead of randomly changing values (so that the constraints are not broken)

== My AAD Glossary ==
;Crossover
: see [[#Mate|Mate]]
;<span id="Evaluation">Evaluation</span>
: a function that computes the objective of an individual
;<span id="Fitness">Fitness</span>
: relative comparison to other individuals; how well does the individual accomplish a task relative to the rest of the population?
;<span id="Individual">Individual</span>
: one specific candidate in the population (with properties such as DNA)
;<span id="Mate">Mate</span>
: represents mating between individuals
;<span id="Mutate">Mutate</span>
: introduces random modifications; purpose is to maintain diversity
;<span id="Objective">Objective</span>
: a value used to characterize individuals that you are trying to maximize or minimize (usually the goal is to increase objective through the evolutionary algorithm)
;<span id="Population">Population</span>
: group of individuals whose properties will be altered
;<span id="Selection">Selection</span>
: represents "survival of the fittest"; gives preference to better individuals, therefore allowing them to pass on their genes
:; Fitness Proportionate
:: the greater the fitness value, the higher the probability of being selected for mating
:; Tournament
:: several tournaments among individuals (number of individuals in each tournament is dependent on tournament size); winners are selected for mating