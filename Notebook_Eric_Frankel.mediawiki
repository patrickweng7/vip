==  Team Member ==
Team Member: Eric Frankel

Email: eric.frankel@gatech.edu

== April 20, 2020 ==
'''Team Meeting Notes'''
* We delivered our final presentation, which I think went quite well.
* You can find our presentation [https://docs.google.com/presentation/d/1mmyBsT76iPt4N7pM0oUf7c2qlhh34gBle978DpOBPrE/edit?usp=sharing here].
* Here are my notes from the presentations. I was able to take detailed notes for ADFs but not the others.
** ADFs
*** Motivation: reuse useful subtrees
*** 4 step process to insert ADFs into the population
*** Wanted to improve upon intelligent ADFs with differential ADFs
*** Primitive analysis
**** Determine if ADFs are useful in EMADE
**** Found that useful primitives were ignored
**** Single primitive not necessarily correlated with individual success
**** Significant # of ADFs were composed of other ADFs
**** ADF as root nodes generally don’t perform well
*** Differential Fitness
**** Fewer ADFs that are higher quality
**** Results didn’t align with the hypothesis, but not statistically significant
*** Selection Methods
**** Assuming ADFs are useful, want to increase their probability of occurrence
**** Select more individuals with more ADFs
** Other teams seem to be progressing towards their goals. I noticed that many of the teams were doing statistical analysis of their results, which is in line with Dr. Zutty's suggestions. 
** There were a lot of impacts from distance learning on people's ability to work through challenges. 
** A lot of other teams were trying to get PACE working, notably the time conflict NLP group. They were able to get MySQL working on the PACE instance itself, which we did not try to do. Interestingly, they thought that our approach of using a remote server for MySQL was better than theirs because it would have insulated them from changes made to PACE that set them back because they had to rework their configuration.
== April 19, 2020 ==
'''Team Meeting Notes'''
* We had our practice presentation with Drs. Rohling and Zutty today, and we got some very helpful feedback
* I was also pleased to see that the entire team attended the practice presentation, but I was a little surprised because of the lack of response to my original poll asking the team when a good meeting time would be.
* Here are my notes from the meeting:
** Better explain how our fitness sharing fits in with the overall selection process. How do the weights that we apply make it into the NSGAII algorithm?
** Add a motivation slide
** Explain more of the “why” for background slides - tie them back to the motivation slide
** Use semi log scale for hypervolume plots
*** Note that these plots are an avg
*** Plot 1 std dev above and below the plots
** Include experimental setup slide
** Clarification on the crossover slide - what we’re using in the experiments vs in neat crossover
** Truncate plots at max #gens
** Add bloat metric slide
** Propose potential new tree distance metric
** Add more words on the slides
** Nothing wrong with negative results, research doesn’t always work out how we hope
** Add a summary slide and tie it back to motivation
** Bottom Line up front - discuss big picture before diving into the details
* We incorporated many of these suggestions into our presentation to improve it before the final presentation with the entire VIP team
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Create Final Presentation
|In Progress
|April 13, 2020
|April 20, 2020
|
|-
|Automated analysis script
|In Progress
|March 24, 2020
|April 6, 2020
|
|}

== April 18, 2020 ==
'''Individual Notes'''
* Analyzed the results gathered from the team in preparation for our practice presentation with Drs. Rohling and Zutty tomorrow
* Initially, results seem to indicate that our speciation and fitness sharing are not effective for controlling bloat, which is a bit disappointing
* We were able to get some statistically significant results this time, which was great, because we were not able to get any significant results for the midterm
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Create Final Presentation
|In Progress
|April 13, 2020
|April 20, 2020
|
|-
|Automated analysis script
|In Progress
|March 24, 2020
|April 6, 2020
|
|}

== April 17, 2020 ==
'''Team Meeting Notes'''
* Varun has 3 runs done for the .15 distance threshold
* Shreyas has completed 8 runs at .6 distance threshold
* Kartik has completed all 10 baseline runs
* Tri has completed 5 runs for .3 distance threshold
* Max has completed 5 runs for .6 distance threshold
* Chris has completed 3 runs at .3 distance threshold, in addition to his work with PACE
* Animesh has completed 9 runs for neat-CX
* Josh has completed 4 runs measuring the effect of varying crossover parameters
* The team is doing a great job of getting runs done, which makes me confident that we will have enough data to a proper analysis
'''Individual Notes'''
* I completed two runs of neat-CX, and started working on our presentation
* I also began work on my analysis notebook, which I will share once it is complete
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Create Final Presentation
|In Progress
|April 13, 2020
|April 20, 2020
|
|-
|Automated analysis script
|In Progress
|March 24, 2020
|April 6, 2020
|
|}

== April 13, 2020 ==
'''Team Notes'''
* Sam has gotten ready to start working on PACE
* Varun is on his second run
* Shreyas provided data that demonstrates the timeout fix is working, this should help us get runs completed in a timely manner
* Kartik has completed 4 runs
* Tri has completed 2 runs
* Rohith is up and running but hasn't completed any runs yet
* Max has completed 2 runs
** Tried to run on PACE with a local master
* Chris is making progress on PACE
* Josh has completed 2 runs and is working on his 3rd
'''Individual Notes'''
* I have been working with Animesh to get some runs for neat-CX done

'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Create Final Presentation
|Not Started 
|April 13, 2020
|April 20, 2020
|
|-
|Automated analysis script
|Not Started
|March 24, 2020
|April 6, 2020
|
|-
|Create an SQL database in Googl Cloud
|Done
|April 10, 2020
|April 14, 2020
|April 13, 2020
|}

== April 10, 2020 ==
'''Individual Notes'''
* Created a shared Google Drive folder that we will use as a repository for all our results per Animesh's suggestion
* Spoke with Aaron from the ADF team regarding individual timeout not working
** Aaron pointed me to a commit that fixed the issues with individuals not timing out correctly, I integrated these changes into fitness_sharing
** Commit here
** This should be a big help because we have been having a problem with individuals hanging and causing the runs to take forever, so this fix should solve that.
* I need to create a MySQL database on Google Cloud for the PACE team to see if that can help them get through their database issues.
** I made this database on my Google Cloud account, and it is currently live. I will work with Chris and Sam and hopefully they will be able to use this database from PACE.
'''Team Meeting Notes'''
* Most first semester students are now up to date with EMADE
* Sam was having persistent problems getting set up, so we moved him to working on PACE because it requires less from his local environment
* Decided to reduce our runs to 30 gens so that we can get more runs done by the final presentation

'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Create an SQL database in Googl Cloud
|Done
|April 10, 2020
|April 14, 2020
|April 13, 2020
|-
|Automated analysis script
|Not Started
|March 24, 2020
|April 6, 2020
|
|-
|Assign tasks to first semesters
|Done
|March 23, 2020
|March 24, 2020
|March 24, 2020
|-
|Conduct baseline EMADE runs
|Done
|March 2, 2020
|March 8, 2020
|March 8, 2020
|-
|Create midterm presentation
|Done
|March 2, 2020
|March 9, 2020
|March 9, 2020
|}

== April 6, 2020 ==
'''Team Meeting Notes'''
* Been working on getting all the first semester students set up with our current version of EMADE still
* Max and Chris are working on PACE setup, and seem to be making good progress. 
* Josh has been working on investigating the drop in # of individuals we saw before the midterm presentation by manipulating the crossover rate
* Animesh has been working on bringing his NEAT crossover code up to date with EMADE
* Set expectations with first semester students for updating the subteam notebook prior to our weekly Monday meetings
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Automated analysis script
|Not Started
|March 24, 2020
|April 6, 2020
|
|-
|Assign tasks to first semesters
|Done
|March 23, 2020
|March 24, 2020
|March 24, 2020
|-
|Conduct baseline EMADE runs
|Done
|March 2, 2020
|March 8, 2020
|March 8, 2020
|-
|Create midterm presentation
|Done
|March 2, 2020
|March 9, 2020
|March 9, 2020
|}

== March 24, 2020 ==
'''Individual Notes'''
* Created a task assignment spreadsheet to better organize task assignments for the whole sub-team
** This gives us an easy way to see what everyone is working on and how to manage that
** Link: https://docs.google.com/spreadsheets/d/17bvkqgS1p1UJue-IjUJ1VqMUxsaLc3pteFfW1V6kCuE/edit?usp=sharing
* Sent the task assignment spreadsheet to new students, explained the first task to them
* One challenge so far is that I have not met any of the new students in person, and I don't really have a good feel for their individual skill levels and interests. This makes it harder to assign tasks to people.
** Plan to use our Friday sub-team meeting to assess this a little bit.
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Automated analysis script
|Not Started
|March 24, 2020
|April 6, 2020
|
|-
|Assign tasks to first semesters
|In Progress
|March 23, 2020
|March 24, 2020
|March 24, 2020
|-
|Conduct baseline EMADE runs
|In Progress
|March 2, 2020
|March 8, 2020
|March 8, 2020
|-
|Create midterm presentation
|In Progress
|March 2, 2020
|March 9, 2020
|March 9, 2020
|-
|Set up PACE-ICE
|Not Started 
|February 24, 2020
|March 2, 2020
|
|}

== March 23, 2020 ==
'''Team Meeting Notes'''
* Told first semester students to expect task assignments from me by tomorrow
* Spoke with Josh about what tasks we should assign the first semesters
** Determining how well the phenotype of an individual corresponds with its genotype
*** If there is little/no correlation between these two then we need to rethink our distance metric for speciation because it means the neat speciation distance metric doesn't work well in EMADE
*** As discussed during the midterm presentation, this could be due to EMADE's trees
** Testing different speciation thresholds of .15, .3, and .6 to determine which offers the best performance in terms of bloat control
** Test restricted vs unrestricted mating for each of the above three thresholds (lower priority as it seems like unrestricted is significantly outperforming restricted)
** Study species assignment and the number of individuals per species (this relates to the phenotype vs genotype correlation)
** Test neat crossover and fitness sharing in the same run
** Create a script to do all the analysis we are currently doing by hand
** All first semesters should read the neat-GP paper so they have an understanding of what we are trying to replicate/what our inspiration is 
** Measure CPU usage, memory pressure, and other metrics on computational performance during the run
* Animesh notified Josh and me that he will be unable to attend our subteam meetings because he will be in Singapore for the rest of the semester and the time difference is too large. I will work with Animesh to determine a time where him, Josh, and myself can meet.

'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Assign tasks to first semesters
|In Progress
|March 23, 2020
|March 24, 2020
|
|-
|Conduct baseline EMADE runs
|In Progress
|March 2, 2020
|March 8, 2020
|March 8, 2020
|-
|Create midterm presentation
|In Progress
|March 2, 2020
|March 9, 2020
|March 9, 2020
|-
|Set up PACE-ICE
|Not Started 
|February 24, 2020
|March 2, 2020
|
|-
|Verify that speciation code is working properly
|Completed
|January 13, 2020
|January 27, 2020
|February 3, 2020
|-
|Fix speciation
|Completed
|February 3, 2020
|February 17, 2020
|February 24, 2020
|}

== March 9, 2020 ==
'''Individual Notes'''
* Animesh found a bug with my notebook, new one is [https://github.gatech.edu/efrankel6/emade/commit/a018c1678ebeaf880fb100e14ad178d17fc97342 here]
* Polished the presentation
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Conduct baseline EMADE runs
|In Progress
|March 2, 2020
|March 8, 2020
|March 8, 2020
|-
|Create midterm presentation
|In Progress
|March 2, 2020
|March 9, 2020
|March 9, 2020
|-
|Set up PACE-ICE
|Not Started 
|February 24, 2020
|March 2, 2020
|
|-
|Verify that speciation code is working properly
|Completed
|January 13, 2020
|January 27, 2020
|February 3, 2020
|-
|Fix speciation
|Completed
|February 3, 2020
|February 17, 2020
|February 24, 2020
|}

== March 8, 2020 ==
'''Individual Notes'''
* My run #3 has  been going all weekend, and thankfully it seems like it's still making progress. Josh and I decided to call our runs at 6pm tonight, after which Josh will send me his results so I can conduct the statistical analysis per Dr. Zutty's instructions at the beginning of the semester.
* Since our runs have not been reaching 50 generations, we will have to compare across the lowest common denominator for statistical comparisons, but we will still make observations about the runs that made it longer.
* I created our midterm presentation slides, where we will all add our results. You can find the presentation [https://docs.google.com/presentation/d/1OsK1UyTKBDKVUQhS4866ONOtRGTuCsb9uMZ8VDXICIE/edit?usp=sharing here], as well as on our sub-team page.
* I stopped my 3rd run. It reached generation 46 but was stuck on the same individual for the entirety of today. 
* Did statistical analysis of our data, but got disappointing results. It seems like none of our results (for fitness sharing) were statistically significant for bloat or hypervolume improvements.
** I think this is most likely due to small sample size (2-3 samples per test) 
** We can also play around with the distance threshold for speciation and see how that impacts results 
** The notebook that I used to run the tests is [https://github.gatech.edu/efrankel6/emade/commit/377a43a69837df29236b01b864e7e31c9fd2dce4 here] 
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Conduct baseline EMADE runs
|In Progress
|March 2, 2020
|March 8, 2020
|March 8, 2020
|-
|Create midterm presentation
|In Progress
|March 2, 2020
|March 9, 2020
|
|-
|Set up PACE-ICE
|Not Started 
|February 24, 2020
|March 2, 2020
|
|-
|Verify that speciation code is working properly
|Completed
|January 13, 2020
|January 27, 2020
|February 3, 2020
|-
|Fix speciation
|Completed
|February 3, 2020
|February 17, 2020
|February 24, 2020
|}

== March 6, 2020 ==
'''Individual Notes'''
* The same thing happened with the run stopping making progress on run #2. It seems like it's getting stuck on a specific individual and just not continuing to make progress.
* I am not sure what the root cause of this issue is, so I decided to just restart and try again with run #3. 
'''Team Meeting Notes'''
* Interestingly, Animesh, who is running an older version of EMADE does not have the same problems that Josh and I do with runs getting stuck. 
* After reviewing the individuals in our databases, we noticed that there are ensemble learners in the new version of EMADE, while they are not present in Animesh's version. This could be the cause of the difference in runs getting stuck. 
* We also realized that since Animesh is running a different version of EMADE, it will be hard to compare his results with my baseline runs, so he will conduct a few baseline runs himself. We will avoid this in the future by using the same exact setup for all runs, ideally on PACE-ICE.
* We further discussed our plans for the midterm presentation, including what kinds of resutls to show and how we will pitch ourselves to incoming students.
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Conduct baseline EMADE runs
|In Progress
|March 2, 2020
|March 8, 2020
|
|-
|Create midterm presentation
|Not Started
|March 2, 2020
|March 9, 2020
|
|-
|Set up PACE-ICE
|Not Started 
|February 24, 2020
|March 2, 2020
|
|-
|Verify that speciation code is working properly
|Completed
|January 13, 2020
|January 27, 2020
|February 3, 2020
|-
|Fix speciation
|Completed
|February 3, 2020
|February 17, 2020
|February 24, 2020
|}

== March 5, 2020 ==
'''Individual Notes'''
* After letting my first run go over night, it seems like it has stopped progressing, so I decided to kill it and start a new one. The original plan was to get 50 generations per run, but unfortunately this one only made it to 27 generations.
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Conduct baseline EMADE runs
|In Progress
|March 2, 2020
|March 8, 2020
|
|-
|Create midterm presentation
|Not Started
|March 2, 2020
|March 9, 2020
|
|-
|Set up PACE-ICE
|Not Started 
|February 24, 2020
|March 2, 2020
|
|-
|Verify that speciation code is working properly
|Completed
|January 13, 2020
|January 27, 2020
|February 3, 2020
|-
|Fix speciation
|Completed
|February 3, 2020
|February 17, 2020
|February 24, 2020
|}

== March 4, 2020 ==
'''Individual Notes'''
* Started my baseline titanic runs. The purpose of these runs is to collect data for the EMADE's current performance, so that we can compare it to the performance of EMADE using speciation and NEAT crossover.
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Conduct baseline EMADE runs
|In Progress
|March 2, 2020
|March 8, 2020
|
|-
|Create midterm presentation
|Not Started
|March 2, 2020
|March 9, 2020
|
|-
|Set up PACE-ICE
|Not Started 
|February 24, 2020
|March 2, 2020
|
|-
|Verify that speciation code is working properly
|Completed
|January 13, 2020
|January 27, 2020
|February 3, 2020
|-
|Fix speciation
|Completed
|February 3, 2020
|February 17, 2020
|February 24, 2020
|}

== March 2, 2020 ==
'''Team Meeting Notes'''
* Discussed our concrete plan for the midterm presentation
** I will conduct baseline runs of EMADE so we can compare our results with the current standard
** Josh will do runs that test the performance of speciation (fitness sharing). He will do runs both where mating is restricted by species, and runs where it is not.
** Animesh will do runs to test his implementation of NEAT crossover.
* Standardized our input xml so that we all have the same experimental setup.
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Conduct baseline EMADE runs
|Not Started
|March 2, 2020
|March 8, 2020
|
|-
|Create midterm presentation
|Not Started
|March 2, 2020
|March 9, 2020
|
|-
|Set up PACE-ICE
|Not Started 
|February 24, 2020
|March 2, 2020
|
|-
|Verify that speciation code is working properly
|Completed
|January 13, 2020
|January 27, 2020
|February 3, 2020
|-
|Fix speciation
|Completed
|February 3, 2020
|February 17, 2020
|February 24, 2020
|}

== February 24, 2020 ==
'''Individual Notes'''
* Tried making a color-coded scatter plot of the objective space to visualize speciation, but the plot doesn't really show much. There is an interesting cluster of three different species in the bottom left corner (yellow, purple, and green), which seems to indicate that members of the same species tend to have similar fitnesses, though this is not necessarily the case. It makes sense that there are no clear species boundaries in this plot because speciation is done in a topological space over the structure of the individual trees, rather than in the 2D objective space for the problem. Plot is below for my most recent run on titanic. It includes only individuals that were evaluated in generation 29.
** [[files/Color Coded Objective Space by Species.png|none|thumb]]
*Doing a second run on titanic to confirm previous results. Should be finished and verified by tonight.
**Results from second run were consistent with results from the first run. I'm considering speciation correct until/unless we find any data to the contrary.

'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Set up PACE-ICE
|Not Started 
|February 24, 2020
|March 2, 2020
|
|-
|Verify that speciation code is working properly
|Completed
|January 13, 2020
|January 27, 2020
|February 3, 2020
|-
|Fix speciation
|Completed
|February 3, 2020
|February 17, 2020
|February 24, 2020
|}

== February 21, 2020 ==
'''Team Meeting Notes'''
* Animesh got strange pareto front for standard EMADE run (pareto front got worse from one generation to the next - this may just be a visualization bug)
* Animesh also ran neat crossover for 68 generations, seems to be working (he will manually verify that this is working as expected by comparing a sample of individuals with their offspring by hand)
* I haven't gotten much done since my last entry, but I will catch up before Monday's meeting
* Josh has been having an issue with his computer, which has been impacting his progress. He was still able to get a baseline EMADE run done (39 gens), ran again with original neat-GP fitness sharing for 42 gens and got a similar AUC to the baseline run. This is interesting because the fitness sharing was based on speciation code that I believe to be incorrect. 
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Verify that speciation code is working properly
|Completed
|January 13, 2020
|January 27, 2020
|February 3, 2020
|-
|Fix speciation
|In Progress
|February 3, 2020
|February 17, 2020
|
|}

== February 16, 2020 ==
'''Individual Notes'''
* Fixed the problem of non-increasing species numbers described in my last entry by counting the number of species using the database.
* Changed the speciation to use gene_pool rather than parents to get better species assignments
* After doing two runs, it is clear that the threshold for species distance does affect species assignment (all calculations based on random sample of 500 individuals or total individuals, whichever smaller)
** With the distance threshold set to .4, the max intra-species distance was ~.7, and the min inter-species distance was ~.3
** With the distance threshold set to .15, the max intra-species distance was ~.35, and the min inter-species distance was ~.04
** Unanswered question: why does are the thresholds "fuzzy" rather than exact?
*** Could be because gene_pool = elite_pool + offspring, which changes every generation. So rather than comparing to all individuals in the population, we only compare to individuals in the current gene_pool, which means there can be some individuals in the database that would change the species assignment of a new individual, but they are not considered.
*** I am going to see if adding an age  threshold on my tester notebook makes these thresholds correct
**** Ran on titanic for 29 gens, restricted calculations only to use individuals evaluated in year 29, distance threshold of .15
***** Min inter-species dist: ~.18, max  intra-species dist: ~.35
***** This makes me think it is working because the minimum distance between species is greater than the distance threshold. It seems plausible that the distance within the species is as large as .35 because of the greedy species assignment.
***** I will run more tests to confirm the results of this one.
* New code is [https://github.gatech.edu/efrankel6/emade/commit/5a3922bff56eb80207d6917e74738ee702d6d97c here]
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Verify that speciation code is working properly
|Completed
|January 13, 2020
|January 27, 2020
|February 3, 2020
|-
|Fix speciation
|In Progress
|February 3, 2020
|February 17, 2020
|
|}

== February 14, 2020 ==
'''Team Meeting Notes'''
* Had our subteam meeting
** Animesh has been working on crossover, now testing implementation
** Josh is working on testing the new fitness sharing implementation
*** Using species assignments to change selection probabilities
** I am still working on speciation

== February 10, 2020 ==
'''Individual Notes'''
* Found at least one problem with speciation
** In the speciation method, the count of the current number of species is not accurate. I will replace the current code to use the database and see if it solves the issue.
***Evidence of this issue is in the below screenshot, where the number of species is not monotonically increasing.[[files/Species over Time on Titanic.png|none|thumb]]

'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Verify that speciation code is working properly
|Completed
|January 13, 2020
|January 27, 2020
|February 3, 2020
|-
|Fix speciation
|In Progress
|February 3, 2020
|February 17, 2020
|
|}

== February 9, 2020 ==
'''Individual Notes'''
* Started investigation into why speciation isn't currently working
** Distances calculated are usually on the high side, few less than .5. Original threshold was .15 to be part of the same species, so potentially there is a logic error with the assignment of new species based on distance.
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Verify that speciation code is working properly
|Completed
|January 13, 2020
|January 27, 2020
|February 3, 2020
|-
|Fix speciation
|In Progress
|February 3, 2020
|February 17, 2020
|
|}

== February 3, 2020 ==
'''Individual Notes'''
* When looking through the neat-GP paper, I found that there is a special case for the distance formula that could result in a divide by 0 error, need to check that the implementation handles that case.
* After discussion with Drs. Zutty and Rohling, we decided to refocus our efforts on studying the effects of different species-based selection and crossover methods on bloat. Because of this, we will not implement the full neat-GP algorithm as described in the paper, but we will implement the initial step (speciation), and measure the effects that using the species data during parent selection has on bloat and overall performance.
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Verify that speciation code is working properly
|Completed
|January 13, 2020
|January 27, 2020
|February 3, 2020
|-
|Fix speciation
|Not Started
|February 3, 2020
|February 17, 2020
|
|}

== February 2, 2020 ==
'''Individual Notes'''
* Successfully built a list of DEAP Primitive Trees by using code from database_tree_evaluator.py 
** Current method is pretty slow, as it builds a list of hashes from CSV, then queries the database once for each hash
** Had to use a couple of hacks
*** Notebook is in the src/GPFramework directory so that the code from database_tree_evaluator works
*** Symlinked the datasets and templates directories into src/GPFramework for the same reason
*** Made a dummy cache dictionary because not supplying one breaks some database functions
** Wrote a quick lambda to convert MutableObject returned from the select() method in sql_connection_orm_master.py to a DEAP Primitive Tree:
 dbIndToTree = lambda ind: ind.pickle.__dict__['obj'][0]
* Based on [https://github.gatech.edu/efrankel6/emade/blob/speciation/src/GPFramework/species-verification.ipynb this notebook], it seems like the speciation is not working properly. The min inter-species distance was below the threshold, and the maximum intra-species distance was above the threshold. I will look into this further and resolve this bug ASAP.
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Verify that speciation code is working properly
|In Progress
|January 13, 2020
|January 27, 2020
|
|}

== January 27, 2020 ==
'''Individual Notes'''
* Created Jupyter Notebook to verify speciation is working properly
* Ran into an issue parsing trees from the strings stored in the database
** Tried gp.PrimitiveTree.from_string - fails with type mismatch
** Going to try pickles next
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Verify that speciation code is working properly
|In Progress
|January 13, 2020
|January 27, 2020
|
|}

== January 26, 2020 ==
'''Individual Notes'''
* Ran EMADE with species tagging for 34 generations on Titanic.
* Will analyze the results to verify speciation correctness tomorrow.
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Verify that speciation code is working properly
|In Progress
|January 13, 2020
|January 27, 2020
|
|}

== January 24, 2020 ==
'''Individual Notes'''
* Came up with plan for verifying speciation is working properly
** Do five runs of EMADE, download the database for each one, and compute pairwise distances between species
** Distance calculation will be done with the same formula but different implementation from what is used to determine species
** Verify that all pairwise inter-species distances are above the threshold
'''Current Action Items'''
{| class="wikitable"
!'''Task'''
!'''Current Status'''
!'''Date Assigned'''
!'''Suspense Date'''
!'''Date Resolved'''
|-
|Verify that speciation code is working properly
|In Progress
|January 13, 2020
|January 27, 2020
|
|}

== January 13, 2020 ==
'''Team Meeting Notes'''
* We discussed our initial goal: integrating neat-GP with EMADE and running experiments to test the effect that neat-GP has on our bloat metrics from last semester (e.g. basic bloat)
* Divided up the work to finish the integration so that we can do it in parallel
'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Verify that speciation code is working properly
|Not Started
|January 13, 2020
|January 27, 2020
|
|}

== December 2, 2019 ==
'''Individual Notes'''
* Completed final presentation, which can be found [https://docs.google.com/presentation/d/1hI4GQuZBEOxNT5dWNsQa1xXxLil5w6hd4GZIMAV4qy4/edit?usp=sharing here]
'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete final presentation
|Completed
|November 25, 2019
|December 2, 2019
|December 2, 2019
|}

== December 1, 2019 ==
'''Individual Notes'''
* Modified speciation code to use the species_parents_child method from neatGP codebase
* Changes can be found in [https://github.gatech.edu/efrankel6/emade/commit/122a4149fcb0a80b87959f74cf4426f5b70ae413 this commit]
* Have not been able to thoroughly verify that the species assignment is correct, but Hemang will work on verifying that before our presentation tomorrow
'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get neatGP speciation working
|Completed
|November 18, 2019
|November 22, 2019
|December 1, 2019
|-
|Complete final presentation
|Not Started
|November 25, 2019
|December 2, 2019
|
|}

== November 26, 2019 ==
'''Individual Notes'''
* Completed peer evaluations
* Filled in To-Do lists for the whole semester per feedback from midterm evaluations
'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get neatGP speciation working
|In Progress
|November 18, 2019
|November 22, 2019
|
|-
|Retroactively fill in To-Do lists for previous notebook entries
|Completed
|November 21, 2019
|November 25, 2019
|November 26, 2019
|-
|Peer Evaluation
|Completed
|November 21, 2019
|November 29, 2019
|November 26, 2019
|-
|Complete final presentation
|Not Started
|November 25, 2019
|December 2, 2019
|
|}

== November 25, 2019 ==
'''Individual Notes'''
* Fixed errors with speciation, now need to validate that the species are being assigned correctly
** Primary problem was that I was not running the speciation method on the first generation, which cascaded into incorrect assignment (all to 1) of species for the other individuals in the population
** One question I need to find the answer to: should I be determining an individual's species based on the parents, or the entire population?
** My new code is [https://github.gatech.edu/efrankel6/emade/commit/c7b8e7cdc0e9a175751cfe8762af64e7e9ce55a8 here]
** Picture of species ids along with their respective counts
***[[files/First Run Species.png|none|thumb]]
** I think I will also need to fix the way that the code determines the number of species currently in the gene pool to query the DB
* I also set up a Google Slides for our presentation
'''Team Notes'''
* Communicated presentation outline to the team
* Made sure everyone was on track to accomplish their goals for the presentation this week

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get neatGP speciation working
|In Progress
|November 18, 2019
|November 22, 2019
|
|-
|Retroactively fill in To-Do lists for previous notebook entries
|Not Started
|November 21, 2019
|November 25, 2019
|
|-
|Peer Evaluation
|Not Started
|November 21, 2019
|November 29, 2019
|
|-
|Complete final presentation
|Not Started
|November 25, 2019
|December 2, 2019
|
|}

== November 21, 2019 ==
'''Individual Notes'''
* Debugging issue with the specie_ind function (described in below entry)
* Resolved the original type error, but now I'm getting this:
 TypeError: Primitive <deap.gp.Terminal object at 0x7f4eb98b1780> return type <class 'int'> does not match the expected one: <class 'GPFramework.constants.TriState'>.
* Originally, I was trying to construct a PrimitiveTree from the string output by the my_str function, and that was the cause of the above error. I fixed it by just using individual[0] as the PrimitiveTree rather than the full tree output by my_str. My only concern is that this potentially leaves out ADFs, because I believe that is what's stored in the other elements of the individual. I need to confirm that using individual[0] is a valid way of extracting the PrimitiveTree from the individual.
* Committed [https://github.gatech.edu/efrankel6/emade/commit/a95406d1ef92fa45b5d02f68e8fcd5e6d2d54c8a WIP code], as it now consistently runs without runtime errors. 
* New problem: only species are 1 and -1. I think I am not initializing the species_id properly. 

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get neatGP speciation working
|In Progress
|November 18, 2019
|November 22, 2019
|
|-
|Retroactively fill in To-Do lists for previous notebook entries
|Not Started
|November 21, 2019
|November 25, 2019
|
|-
|Peer Evaluation
|Not Started
|November 21, 2019
|November 29, 2019
|
|}

== November 20, 2019 ==
'''Individual Notes'''
* copied speciation.py and measure_tree.py from the neatGP repo into the EMADE repo 
* Attempted calling speciation.specie_ind function to assign an individual to a species, but it is failing with runtime errors
** I think I need to somehow merge the individual type used in neatGP with the one used in EMADE
* Verified that database insertion code for species_id column on the individuals table is functioning properly
* added a species_id attribute to the Individual class to track species
'''Team Meeting Notes'''
* Finally got a hold of Josh and coordinated with him regarding neatGP integration work. He is working on integrating fitness sharing.

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get neatGP speciation working
|In Progress
|November 18, 2019
|November 22, 2019
|
|}

== November 18,  2019 ==
'''Individual Notes'''
* Began reading through neatGP code, starting with MAIN_FILE.py
* Working off the master branch of [https://github.com/saarahy/neatGP-deap/ this repo].
* Based on the meeting with Hemang (see Team Meeting notes below), I made changes to the database to support tracking speciation
** Added an species_id column to the individuals table
** Added a function to get the count of the number of individuals that belong to a specific species
* I also looked through the master algorithm and noted the places that  I need to add code to track the species
* Tomorrow I will figure out how to reuse as much of the neatGP code as possible in order to do the actual speciation calculation
'''Team Meeting Notes'''
* Talked with Hemang about neatGP integration
** I will work on assigning species based on a dissimilarity metric
** Hemang will work on developing the dissimilarity metric

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get neatGP speciation working
|Not Started
|November 18, 2019
|November 22, 2019
|
|}

== November 11, 2019 ==
'''Team Meeting Notes'''
* Talked with Animesh about my reasoning for negative bloat in the benchmarks
** A couple good questions he brought up
*** Look at individuals in the original generation to see what the are like
*** Look at crossover and mutation methods to validate size decrease theory
'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Integrate neatGP with EMADE
|Not Started
|November 11, 2019
|December 2, 2019
|
|}

== November 5, 2019 ==
'''Individual Notes'''
* Plotted the prediction of the best individual on the test data vs. the ground truth for the test data. Graph below:
* [[files/Comparison of Best Individual Prediction vs. Ground Truth for Symbolic Regression .png|none|thumb]]
** 
** Some notes about the above graph
*** Graph is for symbolic regression on sin(x^2)cos(x) - 1
*** TLDR: I would guess that the reason bloat was negative for the entire run is because the solutions never got accurate enough that they would benefit from adding more nodes, thus there was little evolutionary pressure for trees to grow, and thus little evolutionary pressure to cause bloat. Further, I predict that running the evolution for longer (maybe more like 200 or 300 generations rather than 100) would cause an inflection in bloat after a certain amount of time (once the solutions start getting very close to estimating the actual function).
*** As you can see, the predicted output is not a very good estimate of the ground truth. This is further supported by the best individual having a Continuous MSE > 3, when the range for the function is [-2,0]. This could be the reason for negative bloat during the run because the population never evolved to the point where bloat starts to occur. The run started with an average tree size of 81.78, which is quite large. Based on the Crossover Bias Theory, we would expect the average size of the population to increase because the smaller individuals should be less fit on average than the large individuals, however, this problem can likely be solved with a relatively small number of nodes in an individual, especially when using the higher-order primitives that we have in EMADE. Because of this, we can apply Crossover Bias Theory to say that the smaller individuals are being selected for, because they are more fit on average than the larger individuals at the beginning of the run, which explains the consistent decrease in average tree size. Since both hypervolume and tree size are consistently decreasing, it makes sense that bloat is negative for the entire run.
*** 

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Deep-dive into benchmark results
|Completed
|October 21, 2019
|October 28, 2019
|November 5, 2019
|}

== November 4, 2019 ==
'''Individual Notes'''
* Decided that I will look at the output of the best individual and compare plot it against the actual function (sin(x^2)cos(x) - 1) to make sure that the population was evolving towards a useful solution
** This is because my best theory so far for why bloat was negative for the entire run is just because the solution never got close to approximating the function correctly, though this still doesn't explain the decrease in tree size over time.
** Plotting the output of the best individual vs. the goal function will give me an idea if this theory is correct or not
* Unfortunately, I am having trouble figuring out how to use pickled_individual_reader.py because there is no documentation and few comments. This is a problem in general with EMADE that can make the process of using the framework very frustrating.
* Tried using standalone_tree_evaluator.py but it returns the individual's fitness, and I need the individual's output over the test input data. I have tried modifying the file to do this but have been unsuccessful. I will ask Jason/James during class today to see if they can help me with this problem.
** Fixed this by grabbing and then slightly modifying the "evaluate_new_data" function from database_tree_evaluator.py per James' suggestion

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Deep-dive into benchmark results
|In Progress
|October 21, 2019
|October 28, 2019
|
|}

== November 1, 2019 ==
'''Individual Notes'''
* began analyzing the individuals data for the sin symbolic regression problem to try to understand why bloat was negative for most of the run
* Waiting on the full database from Michael (currently I only have the individuals and bloat tables)

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Deep-dive into benchmark results
|Not Started
|October 21, 2019
|October 28, 2019
|
|}

== October 21, 2019 ==
'''Individual Notes'''
* Created plots to visualize basic bloat benchmarks.
* Put finishing touches on presentation.

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run and Analyze Benchmarks
|Completed
|October 18, 2019
|October 21, 2019
|October 21, 2019
|-
|Create midterm presentation
|Completed
|October 18, 2019
|October 21, 2019
|October 21, 2019
|-
|Deep-dive into benchmark results
|Not Started
|October 21, 2019
|October 28, 2019
|
|}

== October 20, 2019 ==
'''Individual Notes'''
* Prepared background section of presentation. Created a couple slides to explain what bloat is, how we can measure bloat, and selected methods for controlling bloat.
** Used the Bloat section from [https://cswww.essex.ac.uk/staff/rpoli/gp-field-guide/113Bloat.html A Field Guide to Genetic Programming] as a guide. It is a bit outdated but gives a very good explanation of the problem, as well as theoretical explanations for bloat and practical methods for controlling the problem.
* Presentation is linked [https://docs.google.com/presentation/d/1cJccFW1RC8qtmwskcuaJ-xSwl0Heyv_IwihF0YMfo4k/edit#slide=id.g6407a4f5c6_0_18 here]. It can also be found on our [[Bloat Control|subteam page]].

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run and Analyze Benchmarks
|Not Started
|October 18, 2019
|October 21, 2019
|
|-
|Create midterm presentation
|In Progress
|October 18, 2019
|October 21, 2019
|
|}

== October 18, 2019 ==
'''Individual Notes'''
* Installed a new OS on my laptop over the weekend, so I had to reinstall emade. 
** I noticed that the current README specifies sep, lightgbm, or spectral as dependencies that need to be installed, but doesn't include them in the commands that users copy and paste to install the dependencies. I installed these using conda by using the "conda install -c conda-forge sep lightgbm spectral". These packages are not available in normal conda, and at least on my machine, they failed to install using pip. I use the conda-forge channel to install them for this reason.
** I have updated the README in my fork with an extra step to install these packages. You can find that commit [https://github.gatech.edu/efrankel6/emade/commit/851350b78c0f08fd29dffb08cf6a7cf164c5cb4b here].
* Finally made a pull request into upstream DEAP to fix a problem with the current error checking implementation. Pull request is [https://github.com/DEAP/deap/pull/423 here].

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run and Analyze Benchmarks
|Not Started
|October 18, 2019
|October 21, 2019
|
|-
|Create midterm presentation
|Not Started
|October 18, 2019
|October 21, 2019
|
|}

== October 7, 2019 ==
'''Individual Notes'''
* Merged upstream detection_processing branch into the basic-bloat branch on my fork. I believe this deleted the bloat code because gtMOEP.py was replaced by EMADE.py, but I still have a copy of the code, so I will just copy it back in. Merge commit can be found [https://github.gatech.edu/efrankel6/emade/commit/a92bb34d1246ef735f98d49d1eaddddec2985248 here].
* Added database insertion code.
** Created new bloat table in the database, which logs the bloat metric value, hypervolume, and tree size at each generation. Commit can be found [https://github.gatech.edu/efrankel6/emade/commit/6a3463b2f6d72ea9764d5be608172ea00f0f9b98 here.] A screenshot of the bloat table is below.
**[[files/Screenshot of Bloat Table.png|alt=Screenshot of Bloat Table|none|thumb|Screenshot of Bloat Table]]
**A couple notes about the screenshot
***Bloat will always be -1 at generation 0. This is just a dummy value because the bloat metric is computed as change in tree size over change in fitness relative to generation 0. Thus, we can't calculate a bloat metric for generation 0 because it would be 0/0.
***Generations 1-4 show bloat as -0. This is because the hypervolume did not change from generation 0 during these generations. This means that actually computing the bloat metric for these generations would cause a divide by 0 error.
***Some bloat values, for example, generation 9, are negative. This is actually correct because hypervolume decreased and so did tree size, which is effectively negative bloat, i.e. the solution is getting smaller and performing better.

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Store simple bloat metric in database
|Completed
|September 23, 2019
|September 30, 2019
|October 7, 2019
|}

== October 4, 2019 ==
'''Individual Notes'''
* Committed my WIP code for basic bloat metric [https://github.gatech.edu/efrankel6/emade/commit/c9e334c95a037179f9155665270a31a8d24d55e4 here]
* Will add database insertion and clean up the code ASAP (targeting Monday latest)

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Store simple bloat metric in database
|Not Started
|September 23, 2019
|September 30, 2019
|
|}

== September 26, 2019 ==
'''Individual Notes'''
* I ran the test described below overnight, and collected the data into the below table
** Here is a screenshot of the data I collected during the test.[[files/Full Data First Successful Simple Bloat Metric Test.png|none|thumb|Screenshot of data collected during the test.]]
**Here is the data in graphical form. [[files/Graph of Normalized Data from Simple Bloat Metric on Titanic.png|none|thumb|Graph of normalized test data.]]
**Some notes about the above graph are below.
***Generation starts at generation 4 (the 5th generation) because all the generations before that had infinite bloat values.
***Tree size was an objective for this run, which probably affected the results. We will be sure to run our benchmarks without tree size as an objective to avoid this as a confounding factor.
***Hypervolume went negative at a few points, which also caused bloat to be negative for some generations. This is not immediately obvious in the graph of the scaled values. I didn't expect hypervolume to ever be a negative number, so this was a bit surprising to me. I will investigate this further.
***The normalization I did was to scale each metric so that it's value ranged from 0-1. I did this with the following formula:
 scaled_value = (value - min(values))/(max(values) - min(values))
* Based on these data, it seems that the metric is being calculated properly and doing a decent job of measuring bloat. If you look at the graph around generation 30, tree size starts to trend upwards while hypervolume drops and then plateaus. Bloat trends upwards along with tree size, reflecting the increase in size without a corresponding increase in fitness.
* I still need to clean up and commit the code I have worked on, as well as add database support. After that we should be able to run benchmarks.

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Do a baisc analysis of bloat metric on Titanic
|Completed
|September 23, 2019
|September 30, 2019
|September 26, 2019
|-
|Store simple bloat metric in database
|Not Started
|September 23, 2019
|September 30, 2019
|
|}

== September 25, 2019 ==
'''Individual Notes'''
* Rather than doing the database approach that I described in my last entry, I decided to simply output structured strings to stdout in the master process. This is much simpler than using the database while still allowing me to get the data I want to collect. I want to validate the metric ASAP so we can move on to running benchmarks. Once I do that, I will return to the database issue and attempt to log data more properly. I tried using the statistics function but it did not work (XML parsing error). I will investigate this further when I look at properly storing the data in the database.
** The specific structured string output is "bloat: (generation, bloat, hypervolume, average tree size)"
** It is easy to acquire data using grep. I've been doing this: cat master####.out | grep "bloat"
** Output looks like this:
***Screenshot of bloat data acquisition using grep[[files/Basic Bloat Data Screenshot.png|none|thumb]]
'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Do a baisc analysis of bloat metric on Titanic
|Not Started
|September 23, 2019
|September 30, 2019
|
|-
|Store simple bloat metric in database
|Not Started
|September 23, 2019
|September 30, 2019
|
|}

== September 23, 2019 ==
'''Individual Notes'''
* Modified the logHypervolume function to return the hypervolume that it calculates, and use this result in the bloat calculation. This fixed a bug that set all hypervolume values to None because I thought the logHypervolume function returned the hypervolume, but it didn't until I modified it. 
* Got a divide by zero error in the bloat calculation, so I modified it to return infinite bloat if there is no change in fitness. 
* Metric seems to be working now, going to let it run for awhile so we can see how bloat changes over generations. This will be tested in detail when we run benchmarks, but I want to do it for a single run first to make sure that the metric seems valid before running it on a large data set.
** It hung after only about 13 generations, so I killed the process. I will re-run tomorrow after I update the code to use the database. I will also change the timeout to one hour so that individuals that take a long time to evaluate will get killed faster (old timeout was 2.5 hours). 

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Implement simple bloat metric
|Completed
|September 5, 2019
|September 19, 2019
|September 23, 2019
|-
|Do a baisc analysis of bloat metric on Titanic
|Not Started
|September 23, 2019
|September 30, 2019
|
|-
|Store simple bloat metric in database
|Not Started
|September 23, 2019
|September 30, 2019
|
|}

== September 20, 2019 ==
'''Individual Notes'''
* I am working on replacing my scalar fitness metric (sum of squares) with hypervolume to try to solve the negative bloat problem. 

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Implement simple bloat metric
|In Progress
|September 5, 2019
|September 19, 2019
|
|}

== September 19, 2019 ==
'''Individual Notes'''
* Simple bloat metric seems to be almost working now. I modified it so it doesn't consider individuals with infinite fitnesses as these make the average fitness always infinite.
* One problem is that currently some bloat values are negative. I believe this is because I filtered out the individuals with infinite fitnesses, which could skew the average fitness for gen 0 lower. Instead I'm just forcing the scalar fitness metric to return the max float value if any of the fitnesses are infinite.
* Still need to update the scalar fitness value to use hypervolume instead of sum of squares.

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Implement simple bloat metric
|In Progress
|September 5, 2019
|September 19, 2019
|
|}

== September 18, 2019 ==
'''Individual Notes'''
* Picked up where I left off on Monday by modifying the bloat method to only consider individuals with valid fitness.

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Implement simple bloat metric
|In Progress
|September 5, 2019
|September 19, 2019
|
|}

== September 16, 2019 ==
'''Individual Notes'''
* Working on fixing bloat metric
** Each attempt to fix takes a bit of time to evaluate because I have to do a fresh run of EMADE that does at least 1 generation
** Tried moving generation 0 size and fitness calculations to the end of the master_algorithm loop instead of the beginning
*** This didn't work, current problem is that the fitness at generation 0 is still 0, which causes a divide by zero error in the bloat calculation
** Tried making the algorithm recalculate the "gen 0 fitness" every generation until the fitness value is non-zero to fix the problem stated above
*** Found a bug with my implementation of the above solution that made it re-run the calculation on the first generation every time
** Tried excluding infinite fitness as valid, which was a problem with the above. I think that the average fitness will always be infinite, however, because of the invalid individuals in the population. My next try will be to only consider the fitness of the valid individuals.
** For average fitness, use hypervolume of non-dominated pareto front -Dr. Zutty
*** Look at detection processing branch for updated caching
'''Team Notes'''
* Collected progress reports from team members and updated team notebook to reflect our collective progress.

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Implement simple bloat metric
|In Progress
|September 5, 2019
|September 19, 2019
|
|}

== September 15, 2019 ==
'''Individual Notes'''
* Worked out EMADE/DEAP errors, got EMADE running on Titanic data set.
** had to fix DEAP error (see September 9th entry)
** also had to fix import errors that I introduced to get statistics.py into the gtMOEP.py
* Bloat metric not working correctly (always returns 0). Will investigate this tomorrow and hopefully solve by class time.

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Fix EMADE errors
|Completed
|September 9, 2019
|September 16, 2019
|September 15, 2019
|-
|Implement simple bloat metric
|Not Started
|September 5, 2019
|September 19, 2019
|
|}

== September 13, 2019 ==
'''Team Notes'''
* Lead team meeting and assisted members with implementing metrics for quantifying bloat.
* For detailed summary of meeting see our team's page [[Bloat Control|here]].

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Fix EMADE errors
|Not Started
|September 9, 2019
|September 16, 2019
|
|-
|Implement simple bloat metric
|Not Started
|September 5, 2019
|September 19, 2019
|
|}

== September 9, 2019 ==
'''Individual Notes'''
* Still working on implementing the simple bloat operator
* Currently having problems getting EMADE evolution to run properly
** sel_nsga2 is reporting an error because the number of individuals must be divisible by 4, but currently it is getting a population with 525 individuals as input
*** Update from Dr. Zutty: issue in DEAP
**** in tools/emo.py - sel tournament DCD
**** modify the check on length of individuals to only check if it is more than the number of individuals to select
* My approach to implementing the operator is slightly modifying the master algorithm to include the computation. I will move this to use the stats dict once I understand how to populate that dictionary and get it to fill the database properly. 
* Compiled team notes for today's scrum
'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Fix EMADE errors
|Not Started
|September 9, 2019
|September 16, 2019
|
|-
|Implement simple bloat metric
|Not Started
|September 5, 2019
|September 19, 2019
|
|}

== September 6, 2019 ==
'''Team Notes'''
* Lead team meeting and worked with members to divide into subteams working on different metrics for quantifying bloat.
* For detailed summary of meeting results see our team's page [[Bloat Control|here]].
'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Implement simple bloat metric
|Not Started
|September 5, 2019
|September 19, 2019
|
|}

== September 5, 2019 ==
'''Individual Notes'''
* Fixed original EMADE error with help from James
** Used: 
 git lfs pull
* Defined bloat metric
** Rather than using the caching mechanism/hashing data sets at each node in the individual's tree and checking to see if hashes are equal at the input and output, I plan to use the bloat metric defined in ''Measuring Bloat, Overfitting and Functional Complexity in Genetic Programming'' ([https://dl.acm.org/citation.cfm?id=1830643 link]). I decided to do this as a first pass because it is a relatively simple metric that I think I will actually be able to implement. The hashing idea is a good one but seems overly complex and time consuming to implement and execute during a GP run. If it turns out that the metric I plan to use is not effective at quantifying bloat that appears in EMADE runs, I will switch to implementing the more complex hashing metric. 
*** The bloat metric from the above paper takes the definition of bloat as "program growth without (significant) return in terms of fitness." Thus, the metric takes the normalized improvement in average program length (number of nodes) from generation zero to the current generation, and divides it by the corresponding normalized fitness improvement. 
* Sent an email to Dr. Zutty requesting more GCP credits.
* Implemented bloat and scalar_fitness functions in statistics.py (haven't committed yet because need to update my fork to match latest upstream master)
** bloat: implements the bloat metric describe above
** scalar_fitness: returns the sum of the squares of the fitnesses to make the above metric usable for multi-objective GP
*** may want to improve this mechanism. Definitely need to make it account for fitness weights
** have not gotten metric to work with stats table yet (WIP). Hopefully will figure it out tomorrow 
'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish EMADE setup
|Completed
|August 30, 2019
|September 3, 2019
|September 5, 2019
|-
|Define simple bloat metric
|Completed
|September 4, 2019
|September 11, 2019
|September 5, 2019
|-
|Implement simple bloat metric
|Not Started
|September 5, 2019
|September 19, 2019
|
|}

== September 4, 2019 ==
'''Individual Notes'''
* Cloned and configured the latest version of EMADE on my laptop in order to be able to begin testing the bloat detection code.
* Ran into trouble with an error from gzip that I haven't gotten before:  OSError: Not a gzipped file (b've')
** Still haven't been able to resolve this, will work on it tomorrow.
** Goal is to be able to develop and run bloat detection code in order to get a feel for the magnitude of the bloat problem in EMADE.
* Blockers
** EMADE not running properly (commit 78d48bd) on titanic dataset.
** Out of GCP credits. Need these to run more tests once initial metric is developed. Will contact Dr. Zutty tomorrow via email to see if it is possible to get more.
'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish EMADE setup
|In Progress
|August 30, 2019
|September 3, 2019
|
|-
|Define simple bloat metric
|Not Started
|September 4, 2019
|September 11, 2019
|
|}

== August 30, 2019 ==
'''Individual Notes'''

Read the neat-GP paper in full. Below is a bit of a brain dump that attempts to synthesize common themes from the two papers I've read so far
* Seems like speciation and elitism are themes among the SS+E paper and neat-GP. We could look at ways to improve existing speciation methods both in terms of computational complexity and in terms of speciation criteria. Future research suggested by the neat-GP paper includes researching speciation over different spaces, rather than topological similarities. 
** One idea could be to use clustering (e.g. k-means) to do speciation over a specific sample space, but this may unnecessarily increase computational complexity as well as make it harder to automatically create new species, as opposed to the thresholding approach described in the neat-GP paper. 
* It’s interesting that the different crossover methodologies had different performance in different domains, with standard crossover working better for symbolic regression and neat crossover working better for classification. It would be interesting to see how this fits in with EMADE because it can be applied to multiple problem types and the different crossover strategies may have different results when using more complex primitives like the ones we have in EMADE. In addition, neat-GP seems to enforce low rates of crossover between species, it would be interesting to see if doing more inter-species crossover has a positive or negative effect on performance and bloat control.
* I like NEAT’s idea of starting with small trees and evolving them by adding on to find more complex solutions. We could research this further and see how it applies specifically to ML problems. For example, we could do seed population generation using different basic ML techniques (e.g. SVM, Decision Tree) with basic feature engineering (not exactly sure what to do here) and add on to these techniques with more complex learners (e.g. NN) and feature engineering techniques as the trees grow. Intuitively, this will allow us to find solutions that use simpler models for simpler problems and more complex models for harder problems.
'''Team Notes'''
* Determined new short term goal: quantifying the bloat problem in EMADE
** We will do this by running EMADE on classification (e.g. MNIST) and symbolic regression problems (taken from papers we have read) and using either hashing or tree topology to determine size of bloat
** Still need to figure out how to write the code to use caching to detect introns. 
* Once we have quantified and analyzed bloat in EMADE, we will be better able to determine how to apply bloat control techniques to EMADE and GP with high-order primitives in general.
* It will also be useful as we can use the tools we develop to do this analysis for standalone bloat detection/removal on individuals that have already been evolved.

'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read papers
|Completed
|August 26, 2019
|August 31, 2019
|August 30,  2019
|-
|Create semester goals
|Completed
|August 26, 2019
|August 31, 2019
|August 30, 2019
|-
|Get EMADE setup (again)
|Not Started
|August 30, 2019
|September 3, 2019
|
|}

== August 26, 2019 ==
'''Individual Notes'''
* Goals for this week
** Read the following papers
*** neat-GP
*** Reducing code bloat in Genetic Programming Based on Subtree Substituting Technique
*** more to be recommended by Jason
** Evaluate current research for use with high-order primitives/machine learning problems, and decide how to build off 
** Create a timeline of goals for the semester
'''Current Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Read papers
|Not Started
|August 26, 2019
|August 31, 2019
|
|-
|Create semester goals
|Not Started
|August 26, 2019
|August 31, 2019
|
|}

== April 21, 2019 ==
'''Individual Notes'''
* Committed previous changes
** [https://github.gatech.edu/bchau7/emade/commit/2a10a61c501378104cb8ea6e3b141c9dfbe4b1ed 2a10a61c501378104cb8ea6e3b141c9dfbe4b1ed]
* Made the benchmarking section of the presentation

== April 19, 2019 ==
'''Individual Notes'''
* Got results of the second test.[[files/Second Cache Benchmark Results.png|none|thumb]]
** Results pictured above.
** Takeaways
*** Cache always completes many more generations than standard, which is to be expected.
*** Unfortunately, on average cache performed worse than standard, with an average best individual distance of ~40, while standard had an average of ~31. 
*** This means that even though cache is completing many more generations than standard, each generation makes less evolutionary progress towards the objective.
*** I think this has to do with the much lower average valid individual percentage for cache. Cache averaged ~8% valid individuals at the end of the run, while standard averaged ~24%.
*** Cache size does not seem to be proportional to the performance, which suggests something is wrong with the caching implementation.

== April 17, 2019 ==
'''Individual Notes'''
* Started a new test run with the added performance metric. 
** This test was 10 runs (5 with cache, 5 without) for 5 hours each, for a total of 50 hours. All tests were run on the Titanic dataset.

== April 16, 2019 ==
'''Individual Notes'''
* Got results from the first test.[[files/First Cache Benchmarks.png|none|thumb]]
** The above photo shows the output from the first test run.
** Some interesting takeaways
*** Cache leaves us with significantly lower percentage of valid individuals per run.
**** I think this could mean something is wrong with the cache implementation
**** It could also be the reason cache completes so many more generations than standard, because the first 50+ generations of cache run usually have no valid individuals in them. This means they would take almost no time to evaluate, and quickly go to the next generation until a valid individual is found randomly.
**** Seeding the database could help alleviate this problem.
* Added new metric to track the performance of the algorithm. See below entry for details on metric.

== April 15, 2019 ==
'''Individual Notes'''
* Got basic tests working
** The script can now kill other EMADE processes, so each run is a clean start. This fixed the major issue from the previous version.
** Added metric that tracks the percentage of all individuals in the database with valid fitnesses. I added this because I noticed that there were unusually large numbers of invalid individuals in the database when I started using cache.
** Plan to add a new metric to track the performance of the run
*** For the performance metric, I plan to use the euclidean distance between the best individual and the best individual and the origin in the 3d-objective space. This distance allows us to roughly quantify the performance of a specific run of the test in a single number.
* Started running the first round of tests. 
** This round was 4 runs (2 with caching, 2 without) of 5 hours each, for a total of 20 hours

* Commits
** [https://github.gatech.edu/bchau7/emade/commit/122fdffbb4ad0a1abf96f32ea4f4324a11508163 122fdffbb4ad0a1abf96f32ea4f4324a11508163]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish setup of GCP instance
|Completed
|April 4, 2019
|April 5, 2019
|April 13, 2019
|-
|Decide which metrics to report for benchmarking
|Completed
|April 4, 2019
|April 5, 2019
|April 13, 2019
|-
|Run EMADE on sample dataset and look at database to determine how to set up queries for benchmarking
|Completed
|April 4, 2019
|April 6, 2019
|April 13, 2019
|-
|Write a benchmarking script to automatically test caching
|Completed
|April 1, 2019
|April 8, 2019
|April 15, 2019
|}

== April 14, 2019 ==
'''Individual Notes'''
* created the benchmarking script (basic)
** script prints table-like ouptut during the test that shows current run time, number of generations, cache time savings, and cache size
** it also prints averages at the end
*** planning to add more automatic performance calculations (i..e percent improvement)
** currently doesn't stop worker processes, which is a problem. All data from this script is currently wrong because of this.
** Runs multiple tests, but all must be same duration
*** currently, controls are all placed in constants at the top of the file. I will work on taking command line input this week.
** Commits:
*** [https://github.gatech.edu/bchau7/emade/commit/5888ad1bd13e004d47bd34da6c3560f6d4ec36b1 5888ad1bd13e004d47bd34da6c3560f6d4ec36b1]
*** [https://github.gatech.edu/bchau7/emade/commit/7d2b66e9d11eee8bbf49c76bd5d8dc51a524b68e 7d2b66e9d11eee8bbf49c76bd5d8dc51a524b68e]

== April 13, 2019 ==
'''Individual Notes'''
* Made a new n1-highmem-2 GCP instance to run EMADE. This instance has 2vCPUS and 13 GB of RAM, which is much more than the previous instance. 
** First, I imaged the disk for the original instance so I wouldn't have to repeat the tedious EMADE installation process.
** Once GCP finished imaging the disk, I used this to create the new instance with the higher specs. 
** This is instance is much more expensive than the other one, but it doesn't run out of memory. I currently have enough GCP credits to run it for about another 2 weeks.
* Ran EMADE on the Dota dataset using cache overnight, and it seems to be working. I got individuals with non-null fitness data, which is progress over last time. I will try running again with cache on the titanic dataset as I believe the benchmarking data we can get from the titanic dataset will be higher quality than that from the Dota set.
* While the titanic dataset is running, I will look through the data from the Dota dataset to create my queries for the benchmarking script. I set them up to use different databases to avoid one overwriting the other's data.

== April 9, 2019 ==
'''Individual Notes'''
* Got EMADE running on my GCP instance but all individuals have null fitnesses
* Tried seeding with a random forest, but this failed with cannot allocate memory error

== April 7, 2019 ==
'''Individual Notes'''
* Had trouble running EMADE on my GCP instance
* On running, got an error in the worker's .err file, unable to locate google in site-packages

== April 5, 2019 ==
'''Team Meeting'''
* Determined plan for benchmarking script
** finish GCP setup
** run emade with cache
** look through DB to find stats to track
** write queries and functions to automate collection of those stats
** write script to automatically run emade and generate the stats

== April 4, 2019 ==
'''Individual Notes'''
* Read through data.py and launchGTMOEP.py fairly thoroughly, my understanding of the caching functionality based on reading those files is below:
** GTMOEPDataPair.get_caching_mode() - used to enable/disable cache
** Store_in_cache - stores data into the cache
*** Concatenate all the data
*** Generate a new hash for the test data (SHA256)
*** Save the training data, test data, labels if applicable, and the hash
*** Keep track of the size of the training and testing data that was saved
*** Determine the time it took to write the data to disk
*** Update the database with the time it took to run the method originally, time to write the data, and the size of the data on disk
*** Update the GTMOEPData objects for test and train to reflect the location of the cached data on disk
** load_from_cache - loads data from the cache
*** Read the test and training data from disk
*** Apply labels if necessary
*** Update the data objects using what was read from disk
*** Question: What does GTMOEPDataInstance do?
** Loading: caching generally follows this procedure in methods like one_for_all
*** if caching enabled
**** get the previous hash of the data pair
**** compute a "file string" based on the method_string (param) and the hash that was loaded from disk
**** query the database using the file_string to see if it is cached
***** if it's cached
****** Load the hash stored in hash.txt from the correct directory based on the file_string and base directory
****** Update the data pair’s hash to be the one that was just loaded
****** Finally, load the data from the cache (see load from cache description)
****** Return the data pair to avoid executing the rest of the function
** Storing: caching generally follows this procedure in methods like one_for_all
*** If caching enabled
**** Calculate the time it took to run the method, if it’s greater than a threshold value specified in the data pair object
***** Save the data -- see store_in_cache
** Exception handling:
*** If caching enabled
**** Remove any data that was already saved and the directories containing the data
**** Update the database to reflect that the error occurred
** Parsing of the cache parameters as specified in the XML file is done in launchGTMOEP.py
** Questions
*** Caching of models themselves? It seems like currently cache only caches the train and test data, not the model itself. I'm confused as to how this speeds up the performance.
'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish setup of GCP instance
|In Progress
|April 4, 2019
|April 5, 2019
|
|-
|Decide which metrics to report for benchmarking
|Not Started
|April 4, 2019
|April 5, 2019
|
|-
|Run EMADE on sample dataset and look at database to determine how to set up queries for benchmarking
|Not Started
|April 4, 2019
|April 6, 2019
|
|-
|Write a benchmarking script to automatically test caching
|Not Started
|April 1, 2019
|April 8, 2019
|
|}

== April 1, 2019 ==
'''Team Meeting Notes'''
* Decided I would work on creating benchmarking utilities for cache and emade
* Try to make it possible to parallelize execution on multiple GCP instances
'''Individual Notes'''
* Continued working on documenting methods.py and selection_methods.py
* Updated weekly subteam report regarding progress on this week's tasks for the above two files
* Redid my merger of the methods.py and selection_methods.py from the master emade branch on the emade/emade fork. Originally I tried merging the whole of the two branches, but after submitting my PR, Ben suggested I redo it and only commit changes to the files I was assigned. I did so by creating a new branch off of grid_slurm_integration and using git checkout --patch to change only the files I was assigned. Then I reapplied my merge conflict resolution to methods.py that I made in my original PR. I submitted the new version in [https://github.gatech.edu/bchau7/emade/commit/69b6e00802de6dd486528a9cc643d1cff0bfdd3d this commit].
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Merge methods.py from emade/master into bchau/grid_slurm_integration
|Complete
|March 25, 2019
|April 1, 2019
|April 1, 2019
|}

== March 31, 2019 ==
'''Individual Notes'''
* Yash and I worked on merging the methods.py file from emade/emade/master into bchau/emade/grid_slurm_integration
* we also read through selection_methods.py, didLaunch.py, and data.py
* Haven't tested the merged methods.py file because I still need to finish setting up Google Cloud, will do this ASAP
* Started documenting methods.py and selection_methods.py
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Merge methods.py from emade/master into bchau/grid_slurm_integration
|In Progress
|March 25, 2019
|April 1, 2019
|
|-
|Read data.py and didLaunch.py
|Complete
|March 25, 2019
|April 1, 2019
|March 31, 2019
|}

== March 17, 2019 ==
'''Team Meeting Notes'''
* Clarified the axes on all graphs in presentation
** indicated whether we were plotting false negative rates or absolute numbers of false positives and false negatives
* Added a brief comparison of the best individual produced by EMADE and by our first and second GP attempts
* Added a comparison of the Pareto fronts produced by the three different attemtps (ML, GP, and EMADE)

== March 11, 2019 ==
'''Team Meeting Notes'''
* Over the course of the week, we ran EMADE on the Titanic dataset at night
* William ran the master node. Oscar and I were able to connect and run workers, but Zach had trouble connecting because he lives off campus
* In total, we were able to run 48 generations
* To analyze the data, we combined all the pareto front data into one large CSV file that had the pareto front for every generation
* We took this data and filtered it to create the pareto front because we found that not all the individuals provided by EMADE were actually pareto optimal
* We then plotted the AUC over time
** We found that AUC increased over time
** One possible explanation for this is that there were more pareto optimal individuals over time, and this increased outliers that spread the curve out over a larger area
***[[files/Graph of AUC Over Time.png|none|thumb]]
***This shows the outliers that I discuss above, but there is a cluster towards the origin representing better individuals.[[files/Pareto Front for Last Generation.png|none|thumb]]
* To see if EMADE was improving the learner over time, we decided to plot the minimum euclidean distance between the origin and an individual for each generation. This showed a consistently decreasing graph, though it stagnates around generation 35. This graph indicates that the genetic algorithm is making progress even if AUC is increasing over time.
**[[files/Graph of Minimum Euclidean Distance Over Time.png|none|thumb]]
'''Presentation Notes'''
* Need to do more discussion of the individuals produced by EMADE
* Compare Pareto fronts between ML, GP, and EMADE
* Could look at hypervolume instead of the AUC for the 2d objective space
* Clarify axes on graphs
'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run EMADE on titanic dataset
|Complete
|February 25, 2019
|March 11, 2019
|March 11, 2019
|}

== March 2, 2019 ==
'''Team Meeting Notes'''
* Now we had issues connecting to the remote MySQL server
* William set up the server on his computer, but we couldn't connect because we needed to change the bind-address in his MySQL configuration to allow remote connections
* Once we did this we were able to connect as workers and run EMADE
'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run EMADE on titanic dataset
|In Progress
|February 25, 2019
|March 11, 2019
|
|}

== March 1, 2019 ==
'''Team Meeting Notes'''
* Subgroup met to try to get EMADE running
* some members had trouble finishing the EMADE install, so we finished our group meeting and tried to fix our issues individually
* I was having an issue where GP wasn't running due to an error with the version of sklearn 
** the script was written (I believe) for sklearn verion 0.17, so it was trying to import sklearn.gaussian_process.GaussianProcess, which has since been replaced with GaussianProcessRegressor (I'm using sklearn 0.20.3)
** I manually changed this in the code and then rebuilt GPFramework by running ./reinstall in the emade root directory, which solved this issue
'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run EMADE on titanic dataset
|In Progress
|February 25, 2019
|March 11, 2019
|
|}

== February 25, 2019 ==
'''Team Meeting Notes'''
* Unable to attend team meeting due to illness
'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run EMADE on titanic dataset
|Not Started
|February 25, 2019
|March 4, 2019
|
|}

== February 18, 2019 ==
'''Team Meeting Notes'''
* Worked on installing EMADE
* Got EMADE working on my laptop
'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Get EMADE working
|Complete
|February 18, 2019
|February 25, 2019
|February 18, 2019
|-
|Complete Titanic Dataset Analysis with GP
|Complete
|February 11, 2019
|February 18, 2019
|February 17, 2019
|}

== February 13, 2019 ==
'''Individual Notes'''
* Created a thresholding function that made the average prediction of an unevolved population of 300 individuals as the threshold
* Using this thresholding function, was able to get an accuracy of ~79% on the validation set by averaging the predictions of the whole population after evolution
** Evolutionary algorithm: mu plus lambda
*** NGEN = 30
*** MU = 50
*** LAMBDA = 100
*** CXBP = .3
*** MUTBP = .2
*** Mutation function: node replacement
*** crossover: one point
*** selection: tournament (size = 2)
*** random.state = 25
*** primitives: {add, subtract, multiply, sin, cos, thresh} 
**** thresh = return data >= .602248 (magic number calculated from average of predictions of unevolved pop with given pset)
*** Interesting behaviors
**** Success of evolution is dependent on the random state. I believe that this is because changing the random state changes the random population, thus changing the approriate threshold value
**** Similarly, changing anything about the pset, evolutionary parameters, and number of generations results in the same thing that was happening on Feb 11
**** I think I need to figure out a better thresholding function or some other way to convert float values to bools for final prediction
**** Noticed that even if the average (fpr, fnr) at the last generation is approx (0,1), the classifier can still get decent results ~70-79% on the validation set. Not sure why this occurs.
'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Titanic Dataset Analysis with GP
|In Progress
|February 11, 2019
|February 18, 2019
|
|}

== February 11, 2019 ==
'''Individual Notes'''
* Collected false positives and false negatives from group members and plotted our Pareto front, which I uploaded to the wiki
'''Team Meeting Notes'''
* Started working on the Titanic dataset using GP with basic primitives
* Finished creating an error-free evaluation function which returns a tuple (false positive rate, false negative rate) based on the predictions of the individual on the training data
* Still need to work on making this evaluation function and the evolution algorithm effective at solving the problem
** currently, after <10 generations, the average fitness tends to converge to approx. (0,1), meaning the individual predicts that the passenger died almost 100% of the time
** to solve this, I think we need to do a combination of feature engineering and changing of our thresholding function that converts the float value of the prediction to a 0 or 1
'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Titanic Dataset Analysis with GP
|In Progress
|February 11, 2019
|February 18, 2019
|
|}

== February 10, 2019 ==
'''Notes'''
* Built Random Forest classifier for the Titanic dataset
* Used Grid Search to tune the model's hyper-parameters
* Achieved Kaggle score of .77990
* Collected false positives and false negatives from group members and plotted our Pareto front, which I uploaded to the wiki
'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Titanic Dataset Analysis
|Completed
|February 4, 2019
|February 11, 2019
|February 10, 2019
|}

== February 4, 2019 ==
'''Team Meeting Notes'''
* Chose teams based on multi-objective classification (self-report survey of Python and Machine Learning skills)

'''Action Items'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Titanic Dataset Analysis
|Not Started
|February 4, 2019
|February 11, 2019
|
|}

== February 3, 2019 ==
'''Notes'''
* Playing around with the Mu + Lambda algorithm as part of the lab makes me think that the AUC is not an optimal measure of performance, because doing things like using a very small number of generations in order to reduce tree height (one objective to minimize) leads to low AUC, but fairly low performance on the other objective (RMSE). Meanwhile with other parameters that appeared to produce at least one individual in that did a good job at minimizing both objectives had fairly large AUC. I think this is because doing things like increasing population have the effect on increasing the AUC simply beause there are more points. 
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Lab 2
|Completed
|January 28, 2019
|February 4, 2019
|February 3, 2019
|-
|}

== January 28, 2019 ==
'''Team Meeting Notes:'''
* Began lecture on multi-objective GP
* Discussed modelling multi-objective by mating the Pareto optimal individuals in high dimensional space
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Lab 2
|Not Started
|January 28, 2019
|February 4, 2019
|
|-
|}

== January 27, 2019 ==
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Part 1 of Lab 2
|Completed
|January 14, 2019
|January 28, 2019
|January 27, 2019
|-
|}

== January 14, 2019 ==
'''Team Meeting Notes:'''
* Learned basic GP including Tree representation and Parse Trees

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Part 1 of Lab 2
|Not Started
|January 14, 2019
|January 28, 2019
|-
|}

== January 13, 2019 ==
'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Lab 1
|Finished
|January 7, 2019
|January 14, 2019
|January 13, 2019
|}


== January 7, 2019 ==
'''Team Meeting Notes:'''
* Learned about genetic algorithms
* Briefly previewed Lab 1

'''Action Items:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Complete Lab 1
|Not started
|January 7, 2019
|January 14, 2019
|-
|}