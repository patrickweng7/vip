== '''Semester 2''' ==

== 8/26/2019 ==
- New semester, new notebook

- This semester I am part of the "Automatic Preprocessing" team with Anika, who worked on it during the summer.

- We met last Friday 8/23 for an hour to go over our goals for the semester. Right now my main job is to understand the code she wrote over the summer and improve the code to be easier to understand for other people (renaming variables, adding comments, etc.)
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Put our semester goals on the Wiki
|Resolved
|8/26
|8/30
|9/10
|-
|Read through/clarify Anika's code
|Resolved
|8/26
|8/26
|8/30
|}

== 8/28/2019 ==
- Met with Mohan Dodda from the NLP team for an hour and a half. We live in the same building and he has offered to help me out from time to time.

- The purpose of our meeting was for him to give me a crash course in working with GitHub. I had forgotten most of what I learned last semester.

- Went through forks and branches, cloning vs downloading, and the git workflow (git pull, git add, git push, git commit).

- We also tried to clone the preprocessing branch but ran into an authentication error. Once we got past it we cloned the wrong fork/branch several times.

== 8/30/2019 ==
- Meeting today was to take care of uninstalling the current EMADE branches that I had cloned on my computer and clone the preprocessing branch of Anika's fork of the EMADE repository. 

- Anika had trouble getting past the same authentication error that I had on Wednesday, but we eventually resolved it. 

-Couldn't get to running EMADE though since the installation process took a while.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Clone the repository
|Resolved
|8/28
|8/30
|8/30
|-
|Reinstall the necessary modules
|Resolved
|8/30
|8/26
|8/30
|-
|Continue looking through code
|Resolved
|8/30
|9/9
|9/8
|}

== 9/9/2019 ==
- Anika wasn't here today so I had to give the scrum. I was not prepared since we had neglected to post our meeting notes to the team wiki however I had enough time to put everything together while listening to everyone else's scrums.

- This instance highlighted to me the problems that our team is having so far this semester. I realized today that we needed to be posting our sub team notes to the wiki on a weekly basis. So I will take care of that tonight/tomorrow. As a team we also need to improve our communication. In class I created and started working on our sub team page.

- For this week we need to get EMADE running and test it on different kaggle datasets to ensure that the code is working as intended.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Create and publish sub team page
|Resolved
|9/9
|9/10
|9/10
|-
|Run EMADE
|Resolved
|9/9
|9/16
|9/13
|}

== 9/13/2019 ==
- Met today during help desk hours. The main goal of the meeting was to try to run EMADE, however I ran into several issues. Here are the steps I took:
# Conda/pip installed all of the modules listed in the EMADE github instructions
# Installed MYSQL workbench
# However when it came time to run there were certain modules that needed to be installed that weren't included in the EMADE instructions such as "sep" and "lightgbm"
# There was also an issue with the sklearn module "experimental" so I commented out the sections of code that depended on it
- I eventually got through any run-time errors but Anika couldn't get past an error regarding the mysql module not being found. However, I couldn't get the pre-processing code to automatically create a sql schema and fill it in

- I have been typing up the notes for the sub-team wiki so see that for the team's challenges and goals. Link: [[Automatic Preprocessing|https://vip.gatech.edu/wiki/index.php/Automatic_Preprocessing]]
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Figure out why the SQL schema isn't being filled in
|Resolved
|9/13
|9/16
|9/15
|}

== 9/15/2019 ==
- Met with Mohan for an hour and a half today to try to figure out why the SQL schema isn't being filled in. We looked through Anika's code for a while and he explained to me a lot of what it does. We mainly focused on the data.py and data_splitter.py files to understand how the EMADEdata objects are created and stored as well as go through the different parameters that Anika included for preprocessing feature data.

== 9/16/2019 ==
- Met in class today. Our main goal for the meeting was to ensure that the code was working as intended and to try and run EMADE to automatically produce a SQL schema and eventually have valid individuals. Jason came by to see to help us out with ensuring that EMADE was producing valid individuals. However, we didn't get any false positives and false negatives before the meeting ended.

- Our goals for this next week are to start looking into image data while we figure out why we aren't getting valid individuals
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Run EMADE using Titanic dataset
|Resolved
|9/16
|9/23
|9/20
|-
|Look into Image preprocessing (read through articles)
|Resolved
|9/16
|9/23
|9/19, 9/22
|-
|Update sub-team Wiki
|Resolved
|9/16
|9/16
|9/16
|}

== 9/20/2019 ==
[[files/SQL tests.png|thumb|These are databases created while I was testing the code for testing feature data (all the schemas with _test in the name)]]
- Briefly met today for an hour. Anika and I sat down to discuss our approach to preprocessing image data, and to mainly continue testing the code we have for feature data using the titanic dataset to see if we get any valid individuals. Anika took me through the data_splitter.py file to explain the different parameters for preprocessing feature data and their utility.

- Instead of summarizing the articles I read about image preprocessing for this notebook, I'm instead going to list some of the ideas for preprocessing primitives that I got from the article, and perhaps summarize what they do. Also for a full list of link please see our subteam weekly notes page.

- https://towardsdatascience.com/image-pre-processing-c1aec0be3edf:
* resize: resize the image to a base size
* gaussian_blur: slightly blur the image to remove unwanted noise
* segmentation: separating background from foreground objects in the image

== 9/23/2019 ==
- The team met in class today and I gave the scrum at the beginning. Over the weekend I ran EMADE with the titanic dataset for over 500 generations. I started the process running right before the Friday meeting adjourned, and I forgot about it until Sunday night when I opened my command prompt to do some CS homework. Unfortunately, even after all of those generations, none of the individuals in the titanic_test6 schema were producing false negative and false positives. This confirms that there is definitely something wrong with our preprocessing code.

- Jason came over to check out why we weren't getting any valid individuals after 500 generations. Right before he came around we realized that our process for creating folds was returning empty files when the training data-sets were too small. Jason showed us an sklearn method called sklearn.model_selection.ShuffleSplit() that does the same process that were were trying to do. We plan on trying to implement it as replacement if our code continues to fail. Link: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit

- The other problem that we identified was that our code was not producing seed files, which matches our initial suspicion that we weren't getting valid individuals because our code was not seeding in correctly. James Rick stopped by and helped us try to debug the code but we couldn't fix it in today's meeting. Anika will go through the code this week to try and figure out what's wrong.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Continue reading through articles
|Resolved
|9/23
|9/30
|9/28, 9/29, 9/30
|-
|Come up with ideas for image preprocessing primitives
|Resolved
|9/23
|9/30
|9/29, 9/30
|-
|Update sub-team Wiki
|Resolved
|9/23
|9/30
|9/30
|}

== 9/29/2019 ==
- Couldn't meet with Anika with week since she was out of town Thursday/Friday so I instead met with Mohan today. It was brief since we are both busy with schoolwork this weekend (My hell week ends on Tuesday with two midterms and an interview). There was still one last big gap in my understanding of the way our team does automatic preprocessing. Mohan explained to me the process of implementing primitives into EMADE gp_helper and pset.addprimitive. I finally understand that the preprocessing techniques go in as part of the trees at the base.

- https://software.intel.com/en-us/articles/hands-on-ai-part-14-image-data-preprocessing-and-augmentation:
* Rescaling: rescales the image data values from the range of 0 - 255 to 0 - 1 by a constant factor
* Grayscaling: self explanatory
* Samplewise Centering: Normalizes the data so that the mean is zero
* Samplewise Std Normalization: normalizes so that the std deviation is 1
* Featurewise Centering and Featurewise Std Normalization: other normalization techniques
* Rotation: Self explanatory
* Horizontal Shift
* Vertical Shift
* Shearing
* Zoom
* Horizontal Flip
* Vertical Flip

== 9/30/2019 ==
- Met in class today. We think we finally figured out why the preprocessing code isn't working as intended. The "needs_preprocessing" parameter in the data_splitter.py file is by default set to "false". Anika worked on changing the defaults so that for our purposes the code would automatically run how we expect it to.

-We discussed our Mid-semester goals:
# Test the code for feature data preprocessing and produce individuals and compare them to individuals that train on data that has been preprocessed manually
# Implement primitives for image data preprocessing and ideally get it working so that we can do the same evaluation for individuals evaluating image data
- We heard that EMADE already has some image processing capabilities so Oscar will look into what we can use for our purposes for reusing or as a starting point.
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Do Peer Evals
|Resolved
|9/30
|10/4
|10/3
|-
|Update notebook for midsemester notebook check
|Resolved
|9/30
|10/4
|9/30, 10/1, 10/4
|-
|Look into implementing the image preprocessing images
|Resolved
|9/30
|10/7
|10/7
|}

== 10/7/2019 ==
- Anika and I met today today during class to decide where we are going to direct our efforts during the next two weeks (including fall break).

- The following tasks encompass my part of our agenda leading up to the mid-semester presentations.
{| class="wikitable"
!Task
!Current Status
!Date assigned
!Suspense Date
!Date resolved
|-
|Run APE with same Titanic dataset
|Resolved
|10/07
|10/21
|10/20
|-
|Manually Preprocesses Image data
|Resolved
|10/07
|10/21
|10/18
|-
|Start implementing primitives for image data
|Ongoing
|10/07
|10/21
|N/A
|}

== 10/19/2019 ==
- Met during the VIP Hackathon. We spent five hours working on running our comparative experiment on APE versus Manually Preprocessed data EMADE runs and looking into how EMADE processes image data. 

- We encountered a lot of trouble with running the detection processing branch of EMADE. After both of us cloning the branch and trying to run it, we settled on me running the automatic preprocessing branch trials and Anika running the detection processing branch for the control trials

- We didn't get the chance to talk to Austin in person for him to explain how image data is processed in EMADE

- My goal before the mid-semester presentations on Monday is to finish running the APE trials and to put together the presentation for Monday

'''Tasks:'''
{| class="wikitable"
!Task
!Current Status
!Date Assigned
!Suspense Date
!Date Resolved
|-
|Finish running APE trials
|Resolved
|10/19
|10/21
|10/21
|-
|Put together presentation
|Resolved
|10/19
|10/21
|10/21
|}

== 10/21/2019 ==
- Today was the marathon presentation session for the VIP. I worked on the presentation yesterday and today. Anika continued trying to get the detection processing branch to work but couldn't get it to produce valid individuals by the time we were putting together the presentation, so we weren't able to compare the individuals we got and the AUC graphs.
{| class="wikitable"
!Task
!Status
!Date Assigned
!SuspenseDate
!Date
Resolved
|-
|Take a break (after spending the entire weekend with EMADE)
|Resolved
|10/21
|10/28
|10/28
|-
|Put together our pitch for the new semester students
and plan for a bigger team.
|Resolved
|10/21
|10/28
|10/28
|}

== 10/28/2019 ==
- We met today during class and briefly pitched our team to the first semester students.

- We ended up adding two new members to the team: Ford and Marc. We introduced them to the team and went through what we have worked on so far and what we will be working on throughout the rest of this semester. The process for assigning first semester students was much quicker than last semester, though it was much more chaotic and still took a bit, so we did not have time to discuss much else.
{| class="wikitable"
!Task
!Status
!Date Assigned
!SuspenseDate
!Date
Resolved
|-
|Get the first semester additions to clone our branch
|Resolved
|10/28
|11/04
|11/01
|-
|Integrate them into our plan for the rest of the semester
|Resolved
|10/28
|11/04
|11/01
|-
|Update team wiki for past two weeks
|Resolved
|10/28
|11/04
|11/04
|}

== 11/01/2019 ==
- The team met from 4:30 to 5:30 during help desk hours. Ford and Marc successfully cloned the automatic preprocessing branch. We explained to them the different types of data (feature, image, stream, etc.) and then we collectively decided to pursue implementing image data processing primitives for now.

== 11/04/2019 ==
[[files/11-04 Whiteboard picture.jpg|thumb|257x257px|Picture of the whiteboard when I was discussing the numpy.savez function with Austin Dunn.]]
- Half of our team was out sick today. Marc and I delivered the scrum together and then we talked with Austin for the rest of the class about how EMADE loads image data, since he wrote a lot of the code for that over the summer. We specifically went through the "load_image_csv_from_file" and "load_images_from_file" functions defined in 'data.py'. 

- Austin then recommended different ways to save the images before giving them to emade such as np.savez() from numpy which he recommended because it does not require the images to all be of the same shape. At the end of class I also went back to confirm with Austin that it was the 'type' parameter within the 'datasets' tag in the input xml file that changed which loading function was used for the data and I located where that happened in the 'EMADE.py' file under the 'buildClassifier' function.
{| class="wikitable"
!Task
!Status
!Date Assigned
!SuspenseDate
!Date
Resolved
|-
|Talk with Austin to figure out how EMADE handles image data
|Resolved
|11/04
|11/11
|11/04
|-
|Finish orienting first semesters to our team
|Resolved
|11/04
|11/11
|11/08
|-
|Prepare and deliver scrum
|Resolved
|11/04
|11/04
|11/04
|-
|Look at the methods EMADE already has for image data
|Resolved
|11/04
|11/11
|11/08
|}

== 11/08/2019 ==
- We met today during help-desk hours, though Anika was still sick. I decided to run through EMADE's code as well as our subteam's code with Marc and Ford so that they would have a general understanding of how EMADE works, which I think is very helpful and which took me a long time to figure out. We mainly went through the "launchEMADE_prep.py', 'data_splitter.py', 'data.py', and 'EMADE.py' files.

- I then taught them the process of writing and adding primitives and showed them the ones we've added in our code as well as their UnitTests. With this we ended up looking through the 'preprocessing_methods.py', <nowiki>''</nowiki>preprocessing_methods_unit_test.py', and 'gp_framework_helper.py' files.

- Finally, together we looked through the spatial_methods.py file to see the methods that EMADE already has for image data primitives. Before we left we discussed what the first semesters could work on for the rest of the semester, such as adding new functions to the spatial_methods.py file

== 11/11/2019 ==
- I met with the rest of the team today during class. We caught Anika up on what she missed last week and we started work on a primitive using keras that would rotate, shift, and shear, the images and the expand the dataset with the augmented images.

- While Anika and Marc were looking into the keras documentation I decided to look through EMADE's code to see how we might get the truth values from the data_pair objects so that we expand the dataset with the correct target labels.

- I will not be able to meet with the subteam this friday since I have a conflict during our usual meeting time.
{| class="wikitable"
!Task
!Status
!Date Assigned
!SuspenseDate
!Date
Resolved
|-
|Look into how to properly expand the dataset with a primitive
|Resolved
|11/11
|11/18
|11/11
|-
|Plan for the last few weeks of the semester
|Resolved
|11/11
|1/18
|11/18
|}

== 11/18/2019 ==
- The team met on Friday but like I mentioned in the previous entry I was unable to attend. They came today with a keras primitive written, but they had been unable to test it. They slacked me the code and I added the method and it's unit test to the appropriate files but I too ran into errors. I think there were some dependencies for EMADE that were missing from my computer for some reason.

- We then talked to Austin about different ways that we could get the appropriate target values for the data when trying to add the augmented images to our dataset using a primitive. He used the word "hackney" a lot to describe the different options, one of which involved writing a custom evaluation function. I won't lie, I didn't completely follow what he was saying, so I also spent some time reinstalling the dependencies I was missing so that I could test the primitive by the time we meet on Friday.
{| class="wikitable"
!Task
!Status
!Date Assigned
!SuspenseDate
!Date
Resolved
|-
|Talk with Austin about preserving the correct truth values for the augmented dataset
|Resolved
|11/18
|11/25
|11/18
|-
|Fix the errors with the dependencies
|Resolved
|11/18
|11/22
|11/22
|-
|Delegate tasks for the hackathon and rest of the semester
|Resolved
|11/18
|11/23
|11/22
|-
|Go to the VIP Hackathon
|Resolved
|11/18
|11/23
|11/23
|-
|Get the Detection Processing branch trials running for the experiment
|Resolved
|11/18
|11/25
|11/23
|-
|Get Marc running EMADE on his computer
|Resolved
|11/18
|11/25
|11/23
|-
|Look at the PACE ICE documentation
|Resolved
|11/23
|11/25
|11/25
|}

== 11/22/2019 ==
- The team met today during help desk hours for about an hour to plan out the last two week of the semester and to delegate tasks to be done during the hackathon and thanksgiving break. I was still confused about several aspects of expanding the dataset with a primitive so I talked to Jason about it and he recommended that we do it as a preprocessing step before running EMADE.

- We decided that we were going to re-do the experiment we tried for the mid-semester presentation since both Anika and I couldn't get EMADE running correctly on either the Automatic Preprocessing and the Detection Processing branch. This time we decided to switch roles and that I would be running the trials for the manually preprocessed titanic data with Marc and Anika would be running the trials on the Automatic Preprocessing branch with Ford. We set the goal for us all to have EMADE working correctly by the end of the hackathon.

- The other tasks we delegated were regarding writing the code for our branch to handle image data. I have the task of editing the 'data_splitter.py' file so that it will also take in the path of a directory of images and a labels.csv file with the first column named "id" containing the names of the image files and the second column named "label" containing the corresponding target value for the image. Anika is tasked with writing the keras primtives for shifting, shearing, and rotating as well as their unit tests. Ford is going to get some recommended image datasets from Austin and Marc is going to write the script that randomly expands the dataset by performing random transformations to augment the images.

== 11/23/2019 ==
- I was at the Hackathon today from 2:30 to 6:00 pm and got a lot of work done. I first deleted my old clone of the detection processing branch that didn't work and recloned the current version, this took a bit of time. While it was cloning I started writing the script that would properly format the directory of images and a labels csv for EMADE and did my best to help Anika fix the errors she was getting when setting up our branch to run EMADE.

- Once the branch was done cloning I still ran into some errors. The first few were rather easy to fix, such as installing dependencies. I then got EMADE to run correctly for the first two generations until it reached a fatal error. I asked James Rick about it and he performed a quick fix that I don't remember. I tried running EMADE again but got a different fatal error after a few generations. Turns out that it was that error discovered earlier in the semester, and I ended up commenting out two lines of code in 'emo.py' inside of one of scikitlearn's selection functions. 

- After that was fixed I finally got EMADE fully working and I decided to go talk to Jason about setting up my run of EMADE to use the computing clusters he mentioned in class. He said that they were currently not working but recommended that I try using PACE ICE, one of Georgia Tech's computing resources, and he sent me the relevant documentation. 

- The last thing that I did was help Marc run the same manually preprocessed trials of EMADE on his computer. He encountered many of the same issues that I had throughout the hackathon but I was able to walk him through them. I also made more progress with writing the dataset loading script. Overall, this Hackathon was definitely more successful than the last one for me.

== 11/25/2019 ==
[[files/SQL Query.png|thumb|This is the sql query I mentioned. One can see the error I described as well as some individuals from generation 303.]]
- Last class before the final presentations. I left EMADE running non-stop since the hackathon but after 300 generations I still wasn't getting any false positives or false negatives, so there is definitely something wrong. As a team we discussed our progress since Friday and confirmed that everyone new what they needed to get done over the break since we wouldn't see each other until next Monday when we had to give our final presentation.

- I talked to Jason about the issue of having no valid individuals and he showed me some sql queries to look look for basic individuals that started with a learner method. The query was "select * from titanic_test.individuals where tree like 'Learner(ARG0,<nowiki>''</nowiki>. He saw that these tree's were producing errors when they shouldn't and sent Austin to go fix the error. This means that I'll have to wait until the fixes are pushed in order to continue running trials, which hopefully won't be too long.
{| class="wikitable"
!Task
!Status
!Date Assigned
!SuspenseDate
!Date
Resolved
|-
|Write the script for loading image datasets
|Resolved
|11/22
|12/1
|11/30
|-
|Test the script with the cancer detection dataset
|Resolved
|11/25
|12/1
|12/1
|-
|Finish running the titanic trials on the detection processing branch
|Resolved
|11/25
|12/2
|12/1
|-
|Put together the final presentation
|Resolved
|11/25
|12/2
|12/2
|}
[[files/Dataloader script.png|thumb|The dataset loader script]]

== 12/1/2019 ==
- Yesterday I finally finished writing the script to take in an image dataset and write it to a csv file for it to be loaded as EMADE data_pairs using the "load_image_csv_from_file" function I mentioned in an earlier entry. I don't know how to link to code so I will just include a screenshot of the script instead. It took me a bit of time to figure everything out but I took some inspiration from Austin's code in the "load_images_from_file" function. I added the print statements since the process of writing images to a csv took quite a bit of time and it helped me know how far along I was.

- When I tried to run the script on the cancer_detection image dataset I had gotten from kaggle, it took a very, very long time. I eventually managed to write it all to a csv, but the file is so big that it keeps crashing all of my text editors, I guess that I should have seen that coming. Because of this I wasn't able to run EMADE with the image data.

- Regarding the EMADE trials I am currently running though, I am going to let the last one run overnight tonight and it will be done tomorrow morning. Austin pushed the fixes on Tuesday and I've run 4 trials since then. The team is planning on meeting tomorrow at 12:00 to go over the final presentation.

== 12/2/2019 ==
[[files/Paretofrontcode.png|thumb|code I wrote for getting the pareto front]]
- I met up with the team in the culc from 12:00 to 2:00 to finalize the final presentation. We realized that none of us had the code to get the pareto front from our trials so Anika, Marc, and I worked together to write a script that would get us the plots using pymysql and matplotlib. I'll also include a screenshot of that code too.

- We were the first to present, which was good to relieve the anticipation early on. Here is our final presentation: https://gtvault-my.sharepoint.com/:p:/g/personal/aislam43_gatech_edu/EfmFjGoUxphKqxWjFTBFg1IB8-x09vfWbBD7a-AMHOONlg?email=oaguilar3%40gatech.edu&e=hL9Qcn
{| class="wikitable"
!Task
!Status
!Date Assigned
!SuspenseDate
!Date
Resolved
|-
|Put trial results into the final presentation
|Resolved
|11/25
|12/2
|12/2
|-
|Deliver the Final presentation
|Resolved
|12/2
|12/2
|12/2
|-
|Finalize the VIP Notebook
|Resolved
|12/2
|12/4
|12/4
|-
|Do the peer evals
|Resolved
|12/2
|12/4
|12/2
|-
|Update Team Wiki
|Resolved
|12/2
|12/4
|12/4
|}
- I had a busy second semester but I really did learn a lot. I sadly won't be back next semester since I am studying abroad with the help of Jason's recommendation letter, but I hope to be back in the future. I started this VIP knowing zero python or computer science in general and now I have a fairly good understanding of EMADE. I am glad to have been able to explore this branch of machine learning and gain so much exposure in computer science, even if I am an IE major. Signing off for the semester,

Oscar Aguilar

== '''Semester 1''' ==

== 1/11/2019 ==
- I need to figure out how to format my notebook.

- Met with Dr. Zutty to figure out if I should stay in the class despite my lack of experience with Python and computer science in general. (I chose to stay and brace myself for the grind of catching up)
== 1/13/2019 ==
- Set up DEAP and jupyter notebook and Anaconda on my laptop computer in order to set up the lab (with the help of a classmate).

== 1/14/2019 ==
- went through lab 1 and did my best to understand the way that the genetic algorithm works using DEAP. My biggest challenge was to understand the code itself but I had external help.
[[files/In class notes.jpg|thumb|200x200px|Notes from class on genetic programming]]
- Attended week 2 meeting and absorbed as much as I could from the current team's scrum presentations

== 1/28/2019 ==
[[files/Progress.png|thumb|The portion of my python course that I've gotten through by the end of week 3. As can be seen, I am through about 3/5 of the total course material]]
- I have spent the past two weeks learning as much python as I can. I am currently a month ahead in my online python class (CS 1301) and went through codeacademy's tutorial for python. I still lack some of the general CS knowledge required to finish the labs such as working with lists and matrices and complex functions and especially the DEAP toolbox. I did go back through lab 1 and was able to get through 75%, but I couldn't get very far into lab 2. I will try using google to search for the things (syntax and functions) that I don't understand in the labs while I continue blazing through my python course. I will definitely keep referring back to the labs after each unit to see what new things I can understand. 

- As for my notebook I definitely need to start keeping better records of the effort I have put in so far into catching up and trying to understand the labs.

- My goal for the next week is to get through all of Unit 4 in my python class (5 weeks in the course schedule) and then re-try the 2 labs, going to the help desk on Friday if needed. I may also ask my floor mate in this class Alex Gurung for guidance on the weekend if I am still behind.

- Time to absorb as much as I can from this week's lecture.

== 2/4/2019 ==
- As planned I got through another five weeks worth of my python course this past week. I now feel comfortable using python to work with lists, strings, dictionaries, and to a lesser extent, files. I expect that lists will be most useful in this class. I also went back once again and revisited Lab 1 and Lab 2 with this new knowledge. I started running the programs in the labs to see how much I understand in terms of how they work and how it translates into the different generations displayed. I also spent quite a bit of time going through some of DEAP's useful guides on how its tools work. This is something that has confused me for quite a bit of time, but I'm glad I found these guides that explains how the functions included in DEAP's toolbox work and how to use them.

- In terms of where I am at right now, through the combination of DEAP's guides, my python course, and my floormate Alex, I feel confident enough to start making changes to the code in Labs 1 and 2 to see if I can get better results. I definitely understand conceptually how the evolutionary programs that I've seen work. However, I now need to start practicing how to modify the programs on my own if I am ever going to be able to write my own evolutionary programs using DEAP/EMADE. This obviously requires that I continue my frantic learning of computer science (especially python).
[[files/In-class notes on multi-objective genetic programming.jpg|thumb|In-class notes on multi-objective genetic programming]]
- I have a few goals for this next week. I want to get through the last of the material for my online python course (Unit 5) which introduces/covers object oriented programming and algorithms. This will most definitely be directly applicable to this class and is probably crucial to me being able to be finally "caught up" with where I should've been at the start of this semester. I will definitely be relieved once I've done it considering that I've been spending upwards of 20 hours a week on just learning python, in addition to looking through the labs and learning how DEAP works. A second goal is, as previously mentioned, for me to actually start modifying the programs of Labs 1 and 2 to see if I can get better results. For this I might have to come to the help desk on Friday or at least ask my floormate for guidance. Hopefully I'll have screenshots of this to add to my journal. Finally, I want to start working with my newly formed group and do my best not to be a burden.

== 2/11/2019 ==
-This week turned out to be much busier than I expected. Instead of focusing on finishing the last unit of my python course and looking back at the labs, I directed the time that I did have towards the group project to be done this past week. The group submission for the Titanic Data set can be found on the class wiki here: [[Bootcamp Sub-team Spring 2019]] (my group is Group 2). The classifier that I used to construct my model was the Decision Tree Classifier. To be honest, understanding what I needed to do was by far the hardest part of this project. I started by looking at the example that was posted on Slack and spent a good few hours just trying to understand the code itself and how the data was being processed and used to train and evaluate different models. Once I decided on using the Decision Tree Classifier I Googled the parameters of the classifier and spent another hour messing around with the parameters to figure out how the function works and what parameters optimized it's accuracy score for the data we were working with. Submitting it to Kaggle was fairly simple after making an account.

- Because I did not get to spend time working on learning more of python and computer science through my online course and the past labs, my goals for those two things from last week are now the goals for this upcoming week. I did however reference the past labs while trying to figure out the assignment for this week. 
{| class="wikitable"
!<blockquote>Goals/Task:</blockquote>
!Finish last two sections of Online Python Class
!Go back through the Labs
!The Titanic Data Set Group Project
|-
|Date Set:
|1/07
|2/4
|2/4
|-
|Hopeful Due Date:
|2/18
|2/18
|2/11
|-
|Date Finished:
|2/18, 2/23
|2/17
|2/11, 2/17
|}

== 2/18/2019 ==
-Yesterday I worked with my team to tackle the titanic data set problem using genetic programming and DEAP. My team opted to use DEAP's strongly typed GP to write the program, so I ended up spending a lot of time reading through DEAP's guides in order to follow along as well as mess with the program to see how different primitive sets, evaluation functions, and mutation and selection tools affected the program's performance. My individual contribution to this group assignment was rather limited however since I really spent most of my time simply tying to understand how certain parts of the program worked. Thankfully though, we reused a lot of the code from lab two and really only changed the evaluation function so that it gave a fitness score of the individual tree's false positive rate and false negative rate with the objective to minimize those two measures. Because of this, I was able to knock out looking back through lab 2 while doing this week's group project.

-Another thing I did this past week was to finish the second to last section of my python course on object oriented programming, leaving the very last part on algorithms for this next week. This way I will have gone through the entirety of the course material by the time I turn in this journal next Monday. I'll be sure to include a screenshot of the progress page once I've finished it.

-During the group scrums I've been paying extra attention to the stock market sub-team, since it is the one I'd be most interested in joining after spring break at the moment. The stock market was one of my favorite hobbies in high school and it is also the smallest/newest team so hopefully they won't have AS much to explain to me if I join. At the moment the team seems to be getting ready to start evolving their program though not quite yet. Today in class I am going to go ahead and install EMADE.

-This upcoming week I will be filling out the peer-evaluations for my teammates and floormate in this class. As mentioned I will also be finally wrapping up the last of my python course and will continue looking through the past labs/projects to continue understanding the missing parts. I will also of course be working with my team on whatever group project we have for the week. I hope that my teammates aren't tired of my constant questions yet.

== 2/25/19 ==
[[files/Completed python course.png|thumb|This is the progress page for my python course. As can be seen, I have worked through the entire semester's worth of material over the course of seven weeks. All is left are the tests which I do not yet have access to. ]]
- This past week I took advantage of the fact that we were not given an assignment to finish up my python course. I am now familiar with how objects and classes work (which would have been pretty handy when doing the labs) as well as the basic idea of algorithms (which is in the title of this VIP). So yeah, I am now somewhat caught up with the rather fundamental parts of this class. From now until spring break, I can finally finish "catching up" with the class and going back through the labs and hopefully being able to understand a great majority of what is presented. This way I will be able to join a sub-team as more of an asset than a burden. 

- On Friday I also filled out the VIP peer evaluations for my boot-camp teammates and my floormate. They have all been helpful in answering my questions so I did not have much negative feedback to give. Finally, I finished installing and setting up EMADE on my laptop with the help of my floormate. It took a bit longer than I expected since there was a lot of stuff that I had to download including Visual Studio Installer because apparentl3y some part of EMADE relies on C++. 
{| class="wikitable"
!<blockquote>Goals/Task:</blockquote>
!Finish Python Course
!Install EMADE
!Peer Evaluations
|-
|Date Set:
|1/07
|2/18
|2/18
|-
|Date Finished:
|2/23
|2/24
|2/22
|}

== 3/1/19 ==
- Bootcamp sub-team meeting from 4:00 - 5:00 PM. Notes: Caught up the group members who didn't make it to this week's class on the assignment and how we were meant to run EMADE together using MySQL. Zach had trouble installing packages today and I spent most of the time figuring out what steps I needed to take to run the program and connect to the host (William's) server. All the while William and Eric worked together to set up the server on William's computer. We did not attempt to run EMADE today since we ran out of time but did establish what each individual had to do for tomorrow at noon when we are going to try and run the server as well as connect to it. My job is to make sure I know how to connect (I already have everything installed) as well as to download PyCharm to have an easier time editing the in input file and opening the err and out files.

== 3/2/19 ==
- Bootcamp sub-team meeting from 12:00 - 2:00. Notes: we met again today to actually try and run EMADE on our computers. When I tried to run the main command "python src/GPFramework/launchGTMOEP.py templates/input_titanic.xml -w" after editing the template file with the appropriate IP address, username and password, I kept getting a NameError saying that "'subprocess' is not defined." William tried several things to try to fix this but we ran out of time so I am instead going to seek my floormate's help solving it. He is out of town but will be back Monday so I will talk to him about it then. While I did this, WIlliam and Eric worked together to get the server running and getting Eric and Zach to connect to it. William's server crashed a few times but that  it to work and Zach got connected after some trouble installing the packages using conda. 
{| class="wikitable"
!<blockquote>Goals/Task:</blockquote>
!Meet with Team to run EMADE
!Install and set up PyCharm
!Resolve any errors when trying to connect
|-
|Date Set:
|2/25
|3/1
|3/2
|-
|Date Finished:
|3/1, 3/2
|3/2
|3/4
|}

== 3/4/19 ==
- Used class time to meet with sub-team again. Notes: William took care of an error that prevented EMADE from running past the first generation. I am currently trying to resolve the error related to subprocess using what James Rick posted on Slack and with the help of William and Zach. We got an authentication error when trying to pull the "Dev Branch" from git so I am as of now just waiting for the dev branch to clone. Once it's done I should have no problem running EMADE and connecting to William's server.

== 3/11/19 ==
- This week was very busy. I did manage to iron out everything that I needed to in order to connect to my team's EMADE server last Monday and Tuesday. Since then, I have connected with "5 workers per host" several times. William ran the host server every weekday night and the rest of us were able to leave our computers connected and running throughout the night. We had to set the "REUSE" parameter to "1" so that we would not lose our progress each time we started/connected. Even so, Zach and I did have a couple of hiccups throughout the week. At one point I accidentally removed the "Datasets" folder from my EMADE directory without realizing it and so William had to help me troubleshoot the resulting errors. Zach had trouble connecting at night since he lived off of campus so he had to set up a VPN to connect. In the end though, we managed to run through 49 generations with EMADE by today (the presentation). 

- After running EMADE throughout the week, we shifted on the weekend to creating our presentation for the marathon. I was tasked with talking about our approach to the titanic data set using genetic programming. So we each made our respective slides and practiced on our own.
{| class="wikitable"
!<blockquote>Goals/Task:</blockquote>
!Connect to server to run EMADE as worker
!Work on presentation
!Resolve any errors when trying to connect
|-
|Date Set:
|3/4
|3/4
|3/4
|-
|Date Finished:
|3/6, 3/7
|3/10, 3/11
|3/4, 3/5
|}

== 3/25/19 ==
- First class back from spring break. I managed to get assigned to my top pick of the stock market sub-team, which I am very much happy about since being able to work with stocks was a big part of why I joined this VIP.

- Notes from my first in class meeting with my new team: The other first semester students include two other IE's and Zach from my titanic project group! Meetings are typically on Fridays. The team from last semester did not really leave any documentation for us to read and use to catch up. This semester, the team is using linear regression models using EMADE to make predictions. The current team has not yet run EMADE and are still working on primitives. When I asked about what I could work on I was told to read up on Markov decision models as well as signal prediction because those are the next primitives that they want to implement. I am not too sure if I will be much use in writing the code for the primitives with my limited experience but I definitely plan on reviewing the code we've written so far to learn as much as I can. The meeting this week is set for Thursday.

== 3/28/19 ==
- Met with three other team members at the CULC from 7:30 - 9:00 to continue to get caught up. James Rick also came by and was very helpful in answering questions. Here are some notes from the meeting: James ran us through the code for EMADE to help us understand how it works a bit better. We first went through the launchGTMOEP.py file to see how it is initialized, and then we covered the 1771-line GTMOEP.py file and ran through how everything worked with the master and worker processes.  I think that I now understand from a high level how EMADE works though most of the technical features are still a mystery to me. We also discussed different ways we could make predictions, such as change in price versus actual price. 

== 4/1/19 ==
- We split into two sub-teams to accomplish two tasks: data pre-processing and implementing primitives. I was assigned to the pre-processing team since it would be easier for me to pick up. The goal of the preprocessing is to take in a csv file with stock data in the format of "Date, Open, High, Low, Close, and Volume" on each row, and make it into an xml file with the heading #N=5 and each row in the format of "Open at day 0, High at day 0, Low(0), Close(0), Volume(0), Open(1), High(1), Low(1), Close(1), Volume(1), Open(2), … , Open(n), High(n), Low(n), Close(n), Volume(n), target value" where 4/5/19" the number of previous days we want to use in our prediction, and the target value is the market Close of the day we are trying to predict such as 10 days after The meeting is set for Friday at 4:30.
{| class="wikitable"
!Goals/Task:
!Read through the sample data set and James' Sample Preprocessing code
!Learn Numpy
!Figure out what I need to change in the sample code
|-
|Date Set:
|4/1
|4/5
|4/1
|-
|Date Finished:
|4/5
|4/5
|4/5
|}

== 4/5/19 ==
- Met with the entire team at the CULC from 4:30 to 7:00. I looked at the sample data set for the GE stock as well as James Rick's sample code that he wrote for preprocessing the data. I had trouble understanding what a lot of it did since he mainly used numpy to interact with the files and create folds. I decided then to look up how numpy works and stumbled upon this tutorial: http://cs231n.github.io/python-numpy-tutorial/#python. I've read through most of it, but it didn't really cover the numpy methods that James used so I will have to look those up individually. Apparently the people working on preprocessing just need to make changes that make it easier to control how many previous days EMADE uses for the prediction as well as the target day and number of folds. I was able to easily follow the changes that Sarthak made to the code by creating a local variable. I still need to figure out how to make changes to the GitHub stocks branch but I will be asking Alex (my floormate) a bunch of those questions on Sunday when I see him. I also learned how to pull the branch in order to update the changes made to it. Before the next meeting on Monday I want to continue learning numpy since I expect to see much more of it in this class as well as meet with my floormate to ask a lot of the technical questions I have about the work I need to do.

== 4/8/19 ==
-Yesterday I met with my floormate Alex to ask about a few of the things that I didn't know such as how to work on a shared repository using GitHub. He briefly went over the Git workflow with "pull", "add", "commit" and "push". I also remembered what Dr. Zutty told me at the beginning of the year about what I could do to catch up with what I need to know. He recommended visiting code academy, so I re-visited the website and started their introduction to data science course, which covers SQL, python, a bunch of python's libraries including pandas, numpy, and matplotlib, and also gives an introduction to machine learning. This seems like it will be very useful so I will continue working on this course throughout the week.

- In class meeting with team. Went over our progress and what is next in the scrum. As part of preprocessing we want to add a few more things to make it easier to change the number of and spacing between the folds. The meeting is set for this Saturday at 4:00 PM.
{| class="wikitable"
!Goals/Task:
!Read through articles in Slack
!Look up more stuff about using Git
!Figure out what I need to work on in the preprocessing code
|-
|Date Set:
|4/8
|4/5
|4/8
|-
|Date Finished:
|4/21
|4/7
|4/13
|}

== 4/13/19 ==
-Met at the CULC from 4:00-6:00 with most of the team. I was the only person on the pre-processing team who made it to the meeting, so I wasn't able to ask specific questions about the program. I did however ask Zach about how to use pycharm and he showed me how to run the program we are writing through the command bar using the python command. Once he'd shown me this, I was finally able to work on my own and I started running the program (adding many print statements) to figure out exactly how it works. While running it though I found a good amount of errors, so I set to work debugging the program. For example, I found that when trying to slice the dataset, the variables were either floats or numpy's int64 data type and were therefore resulting in a type error so I fixed that. Another problem that confused me was the logic behind creating the folds, because it seemed the training and test data were slicing from the same subsets of data. I will wait until next meeting to check with Tan before pushing my changes and then I'll link the code into here.

== 4/15/19 ==
-Last in-class meeting before our final presentation. It turns out that the code I was debugging was Sarthak's and not Tan's, so I told him about the changes I made and he pushed them himself. I don't know how to link to code but it is in the file preprocessing_stock_new.py in the testcode folder of the stock branch. I also asked the questions I had about the logic behind creating the folds. He told me that Jiseok had told him that the folds should over-lap, which confused me especially since most of the testing data folds were also part of the training data folds. There were still parts of the code that didn't work as intended so I might try to work through it this week if Sarthak doesn't, but I was also told that the team testing the regression models with EMADE were just going to use the preprocessed data from last semester. If that is the case then I will use the remaining days to work on the presentation, including reading through the articles cited. 

-As for the codeacademy course, I got through the first section on working with SQL and learned some of the fundamental ways I can manipulate databases. However, the rest of the course was locked behind a paid subscription, and upon further inspection, so are all of the relevant courses on the website. But even if I won't be continuing learning with codeacademy for the time being, I now at least understand why we need to run EMADE through MySQL and how it works at a very high level. Our last team meeting of the semester is set for this Sunday at 6:00 PM.

== 4/21/19 ==
-I trekked from west campus to U-House (past Tech Square) to meet with the team one last time from 6:00 to 9:00 PM in order to prepare for our final presentation tomorrow. Unfortunately, only four out of the eight other team members came to the meeting. I quickly found out that the four who were there (Zach, Sean, Yoonwoo, and Jiseok) had also worked for a quite a bit of time last night/ this morning on implementing a few more regression models. I could really ask for too many specifics but from what they told me, Zach had quite a bit of trouble getting a model called RBF to work, even with the help of the others. They said that they were currently running the models with EMADE, but that we would only get our results a few hours before our presentation. They also had me redeem my cloud computing credits to help the process.

-Before the meeting I had taken the time to read the main article our team was working off of on "Results From Comparing Classical and Machine Learning Methods for Time Series Forecasting":

https://machinelearningmastery.com/findings-comparing-classical-and-machine-learning-methods-for-time-series-forecasting/

The article is an overview of various studies done evaluating the effectiveness of statistical and machine learning models, and a comparison of the results. The article did not delve in too deep into the differences between each type of model it looked at, instead simply listing them, but I did recognize a few of the models that the team had implemented over the course of the semester such as Multi-Layer Perceptron (MLP), Long Short-Term Memory (LTSM), and the dreaded Radial Basis Functions (RBF), and I payed extra attention to their results demonstrated in the article. I tried following the links the article provided to a few of the studies, but after reading a few abstracts I realized that I didn't have the time to dive into that rabbit hole. Overall, the article concluded that the classical statistical methods were outperforming the machine learning methods, but also noted that "the study does not look at more complex time series problems." It could not hypothesize why the ML methods were performing so poorly though. 

Before reading the article I wasn't even aware of what a time-series forecasting problem even is besides predicting the stock market. Now though, I understand the reasoning behind the team's approach of implementing these different models as primitives for EMADE to use.

-As for the meeting itself, the present members created a google slides and we each worked individually on creating new slides. I did both of the data parsing slides, adding screenshots from the code we wrote, since this was the area I had worked on. I also made additions to a few other slides near the beginning. At the end of the meeting we assigned people to the slides and debated what to do with the people who didn't show up. I will be introducing the team and covering the project description and maybe parts of the data parsing slides. The rest of the guys there still have a few things to do such as add the results when we get them, but I confirmed that there was nothing left for me to do before tomorrow besides learning my lines.

-Here's the presentation: https://docs.google.com/presentation/d/10xf9KcT4J-MECnhHFCqxyt9AXUIUhVRzZtdGDKRxJh4/edit#slide=id.g582d6f2568_1_6
{| class="wikitable"
!Goals/Task:
!Redeem Cloud credit
!Work on presentation
!Prepare for Presentation
|-
|Date Set:
|4/21
|4/21
|4/21
|-
|Date Finished:
|4/21
|4/21
|4/22
|}

== 4/22/19 ==
-Last class of the semester. My team presented first. It turns out that the guys couldn't completely sort out EMADE so they individually tested the models they implemented as primitives and then compared the results, which lined up with what the article I summarized said. Though our ML models did not necessarily have enough time to maybe find the best solution. I ended up covering only the introduction and left the data parsing slides to Anika and Sarthak. Even though we were the first team to present, I did not follow the rest of my teammates and leave soon after (I think some of them had conflicts). I instead decided to stay and watch the other presentations, though I had to leave at 7:00 before the last one.

-I thought that the Caching sub-team's presentation was particularly interesting and well done. I definitely understood the general premise of the team's project and followed a good amount of what they covered, such as Alex's slides on dealing with deleting excess individuals with varying weights while optimizing for time. I also found the EEG presentation interesting, especially since I found out that it was another one of the time-series type of problems that I'd read about. I am not too sure how many people will be returning to our sub-team next semester, but I definitely want to continue, and if the team doesn't continue then I might try to join caching.

== Final Entry ==
Before this semester, the only experience I had with computer science was teaching myself how to write simple programs in my calculator using TI-Basic. I won't lie, I had no idea what was going on in the first meeting and was intimidated to the point that I was about to drop the class. I instead met with Dr. Zutty and decided to work on my own to catch up and ask ALOT of questions. Throughout the course of the semester, I learned everything from the fundamentals of computer science to python itself, from genetic programming to working with GitHub and EMADE, and most of all, I learned how to conduct group research in computer science.

The feedback that I got from the midterm evaluations was to include more notes from meetings and class. I made sure to record what I was told and what I learned at the meeting with my sub-team since spring break, and I also went back and inserted some of my handwritten notes from classes in the first half of the semester to address this concern. I was also advised to include more to-do lists with action items. While I did try to add them where I could, since most of my work was simply me learning about how things worked instead of writing code and solving specific issues, I had to combine the to-do lists to span over several entries. However, I did make an effort to document my thought process and include more entries than just one per week.

I really enjoyed learning about automated algorithm design and computer science in general during this semester and do not regret keeping the class despite the grind to catch up. I was one of the only members of my sub-team to attend all of the meetings we had since I joined in spring break, and while I may not have been the most productive worker in terms of contributing to the project, I hope that my effort and enthusiasm is reflected in my peer-evaluations for the second half of the semester. This is why, accounting for everything I went over in this final entry for the semester, I believe I should end with an A in this class. I am looking forward to continuing this VIP in the fall and thanks to all of the classmates that answered my endless questions, I am much more confident than I was at the beginning of the semester. I plan on using my free time this summer to learn more CS so I am even more ready. Thanks for the opportunity to learn and participate this semester.

- Oscar Aguilar